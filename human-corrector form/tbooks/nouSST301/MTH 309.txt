 NATIONAL OPEN UNIVERSITY OF NIGERIA SCHOOL OF SCIENCE AND TECHNOLOGY COURSE CODE: MTH 309 COURSE TITLE: OPTIMIZATION THEORY  MTH 309 OPTIMIZATION THEORY Prof. U.
A. Osisiogu August 28, 2012  CONTENTS I 7 1 Linear Programming 9 1.1 Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
9 1.2 Objectives .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
9 1.3 Main Contents .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
10 1.3.1 Formulation of LP Problems .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
10 1.3.2 General Form of LPP .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
10 1.3.3 Matrix Form of LP Problem .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
11 1.3.4 Sensitivity Analysis .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
16 1.3.5 Shadow Price .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
18 1.3.6 Economic Interpretation .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
19 1.4 Conclusion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
20 1.5 Summary .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
20 1.6 Tutor Marked Assignments (TMAs) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
21 II Methods of Solutions to Linear Programming Problems 26 2 Graphical and Algebraic Methods.
27 2.1 Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
27 2.2 Objectives .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
27 2.3 Main Content .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
27 1  CONTENTS CONTENTS 2.3.1 Graphical Method .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
27 2.3.2 Procedure For Solving LPP By Graphical Method .
.
.
.
.
.
.
.
.
.
.
.
27 2.3.3 Some More Cases .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
31 2.3.4 The Algebraic Method .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
35 2.3.5 Relationship between the Graphical and the Algebraic methods.
.
.
.
.
37 2.4 Conclusion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
39 2.5 Summary .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
39 2.6 Tutor Marked Assignments(TMAs) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
42 3 Simplex Algorithm (Algebraic and Tabular forms) 45 3.1 Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
45 3.2 Objectives .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
45 3.3 Simplex Algorithm .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
46 3.3.1 Algebraic Simplex Method .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
46 3.3.2 Simplex Method-Tabular Form .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
48 3.3.3 Pivoting .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
50 3.3.4 Applications .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
59 3.3.5 Minimization Problem .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
64 3.3.6 Applications .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
71 3.4 Conclusion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
73 3.5 Summary .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
73 3.6 Tutor Marked Assignments(TMAs) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
73 4 Artificial Variables Technique 81 4.1 Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
81 4.2 Objectives .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
81 4.3 Main Content .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
81 4.3.1 The Charne’s Big M Method .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
81 4.3.2 The Two-Phase Simplex Method .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
88 4.4 Conclusion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
91 4.5 Summary .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
91 4.6 Tutor Marked Assignments(TMAs) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
92 5 Simplex Algorithm- Initialization and Iteration 95 2  CONTENTS CONTENTS 5.1 Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
95 5.2 Objectives .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
95 5.3 Main Content .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
95 5.3.1 Initialization .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
95 5.3.2 Iteration-Degeneracy .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
98 5.3.3 Methods to Resolve Degeneracy .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
99 5.3.4 Termination .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
103 5.3.5 Alternate Optimum .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
103 5.3.6 Unboundedness (Or Unbounded Solution) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
106 5.3.7 Special examples .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
114 5.4 Conclusion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
117 5.5 Summary .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
117 5.6 Tutor Marked Assignemts (TMAs) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
118 III 122 6 Duality in Linear Programming 123 6.1 Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
123 6.2 Objective .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
123 6.3 Main Content .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
124 6.3.1 Formulation of Dual Problems .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
124 6.3.2 Definition of the Dual Problem .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
124 6.3.3 Important Results in Duality .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
129 6.3.4 Dual Simplex Method .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
132 6.3.5 SENSITIVITY ANALYSIS .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
139 6.4 Conclusion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
146 6.5 Summary .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
146 6.6 Tutor Marked Assignments(TMAs) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
146 IV 156 7 Transportation Problem 157 7.1 Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
157 3  CONTENTS CONTENTS 7.2 Objective .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
157 7.3 Transportation Problem .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
158 7.3.1 Mathematical Formulation (The Model) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
158 7.3.2 Definitions .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
159 7.3.3 Optimal Solution .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
160 7.3.4 North-West Corner Rule .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
160 7.3.5 Least Cost or Matrix Minima Method .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
162 7.3.6 Vogel’s Approximation Method (VAM) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
164 7.3.7 Optimality Test .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
169 7.3.8 MODI Method .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
169 7.4 Conclusion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
175 7.5 Summary .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
175 7.6 Tutor Marked Assignments .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
176 8 Integer Programming 179 8.1 Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
179 8.2 Objectives .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
179 8.3 Integer Programmining Model .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
180 8.3.1 Methods of Solving Integer Programming Problem .
.
.
.
.
.
.
.
.
.
.
180 8.3.2 Gomory’s Fractional Cut Algorithm or Cutting Plane Method for Pure (All) IPP .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
180 8.3.3 Mixed Integer Programming Problem .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
188 8.3.4 Branch And Bound Method .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
192 8.4 Conclusion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
201 8.5 Summary .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
201 8.6 Tutor Marked Assignments(TMAs) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
202 V 204 9 Basic Concepts of Rn 205 9.1 Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
205 9.2 Objectives .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
205 9.3 Functions .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
206 9.3.1 Continuous Functions .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
206 4  CONTENTS CONTENTS 9.3.2 Differentiable and Continuously Differentiable Functions .
.
.
.
.
.
.
.
207 9.3.3 Partial Derivatives and Differentiability .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
210 9.3.4 Directional Derivatives and Differentiability .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
212 9.3.5 Higher Order Derivatives .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
212 9.4 Quadratic Forms: Definite and Semidefinite Matrices .
.
.
.
.
.
.
.
.
.
.
.
.
.
214 9.4.1 Quadratic Forms and Definiteness .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
214 9.4.2 Identifying Definiteness and Semidefiniteness .
.
.
.
.
.
.
.
.
.
.
.
.
.
216 9.5 Some Important Results .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
218 9.5.1 Separation Theorems .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
219 9.5.2 The Intermediate and Mean Value Theorems .
.
.
.
.
.
.
.
.
.
.
.
.
.
220 9.5.3 The Inverse and Implicit Function Theorems .
.
.
.
.
.
.
.
.
.
.
.
.
.
224 9.6 Conclusion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
225 9.7 Summary .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
225 9.8 Tutor Marked Assignments .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
225 10 Optimization in Rn 229 10.1 Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
229 10.2 Objectives .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
229 10.3 Main Content .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
229 10.3.1 Optimization problems in Rn .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
229 10.3.2 Types of Optimization problem .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
232 10.3.3 The Objectives of Optimization Theory .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
233 10.4 Existence of Solutions: The Weierstrass Theorem .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
233 10.4.1 The Weierstrass Theorem .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
234 10.5 Conclusion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
238 10.6 Summary .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
239 10.7 Tutor Marked Assignments(TMAs) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
239 11 Unconstrained Optimization 241 11.1 Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
241 11.2 Objectives .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
241 11.3 Main Content .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
242 11.3.1 Gradients and Hessians .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
242 11.3.2 Local, Global and Strict Optima .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
243 5  CONTENTS CONTENTS 11.3.3 Optimality Conditions For Unconstrained Problems .
.
.
.
.
.
.
.
.
.
.
243 11.3.4 Coercive functions and Global Minimizers .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
250 11.4 Conve x Sets and Convex Functions .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
251 11.4.1 Convex Sets .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
251 11.4.2 Convex Functions .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
253 11.4.3 Convexity and Optimization .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
254 11.5 Conclusion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
260 11.6 Summary .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
260 11.7 Tutor Marked Assignments (TMAs) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
261 12 Constrained Optimization 264 12.1 Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
264 12.2 Objectives .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
264 12.3 Constrained Optimization Problem .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
264 12.4 Equality-Constraint .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
266 12.4.1 Lagrangian .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
268 12.4.2 General Formulation .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
270 12.5 Inequality Constraints .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
273 12.6 Conclusion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
273 12.7 Summary .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
274 12.8 Tutor Marked Assignments(TMAs) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
274 6  Module I 7  Linear Programming was first conceived by George B Dantzig around 1947.
Historically, the work of a Russian mathematician Kantorovich (1939) was published in 1959, yet Dantzig is still credited with starting linear programming.
Infact, Dantzig did not use the term Linear Programming, his first paper was titled “Programming in Linear Structure”.
Much later, the term “Linear programming” was coined by Koopmans in 1948.
The Simplex method which is the most popualar and powerful tool for solving linear pro- gramming, to be studied in full later in this course, was published by Dantzig in 1949.
In this course, you will learn various tools in operations research, such as linear program- ming, transportation and assignment problems and so on.
Before going into a detailed study, it is very important that you have a full understanding of what operations research is all about.
Operation Research, also called ’OR’ for short is “scientific approach to decision making, which seeks to determine how best to design and operate a system, under conditions requiring the allocation of scarce resources.” Operation research as a field provides a set of algorithms that acts as tools for effective prob- lem solving and decision making in chosen application areas.
OR has extensive applications in engineering, business and public systems and is also used extensively by manufacturing and service industries in decision making.
The history of OR as a field dates back to the second World war II when the British military asked scientists to analyze military problems.
In fact, second world war was perhaps the first time when people realised that resources where scarce and have to be used effectively and allocated efficiently.
The application of mathematics and scientific method to military applications was called “Operations Research” to begin with.
But today, it has a different definition, it is also called “Management Science”.
In general the term Management Science also includes Operations Research, in fact, this two terms are used interchangeably.
As such, OR is defined as a scien- tific approach to decision making that seeks conditions of allocating scarce resources.
In fact the most important thing in operations research is that resources are scarce and these scarce resources are to be used efficiently.
In this course, you are going to study the following topics Linear programming,(Formulations and Solutions), Duality and Sensitivity Analysis, Transportation Problem, Assignment Problem, Dynamic Programming and Deterministic Inventory Models.
8  UNIT 1 LINEAR PROGRAMMING 1.1 Introduction Linear programming deals with the optimization (maximization or minimization) of a function of variables known as the objective functions.
It is subject ot a set of linear equalities and/or inequalities known as constraints.
Linear programming is a mathematical technique which in- volves the allocation of limited resources in an optimal manner, on the basis of a given criterion of optimality.
In this unit, properties of Linear Programming Problems (LPP) are discussed.
The graph- ical method of solving LPP is applicable where two variables are involved.
The most widely used method for solving LPP problems consisting of any number of variables is called simplex method, developed by G. Dantzig in 1947 and made generally available in 1951.
1.2 Objectives At the end of this unit, you should be able to (i) Write a Linear programming model.
(ii) Define and use some certain terminologies which shall be useful to you in this course, Linear programming.
(iii) Formulate a linear programming problem, and (iv) Perfom a sensitivity analysis.
9  UNIT 1.
LINEAR PROGRAMMING 1.3 Main Contents 1.3.1 Formulation of LP Problems The procedure for mathematical formulation of a LPP consists of the following steps: Step 1 Write down the decision variables of the problem.
Step 2.
Formulate the objective function to be optimized (maximized or minimized) as a linear function of the decision variables.
Step 3.
Formulate the other conditions of the problem such as resource limitation.
market constraints, interrelations between variables etc., as linear inequalities or equations in terms of the decision variables.
Step 4.
Add the non-negative constraint from the considerations so that the negative values of the decision variables do not have any valid physical interpretation.
The objective function, the set of constraints and the non-negative restrictions together form a Linear Programming Problem (LPP).
1.3.2 General Form of LPP The general form of the LPP can be stated as follows: In order to find the values of n decision variables x , x , .
.
.
, x to minimize or maximize 1 2 n the objective function.
Z = c1x1 + c2x2 + · · · + cnxn (1.1) and also satisfy the constraints   a11x1 + a12x2 + · · · + a1nxn   b1    ≥  a21x1 + a22x2 + · · · + a2nxn   b2 .
= .
(1.2)   ai1x1 + ai2x2 + · · · + ainxn   bi   .
.
 ≤  .
  am1x1 + am2x2 + · · · + amnxn bm where the constraints may be in the form of inequality ≤ or ≥ or even in the form of an equation (=) and finally satisfy the non-negative restrictions x ≥ 0, x ≥ 0, .
.
.
, x ≥ 0 (1.3) 1 2 n 1  UNIT 1.
LINEAR PROGRAMMING 1.3.3 Matrix Form of LP Problem The LPP can be expressed in the matrix as follows: Maximize or Minimize z = cx (Objective Functions) Subject to: Ax (≤=≥) b (Constraints) (1.4) b > 0, x ≥ 0, (Nonnegative restrictions) where x = (x , x , .
.
.
, x ), c = (c , c , .
.
.
, c ), 1 2 n 1 2 n     b1 a11 a12 · · · a1n         b = b2  A =  a12 a22 · · · a2n         .
.
  .
  .
.
· · · ..  b a a · · · a n m1 m2 mn m×n Example 1.3.1 A manufacturer produces two types of models M and M .
Each model of the 1 2 type M requires 4 hours of grinding and 2 hours of polishing; whereas each model of the type 1 M requires 2 hours of grinding and 5 hours of polishing.
The manufacturer has 2 grinders and 2 3 polishers.
Each grinder works 40 hours a week and each polisher works for 60 hours a week.
Profit on M model is $3.00 and on model M is $4.00.
Whatever is produced in a week is sold 1 2 in the market.
How should the manufacturer allocate his production capacity to the two types of model, so that he may make the maximu profit in a week?
☞ Solution.
Decsion variables: Let x1 and x2 be the number of units of M1 and M2 models.
Objective function: Since the profit on both the modes are given, you have to maximize the profit viz.
max z = 3x1 + 4x2 Constraints There are two constraints-one for grinding and the other for polshing.
Numbers of hours available on each grinder for one week is 40.
There are 2 grinders.
Hence the manufacturer does not have more than 2 × 40 = 80 hours of grinding.
M1 requires 4 hours of grinding and M requires 2 hours of grinding.
2 The grinding constraint is given by 4x1 + 2x2 ≤ 80.
Since there are 3 polishers, the available time for poloshing in a week is given by 3 × 60 = 180 hours of polishing.
M requires 2 hours of polishing and M requires 5 hours.
Hence we 1 2 have 2x1 + 5x2 ≤ 180.
1  UNIT 1.
LINEAR PROGRAMMING Finally you have, Maximize z = 3x1 + 4x2 Subject to: 4x + 2x ≤ 80 1 2 2x + 5x ≤ 180 1 2 x , x ≥ 0.
1 2 ✍ Example 1.3.2 A company manufactures two products A and B.
These products are processed in the same machine.
It takes 10 minutes to process one unit of product A and 2 minutes for each unit of product B and the machine operates for a maximum of 35 hours in a week.
Product A requires 1kg and B 0.5kg of raw material per unit, the supply of which is 600kg per week.
Market constraints on product B is known to be minimum of 800 units every week.
Product A costs $5 per unit and sold at $10.
product B costs $6 per unit and can be sold in the market at a unit price of $8.
Determine the number of units of A and B per week to maximize the profit.
☞ Solution.
Decision Variable: Let x and x be the number of products A and B 1 2 respectively.
Objective function: Cost of product A per unit is $5 and selling price is $10 per unit.
Therefore Profit on one unit of product A = 10 − 5 = $5.
x units of product A contributes a profit of $5x , profit constribution from one unit of 1 1 product B = 8 − 6 = $2 x2 units of product B constribute a profit of $2x2 The objective function is given by Maximize z = 5x1 + 2x2 Constraints: The requirement constraint is given by 10x + 2x ≤ (35 × 60) 1 2 10x + 2x ≤ 2100.
1 2 Raw material constraint is given by , x1 + 0.5x2 ≤ 600 Market demand of product B is 800 units every week x ≥ 800 2 1  UNIT 1.
LINEAR PROGRAMMING The complete LPP is Maximize 5x1 + 2x2 Subject to 10x + 2x ≤ 2100 1 2 x + 0.5x ≤ 600 1 2 x ≥ 800 2 x , x ≥ 0.
1 2 ✍ Example 1.3.3 A person requires 10,12, and 12 units of chemicals A, B and C respectively, for his garden.
A liquid product contains 5,2, and 1 units of A, B and C respectively, per jar.
A dry product contains 1,2 and 4 units of A, B and C per carton.
If the liquid product sell for $3 per jar and the dry product sells for $2 per carton, how many of each should be purchased, in order to minimize the cost and meet the requirements?
☞ Solution.
Decision Variables: Let x and x be the number of units of liquid and dry 1 2 products.
Objective function: Since the cost for the products are given, you have to minimize the cost Minimize z = 3x + 2x .
1 2 Constraints: As there are 3 chemicals and their requirements are given, you have three con- straints for these three chemicals.
5x1 + x2 ≥ 10 2x + 2x ≥ 12 1 2 x1 + 4x2 ≥ 12.
Finally the complete LPP is Minimize z = 3x1 + 2x2 Subject to: 5x1 + x2 ≥ 10 2x + 2x ≥ 12 1 2 x + 4x ≥ 12 1 2 x , x ≥ 0.
1 2 ✍ 1  UNIT 1.
LINEAR PROGRAMMING Example 1.3.4 A paper mill produces two grades of paper namely X and Y. Owing to raw material restrictions, it cannot produce more than 400 ton of grade X and 300 tons of grade Y in a week.
There are 160 production hours in a week.
It requires 0.2 and 0.4 hours to produce a ton of products H and Y respectively without corresponding profits of $200 and $500 per ton.
Formulate the above as a LPP to maximize profit and find the optimum product mix.
☞ Solution.
Decision Variables: Let x and x be the number of units of two grades of 1 2 paper of X and Y.
Objective function: Since the profit for the two grades of paper X and Y are given, the objective function is to maximize the profit.
Maximize z = 200x1 + 500x2 Constraints: There are 2 constraints, one referring to raw material, and the other to pro- duction hours.
Maximize z = 200x + 500x 1 2 Subject to: x1 ≤ 400 x ≤ 300 2 0.2x + 0.4x ≤ 160 1 2 x1, x2 ≥ 0.
✍ Example 1.3.5 A company manufactures two products A and B.
Each unit of B takes twice as long to produce as one unit of A and if the company was to produce only A, it would have time to produce 2,000 units per day.
The availability of the raw material is sufficient to produce 1,500 units per day of both A and B combined.
Product B requiring a special ingredient, only 600 units can be made per day.
If A fetches a profit of $2 per unit and B a profit of $4 per unit, find the optimum product mix by graphical method.
☞ Solution.
Let x and x be the number of units of the products A and B respectively.
1 2 The profit after selling these two products is given by the objective function, Maximize z = 2x1 + 4x2 Since the company can produce at most 2,000 units of the product in a day and type B requires twice as much time as that of type A, production restriction is given by x + 2x ≤ 2, 000.
1 2 Since the raw material are sufficient to produce 1,500 units per day if both A and B are combined, you have x1 + x2 ≤ 1500 There are special ingredients for the product B so you have x2 ≤ 600.
1  UNIT 1.
LINEAR PROGRAMMING Also, since the company cannot produce negative quantities, x1 ≥ 0 and x2 ≥ 0.
Hence the problem can be finally put in the form: Maximize z = 2x1 + 4x2 Subject to: x1 + 2x2 ≤ 2, 000 x + x ≤ 1500 1 2 x ≤ 600 2 x , x ≥ 0.
1 2 ✍ Example 1.3.6 A firm manufactures 3 products A, B and C. The profits are $3, $2 and $4 re- spectively.
The firm has 2 machines and given below is the required processing time in minutes for each machine on each product Product A B C Machines M1 4 3 5 M 3 2 4 1 Table 1.1: Machines M and M have 2, 000 and 2,500 machines minutes respectively.
The firm must 1 2 manufacture 100A’s, 200 B’s and 50 C ’s but no more than 150 A’s.
Set up an LP problem to maximize the profit.
☞ Solution.
Let x , x , x be the number of units of the products A, B, C respectively.
1 2 3 Since the profits are $3, $ 2 and $ 4 respectively, the total profit gained by the firm after selling these three products is given by, z = 3x + 2x + 4x .
1 2 3 The total number of minutes required in producing these three products at machine M is 1 given by 4x + 3x + 5x and at machine M , it is given by 3x + 2x + 4x .
1 2 3 2 1 2 3 The restrictions on the machines M and M are given by 2,000 minutes and 2,500 minutes.
1 2 4x + 3x + 5x ≤ 2000 1 2 3 3x + 2x + 4x ≤ 2500 1 2 3 1  UNIT 1.
LINEAR PROGRAMMING Also, since the firm manufactures 100 A’s, 200 B’s and 50 C ’s but not more than 150 A’s the further restriction becomes 100 ≤ x1 ≤ 150 x ≥ 200 2 x ≥ 50 3 Hence the allocation problem of the firm can be finally put in the form: Maximize z = 3x1 + 2x2 + 4x3 Subject to: 4x1 + 3x2 + 5x3 ≤ 2, 000 3x + 2x + 4x ≤ 2500 1 2 3 100 ≤ x ≤ 150 1 x ≥ 200 2 x ≥ 50 3 x , x , x ≥ 0 1 2 3 ✍ 1.3.4 Sensitivity Analysis The term sensitivity analysis, often known as post-optimality analysis refers to the optimal so- lution of a linear programming problem, formulated using various methods You have learnt the use and importance of dual variables to solve an LPP.
Here, you will learn how sensitivity analy- sis helps to solve repeatedly the real problem in a little different form.
Generally, these scenarios crop up as an end result of parameter changes due to the involvement of new advanced tech- nologies and the accessibility of well-organized latest information for key (input) parameters or the ’what-if’ questions.
Thus, sensitivity analysis helps to produce optimal solution of simple pertubations for the key parameters.
For optimal solutions, consider the simplex algorigthm as a ’black box’ which accepts the input key parameters to solve LPP as shown below Example 1.3.7 Illustrate sensitivity analysis using simplex method to solve the following LPP.
Maximize z = 20x1 + 10x2 Subject to: x + x ≤ 3 1 2 3x + x ≤ 7 1 2 x , x ≥ 0 1 2 1  UNIT 1.
LINEAR PROGRAMMING Simplex Algorithm Linear Program ?
Optimal Solution Figure 1.1: ☞ Solution.
Sensitivity analysis is done after making the initial and final tableau using the simplex method.
Add slack variables to convert it into equation form.
Maximize z = 20x1 + 10x2 + 0x3 + 0x4 Subject to: x + x + x + 0x = 3 1 2 3 4 3x + x + 0x + x = 7 1 2 3 4 x , x ≥ 0 1 2 To find the basic feasible solution, put x = 0 and x = 0. this gives z = 0, x = 3 and 1 2 3 x = 7.
The initial table will be as follows.
: 4 Initial table B x x x x x  1 2 3 4 B x 1 1 1 0 3 3 3 x 3 1 0 1 7 7/ 3  4 z −c −20  -10 0 0 0 j j Table 1.2: x Find θ = B for each row and find minimum for the second row.
Here, z j − cj is maximum xj negative (−20).
Hence x1 enters the basis and x4 leaves the basis.
It is shown with the help of arrows.
Key element is 3, key row is second row and key column is x .
Now convert the key element 1 into entering key by dividing each element of the key row by key element using the following formula: ( l Product of elements in the key row and key column New element = Old element − Key element 1  UNIT 1.
LINEAR PROGRAMMING B x x x x x  1 2 3 4 B x 0 2/3 1 -1/3 2/3 1  3 x 1 1/3 0 1/3 7/3 7 1 z −c 0 −10 / 3  0 20 140/3 j j Table 1.3: The following is the first iteration tableau.
Since z − c has one value less than zero, i.e., negative value hence this is not yet optima j j solution.
Value -10/3 is negative hence x enters the basis and x leaves the basis.
Key row is 2 3 upper row.
B x x x x x  1 2 3 4 B x 0 1 3/2 -1/2 1 2 x 1 0 0 4/3 4/3 1 z −c 0 0 0 25 110/3 j j Table 1.4: z − c ≥ 0 for all j, hence optimal solution is reached, where x = 4 , x = 1; z = 110 ✍ j j 1 3 2 3 1.3.5 Shadow Price The price of value of any item is its exchange ratio, which is relative to some standard item.
Thus, you may say that shadow price, also known as marginal value, of a constant i is the change it induces in the optimal value of the objective function due to the result of any change in the value, i.e., on the right-hand side of the constraint i.
This can be formularized assuming, z = objective function b = right-handed side of constraint i i π∗ = standard price of constraint i; At optimal solution z∗ = v∗ = bT π∗ (Non-degenerate solution).
Under this situation, the change in the value of z per change of b for small changes in b is i i obtained by partially differentiating the objective function z, with respect to the righthanded side b , which is further illustrated as i lz = π∗ ∂b i 1  UNIT 1.
LINEAR PROGRAMMING where, π∗ = price associated with the righthanded side.
i It is this price, which was interpreted by Paul Sammelson as shadow price.
1.3.6 Economic Interpretation You have often seen that shadow prices are being frequently used in the economic interpretation of the data in linear programming.
Example 1.3.8 To find the economic interpretation of shadow price under non-degeneracy, you will need to consider the linear programming to find out minimum of objective function z, x ≥ 0, which is as follows: −x − 2x − 3x + x = 1 2 3 4 z x + 2x = 6 1 4 x + 3x = 2 2 4 x − x = 1 3 4 Now, to get an optimal basic solution, you can calculate the numericals; x = 6, x , x = 1, x = 0, z = −13.
1 2 3 4 The optimal solution for the shadow price is: π◦ = −1, π◦ = −2, π◦ = −3, 2 3 as, z = b π + b π + b π , where b = (6, 2, 1); 1 1 2 2 3 3 it denotes, ∂z ∂z ∂z = π = −1, = π = −2, = π = −3.
1 2 3 ∂bi ∂b2 ∂b3 As these shadow prices and the changes take place in a non-degenerate situation so, they do not impact the small changes of b .
Now, if this same situation is repeated in a degenerate i situation, you will have to replace b3 = 1 by b3 = 0; thereby ∂z/∂b+3 = −3, only if the change in b is positive.
However, you need to keep in mind that if b is negative, then x will drop out 3 3 3 of the basis and x transcends as the basic and the shadow price may be illustrated as; 4 π1◦ = −1, π◦2 = −2, π◦3 = ∂z/∂b−3 = −9 Here, you see that the interpretation of the dual variables π, and dual objective function ν corresponds to column j of the primal problem.
So, the goal of linear programming (Simplex method) is to determine whether there is a basic feasibility for optimal solution, in the most cost-effective manner.
1  UNIT 1.
LINEAR PROGRAMMING Thus, at iteration, t, the total cost of the objective function and this can be illustrated as: m ν = πT b = π b i i i=1 here, π =simplex multipliers which is associated with the basis B.
So, you may say that the prices of the problem of the dual variables are selected in such a manner, that there is a maximization of the implicit indirect cost of the resources that are consumed by all the activities.
Whenever any basic activity is conducted, it is done at a positive level and all non-basic activities are kept at a zero level.
Hence, if the primal-dual variable system is utilized, then the slack variable is maintained at a positive level in an optimal soltuion and the corresponding dual variable is equal to zero.
1.4 Conclusion In this unit you have learnt that the objective function of a linear Programming problem can be of two types, namely minimization or maximization.
The constraints could be of any of the three types “greater than or equal to (≥)”, “less than or equal to (≤)” or “equal to (=)”.
You also learnt that a formulation is superior if it has fewer decision variables and fewer constraints.
For problems that have the same number of variables, the one with fewer constraints is superior, and for problems with the same number of constraints the one with fewer variables is superior.
We also saw that the same problem can have different formulations, depending on how the person formulating looks at the problem.
As seen in the second example which has two different formulations.
And these two formulations will give effectively the same solutions though they have different number of variables.
You also saw the non-negativity restrictions.
In this unit you studied, two examples, making a total of 4 examples so far in this course.
You can go on and on to create different situations or formulations endlessly.
And with every formulation, you can actually learn something new.
But with these four examples, you have been able to know various aspects of problem formulations, the terminologies, definitions in terms of objective functions, constraints and decision variables.
And that different situations determines when the variables are apparent and when they follow a certain pattern.
Lastly, you saw a problem where you defined two formulations and solving one problem is as enough as solving the other.
With this you have come to the end of Linear programming formulations.
In the next unit, you shall consider how to solve linear programming problems.
1.5 Summary In summary, you have (i) seen how to Formulate a linear programming problem.
2  UNIT 1.
LINEAR PROGRAMMING (ii) known some terminologies used in Linear Programming in terms of decision variables, objective functions, constraints and non-negativity condition (iii) seen different types of objective functions i.e., minimization and maximization objectives.
(iv) seen different types of constraints, i.e., “greater than or equal to (≥),” ”equal to (=)” or “less than or equal to (≤)” constraints.
(v) also seen different types of variables.
In the next unit you shall go through two more formulations to understand some more aspects of problem form which would be covered which have not been covered in these two examples.
Having gone through this unit, you are able to • Formulate linear programming model for a cutting stock problem.
• Formulate a linear programming model from game theory.
• With the ideas learnt, formulate various other problems in linear programming.
1.6 Tutor Marked Assignments (TMAs) Exercise 1.6.1 1.
Which of the following is true about a Linear Programming Problem?
(a) It has nonlinear Objectives.
(b) It has linear constraints.
(c) The variables could take any value.
(d) They number of constraints must be equal to the number of variables.
2.
The Constraints of a linear programming problem can be (a) greater than or equal to, less than or equal to or equal to.
(b) a combination of greater than or equal to, less than or equal to and equal to (c) all of the above (d) none of the above.
3.
A mathematical programming which is not a linear programming problem is best referred to as (a) nonlinear programming (b) integer programming (c) transportation problem 2  UNIT 1.
LINEAR PROGRAMMING (d) quadratic programming.
4.
A linear programming model must be made up of (a) Linear objective function, Linear constraints and unrestricted decision variables.
(b) Linear objective function, Linear constraints and non-negative decision variables.
(c) Objective function, constraints and non-negative decision variables.
(d) Linear objective function, constraints and unrestricted decision variables.
5.
Any linear programming problem has (a) a unique formulation.
(b) many formulations depending on how one looks at the problem.
(c) a maximum of two formulations (d) a maximum of three formulations 6.
Which of the following is not a major aim in Operation research (a) Minimization of the cost (b) Maximization of profit (c) Minimization of resources.
(d) Wastage of raw materials.
Exercise 1.6.2 1.
A merchant plans to sell two models of home computers at costs of $250 and $400, respectively.
The $250 model yields a profit of $45 and the $400 model yields a profit of $50.
The merchant estimates that the total monthly demand will not exceed 250 units.
Find the number of units of each model that should be stocked in order to maximize profit.
Assume that the merchant does not want to invest more than $70,000 in computer inventory.
2.
A fruit grower has 150 acres of land available to raise two crops, A and B.
It takes one day to trim an acre of crop A and two days to trim an acre of crop B, and there are 240 days per year available for trimming.
It takes 0.3 day to pick an acre of crop A and 0.1 day to pick an acre of crop B, and there are 30 days per year available for picking.
Find the number of acres of each fruit that should be planted to maximize profit, as- suming that the profit is $140 per acre for crop A and $235 per acre for B.
3.
A grower has 50 acres of land for which she plans to raise three crops.
It costs $200 to produce an acre of carrots and the profit is $60 per acre.
It costs $80 to produce an acre of celery and the profit is $20 per acre.
Finally, it costs $140 to produce an acre of lettuce and the profit is $30 per acre.
Use the simplex method to find the number of acres of each crop she should plant in order to maximize her profit.
Assume that her cost cannot exceed $10,000.
2  UNIT 1.
LINEAR PROGRAMMING 4.
A fruit juice company makes two special drinks by blending apple and pineapple juices.
The first drink uses 30% apple juice and 70% pineapple, while the second drink uses 60% apple and 40% pineapple.
There are 1000 liters of apple and 1500 liters of pineapple juice available.
If the profit for the first drink is $0.60 per liter and that for the second drink is $0.50, use the simplex method to find the number of liters of each drink that should be produced in order to maximize the profit.
5.
A manufacturer produces three models of bicycles.
The time (in hours) required for assembling, painting, and packaging each model is as follows.
Model A Model B Model C Assembling 2 2.5 3 Painting 15 2 1 Packaging 1 0.75 1.25 The total time available for assembling, painting, and packag- ing is 4006 hours, 2495 hours and 1500 hours, respectively.
The profit per unit for each model is $45 (Model A), $50 (Model B), and $55 (Model C).
How many of each type should be produced to obtain a maximum profit?
6.
Suppose in Exercise 5 the total time available for assembling, painting, and packaging is 4000 hours, 2500 hours, and 1500 hours, respectively, and that the profit per unit is $48 (Model A), $50 (Model B), and $52 (Model C).
How many of each type should be produced to obtain a maximum profit?
7.
A company has budgeted a maximum of $600,000 for advertising a certain product na- tionally.
Each minute of television time costs $60,000 and each one-page newspaper ad costs $15,000.
Each television ad is expected to be viewed by 15 million viewers, and each newspaper ad is expected to be seen by 3 million readers.
The company’s market research department advises the company to use at most 90% of the advertising budget on television ads.
How should the advertising budget be allocated to maximize the total audience?
8.
Rework Exercise 7 assuming that each one-page newspaper ad costs $30,000.
9.
An investor has up to $250,000 to invest in three types of investments.
Type A pays 8% annually and has a risk factor of 0.
Type B pays 10% annually and has a risk factor of 0.06.
Type C pays 14% annually and has a risk factor of 0.10.
To have a well-balanced portfolio, the investor imposes the following conditions.
The average risk factor should be no greater than 0.05.
Moreover, at least one-fourth of the total portfolio is to be allocated to Type A investments and at least one-fourth of the portfolio is to be allocated to Type B investments.
How much should be allocated to each type of investment to obtain a maximum return?
2  UNIT 1.
LINEAR PROGRAMMING 10.
An investor has up to $450,000 to invest in three types of investments.
Type A pays 6% annually and has a risk factor of 0.
Type B pays 10% annually and has a risk factor of 0.06.
Type C pays 12% annually and has a risk factor of 0.08.
To have a well-balanced portfolio, the investor imposes the following conditions.
The average risk factor should be no greater than 0.05.
Moreover, at least one-half of the total portfolio is to be allocated to Type A investments and at least one-fourth of the portfolio is to be allocated to Type B invest- ments.
How much should be allocated to each type of investment to obtain a maximum return?
11.
An accounting firm has 900 hours of staff time and 100 hours of reviewing time available each week.
The firm charges $2000 for an audit and $300 for a tax return.
Each audit requires 100 hours of staff time and 10 hours of review time, and each tax return requires 12.5 hours of staff time and 2.5 hours of review time.
What number of audits and tax returns will bring in a maximum revenue?
12.
The accounting firm in Exercise 11 raises its charge for an audit to $2500.
What number of audits and tax returns will bring in a maximum revenue?
13.
A company has three production plants, each of which pro- duces three different models of a particular product.
The daily capacities (in thousands of units) of the three plants are as follows.
Model 1 Model 2 Model 3 Plant 1 8 4 8 Plant 2 6 6 3 Plant 3 12 4 8 The total demand for Model 1 is 300,000 units, for Model 2 is 172,000 units, and for Model 3 is 249,500 units.
Moreover, the daily operating cost for Plant 1 is $55,000, for Plant 2 is $60,000, and for Plant 3 is $60,000.
How many days should each plant be operated in order to fill the total demand, and keep the operating cost at a minimum?
14.
The company in Exercise 13 has lowered the daily operating cost for Plant 3 to $50,000.
How many days should each plant be operated in order to fill the total demand, and keep the operating cost at a minimum?
15.
A small petroleum company owns two refineries.
Refinery 1 costs $25,000 per day to operate, and it can produce 300 barrels of high-grade oil, 200 barrels of medium-grade oil, and 150 barrels of low-grade oil each day.
Refinery 2 is newer and more modern.
It costs $30,000 per day to operate, and it can produce 300 barrels of high-grade oil, 250 barrels of medium-grade oil, and 400 barrels of low-grade oil each day.
The company has orders totaling 35,000 barrels of high-grade oil, 30,000 barrels of medium-grade oil, and 40,000 barrels of low-grade oil.
How many days should the company run each refinery to minimize its costs and still meet its orders?
2  UNIT 1.
LINEAR PROGRAMMING 16.
A steel company has two mills.
Mill 1 costs $70,000 per day to operate, and it can produce 400 tons of high-grade steel, 500 tons of medium-grade steel, and 450 tons of low-grade steel each day.
Mill 2 costs $60,000 per day to operate, and it can produce 350 tons of high-grade steel, 600 tons of medium-grade steel, and 400 tons of low-grade steel each day.
The company has orders totaling 100,000 tons of high-grade steel, 150,000 tons of medium-grade steel, and 124,500 tons of low-grade steel.
How many days should the company run each mill to minimize its costs and still fill the orders?
2  Module II Methods of Solutions to Linear Programming Problems 26  UNIT 2 GRAPHICAL AND ALGEBRAIC METHODS.
2.1 Introduction In this unit, you will be introduced graphical and algebraic methods of solving linear program- ming problems 2.2 Objectives At the end of this unit, you should be able to (i) solve linear programming problems using graphical method.
(ii) solve linear programming problems using algebraic method.
2.3 Main Content 2.3.1 Graphical Method Simple linear programming problems with two decision variables can be easily solved by graph- ical method.
2.3.2 Procedure For Solving LPP By Graphical Method The steps involved in graphical method are as follows: 27  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
Step 1 Consider each inequality constraint as an equation.
Step 2 Plot each equation on the graph, as each will geometrically represent a straight line.
Step 3 Mark the region.
If the inequality constraint corresponding to the line is ≤, then the region below the line lying in the first quadrant (due to non-negativity of variables) is shaded.
For the inequality constraint with ≥ sign, the region above the line in the first quadrant is shaded.
The points lying in the common region will satisfy all the constraints simultaneously.
The common region thus obtained is called the “feasible region”.
Step 4 Assign an arbitrary value, say zero, to the objective function.
Step 5 Draw the straight line to represent the objective function with the arbitrary value (i.e., a straight line through the origin).
Step 6 Stretch the objective function line till the extreme points of the feasible region.
In the maximization case, this line will stop farthest from the origin, passing through at least one corner of the feasible region.
In the minimization case, this line will stop nearest to the origin, passing through at least one corner of the feasible region.
In the minimization case, this line will stop nearest to the origin, passing through at least one corner of the feasible region.
Step 7 Find the co-ordinates of the extreme points selected in step 6 and find the maximum or minimum value of z.
Note As the optimal values occur at the corner points of the feasible region, it is enough to calculate the value of the objective function of the corner points of the feasible region and select the one that gives the optimal solution.
That is, in the case of maximization problem, the optimal point corresponds to the corner point at which has the objective function as maximum value, and in the case of minimization, the optimal solution is the corner point which gives the objective function the minimum value for the objective function.
Example 2.3.1 Solve the following LPP by graphical method Minimize z = 20x1 + 10x2 Subject to.
x + 2x ≤ 40 1 2 3x + x ≥ 30 1 2 4x + 3x ≥ 60 1 2 x , x ≥ 0 1 2 ☞ Solution.
Replace all the inequalities of the constraints by equation x + 2x = 40 passes through (0, 20)(40, 0) 1 2 3x + x passes through (0, 30)(10, 0) 1 2 28  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
4x + 3x = 60 passes through (0, 20)(15, 0) 1 2 Plot the graph of each on the same graph y=x 2 40 30 20 C(4,18) 8 88 D(6,12)8888 10 88888 8888888 88888888 (40,0) 888888888 x=x 0 (15,0) 1 10 30 40 Figure 2.1: The feasible region is ABCD.
C and D are points of intersection of lines.
C intersects x + 2x = 40, and 3x + x = 30 1 2 1 2 and D intersects 4x + 3x = 60, and x + x = 30.
Thus C = (4, 18) and D = (6, 12) 1 2 1 2 Corner points Value of z = 20x1 + 10x2 A(15, 0) 300 B(40, 0) 800 C (4, 18) 260 D(6, 12) 240 (Minimum value) Therefore the minimum value of z occurs at D(6,12).
Hence, the optimal solution is x = 1 6, x2 = 12.
✍ 29  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
Example 2.3.2 Use graphical method to solve the LPP.
Maximize z = 6x1 + 4x2 Subject to −2x + x ≤ 2 1 2 x − x ≤ 2 1 2 3x + 2x ≤ 9 1 2 x , x ≥ 0.
1 2 ☞ Solution.
Replacing the inequality by equality −2x + x = 2 passes through (0, 2), (−1, 0) 1 2 x − x = 2 passes through (0, −2), (2, 0) 1 2 3x + 2x = 9 passes through (0, 4.5), (3, 0) 1 2 20" wastage=2" 2 by 9" Figure 2.2: Page 24-1 Feasible region is given by ABC.
30  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
Corner points Value of z = 6x1 + 4x2 O(0, 0) 0 A(2, 0) 12 B(13/5,3/5) 18 (Maximum value) C(5/7, 24/7) 18 (Maximum value) The maximum value of z is attained at C (13/5, 3/5) or at D(5/7, 24/7) Therefore optimal solution is x1 = 13/5, x2 = 3/5 or x1 = 5/7, x2 = 24/7.
✍ Example 2.3.3 Use graphical method to solve the LPP.
Maximize 3x1 + 2x2 Subject to 5x1 + x2 ≥ 10 x + x ≥ 6 1 2 x + 4x ≥ 12 1 2 x , x ≥ 0 1 2 ☞ Solution.
Corner points Value of z = 3x1 + 2x2 A(0, 10) 20 B(1, 5) 13 (Minimum value) C (4, 2) 16 D(12, 0) 36 Since the minimum value is attained at B(1,5) the optimum solution is x = 1, x = 5.
1 2 Note: In the above problem if the objective function is maximization, then the solution is unbounded, as maximum value occurs at infinity.
✍ 2.3.3 Some More Cases There are some linear programming problems which may have, 31  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
20" wastage=4" 2 by 8" Figure 2.3: Page 25-1 (i) a unique optimal solution (ii) an infinite number of optimal solutions.
(iii) an unbounded solution (iv) no solution.
The following examples will illustrate these cases.
Example 2.3.4 Solve the LPP by graphical method.
Maximize z = 100x1 + 40x2 Subject to.
5x + 2x ≤ 1, 000 1 2 3x1 + 2x2 ≤ 900 x1 + 2x2 ≤ 500 x1, x2 ≥ 0 ☞ Solution.
The solution space is given by the feasible region OABC.
Corner points Value of z = 100x1 + 40x2 O(0, 0) 0 A(200, 0) 20, 000 (Maximum value of z) B(125, 187.5) 20, 000 C (0, 250) 10, 000 32  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
y=x 2 600 400 C(0,250) 200 B(125,187.5) f eas ible r eg ion A(200,0) x=x1 O 600 200 400 Figure 2.4: Page 26-1 Therefore the maximum value of z occurs at two vertices A and B.
Since there are infinte number of points on the line joining A and B is gives the same maximum value of z Thus, there are infinite number of optimal solutions for the LPP.
✍ Example 2.3.5 Solve the following LPP Maximize z = 3x1 + 2x2 Subject to x − x ≥ 1 1 2 x + x ≥ 3 1 2 x , x ≥ 0 1 2 33  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
☞ Solution.
y=x 2 4 A(0,3) fe asib le re gio n 2 B(2,1) x=x 1 O 2 4 −1 Figure 2.5: Page 26-2 The solution space is unbounded.
The value of the objective function at the vertices A and B are z(A) = 6, z(B) = 6.
But there exists points in the convex region for which the value of the objective function is more than 8.
In fact, the maximum value of z occurs at infinity.
Hency, the problem has an unbounded solution.
✍ No feasible solution When there is no feasible region formed by the constraints in conjuction with non-negativity conditions, then no solution to the LPP exists.
Example 2.3.6 Solve the following LPP.
Maximize z = x1 + x2 Subject to x + x ≤ 1 1 2 −3x + x ≥ 3 1 2 x , x ≥ 0 1 2 34  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
☞ Solution.
There’s being no point (x1, x2) common to both the shaded regions, you could not find a feasible region for this problem.
So the problem cannot be solved.
Hence, the problem has no solution.
y=x 2 88 88 4 88 88 88 2 O x=x −1 1 2 3 1 −1 Figure 2.6: Page 27-1 ✍ 2.3.4 The Algebraic Method • Consider this example and illustrate the algebraic method.
Maximize z = 6x1 + 5x2 subject to x1 + x2 ≤ 5 (2.1) 3x + 2x ≤ 12 1 2 x , x ≥ 0 1 2 • Assuming that you know how to solve linear equations, you can convert the inequalities into equations by adding Slack variables x and x respectively.
3 2 • These two slack variables represents the amount of resources A and B respectively that are not utilized during production, and they do not contribute to the objective function.
35  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
So the linear programming problem becomes Maximize z = 6x1 + 5x2 + 0x3 + 0x4 Subject to: x1 + x2 + x3 = 5 (2.2) 3x + 2x + x = 12 1 2 4 x , x , x , x ≥ 0 1 2 3 4 Observe that x and x must be greater than or equal to zero.
The restriction of these 3 4 new variables which is consistent with the non-negativity requirement of linear programming problems makes the new problem very important to us.
You can now proceed to solve problem 2.2.
It is Very important to note that solving problem 2.2 is the same as solving problem 2.1.
• With the addition of slack variables, you now have four variables and two equations.
With the two equations, you can solve only for two variables at a time.
• You have to fix any two variables to some arbitrary value and can solve for the remaining two variables.
• The two variables that you fix arbitrary values can be chosen in 4C = 6ways.
2 • In each of these six combinations, you can actually fix the variables to any value resulting in infinite number of solutions.
– However, you can consider fixing the arbitrary values to zero and hence consider only six distinct possible solutions.
• The variables that you fix to zero are called non-basic variables and the variables that you solved for are called basic variables.
– These solutions obtained by fixing the non basic variables to zero are called basic solutions.
• Among the six basic solutions obtained, you observe that four are feasible.
– Those basic solutions that are feasible (i.e., satisfy all constraints and the non- negativity restrictions) are called basic feasible solutions • The remaining two (solutions 3 and 4) have negative values for some variables and are therefore infeasible.
– You should be interested only in feasible solutions and therefore do not evaluate the objective function for infeasible solutions.
For this problem, the six basic solutions are: 1.
Variables x and x are non-basic and set to zero.
Substituting you get x = 5, x = 12 1 2 3 4 and the value of the objective function z = 0.
36  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
2.
Variables x and x are non-basic and set to zero.
Substituting, you solve for x = 5 and 1 3 2 2x + x = 12 and get x = 5, x = 2 and the value of the objective function z = 25.
2 4 2 4 3.
Variables x and x are non-basic and set to zero.
Substituting, you solve for x + x = 5 1 4 2 3 and 2x = 12 which gives you x = 6, x = −1.
Here you don’t need to evaluate the 2 2 3 value of the objective function because, the value x = −1 is not a feasible solution, 3 where the objective function is evaluated only at feasible solutions.
4.
Variables x and x are non-basic and set to zero.
Substituting, you solve for x + x = 5 2 4 1 3 and 3x = 12 which gives you x = 4, x = 1 and the value of the objective function 1 1 3 z = 24.
5.
Variables x and x are non-basic and set to zero.
Substituting, you solve for x = 5 and 2 3 1 3x1 + x4 = 12 which gives you x1 = 5, x3 = −3, a nonfeasible solution so that you don’t need to compute the value of the objective function.
6.
Variables x and x are non-basic and set to zero.
Substituting, you solve for x + x = 5 3 4 1 2 and 3x + 2x = 12, which gives you x = 2, x = 3 and the value of the objective 1 2 1 3 function z = 27.
Since the 6th problem has the maximum objective function value z = 27, then, x = 2, x = 3, 1 2 x = x = 0 is the optimum basic solutions.
3 4 Among these six basic solutions, you will observe that four are feasible.
Those basic solutions that are feasible (i.e., satisfy all the constraints) are called basic feasible solutions.
The remaining two (solutions 3 and 5) have negative values for some variables and therefore infeasible.
You are only interested only in feasible solutions and therefore do not evaluate the objective function for infeasible solutions.
Consider a non basic solution from the sixth solution.
Also assume that variables x and 3 x are fixed to arbitrary values (other than zero).
You have to fix them at non-negative values, 4 otherwise they will be infeasible.
Fix x = 1 and x = 1 On substitution you get x + x = 4 3 4 1 2 and 3x + 2x = 11 and get x = 3, x = 3 and value of the objective function z = 23.
1 2 1 2 This non-basic feasible solution is clearly inferior to the solution x = 2, x = 3 obtained as a 1 2 basic feasible solution by fixing x and x to zero.
The solution (3,1) is an interior point in the 3 4 feasible region while the basic feasible solution (2,3) is a corner point.
And you have seen that it is enough only to evaluate corner points.
2.3.5 Relationship between the Graphical and the Algebraic methods.
Having solved this problem, you can observe that; • the four basic feasible solutions correspond to the four corner points.
• Every non-basic solution that is feasible corresponds to an interior point in the feasible region and every basic feasible solution corresponds to a corner point solution.
• In the algebraic method, it is enough only to evaluate the basic solutions, find out the feasible ones and evaluate the objective function to obtain the optimal solution.
37  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
x2 8 6 3x 1+ 2x 2=12 (0,5) 4 2 (2,3) x 1 + x 2= 5 f ea si bl e Re gi on (0,0) x1 ( 4,0) Figure 2.7: Summary of the Algebraic Method In general, the algebraic approach for solving linear programming problems follows the pattern below 1.
Convert the inequalities into equations by adding slack variables.
2.
Assuming that there are m equations and n variables, set n − m (non-basic) variables to zero and evaluate the solution for the remaining m basic variables.
Evaluate the objective function if the basic solution is feasible.
3.
Perform Step 2 for all the nC combinations of basic variables.
m 4.
Identify the optimum solution as the one with the maximum(minimum) value of the ob- jective function.
Advantages of the Algebraic Method You saw that the graphical method is very good in solving linear programming problem with only two variables, but the algebraic method can be used to solve for any number of variables and any number of constraints provided that you can solve the system of linear equations ob- tained.
Disadvantages of the Algebraic Method The distinct disadvantages of the algebraic method are • You will end up evaluating a total of nC basic solutions, which is a very large number m of solutions to evaluate before arriving at the optimal.
• Among these large solutions you have, there are infeasible solutions that are not neces- sary.
38  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
• Also you would expect that the solutions to be better and better as you progress, but this is not the case as it does not follow a specific pattern.
For example, in the just concluded 39  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
problem, you obtained a value z = 25 and afterwards got z = 24 before arriving at z = 27.
If you had not considered all the points before concluding, you would have not gotten the right answer.
2.4 Conclusion In this unit, you studied the graphical and the algebraic method for solving a linear programming problem.
You have also seen there limitations.
With these limitations of the algebraic method, it becomes imperative to consider a method that is better than the algebraic method and the graphical method.
This method - would not evaluate infeasible solutions.
- should progressively give you better solutions.
- should be able to terminate as soon as it has found the optimum.
It should not put you in a situation where you have evaluated the optimum but still have to evaluate the rest before you would realize that you have arrived at an optimum solution earlier.
A method that can do all these would add more value to the algebraic method that you have seen.
Obviously, that method would require more computation and extra effort.
This method is called the simplex method which is essentially an extension of the algebraic method and exactly addresses the three concerns you have listed above.
Simplex method is the most important tool that had been developed to solve linear programming problems.
This shall be discussed in detail in the next unit.
2.5 Summary Having gone through this unit, you are now able to; 1.
Solve linear programming problems using graphical methods 2. solve linear programming problems using algebraic methods.
3.
A set of values x , x , .
.
.
, x that satisfies (1.2) of LPP is called its solution 1 2 n 4.
Any feasible solution to LPP, which satisfies the non-negativity restriction (1.3) is called its feasible solution.
5.
Any feasible solution, which optimizes (minimizes or maximizes) the objective function (1.1) of the LPP is called optimum solution.
6.
Given a system of m linear equations with n variables (m < n), any solution that is obtained by solving m variables keeping the remaining n − m variables zero is called a basic solution.
Such m variables are called basic variables and the remainiing are called non-basic variables.
40  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
n!
The number of basic solutions ≤ m!
(n − m)!
7.
A basic feasible solution is a basic solution which also satifies (1.3), that is all basic variables are non-negative.
Basic feasible solutions are of two types: (a) Non-degenerate: A non-degenerate basic feasible solution is a the basic feasible so- lution that has exactly m positive x ’s(i = 1, .
.
.
, m) i.e., None of the basic variables i are zero.
(b) Degenerate: A basic feasible solution is said to be degenerate if one or more basic variables are zero.
8.
If the value of the objective function can be increased or decreased indefinitely, such solutions are called unbounded solutions.
9.
A general LPP can be classified as canonical or standard forms.
(a) In standard form, irrespective of the objective function, namely, maximize or min- imize, all the constraints are expressed as equations.
Moreover RHS of each con- straint and all variables are non-negative.
i.e., A LPP that can be expressed in the matrix form (min or max) z = c x + c x + · · · + c x 1 1 2 2 n n Subject to: Ax ≥ b (2.3) x ≥ 0 is said to be in standard form.
Where b ≥ 0, i = 1, .
.
.
m, A is an m × n matrix, i x = (x , .
.
.
, x )t and c = (c , .
.
.
, c ) 1 n 1 n The Standard form is characterised by the following i.
The objective function is of maximization type.
ii.
All constraints are expressed as equations.
iii.
Right hand side of each constraint is non-negative.
iv.
All variables are non-negative.
(b) In canonical form, if the objective function is of maximization, all the constraints other than non-negative conditions are ’≤’ type.
If the objective function is of min- imization, all the constraints other than non-negative condition are ’≥’ type.
The Canonical form is characterised by the following; i.
The objective function is of maximization type.
ii.
All constraints are (≤) type.
iii.
All variables x (i = 1, .
.
.
, n) are non-negative.
i Note: (i) Minimization of a function z is equivalent to maximization of the negative expres- sion of this function, i.e., min z = − max(−z).
41  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
(ii) An inequality reverses when multiplied by (-1).
(iii) Suppose you have the constraint equation, a11x1 + a12x2 + · · · + a1nxn = b1 This equation can be replaced by two weak inequalities in opposite directions, a11x1 + a12x2 + · · · + a1nxn ≤ b1 and a11x1 + a12x2 + · · · + a1nxn ≥ b1 (iv) If a variable is unrestricted in sign, then it can be expressed as a difference of two non-negative variables, i.e., if x1 is unrestricted in sign, then x1 = xt1 − x2t t, where xt , xtt ≥ 0.
1 1 (v) In standard form, all the constraints are expressed in equation, which is possible by introducing some additional variables called ’slack variables’ and ’surplus vari- ables’ so that a system of simultaneous linear equations is obtained.
The necessary transformation will be made to ensure that bi ≥ 0.
– If the constraints of a general LPP be n a x ≤ b (i = 1, 2, .
.
.
, m).
ij j i j=1 Then the non-negative variable x (i = 1, .
.
.
m), which are introduced to n+i convert the inequalities (≤) to the equalities, i.e., n a x + x = b (i = 1, .
.
.
, m) ij j n+i i j=1 are called slack variables.
Slack variables are also defined as the non-negative variables that are added in the LHS of the constraint to convert the inequality (≤) into an equation.
– If the constraints of a general LPP be n a x ≥ b (i = 1, 2, .
.
.
, m).
ij j i j=1 Then the non-negative variable x (i = 1, .
.
.
m), which are introduced to n+i convert the inequalities (≤) to the equalities, i.e., n a x − x = b (i = 1, .
.
.
, m) ij j n+i i j=1 are called surplus variables.
Surplus variables are also defined as the non-negative variables that are removed from the LHS of the constraint to convert the inequality (≥) into an equation.
42  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
2.6 Tutor Marked Assignments(TMAs) Exercise 2.6.1 1.
Consider the following problem.
Maximize 2x1 + 5x2 Subject to x + 2x ≤ 16 1 2 2x + x ≤ 12 1 2 x , x ≥ 0 1 2 (a) Sketch the feasible region in the (x , x ) space.
1 2 (b) Identify the regions in the (x , x ) space where the slack variables x and x are 1 2 3 4 equal to zero.
(c) Solve the problem using graphical method.
2.
Consider the following problem.
Maximize 2x1 + 3x2 Subject to x + x ≤ 2 1 2 4x + 6x ≤ 9 1 2 x , x ≥ 0 1 2 (a) Sketch the feasible region.
(b) Find two alternative optimal extreme (corner) points.
(c) Find an infinite class of optimal solutions.
3.
Consider the following problem.
Maximize 3x1 + x2 Subject to −x + 2x ≤ 6 1 2 x ≤ 4 2 (a) Sketch the feasible region.
(b) Verify that the problem has an unbounded optimal solution.
Solve the following problems by graphical method.
43  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
4.
Maximize z = x − 3x 1 2 Subject to x + x ≤ 300 1 2 x − 2x ≤ 200 1 2 2x + x ≤ 100 1 2 x ≤ 200 2 x , x ≥ 0 1 2 [Ans max z = 205, x = 200, x = 0] 1 2 5.
Maximize z = 5x + 8y Subject to x + y ≤ 36 x + 2y ≤ 20 3x + 4y ≤ 42 x, y ≥ 0 [Ans max z = 82, x = 2, y = 9] 6.
Maximize z = x + 3y Subject to x + y ≤ 300 x − 2y ≤ 200 x + y ≤ 100 y ≥ 200 x, y ≥ 0 [Ans max z = 700, x = 100, y = 200] 7.
Egg contains 6 units of vitamin A and 7 units of vitamin B per gram and costs 12 paise per gram.
Milk contains 8 units of vitamin A and 12 units of vitamin B per gram and costs 20 paise per gram.
The daily minimum requirement of vitamin A and vitamin B are 100 units and 120 units respectively.
Find the optimal product mix.
[min z = 205, x = 5, x = 1.25] 1 2 44  UNIT 2.
GRAPHICAL AND ALGEBRAIC METHODS.
8.
Solve graphically the following LPP.
Maximize z = 20x1 + 10x2 Subject to x1 + 2x2 ≤ 40 3x + x ≥ 30 1 2 4x1 + 3x2 ≥ 60 x1, x2 ≥ 0 [Ans min z = 240, x = 6, x = 12] 1 2 9.
A company produces two different products, A and B and makes a profit of $40 and $30 per unit respectively.
The production process has a capacity of 30,000 man-hours.
It takes 3 hours to produce one unit of A and one hour to produce one unit of B.
The market survey indicates that the maximum number of units of product A that can be sold is 8,000 and those of B is 12,000 Formulate the problem and solve it by graphical method to get maximum profit.
[Ans max z = 40x + 30x , subject to 3x + x ≤ 30, 000; x ≤ 8, 000; x ≤ 1 2 1 2 1 2 12, 000, x1, x2 ≥ 0 (min z = 240, x1 = 6, x2 = 12)] 10.
Solve the following LPP, graphically.
Maximize z = 3x − 2y Subject to −2x + 3y ≤ 9 x − 5y ≥ − 20 x, y ≥ 0 [Ans max z = 700, x = 100, y = 200] 11.
Solve graphically the following LPP.
Minimize z = −6x1 − 4x2 Subject to 2x + 3x ≥ 30 1 2 3x + x ≤ 24 1 2 x + x ≥ 3 1 2 x1, x2 ≥ 0 [AnsInfinite number of solutions min z = −48] 45  UNIT 3 SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) 3.1 Introduction In this unit, you shall be looking at the Simplex Algorithm to solve Linear programming prob- lems.
In the last unit, you started the topic in Linear programming Solutions by looking at the graphical and algebraic methods.
And you said that the algebraic method should have three important characteristics, • it should not evaluate any infeasible solution.
• it should be capable of given progressively better basic feasible solutions • it should be able to identify the optimum and terminate when it is reached.
But you discovered that the algebraic method lack this important characteristics.
You are now going to see the Simplex method which possesses these three important characteristics.
You will first of consider the algebraic and the tabular forms of the simplex method.
3.2 Objectives At the end of this unit, you should be able to • Solve linear programming problem using the algebraic Simplex method • Solve linear programming problem using the Taublar form of the Simplex method.
45  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) 3.3 Simplex Algorithm 3.3.1 Algebraic Simplex Method To begin with, here is a simple example.
Example 3.3.1 Consider the product mix problem.
Maximize z = 6x1 + 5x2 Subject to x1 + x2 ≤ 5 (3.1) 3x + 2x ≤ 12 1 2 x , x ≥ 0 1 2 As in the last unit, you should first convert the inequalities to equations as shown below Maximize z = 6x1 + 5x2 + 0x3 + 0x4 Subject to: x1 + x2 + x3 = 5 (3.2) 3x + 2x + x = 12 1 2 4 x1, x2, x3, x4 ≥ 0 Note that slack variables have zero contributions to the objective function, therefore, solving (3.1) is the same as solving (3.2).
One important thing about the Simplex method is that since it should not evaluate any in- feasible solution, you would need to begin to solve with a basic feasible solution, and to do this, you will fix x = 0 and x = 0, so that x = 5 and x = 12.
1 2 3 4 Remark 3.3.1 Infact one of the important things in any linear programming problem is that the constraints should not have a negative value on the right hand side.
If the constraint has a negative value on the right hand side, then you will need to multiply the constraint by -1 to make it non-negative, although the sign of the inequality may be reversed.
So you would make an assumption that all linear programming problem that you solve, the constraint should have a non-negative value of the righthand side.
It can have a zero but it should not have a negative.
Since each of these constraints have a non-negative value on the right hand side, and each of the slack variables appears in only one of the equations, it is now very easy to fix the rest of the variables to zero and have a starting solution of x = 5 and x = 12 which is basic feasible.
It 3 4 is basic because the variables x and x are fixed to zero, and feasible because x and x , each 1 2 3 4 appear only in one of the constraints and are non-negative.
Thus the first basic feasible solution (or the starting solution) for this problem is x = x = 1 2 0, x = 5 and x = 12.
3 4 46  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) Iteration 1 Having identified the basic variables, i.e.
x and x , write this basic variables and the objective 3 4 function in terms of the non-basic variables x and x , as follows, x = 5 − x − x , x = 1 2 3 1 2 4 12 − 3x1 − 2x2 and z = 6x1 + 5x2.
If you set x1 = 0 and x2 = 0, then x3 = 5, x4 = 12 and z = 0.
But you are interested in maximizing the objective function z which right now is zero, with x = x = 0 and are non-basic.
To increase z, you have to increase x and x , since both 1 2 1 2 have strictly positive coefficients.
In Simplex method, the idea is that you should increase one variable at a time.
In other words, you will either increase x or x to maximize z.
But since, 1 2 the coefficient of x , 6 is greater than the coefficient of x , it is better to increase x because the 1 2 1 rate of increase would be higher.
Presently, x = 0.
There will be a limit the value x can take because as you increase x , 1 1 1 you will realize that x and x will decrease.
For instance, if x = 1, x = 0 still, then x = 4 3 4 1 2 3 and x = 9.
Thus, as x increases, x and x start reducing to zero.
Therefore you will increase 4 1 3 4 to a point where one of them becomes zero, otherwise increasing x beyond that will end up 1 making either x or x negative, which would violate the non-negativity restriction, and you do 3 4 not want it.
Now looking at the equations x3 = 5 − x1 − x2 (3.3) and x4 = 12 − 3x1 − 2x2 (3.4) The highest value x can take in (3.3) for x to remain non-negative is 5 and the highest it can 1 3 take in (3.4) for x to remain non-negative is 4.
So the highest value x can take is min 5, 4 = 4.
4 1 A further increase in x would result to a negative value of x and would violate the non- 1 4 negativity restriction.
Hence equation (3.4) becomes the binding equation which determines the highest value x can take.
This leads us to the second iteration.
1 Iteration 2.
Rewriting equation (3.4) for x , you will have and substituting in the rest give you x = 4 − 1 1 23 x2 −1 3 x4, x3 = 5 − (4 −2 3 x2 −1 3 x4) − x2 = 1 −1 3 x2 +1 3 x4 and z = 6(4 −2 3 x2 −1 3 x4) + 5x2 = 24 + x2 − 2x4.
In this iteration, x1 and x3 are basic, while x2 and x4 are non-basic.
Letting x = x = 0, then x = 4, x = 1 and z = 24.
2 4 1 3 This is another basic feasible solution that you have obtained.
It is basic because x = x = 2 4 0 and feasible because the value of the variables are non-negative.
Remember your objective is to increase z = 24 + x − 2x further.
This you can do by 2 4 either increasing x or decreasing x (x has a negative coefficient).
But x is non-basic and 2 4 4 4 already at zero, so you cannot decrease x further, otherwise it will violate the non-negativity 4 restriction.
Also x is non-basic and is zero, So you will increase x in other to increase z.
2 2 47  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) Consider the equations 2 1 x1 = 4 − 3 x2 − 3 x4 (3.5) and 1 1 x3 = 1 − 3 x2 + 3 x4 (3.6) you will observe that the highest value x can take in (3.5) so that x remains feasible is x = 6 2 1 2 and the highest value x can take in (3.6) so that x remains feasible is x = 3.
Thus, for both 2 3 2 variables x and x to remain feasible, the highest value x can take is min 6, 3 = 3 A further 1 3 2 increase for the value of x beyond 3 makes x negative and would violate the non-negativity 2 3 restriction.
Hence equation (3.6) becomes the binding equation which determines the highest value x can take.
This leads us to the third iteration.
2 Iteration 3 Rewriting equation (3.6) for x , you will have and substituting in the rest give you x = 3 − 1 2 3x + x , x = 4 − 2 (3 − 3x + x ) − 1 x = 2 + 3x − x and z = 24 + (3 − 3x + x ) − 2x 3 4 1 3 4 4 3 4 3 4 4 = 3 3 27 − 3x2 − x4.
In this iteration, x1 and x2 are basic, while x3 and x4 are non-basic.
Letting x = x = 0, then x = 2, x = 3 and z = 27.
3 4 1 2 Now, you can check whether you can increase z = 27 − 3x − x further.
To increase z 3 4 further, you can either decrease x or x because both have negative coefficients.
But it is not 3 4 possible to decrease any of x or x because both are already zero and decreasing them will 3 4 make them infeasible.
So you cannot proceed any further from this point to try and increase z further.
Hence you will stop here and conclude that the best solution which is x = 2, x = 3 1 2 and z = 27 have been obtained.
You will notice that this the same solution you obtained with the graphical and the algebraic method.
A close examination of this method shows you that you have done exactly the three impor- tant things you want it to do, which are • it did not evaluate any infeasible solution because you put extra effort to determine the limiting value the entering variables can take so that the non-negativity restriction is not violated.
• it evaluated progressively better basic feasible solutions, because at each time you were only trying to increase the objective function for the maximization problem.
• it terminated immediately the optimum solution is reached.
This is the simplex method represented on algebraic form.
3.3.2 Simplex Method-Tabular Form Here you will see the Simplex method represented in tabular form.
The simplex method is carried out by performing elementary row operations on a matrix you would call the simplex 48  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) tableau.
This tableau consists of the augumented matrix corresponding to the constraints eqau- ations together with the coefficients of the objective function written in the form −c x − c x − · · · − c x + (0)s + (0)s + · · · + (0)s + z = 1 1 2 2 n n 1 1 m 0 In the tableau, it is customary to omit the coefficient of z.
For instance, the simplex tableau for the linear programming problem Maximize z = 4x1 + 6x2 Subject to: −x1 + x2 ≤ 11 (3.7) x + x ≤ 27 1 2 2x + 5x ≤ 90 1 2 By the addition of slack variables x , x and x to the constraints, you can rewrite the above 3 4 5 problem as Maximize z = 4x1 + 6x2 + 0x3 + 0x4 + 0x5 Subject to: −x1 + x2 + x3 = 11 (3.8) x + x + x = 27 1 2 4 2x + 5x + x = 90 1 2 5 Since slack variables have zero contributions to the objective function, solving (3.7) is the same as solving (3.8) Initial Simplex tableau The initial simplex tableau for this problem is as follows B x x x x x x 1 2 3 4 5 B x3 -1 1 1 0 0 11 x4 1 1 0 1 0 27 x 2 5 0 0 1 90 5 z −c -4 -6 0 0 0 0 j j Table 3.1: For this initial simplex tableau, the basic variables are x , x and x , and the non-basic 3 4 5 variables (which have a value of zero) are x and x .
Hence, from the two columns that are 1 2 farthest to the right, you see that the current solution is 49  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) x = 0, x = 0, x = 11, x = 27, and x = 90 1 2 3 4 5 This solution is a basic feasible solution and is often written as (x , x , x , x , x ) = (0, 0, 11, 27, 90) 1 2 3 4 5 The entry in the lower-right corner of the simplex tableau is the current value of z.
Note that the bottom-row entries under x and x are the negatives of the coefficients of x and x in the 1 2 1 2 objective function z = 4x + 6x .
1 2 To perform an optimal check for a solution represented by the simplex tableau, you will look at the entries in the bottom row (z − c row) of the tableau.
If any of these entries are j j negative (as above), then the current solution is not optimal.
3.3.3 Pivoting Once you have set up the initial simplex tableau for a linear programming problem, the simplex method consists of checking for optimality and then, if the current solution is not optimal, improving the current solution.
(An improved solution is one that has a larger z-value than the current solution.)
To improve the current solution, you will bring a new basic variable into the solution-you would call this variable the entry variable.
This implies that one of the current basic variables must leave, otherwise you would have too many variables for a basic solution- you would call this variable the departing variable.
You are to choose the entering and the departing variables as follows.
1.
The entering variable corresponds to the smallest (the most negative) entry in the bottom (i.e.
zj − cj ) row of the tableau.
2.
The departing variable corresponds to the smallest non-negative ratio of b /a in the i ij column determined by the entering variable.
3.
The entry in the simplex tableau in the entring variable’s column and departing variable’s row is called the pivot.
Finally, to form the improved solution, you will apply Gauss-Jordan elimination to the column that contains the pivot, as illustrated in the following example.
(This process is called pivoting.)
Example 3.3.2 Pivoting to Find an Improved Solution.
Use the simplex method to find an improved solution for the linear programming problem rep- resented by the following tableau.
50  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) B x x x x x x 1 2 3 4 5 B x3 -1 1 1 0 0 11 x4 1 1 0 1 0 27 x 2 5 0 0 1 90 5 z −c -4 -6 0 0 0 0 j j Table 3.2: The objective function for this program is z = 4x + 6x .
1 2 ☞ Solution.
Note that the current solution (x = 0, x = 0, x = 11, x = 27, x = 90) 1 2 3 4 5 corresponds to a z-value of 0.
To improve this solution, you determine that x is the entering 2 variable, because −6 is the smallest entry in the z − c row.
j j B x x x x x x 1 2 3 4 5 B x3 -1 1 1 0 0 11 x4 1 1 0 1 0 27 x 2 5 0 0 1 90 5 z −c -4 −6  0 0 0 0 j j Table 3.3: To see why you should choose x as the entering variable, remember that z = 4x + 6x .
2 1 2 Hence, it appears that a unit change in x produces a change of 6 in z, whereas a unit change in 2 x produces a change of only 4 in z.
1 To find the departing variable, you will locate the b ’s that have corresponding positive elements i in the entering variables column and form the following ratios 11 27 90 θ : = 11, = 27, = 18 (3.9) 1 1 5 Here the smallest positive ration is 11, so you will choose x as the departing variable.
3 51  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) B x x x x x x  1 2 3 4 5 B x3 -1 1 1 0 0 11 11  x 4 1 1 0 1 0 27 27 x 2 5 0 0 1 90 18 5 z −c -4 −6  0 0 0 0 j j Table 3.4: Note that the pivot is the entry in the first row and second column.
Now, you will use Gauss-Jordan elimination to obtain the following improved solution.
Before Pivoting After Pivoting     −1 1 1 0 0 11 −1 1 1 0 0 11  1 1 0 1 0 27  -v-  2 0 −1 1 0 16   2 5 0 0 1 90   7 0 −5 0 1 35  −4 −6 0 0 0 0 −10 0 6 0 0 66 The new tableau now appears as follows B x x x x x x 1 2 3 4 5 B x2 -1 1 1 0 0 11 x4 2 0 -1 1 0 16 x 7 0 -5 0 1 35 5 z −c -10 0 6 0 0 66 j j Table 3.5: Note that x has replaced x in the basis column and the improved solution 2 3 (x , x , x , x , x ) = (0, 11, 0, 16, 35) 1 2 3 4 5 has a z-value of z = 4x + 6x = 4(0) + 6(11) = 66 1 2 ✍ Iteration 2 In example 1 the improved solution is not yet optimal since the bottom row still has a negative entry.
Thus, you can apply another iteration of the simplex method to further improve our 52  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) solution as follows.
You choose x as the entering variable.
Moreover, the smallest non-negative 1 ratio 11/(−1), 16/2 = 8, and 35/7 = 5 is 5, so x is the departing variable.
Gauss Jordan 5 elimination produces the following.
B x x x x x x  1 2 3 4 5 B x 2 -1 1 1 0 0 11 _ x 4 2 0 -1 1 0 16 8 x 7 0 -5 0 1 35 5  5 z −c −10  0 6 0 0 66 j j Table 3.6: The pivot is the entry in the third row and the first column.
Pivoting using Gaussian Elimi- nation, you will obtain the following improved solution.
    −1 1 1 0 0 11 −1 1 1 0 0 11  2 0 −1 1 0 16  -v-  2 0 −1 1 0 16   7 0 −5 0 1 35   1 0 −7 5 0 17 5  −10 0 6 0 0 66 − 10 0 6 0 0 66   -v-  010 100 −237577 100 −712717 1566  0 0 −7 8 0 170 116 Thus, the new simplex tableau is as follows B x x x x x x 1 2 3 4 5 B x2 0 1 2/7 0 1/7 16 x4 0 0 3/7 1 -2/7 6 x 1 0 -5/7 0 1/7 5 1 z −c 0 0 -8/7 0 10 / 7 116 j j Table 3.7: In this table, observe that x has replaced x in the basic column and the improved solution 1 5 (x , x , x , x , x ) = (5, 16, 0, 6, 0) 1 2 3 4 5 has a z-value of z = 4x + 6x = 4(5) + 6(16) = 116 1 2 53  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) Third Iteration In this tableau, there is still a negative entry in the bottom row.
Thus, you will choose x as the 3 entry variable and x as the departing variable, as shown in the following tableau.
4 B x x x x x x θ 1 2 3 4 5 B x2 0 1 2/7 0 1/7 16 56 x4 0 0 3/7 1 -2/7 6 14  x 1 0 -5/7 0 1/7 5 _ 1 z −c 0 0 −8 /7  0 10 / 7 116 j j Table 3.8: The pivot entry is the entry in the second row and third column as shown in the table above.
By performing one more iteratioin of the simplex method, you will obtain the following tableau.
B x1 x2 x3 x4 x5 xB x 0 1 0 - 2 1 12 2 3 3 x 0 0 1 7 - 2 14 3 3 3 x1 1 0 0 53 - 13 15 zj − cj 0 0 0 8 10 132 3 7 Table 3.9: Final Tableau 54  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) In this tableau, there are no negative elements in the bottom row.
You have therefore deter- mined the optimal solution to be (x , x , x , x , x ) = (15, 12, 14, 0, 0) 1 2 3 4 5 with z = 4x + 6x = 4(15) + 6(12) = 132.
1 2 Remark 3.3.2 Ties may occur in choosing entering and/or departing variables.
Should this happen, any choice among the tied variables may be made.
Because the linear programming problem in Example 3.3.4 involved only two decision vari- ables, you can use graphical method to solve it, as you did in unit 3.
Notice in Figure 3.3.3 that each iteration in the simplex method corresponds to moving a given vertex to an adjacent vertex with an improved z-value.
x1 30 25 20 (5,16) 15 (15,12) (0,11) 10 5 (27,0) x (0,0) 2 5 10 15 20 25 30 Figure 3.1: The Simplex Method You will summarize the steps involved in the simplex method as follows.
To solve a linear programming problem in standard form, use the following steps.
1. convert each inequality in the set of constraints to an equation by adding slack variables.
2.
Create the initial simplex tableau.
55  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) 3.
Locate the most negative entry in the bottom row.
The column for this entry is the en- tering column.
(If ties occur, any of the tied entries can be used to determine the entring column.)
4.
Form the ratios of the entries in the “b-column” with their corresponding positive entries in the entering column.
The departing column corresponds to the smallest non-negative ration b /a .
(If all entries in the entering column are 0 or negative, then there is no i ij maximum solution.
For ties, choose either entry.)
The entry in the departing now and the entering column is called the pivot.
5.
Use elementary row operations so that the pivot is 1, and all other entries in the entering column are 0.
This process is called pivoting.
6.
If all entries in the bottom row are zero or positive, this is the final tableau.
If not, go back to step 3.
7.
If you obtain a final tableau, then the linear programming problem has a maximum solu- tion, which is given by the entry in the lower-right corner of the tableau.
Note that the basic feasible solution of an initial simplex tableau is (x , x , .
.
.
, x , x , x , .
.
.
, x ) = (0, 0, .
.
.
, 0, b , b , .
.
.
, b ) 1 2 n n+1 n+2 n+m 1 2 m This solution is basic because at most m variables are nonzero (namely the slack vari- ables).
It is feasible because each variable is non-negative.
In the next two examples, you illustrate the use of the simplex method to solve a problem involving three decision variables.
Example 3.3.3 The Simplex Method with Three Decision Variables Use the simlex method to solve the following linear programming problem.
Maximize z = 2x1 − x2 + 2x3 Subject to 2x + x ≤ 10 1 2 x + 2x − 2x ≤ 20 1 2 3 x + 2x ≤ 5 2 3 x , x , x ≥ 0 1 2 3 56  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) ☞ Solution.
By the addition of slack variables x4, x5 and x6, you have the following equivalent form Maximize z = 2x − x + 2x + 0x + 0x + 0x 1 2 3 4 5 6 Subject to 2x + x + x = 10 1 2 4 x + 2x − 2x + x = 20 1 2 3 5 x + 2x + x = 5 2 3 6 x1, x2, x3, x4, x5 ≥ 0 Using the basic feasible solution (x , x , x , x , x , x ) = (0, 0, 0, 10, 20, 5) 1 2 3 4 5 6 the initial simplex tableau for this problem is as follows.
(Try checking these computation and note the “tie” that occurs when choosing the first entering variable.)
B x x x x x x x θ 1 2 3 4 5 6 B x4 2 1 0 1 0 0 10 ∞ x 1 2 -2 0 1 0 20 -10 5 x6 0 1 2 0 0 1 5 52 → z − c -2 1 -2 ↑ 0 0 0 0 j j B x x x x x x x θ 1 2 3 4 5 6 B x4 2 1 0 1 0 0 10 5 → x 1 3 0 0 1 1 25 25 5 x3 0 12 1 0 0 12 52 ∞ z − c -2 ↑ 2 0 0 0 1 5 j j x1 x2 x3 x4 x5 x6 RHS x 1 1 0 1 0 0 5 1 2 2 x 0 5 0 - 1 1 1 20 5 2 2 x3 0 12 1 0 0 12 52 z − c 0 3 0 1 0 1 15 j j 57  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) This implies that the optimal solution is 5 x , x , x , x , x ) = (5, 0, , 0, 20, 0) 1 2 3 4 5 2 and the maximum value of z is 15.
✍ Ocassionally, the constraints in a linear programming problem will include an equation.
In such cases, you still add a “slack variable” called an artificial variable to form the initial simplex tableau.
Techinically, this new variable is not a slack variable (because ther is no slack to be taken).
Once you have determined an optimal solution in such a problem, you should check to see that any equations given in the original constraints are satisfied.
Example 3.3.4 illustrates such a case.
Example 3.3.4 The Simplex Method with Three Decision Variables Use the simplex method to solve the following linear programming problem.
Maximize z = 3x1 + 2x2 + x3 Subject to 4x + x + x = 30 1 2 3 2x + 3x + x ≤ 60 1 2 3 x + 2x + 3x ≤ 40 1 2 3 x , x , x ≥ 0 1 2 3 ☞ Solution.
Once again, by addition of slack variables, x , x and x , you have the 4 5 6 following equivalent form Maximize z = 3x1 + 2x2 + x3 Subject to 4x + x + x + x = 30 1 2 3 4 2x + 3x + x + x = 60 1 2 3 5 x + 2x + 3x + x = 40 1 2 3 6 x1, x2, x3 ≥ 0 Using the basic feasible solution (x , x , x , x , x , x ) = (0, 0, 0, 30, 60, 40) 1 2 3 4 5 6 the initial simplex tableau for this problem is as follows.
(Note that x is an artificial variable, 4 rather than a slack variable.)
This implies that the optimal solution is (x , x , x , x , x , x ) = (3, 18, 0, 0, 0, 1) 1 2 3 4 5 6 and the maximum value of z is 45.
(This solution satisfies the equation given in the constraints because 4(3) + 1(18) + 1(0) = 30.)
✍ 58  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) B x x x x x x x θ 1 2 3 4 5 6 B x4 4 1 1 1 0 0 30 125 → x 2 3 1 0 1 0 60 30 5 x 1 2 3 0 0 1 40 40 6 zj − cj -3 ↑ -2 -1 0 0 0 0 B x x x x x x x θ 1 2 3 4 5 6 B x1 1 14 14 14 0 0 125 30 xx5 00 572 1121 -- 121 10 10 4655 11380 → 6 4 4 4 2 7 zj − cj 0 - 54 ↑ - 14 34 0 0 425 B x1 x2 x3 x4 x5 x6 xB x 1 0 1 3 - 1 0 3 1 5 10 10 x 0 1 1 - 1 2 0 18 2 5 5 5 x6 0 0 152 110 - 170 1 1 zj − cj 0 0 0 12 12 0 45 3.3.4 Applications Example 3.3.5 A Business Application: Maximum Profit A manufacturer produces three types of plastic fixtures.
The time required for molding trimming, and packaging is given in Table 3.10.
(Times are given in hours per dozen fixtures.)
How many dozen of each type of Process Type A Type B Type C Total time available Molding 1 2 3 12, 000 2 Trimming 2 2 1 4, 600 3 3 Packaging 1 1 1 2, 400 2 3 2 Profit $11 $16 $15 − Table 3.10: fixture should be produced to obtain a maximum profit?
☞ Solution.
Letting x , x , and x represent the number of dozen units of Types A, B and 1 2 3 C, respectively, the objective function is given by Profit = P = 11x + 6x + 15x .
1 2 3 Moreover, using the information in the table, you would construct the following constraints.
59  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) x + 2x + 3 x ≤ 12, 000 1 2 2 3 32 x 1 + 32 x2 + x3 ≤ 4, 600 21 x1 + 31 x2 + 21 x3 ≤ 2, 400 with x1, x2, x3 ≥ 0.
The linear programming model of this problem is Maximize P = 11x + 6x + 15x .
1 2 3 x + 2x + 3 x ≤ 12, 1 2 2 3 000 32 x1 + 32 x2 + x3 ≤ 4, 600 21 x1 + 31 x 2 + 21 x3 ≤ 2, 400 x , x , x ≥ 0 1 2 3 Adding slack variables x , x and x to the constraints, gives you 4 5 6 Maximize P = 11x + 6x + 15x .
1 2 3 x + 2x + 3 x + x = 12, 000 1 2 2 3 4 2 x + 2x + x + x = 4, 600 3 1 3 2 3 5 1 x + 1 x + 1x + x = 2, 400 2 1 3 2 2 3 6 x , x , x , x , x , x ≥ 0 1 2 3 4 5 6 Now applying the simplex method with the basic feasible solution (x , x , x , x , x , x ) = (0, 0, 0, 12000, 4600, 2400) 1 2 3 4 5 6 you obtain the following tableau.
From this final tableau, you see that the maximum profit is $100,200, and this is obtained by the following production levels.
Type A: 600 dozen units Type B: 5,100 dozen units ✍ Type C: 800 dozen units.
Remark 3.3.3 In example 3.3.5, note that the second simplex tableau contains a “tie” for the minimum entry in the bottom row.
(Both the first and third entries in the bottom row are -3.)
although you chose the first column to represent the departing variable, you could have chosen the third column.
A trial of this will give the same solution.
Example 3.3.6 A Business Application: Media Selection The advertising alternatives for a company include television, radio, and newspaper advertisements.
The cost and estimates for 60  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) audience coverage are given in Table 3.3.6.
61  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) B x x x x x x x θ 1 2 3 4 5 6 B x 1 2 3 1 0 0 12000 6000 4 2 x5 23 23 1 0 1 0 4600 6900 x6 12 31 12 0 0 1 2400 7200 zj − cj -11 -16 -15 0 0 0 0 x x x x x x RHS θ 1 2 3 4 5 6 x2 12 1 34 12 0 0 6000 12000 x5 13 0 12 - 31 1 0 600 1800 x6 031 0 14 - 61 0 1 400 1200 zj − cj -3 0 -3 8 0 0 96000 x x x x x x RHS θ 1 2 3 4 5 6 x 0 1 3 3 0 - 3 5400 14400 2 8 4 2 x 0 0 1 - 1 1 -1 200 1200 5 4 6 x1 1 0 34 - 12 0 3 1200 1600 zj − cj 0 0 - 34 123 0 9 99600 x x x x x x RHS 1 2 3 4 5 6 x 0 1 0 1 - 3 0 5100 2 2 x 0 0 1 - 2 4 -4 800 3 3 x 1 0 0 0 -3 -3 1200 1 zj − cj 0 0 0 6 3 6 100200 Television Newspaper Radio Cost per advertisement $2,000 $600 $300 Audience per advertisement 100,000 40,000, 18,000 Table 3.11: The local newspaper limits the number of weekly advertisements from a single company to ten.
Moreover, in order to balance the advertising among the three types of media, no more than half of the total number of advertisements should occur on the ratio, and at least 10% should occur on television.
The weekly advertising budget is $18,200.
How many advertisements should be run in each of the three types of media to maximize the total audience?
☞ Solution.
To begin, let x , x , and x represent the number of advertisements in televi- 1 2 3 sion, newpaper, and radio, respectively.
The objective function (to maximize) is therefore z = 100000x1 + 40000x2 + 18000x3 62  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) where x1, x2, x3 ≥ 0.
The constraints for this problem are as follows.
2000x + 600x + 300x ≤ 18200 1 2 3 x ≤ 10 2 x ≤ 0.5(x + x + x ) 3 1 2 3 x ≥ 0.1(x + x + x ) 1 1 2 3 A more manageable form of this system of constraints is as follows  20x + 6x + 3x ≤ 182 1 2 3    x2 ≤ 10  Constraints −x1 − x2 + x3 ≤ 0     −9x1 + x2 + x3 ≤ 0 Putting everything together, you obtain the formulation of the problem as Maximize z = 100000x1 + 40000x2 + 18000x3 Subject to: 20x + 6x + 3x ≤ 182 1 2 3 x ≤ 10 2 −x1 − x2 + x3 ≤ 0 −9x1 + x2 + x3 ≤ 0 Thus, the initial simplex tableau and iteration are shown in the table below.
63  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) x1 x2 x3 x4 x5 x6 x7 RHS θ x4 020 6 3 1 0 0 0 182 9110 x 0 1 0 0 1 0 0 10 5 x -1 -1 1 0 0 1 0 0 6 x7 - 9 1 1 0 0 0 1 0 z − c - 100000 -40000 -18000 0 0 0 0 0 j j x1 x2 x3 x4 x5 x6 x7 RHS θ x1 1 130 220 210 0 0 0 9110 931 x 0 0 1 0 0 1 0 0 10 10 5 x6 0 - 170 2230 210 0 1 0 9110 x7 0 3170 2407 290 0 0 1 81109 83179 z − c 0 -10000 -3000 5000 0 0 0 910000 j j x x x x x x x RHS θ 1 2 3 4 5 6 7 x 1 0 3 1 - 3 0 0 61 122 1 20 20 20 10 3 x2 0 1 0 0 1 0 0 10 x6 0 0 02230 210 170 1 0 11601 14 x7 0 0 4270 290 - 1307 0 1 41409 84978 zj − cj 0 0 0 112830 00 272230 00 602030 0 0 1052000 x x x x x x x RHS 1 2 3 4 5 6 7 x1 1 0 0 213 - 293 - 233 0 4 x 0 1 0 0 1 0 0 10 2 x3 0 0 1 213 1243 2203 0 14 x7 0 0 0 283 - 12138 - 4273 1 12 zj − cj 0 0 0 112830 00 272230 00 602030 0 0 1052000 From this tableau, you see that the maximum weekly audience for an advertising budget of %18200 is z = 1, 052, 000 Maximum weekly audience and this occurs when x = 4, x = 10, and x = 14.
The result is sum up here.
1 2 3 Number of Media Advertisements Cost Audience Television 4 $8,000 400,000 Newpaper 10 $6,000 400,000 Radio 14 $4,200 252,000 Total 28 $18,200 1,052,000 ✍ 64  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) 3.3.5 Minimization Problem A minimization problem is in standard form if it is of the form Minimize w = c x + c x + · · · + c x 1 1 2 2 n n Subject to a11x1 + a12x2 + · · · + a1nxn ≥ b1 a21x1 + a22x2 + · · · + a2nxn ≥ b2 (3.10) .
a x + a x + · · · + a x ≥ b m1 1 m2 2 mn n m where xi ≥ 0 and bi ≥ 0.
The basic procedure used to solve such a problem is to convert it to a maximization problem in standard form, and then apply the simplex method as discussed in unit 4.
Example 3.3.7 Minimization Problem.
Solve the following.
Minimize w = 0.12x1 + 0.15x2 Subject to 60x + 60x ≥ 300 1 2 12x + 66x ≥ 336 1 2 10x + 30x ≥ 390 1 2 x , x ≥ 0 1 2 By graphical method the solution to this problem is given by Figure 3.2: Now using the simplex method, The first step in conveting this problem to a maximization problem is to form the augmented matrix for this system of inequalities.
To this augmented matrix you add a last row that represents the coefficients of the objective function, as follows.
  60 60 .
300    12 6 .. 36     10 30 .
90     · · · · · · · · · · · ·  0.12 0.15 .
0 Next, form the transpose of this matrix by interchanging its rows and columns.
65  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS)   60 12 10 .
0.12    .
  60 6 30 .
0.15     · · · · · · · · · · · · · · ·  300 36 90 .
0 Note that the rows of this matrix are the columns of the first matrix, and vice versa.
Finally, interpret the new matrix as a maximization problem as follows.
(To do this, we introduce new variables, y , y , and y .)
You call this corresponding maximization problem the dual of the 1 2 3 original minimization problem.
Dual Maximization Problem Maximize z = 300y + 36y + 90y Dual objective function 1 2 3  Subject to 60y1 + 12y2 + 10y3 ≤ 0.12  Dual contraints  60y1 + 6y2 + 30y3 ≤ 0.15 where y ≥ 0, y ≥ 0 and y ≥ 0.
1 2 3 As it turns out, the solution of the original minimization problem can be found by applying the simplex method to the new dual problem, as follows.
y y y y y RHS θ 1 2 3 4 5 y4 060 12 10 1 0 0.12 0.002 y 60 6 30 0 1 0.15 0.004 5 zj − cj - 300 -36 -90 0 0 0 Table 3.12: Initial Tableau and Iteration 1 y y y y y RHS θ 1 2 3 4 5 y1 1 15 16 6 10 0 510 0 2 530 y5 0 -6 020 -1 1 130 0 2 0 30 0 zj − cj 0 24 40 5 0 35 y y y y y RHS θ 1 2 3 4 5 y1 1 14 0 410 - 112 0 4 0 70 0 235 0 y3 0 - 130 1 - 210 210 2 0 30 0 2 0 30 0 zj − cj 0 12 0 3 2 3530 ↑ ↑ x x 1 2 Thus, the solution of the dual maximization problem is z = 33 = 0.66.
This is the same 50 value you obtained using graphical method.
The x-values corresponding to this optimal solution are obtained from the entries in the bottom row corresponding to slack variable columns.
In other words, the optimal solution occurs when x = 3 and x = 2.
1 2 66  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) The fact that a dual maximization problem has the same solution as its original minimization problem is stated formally in a result called the von Neumann Duality Principle, after the American mathematician John von Neumann (1903-1957).
Theorem 3.3.1 The von Neumann Duality Principle The objective value w of a minimization problem in standard form has a minimum value if and only if the objective value z of the dual maximization problem has a maximum value.
Moreover, the minimum value of w is equal to the maximum value of z.
Solving a Minimization Problem The steps involved in solving a minimization problem is summarized as follows.
A minimization problem is in standard form if it is as follows; Minimize w = c1x1 + c2x2 + · · · + cnxn Subject to: a11x1 + a12x2 + · · · + a1nxn ≥ b1 a21x1 + a22x2 + · · · + a2nxn ≥ b2 .
am1x1 + am2x2 + · · · + amnxn ≥ bm where x ≥ 0 and b ≥ 0.
To solve this problem you use the following steps j i 1.
Form the augmented matrix for the given system of inequalities, and add a bottom row consisting of the coefficients of the objective function.
  a11 a12 · · · a1n .
b1    a21 a22 · · · a2n .
b2     · · · · · ·     am1 am2 · · · amn .. bm  .
 · · · · · · · · · · · · .
· · ·  c1 c2 · · · cn .
0 2.
Form the transpose of this matrix.
  .
a11 a21 · · · am1 .
c1    a12 a22 · · · am2 .
c2     · · · · · ·     a1n a2n · · · amn .. cn  .
 · · · · · · · · · · · · .
· · ·  b1 b2 · · · bn .
0 67  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) 3.
Form the dual maximization problem corresponding to this transposed matrix.
That is, Maximize z = b1y1 + b2y2 + · · · + bnyn Subject to: a y + a y + · · · + a y ≤ c 11 1 21 2 m1 m 1 a12y1 + a22y2 + · · · + am2ym ≤ c2 .
a1ny1 + a2ny2 + · · · + amnym ≤ cn where y ≥ 0, y ≥ 0 and y ≥ 0 1 2 m 4.
Apply the simplex method to the dual maximization problem.
The maximum value of z will be the minimum value of w. Moreover, the values of x , x , .
.
.
, x will occur in 1 2 n the bottom row of the final simplex tableau, in the columns corresponding to the slack variables.
Example 3.3.8 Solving a Minimization Problem Solve the following minimization problem.
Minimize w = 3x1 + 2x2 Subject to: 2x + x ≥ 6 1 2 x + x ≥ 4 1 2 x , x ≥ 0 1 2 ☞ Solution.
The augmented matrix corresponding to this minimization problem is   2 1 .
6    1 1 .
4     .
  · · · · · · .
· · ·  6 4 .
0 Thus, the matrix corresponding to the dual maximization problem is given by the following transpose.
  2 1 .
3      1 1 .
2     .
  · · · · · · .
· · ·  3 2 .
0 68  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) This implies that the dual maximization problem is as follows.
Dual Maximization Problem: Maximize z = 6y1 + 4y2 Subject to: 2y + y ≥ 3 1 2 y + y ≥ 4 1 2 y , y ≥ 0 1 2 You will now apply the simplex method to the dual problem as follows.
Basic variables ↓ y y y y RHS(b) 1 2 3 4 y3 02 1 1 0 3 → Departing y 1 1 0 1 2 4 z − c -6 -4 0 0 0 j j ↑ Entering Basic variables ↓ y y y y RHS(b) 1 2 3 4 y 1 1 1 0 3 1 2 2 2 y4 0 021 - 21 1 12 → Departing z − c 0 -1 3 0 9 j j ↑ Entering Basic variables ↓ y y y y RHS(b) 1 2 3 4 y 1 0 1 -1 1 1 y 0 1 -1 2 1 2 z − c 0 0 2 2 10 j j ↑ ↑ x x 1 2 Table 3.13: 69  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) From this final simplex tableau, you see that the maximum value of z is 10.
Therefore, the solution of the original minimization problem is w = 10 and this occurs when x = 2 and x = 2 ✍ 1 2 Both the minimization and the maximization linear programming problems in Example 3.3.8 could have been solved with a graphical method, as indicated in Figure 3.3.
Note in Figure 3.3(a) that the maximum value of z = 6y1 − 4y2 is the same as the minimum value of w = 3x + 2x , as shown in Figure 3.3 (b).
1 2 Figure 3.3: Example 3.3.9 Solving a Minimization Problem Solve the following linear programming problem.
Minimize w = 2x1 + 10x2 + 8x3 Subject to: x + x + x ≥ 6 1 2 3 x + 2x ≥ 8 2 3 −x + 2x + 2x ≥ 4 1 2 3 x , x , x ≥ 0 1 2 3 ☞ Solution.
The augmented matrix corresponding to this minimization problem is   1 1 1 .
6    .
 0 1 2 .
8      −1 2 2 .. 4       · · · · · · · · · .
· · ·  2 10 8 .
0 Thus, the matrix corresponding to the dual maximization problem is given by the following transpose.
  1 0 −1 .
2    .
 1 1 2 .
10      1 2 2 .
4   .
  · · · · · · · · · .
· · ·  6 8 4 .
0 70  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) This implies that the dual maximization problem is as follows.
Dual Maximization Problem: Maximize z = 6y1 + 8y2 + 4y3 Subject to: y − x ≥ 2 1 3 y + y + 2y ≥ 10 1 2 3 y + 2y + 2y ≥ 8 1 2 3 y , y , y ≥ 0 1 2 3 Now apply the simplex method to the dual problem as follows.
Basic variables ↓ y y y y y y RHS(b) 1 2 3 4 5 6 y4 1 0 -1 1 0 0 2 y 1 1 2 0 1 0 10 5 y6 1 02 2 0 0 1 8 → Departing z − c -6 -8 -4 0 0 0 0 j j ↑ Entering Basic variables ↓ y y y y y y RHS(b) 1 2 3 4 5 6 y4 01 0 -1 1 0 0 2 → Departing y5 12 0 1 0 1 - 21 6 y2 12 1 1 0 0 12 4 z − c -2 -0 4 0 0 4 32 j j ↑ Entering Basic variables ↓ y y y y y y RHS(b) 1 2 3 4 5 6 y 1 0 -1 1 0 0 2 1 y5 0 0 32 - 21 1 - 21 5 y2 0 1 32 - 21 0 12 3 z − c 0 0 2 2 0 4 36 j j ↑ ↑ ↑ x x x 1 2 3 Table 3.14: Final Tableau 71  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) From this final simplex tableau, you see that the maximum value of z is 36.
Therefore, the solution of the original minimization problem is w = 36 Minimum Value and this occurs when x = 2, x = 0, and x = 4.
✍ 1 2 3 3.3.6 Applications Example 3.3.10 A Business Application: Minimum Cost A small petroleum company owns two refineries.
Refinery 1 costs $20,000 per day to operate, and it can produce 400 barrels of high-grade oil, 300 barrels of medium-grade oil, and 200 barrels of low-grade oil each day.
Refinery 2 is newer and more modern.
It costs $25,000 per day to operate, and it can produce 300 barrels of high-grade oil, 400 barrels of medium-grade oil, and 500 barrels of low-grade oil each day.
The company has orders totaling 25,000 barrels of high-grade oil, 27,000 barrels of medium- grade oil, and 30,000 barrels of low-grade oil.
How many days should it run each refinery to minimize its costs and still refine enough oil to meet its orders?
☞ Solution.
To begin, let x and x represent the number of days the two refineries are 1 2 operated.
Then the total cost is given by C = 20000x + 25000x Objective function 1 2 The constraints are given by  (High-grade) 400x + 300x ≥ 25000 1 2    (Medium-grade) 300x + 400x ≥ 27000 Constraints 1 2   (Low-grade) 200x + 500x ≥ 30000 1 2 where x1 ≥ 0 and x2 ≥ 0.
Thus the linear programming model of this problem is as follows Minimize C = 20000x1 + 25000x2 Subject to: 400x + 300x ≥ 25000 1 2 300x + 400x ≥ 27000 1 2 200x + 500x ≥ 30000 1 2 x , x ≥ 0 1 2 The augumented matrix corresponding to this minimization problem is.
The augumented matrix corresponding to this minimization problem is 72  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS)   400 300 .
25000    .
 300 400 .
27000      200 500 .
30000    .
 · · · · · · .
· · ·  20000 25000 .
0 The matrix corresponding to the dual maximization problem is given by the transpose of the augumented matrix below   400 300 200 .
20000      300 400 500 .
25000     · · · · · · · · · .
· · ·  25000 27000 30000 .
0 Applying the simplex method to the dual problem as follows.
Basic variables ↓ y y y y y RHS(b) 1 2 3 4 5 y4 400 300 200 1 0 20000 y5 300 400 5000 0 1 25000 → Departing z − c -25000 -27000 -30000 0 0 0 j j ↑ Entering Basic variables ↓ y y y y y RHS(b) 1 2 3 4 5 y4 2080 140 0 1 - 25 10000 → Departing y3 35 45 1 0 510 0 50 zj − cj -7000 -3000 0 0 60 1500000 ↑ Entering Basic variables ↓ y y y y y RHS(b) 1 2 3 4 5 y1 1 12 0 218 0 - 710 0 275 0 y3 0 12 1 - 1 4 30 0 315 0 270 0 z − c 0 500 0 25 50 1750000 j j ↑ ↑ x x 1 2 From the third simplex tableau, we see that the solution to the original minimization problem 73  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) is C = $1750000 Minimum cost and this occurs when x = 25 and x = 50.
Thus, the two refineries should be operated for the 1 2 following number of days.
Refinery 1: 25 days Refinery 2: 50 days Note that by operating the two refineries for this number of days, the company will have pro- duced the following amounts of oil.
High-grade oil: 25(400) + 50(300) = 25000 barrels Medium-grade oil: 25(300) + 50(400) = 27500 barrels Low-grade oil: 25(200) + 50(500) = 30000 barrels Thus, the original production level has been met (with a surplus of 500 barrels of medium-grade oil).
✍ 3.4 Conclusion In this unit you considered how to solve linear programming problem using simplex method- Algebraic and tabular form.
You have learnt how to solve a linear programming problem which has a maximization objective function using the simplex method.
and also considered how to solve a linear programming problem with minimization type-objective function.
3.5 Summary Having gone through this unit, you now know how to solve linear programming problem using the algebraic and tabular simplex algorithms.
3.6 Tutor Marked Assignments(TMAs) Exercise 3.6.1 In Exercises 1-4, write the simplex tableau for the given linear programming problem.
You do not need to solve the problem.
74  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) Maximize z = x1 + 2x2 Subject to 2x1 + x2 ≤ 8 1. x1 + x2 ≤ 5 x , x ≥ 0 1 2 Maximize z = x1 + 3x2 Subject to x + x ≤ 4 1 2 2. x1 − x2 ≤ 1 x , x ≥ 0 1 2 Maximize z = 2x1 + 3x2 + 4x3 Subject to x + 2x ≤ 12 1 2 3. x1 + x3 ≤ 8 x , x , x ≥ 0 1 2 3 Maximize z = 6x1 − 9x2 Subject to 2x − 3x ≤ 6 1 2 4. x1 + x2 ≤ 20 x , x ≥ 0 1 2 In Exercises 5-8, Explain why the linear programming problem is not in standard form as given.
Minimize z = x1 + x2 5.
Subject to x1 + 2x2 ≤ 4 x , x ≥ 0 1 2 Maximize z = x1 + x2 Subject to x + 2x ≤ 6 1 2 6.
2x1 − x2 ≤ −1 x , x ≥ 0 1 2 75  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) Maximize z = x1 + x2 Subject to x1 + x2 + 3x3 ≤ 12 7.
2x1 − 2x3 ≥ 1 x + x ≤ 0 2 3 x , x , x ≥ 0 1 2 3 Maximize z = x1 + x2 Subject to x + x ≥ 4 1 2 8.
2x1 + x2 ≥ 6 x , x ≥ 0 1 2 In Exercises 9-20, use the simplex method to solve the given linear programming prob- lem.
9.
Maximize z = x1 + 2x2 Subject to: x + 4x ≤ 8 1 2 x + x ≤ 12 1 2 x , x ≥ 0 1 2 10.
Maximize z = x1 + 2x2 Subject to: x + 2x ≤ 6 1 2 3x + 2x ≤ 12 1 2 x , x ≥ 0 1 2 11.
Maximize z = 5x1 + 2x2 + 8x3 Subject to: 2x − 4x + x ≤ 42 1 2 3 2x + 3x − x ≤ 42 1 2 3 6x − x + 3x ≤ 42 1 2 3 x , x , x ≥ 0 1 2 3 12.
Maximize z = x1 − x2 + 2x3 76  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) Subject to: 2x1 + 2x2 ≤ 8 x ≤ 5 3 x , x , x ≥ 0 1 2 3 13.
Maximize z = 4x1 + 5x2 Subject to: x + x ≤ 10 1 2 3x + 7x ≤ 42 1 2 x , x ≥ 0 1 2 14.
Maximize z = x1 + 2x2 Subject to: x + 3x ≤ 15 1 2 2x − x ≤ 1 2 12 x , x ≥ 0 1 2 15.
Maximize z = 3x1 + 4x2 + x3 + 7x4 Subject to: 8x + 3x + 4x + x ≤ 7 1 2 3 4 2x + 6x + x + 5x ≤ 3 1 2 3 4 x + 4x + 5x + 2x ≤ 8 1 2 3 4 x , x , x , x ≥ 0 1 2 3 4 16.
Maximize z = x1 Subject to: 3x + 2x ≤ 60 1 2 x + 2x ≤ 28 1 2 x + 4x ≤ 48 1 2 x , x ≥ 0 1 2 17.
Maximize z = x1 − x2 + x3 Subject to: 2x1 + x2 − x3 ≤ 40 x + x ≤ 25 1 3 2x + 3x ≤ 32 2 3 x , x , x ≥ 0 1 2 3 77  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) 18.
Maximize z = 2x1 + x2 + 3x3 Subject to: x + x + x ≤ 59 1 2 3 2x + 3x ≤ 75 1 3 x + 6x ≤ 54 2 3 x , x , x ≥ 0 1 2 3 19.
Maximize z = x1 + 2x2 − x4 Subject to: x1 + 2x2 + 3x3 ≤ 24 3x + 7x + x ≤ 42 2 3 4 x , x , x , x ≥ 0 1 2 3 4 20.
Maximize z = x1 + 2x2 + x3 − x4 Subject to: x1 + x2 + 3x3 + 4x4 ≤ 60 x + 2x + 5x ≤ 50 2 3 4 2x + 3x + 6x ≤ 72 1 2 4 x , x , x , x ≥ 0 1 2 3 4 Exercise 3.6.2 In Exercise 1-6, determine the dual of the given minimization problem.
1.
Minimize w = 3x1 + 3x2 Subject to: 2x + x ≥ 15 1 2 x + x ≥ 12 1 2 x , x ≥ 0 1 2 2.
Minimize w = 2x1 + x2 Subject to: 5x + x ≥ 9 1 2 2x + 2x ≥ 10 1 2 x , x ≥ 0 1 2 3.
Minimize w = 4x1 + x2 + x3 78  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) Subject to: 3x1 + 2x2 + x3 ≥ 23 x + x ≥ 10 1 3 8x + x + 2x ≥ 40 1 2 3 x1, x2, x3 ≥ 0 4.
Minimize w = 9x1 + 6x2 Subject to: x + 2x ≥ 5 1 2 2x + 2x ≥ 8 1 2 2x + x ≥ 6 1 2 x , x ≥ 0 1 2 5.
Minimize w = 14x1 + 20x2 + 24x3 Subject to: x + x + 2x ≥ 7 1 2 3 x + 2x + x ≥ 4 1 2 3 x , x , x ≥ 0 1 2 3 6.
Minimize w = 9x1 + 4x2 + 10x3 Subject to: 2x + x + 3x ≥ 6 1 2 3 6x + x + x ≥ 9 1 2 3 x , x , x ≥ 0 1 2 3 In Exercises 7-12, (a) solve the given minimization problem by the graphical method, (b) formulate the dual problem, and (c) solve the dual problem by the graphical method.
7.
Minimize w = 2x1 + 2x2 Subject to: x + 2x ≥ 3 1 2 3x + 2x ≥ 5 1 2 x , x ≥ 0 1 2 8.
Minimize w = 14x1 + 20x2 Subject to: x + 2x ≥ 4 1 2 7x + 6x ≥ 20 1 2 x , x ≥ 0 1 2 79  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) 9.
Minimize w = x1 + 4x2 Subject to: x + x ≥ 3 1 2 −x + 2x ≥ 2 1 2 x , x ≥ 0 1 2 10.
Minimize w = 2x1 + 6x2 Subject to: −2x + 3x ≥ 0 1 2 x + 3x ≥ 9 1 2 x , x ≥ 0 1 2 11.
Minimize w = 6x1 + 3x2 Subject to: 4x + x ≥ 4 1 2 x ≥ 2 2 x , x ≥ 0 1 2 12.
Minimize w = x1 + 6x2 Subject to: 2x + 3x ≥ 15 1 2 −x + 2x ≥ 3 1 2 x , x ≥ 0 1 2 In Exercises 13-29, solve the given minimzation problem by solving the dual maximiza- tion problem with the simplex method.
13.
Minimize w = x2 Subject to: x + 5x ≥ 10 1 2 −6x + 5x ≥ 3 1 2 x , x ≥ 0 1 2 14.
Minimize w = 3x1 + 8x2 Subject to: 2x + 7x ≥ 9 1 2 x + 2x ≥ 4 1 2 x , x ≥ 0 1 2 15.
Minimize w = 2x1 + x2 80  UNIT 3.
SIMPLEX ALGORITHM (ALGEBRAIC AND TABULAR FORMS) Subject to: 5x1 + x2 ≥ 9 2x + 2x ≥ 10 1 2 x , x ≥ 0 1 2 16.
Minimize w = 2x1 + 2x2 Subject to: 3x + x ≥ 6 1 2 −4x + 2x ≥ 2 1 2 x , x ≥ 0 1 2 17.
Minimize w = 8x1 + 4x2 + 6x3 Subject to: 3x + 2x + x ≥ 6 1 2 3 4x + x + 3x ≥ 7 1 2 3 2x + x + 4x ≥ 8 1 2 3 x , x , x ≥ 0 1 2 3 18.
Minimize w = 8x1 + 16x2 + 18x3 Subject to: 2x + 2x − 2x ≥ 4 1 2 3 −4x + 3x − x ≥ 1 1 2 3 x − x + 3x ≥ 8 1 2 3 x , x , x ≥ 0 1 2 3 19.
Minimize w = 6x1 + 2x2 + 3x3 Subject to: 3x + 2x + x ≥ 28 1 2 3 6x + x ≥ 24 1 3 3x + x + 2x ≥ 40 1 2 3 x , x , x ≥ 0 1 2 3 20.
Minimize w = 42x1 + 5x2 + 17x3 Subject to: 3x − x + 7x ≥ 5 1 2 3 −3x − x + x ≥ 8 1 2 3 6x + x + x ≥ 16 1 2 3 x , x , x ≥ 0 1 2 3 81  UNIT 4 ARTIFICIAL VARIABLES TECHNIQUE 4.1 Introduction LPP in which constraints may also have ≥ and = signs after ensuring that all b ≥ 0 i are considered in this section.
In such cases basis matrix cannot be obtained as an identify matrix in the starting simplex table, therefore you have to introduce a new type of variable called the artifical variable.
These variables are fictitious and cannot have any physical meaning.
The artifical variable technique is merely a device to get the starting basic feasible solution, so that simplex procedure may be adopted as usual until the optimal solution is obtained.
4.2 Objectives In this section you shall learn two methods for solving LPP in which you have to introduce artifical variables.
The methods are 1.
The Charne’s Big M Method or the Method of Penalties.
2.
The Two-Phase Simplex Method.
4.3 Main Content 4.3.1 The Charne’s Big M Method The following steps are involved in solving an LPP using the Big M method.
Step 1.
Express the problem in the standard form.
81  UNIT 4.
ARTIFICIAL VARIABLES TECHNIQUE Step 2.
Add non-negative artificial variables to the left side of each of the equations corre- sponding to constraints to the type ≥ or = .
However, addition of these artificial variables causes violation of the corresponding constraints.
Therefore, you would like to get rid of these variables and not allow them to appear in the final solutions.
This is achieved by assigning a very large penalty (-M for maximization and M for minimization) in the objective function.
Step 3.
Solve the modified LPP by simplex method, until any one of the three cases may arise.
1.
If no artifical variable appears in the basis and the optimality conditions are satisfied, then the current solution is an optimal basic feasible solution.
2.
If at least one artificial variable in the basis at zero level and the optimality condition is satisfied, then the current solution is an optimal basic feasible solution (though degenerated).
3.
If at least one artificial varialble appears in the basis at positive level and the opti- mality condition is satisfied, then the original problem has no feasible solution.
The solution satisfies the constraints but does not optimize the objective function, since it contains a very large penalty M and is called pseudo optimal solution.
Note: While applying simplex method, whenever an artifical variable happens to leave the basis, you have to drop that artificial variable and omit all the entries corresponding to its column from the simplex table.
Example 4.3.1 Use penalty method to solve the following problem Maximize z = 3x1 + 2x2 Subject to: 2x + x ≤ 2 1 2 3x + 4x ≥ 12 1 2 x , x ≥ 0 1 2 ☞ Solution.
By introducing slack variable slack variable x ≥ 0, surplus variable x ≥ 0 3 4 and artificial variable A1 ≥ 0, the given LPP can be reformulated as: Maximize z = 3x1 + 2x2 + 0x3 + 0x4 − M A1 Subject to: 2x + x + x = 2 1 2 3 3x + 4x − x + A = 12 1 2 4 1 x , x ≥ 0 1 2 The starting feasible solution is x = 2, A = 12.
3 1 82  UNIT 4.
ARTIFICIAL VARIABLES TECHNIQUE Initial tableau B x x x x A x θ 1 2 3 4 1 B x3 2 1 1 0 0 2 2 → A 3 4 0 -1 1 12 3 1 zj − cj -3M -3 -4M -2 0 M 0 -12M ↑ Since some of the z − c ≤ 0, the current feasible solution is not optimum.
Choose the j j most negative z − c = −4M − 2.
Therefore x variable enters the basis, and the basic j j 2 variable x leaves the basis.
3 First Iteration B x1 x2 x3 x4 A1 xB x2 2 1 1 0 0 2 A -5 0 -4 -1 1 4 1 zj − cj 5M +1 0 4M +2 M 0 4-4M Since all zj − cj ≥ 0 and an artificial variable appears in the basis, at positive level, the given LPP does not possess any feasible solution.
But the LPP possesses a pseudo optimal solution.
✍ Example 4.3.2 Solve the LPP.
Minimize z = 4x1 + x2 Subject to: 3x + x = 3 1 2 4x + 3x ≥ 6 1 2 x + 2x ≤ 4 1 2 x , x ≥ 0 1 2 83  UNIT 4.
ARTIFICIAL VARIABLES TECHNIQUE ☞ Solution.
Since the objective function is minimization, you have to convert it to maximiza- tion using min z = − max(−z) = − max z∗ , where z∗ = −z, so that you have Minimize z∗ = −4x − 1 x2 Subject to: 3x + x = 3 1 2 4x + 3x ≥ 6 1 2 x + 2x ≤ 4 1 2 x , x ≥ 0 1 2 Convert the given LPP into standard form by adding artificial variables A , A , surplus variable 1 2 x and slack variable x to get the initial basic feasible solution.
3 4 Minimize z∗ = −4x − x + 0x + 0x − M A + M 1 2 3 4 1 A2 Subject to: 3x + x + A = 3 1 2 1 4x + 3x − x + A = 6 1 2 3 2 x + 2x + x = 4 1 2 4 x , x , x , x , A , A ≥ 0 1 2 3 4 1 2 The starting feasible solution is A = 3, A = 6, x = 4.
1 2 4 Initial solution B x x A x A x x θ 1 2 1 3 2 4 B A 3 1 1 0 0 0 3 3 1 A 4 3 0 -1 1 0 6 2 2 x4 1 2 0 0 0 1 4 2 → z − c -7M +4 -4M +1 0 M 0 0 -9M j j ↑ Since some of the zj − cj ≤ 0, the current feasible solution is not optimum.
x2 enters the basis and the basic variable x leaves the basis.
4 84  UNIT 4.
ARTIFICIAL VARIABLES TECHNIQUE First Iteration B x x A x A x x θ 1 2 1 3 2 4 B A1 5/2 0 1 0 0 -1/2 3/2 3/5 A2 5/2 0 0 -1 1 -3/2 3/2 3/5 → x 1/2 1 0 0 0 1/2 3/2 3 2 zj − cj -5M +7/2 0 0 M 0 2M -1/2 -3M -3/2 ↑ Since z1 −c1 is negative, the current feasible solution is not optimum.
Therefore, x1 variable enters the basis and the artificial variable A leaves the basis.
2 Second Iteration B x x A x x x θ 1 2 1 3 4 B A1 0 0 1 1 1 0 0 → x1 1 0 0 -2/5 -3/5 3/5 − x2 0 1 0 -1/5 4/5 6/5 − z − c 0 0 0 -M +9/5 -M +8/5 -18/5 j j ↑ Since z4 − c4 is most negative, x3 enters the basis and the artificial variable A1 leaves the basis.
Third Iteration B x x x x x θ 1 2 3 4 B x3 0 0 1 1 0 0 → x1 1 0 0 -1/5 3/5 − x2 0 1 0 1 6/5 6/5 zj − cj 0 0 0 -1/5 -18/5 ↑ Since z4 − c4 is most negative, x4 enters the basis and x3 leaves the basis.
85  UNIT 4.
ARTIFICIAL VARIABLES TECHNIQUE Fourth Iteration B x1 x2 x3 x4 xB x 0 0 1 1 0 4 x 1 0 1/5 0 3/5 1 x2 0 1 0 0 6/5 z − c 0 0 1/5 0 -18/5 j j Since all z − c ≥ 0, the solution is optimum and is given by x = 3/5, x = 6/5, and j j 1 2 max z = −18/5.
Therefore min z = − max(−z) = 18/5.
✍ Example 4.3.3 Solve the LPP by the Big M method.
Maximize z = x1 + 2x2 + 3x3 − x4 Subject to: x + 2x + 3x = 15 1 2 3 2x + x + 5x = 20 1 2 3 x + 2x + x + x = 4 1 2 3 4 x , x ≥ 0 1 2 ☞ Solution.
Since the constraints are equations, introduce artificial variables A , A ≥ 0.
1 2 The reformulated problem is given as follows Maximize z = x1 + 2x2 + 3x3 − x4 − M A1 − M A2 Subject to: x + 2x + 3x + A = 15 1 2 3 1 2x + x + 5x + A = 20 1 2 3 2 x + 2x + x + x = 4 1 2 3 4 x , x ≥ 0 1 2 The Initial solution is given by A = 15, A = 20, and x = 10.
1 2 4 86  UNIT 4.
ARTIFICIAL VARIABLES TECHNIQUE Initial solution B x x x x A A x θ 1 2 3 4 1 2 B A 1 2 3 0 1 0 15 5 1 A2 2 1 5 0 0 1 20 4 → x 1 2 1 1 0 0 10 10 4 zj − cj -3M -2 -3M -4 -8M -4 0 0 0 -35M -10 ↑ Since z3 − c3 is most negative, x3 enters the basis and the basic variable A2 leaves the basis.
First Iteration B x x x x A x θ 1 2 3 4 1 B A1 -1/5 7/5 0 0 1 3 15/7 → x 2/5 1/5 1 0 0 4 20 3 x4 3/5 9/5 0 1 0 6 30/9 zj − cj 1/5M -2/5 -7/5M -16/5 0 0 0 -3M +4 ↑ Since z2 − c2 is most negative, x2enters the basis and the basic variable A1 leaves the basis.
Second Iteration B x x x x x θ 1 2 3 4 B x2 -1/7 1 0 0 15/7 15/7 → x 3/7 0 1 0 25/7 20 3 x4 6/7 0 0 1 15/7 30/9 zj − cj -6/7 0 0 0 90/7 ↑ Since z − c is most negative, the current feasible solution is not optimum.
Therefore, x 1 1 1 enters the basis and the basis and the basic variable x leaves the basis 4 87  UNIT 4.
ARTIFICIAL VARIABLES TECHNIQUE Third Iteration B x1 x2 x3 x4 xB x 0 1 0 1/6 15/6 2 x 0 0 1 3/6 15/6 3 x1 1 0 0 7/6 15/6 zj − cj 0 0 0 4 15 Since all z − c ≥ 0, the solution is optimum and is given by x = x = x = 15/6 = 5/2 j j 1 2 3 and max z = 15.
✍ 4.3.2 The Two-Phase Simplex Method The two-phase method is another method to solve a given LPP involving some artifical vari- ables.
The solution is obtained in two phases.
Phase I In this phase, you have to construct an auxilliary LPP leading to a final simplex tableau con- taining a basic feasible solution to the original problem.
Step 1 Assign a cost -1 to each artificial variable and a cost 0 to all other variables and get a new objective function z∗ = −A − A − · · · 1 2 − where A are artificial variables.
i Step 2 Write down the auxiliary LPP in which the new objective function is to be maximized, subject to the given set of constraints.
Step 3 Solve the auxiliary LPP by simplex method until either of the following three cases arise: (i) Max z∗ < 0 and at least one artificial variable appears in the optimum basis at positive level.
(ii) Max z∗ = 0 and at least one artificial variable appears in the optimum basis at zero level.
(iii) Max z∗ = 0 and no artificial variable appears in the optimum basis.
In case (i), given LPP does not possess any feasible solution.
where as in cases (ii) and (iii) you go to phase II.
88  UNIT 4.
ARTIFICIAL VARIABLES TECHNIQUE Phase II Use the optimum basic feasible solution of phase I as a starting solution for the solution for the original LPP.
Assign the actual costs to the variable in the objective function and a zero cost to every artifical variable in the basis at zero level.
Delete the artifical variable column that is eliminated from the basis in phase 1 from the table.
Apply simplex method to the modified simplex table obtained at the end of phase 1 till an optimum basic feasible solution is obtained or till there is an indication of unbounded solution.
Example 4.3.4 Use two-phase simplex method to solve, Maximize z = 5x1 + 3x2 Subject to 2x + x ≤ 1 1 2 x + 4x ≥ 6 1 2 x , x ≥ 0.
1 2 ☞ Solution.
Convert the given problem into a standard form by adding slack, surplus and artificial variables.
You from the auxiliary LPP by assigning the cost -1 to the artifical variable and 0 to all the other variables.
Phase 1 Maximize z∗ = 0x1 + 0x2 + 0x3 + 0x4 − 1A1 2x + x + x = 1 1 2 3 x1 + 4x2 − x4 + A1 = 6 x , x , x , x , A ≥ 0 1 2 3 4 1 Initial basic feasible solution is given by x = 1, A = 6.
3 1 B x x x x A x θ 1 2 3 4 1 B x3 2 1 1 0 0 1 1 → A 1 4 0 -1 1 6 1.5 1 zj − cj -1 -4 ↑ 0 1 0 -6 B x1 x2 x3 x4 A1 xB x2 2 1 1 0 0 1 A -7 0 -4 -1 1 2 1 zj − cj 7 0 4 1 0 -2 89  UNIT 4.
ARTIFICIAL VARIABLES TECHNIQUE Since all zj − cj ≥ 0, an optimum feasible solution to the auxiliary LPP is obtained.
But as Max z∗ < 0, and an artifical variable A is in the basis at a positive level, the original LPP does 1 not posses any feasible solution.
✍ Example 4.3.5 Solve by two phase simplex method Maximize z = −4x − 3x − 1 2 9x3 Subject to: 2x + 4x + 6x ≥ 15 1 2 3 6x + x + 6x ≥ 12 1 2 3 x , x , x ≥ 0 1 2 3 ☞ Solution.
Convert the given LPP into standard form by introducing surplus variables x , x and artificial variables A , A .
The initial solution is given by A = 15, A = 12.
3 4 1 2 1 2 Phase I Construct an auxiliary LPP by assigning a cost 0 to all the variables and -1 to each artificial variable subject to the given set of constraints, and it is given by Maximize z∗ = 0x1 + 0x2 + 0x3 + 0x4 + 0x5 − 1A1 − 1A2 Subject to: 2x + 4x + 6x + x + A = 15 1 2 3 3 1 6x + x + 6x − x + A = 12 1 2 3 4 2 B x x x x x A A x θ 1 2 3 4 5 1 2 B A 2 4 6 -1 0 1 0 15 5/2 1 A2 6 1 6 0 -1 0 1 12 2 → zj − cj -8 -5 -12 ↑ 1 1 0 0 -27 B x x x x x A A x θ 1 2 3 4 5 1 2 B A1 -4 3 0 -1 1 1 -1 3 1 → x 1 1/6 1 0 -1/6 0 1/6 2 12 3 zj − cj 4 -3 0 1 -1 0 2 -3 B x x x x x A A x θ 1 2 3 4 5 1 2 B x -4/3 1 0 -1/3 1/3 1/3 -1/3 1 2 x 22/18 0 1 1/18 -4/18 -1/18 4/18 11/6 3 z − c 0 0 0 1 1 1 1 0 j j Since all z − c ≥ 0, the current basic feasible solution is optimal.
Since Max z∗ = 0 j j and no artificial variable appears in the basis, you will proceed to phase II.
90  UNIT 4.
ARTIFICIAL VARIABLES TECHNIQUE Phase II Consider the final simplex table of phase I; also consider the actual cost associated with the original variables.
Delete the artifical variables A , A column from the table as these variables 1 2 are eliminated from the basis in phase I.
B x x x x x x θ 1 2 3 4 5 B x -4/3 1 0 -1/3 1/3 1 2 x 22/18 0 1 1/18 -4/18 11/6 3 z − c 4 3 9 0 0 0 j j Recall that z = −4x − 3x − 9x .
Thus multiply row 1 and row 2 in the above table by − 1 2 3 3 and −9 respectively and add to row 3, to get B x x x x x x θ 1 2 3 4 5 B x2 -4/3 1 0 -1/3 1/3 1 − x3 22/18 0 1 1/18 -4/18 11/6 3/2 → zj − cj -3 ↑ 0 0 1/2 1 -39/2 B x x x x x x θ 1 2 3 4 5 B x 0 1 12/11 -3/11 -1/11 3 2 x 1 0 18/22 1/22 -4/22 3/2 1 z − c 0 0 27/11 7/11 1 -15 j j Since all z − c ≥ 0, the current basic feasible solution is optimal.
Therefore the optimal j j solution is given by max z = −15, x = 3/2, x = 3, x = 0.
✍ 1 2 3 4.4 Conclusion In this unit, you have considered LPP problems, methods of solving linear programming prob- lem with ≥ type or = type constraint and positive right hand side.
You have learnt how to initialize your solution in such cases by introducing an artificial variable, and solving the prob- lem using the big-M method or the two-phase method.
4.5 Summary Having gone through this unit, you are now able to (i) Initialize the solution of a linear programming problem with ≥-type constraint.
(ii) Use the big-M and the phase II method to solve some linear programming problems.
91  UNIT 4.
ARTIFICIAL VARIABLES TECHNIQUE 4.6 Tutor Marked Assignments(TMAs) Exercise 4.6.1 1.
Minimize z = 12x1 + 12x2 Subject to: 6x + 8x ≥ 100 1 2 7x + 12x ≥ 120 1 2 x , x ≥ 0 1 2 [Ans.
x = 15, x = 5/4, and min z = 205] 1 2 2.
Maximize z = 2x1 + x2 + 3x3 Subject to: x + x + 2x ≥ 5 1 2 3 2x + 3x + 4x = 12 1 2 3 x , x , x ≥ 0 1 2 3 [Ans.
x = 3, x = 2, x = 0 and min z = 8] 1 2 3 3.
Maximize z = 2x1 + 4x2 + x3 Subject to: x − 2x − x ≥ 5 1 2 3 2x − x + 2x = 2 1 2 3 −x + 2x + 2x ≥ 1 1 2 3 x , x , x ≥ 0 1 2 3 4.
Minimize z = 4x1 + 3x2 + x3 Subject to: x + 2x + 4x ≥ 12 1 2 3 3x + 2x + x ≥ 12 1 2 3 x , x , x ≥ 0 1 2 3 [Ans.
x = 0, x = 10/3, x = 4/3 and min z = 34/3] 1 2 3 5.
Maximize z = 2x1 + 3x2 + 5x3 92  UNIT 4.
ARTIFICIAL VARIABLES TECHNIQUE Subject to: 3x1 + 10x2 + 5x3 ≥ 15 33x − 10x + 9x ≤ 33 1 2 3 x + 2x + 2x ≥ 4 1 2 3 x , x , x ≥ 0 1 2 3 Use the two phase method to solve the following LPP.
6.
Maximize z = 2x1 + x2 + x3 Subject to: 4x + 6x + 3x ≤ 8 1 2 3 3x − 6x − 4x ≤ 1 1 2 3 2x + 3x − 5x ≥ 4 1 2 3 x , x , x ≥ 0 1 2 3 [Ans.
x = 9/7, x = 10/21, x = 0 and max z = 64/21] 1 2 3 7.
Maximize z = 2x1 + x2 + x3 Subject to: 4x + 6x + 3x ≤ 8 1 2 3 3x − 6x − 4x ≤ 1 1 2 3 2x + 3x − 5x ≥ 4 1 2 3 x , x , x ≥ 0 1 2 3 [Ans.
x = 9/7, x = 10/21, x = 0 and max z = 64/21] 1 2 3 8.
Minimize z = −2x − x 1 2 Subject to: x1 + x2 ≥ 2 x1 + x2 ≤ 4 x1, x2 ≥ 0 [Ans.
x1 = 4, x2 = 0 and min z = −8] 9.
Maximize z = 5x1 − 2x2 + 3x3 93  UNIT 4.
ARTIFICIAL VARIABLES TECHNIQUE Subject to: 2x + 2x − x ≥ 1 2 3 2 3x1 − 4x2 ≤ 3 x + 3x ≤ 2 3 5 x , x , x ≥ 1 2 3 [Ans.
x = 23/3, x = 5, x = 0 and max z = −8] 1 2 3 0 10.
Maximize z = 2x1 + 3x2 + 5x3 Subject to: 3x + 10x + 5x ≤ 15 1 2 3 33x − 10x + 9x ≤ 33 1 2 3 x + 2x + x ≥ 4 1 2 3 x , x , x ≥ 0 1 2 3 94  UNIT 5 SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION 5.1 Introduction In the last unit, you looked at solving linear programming problems using simplex algorithm and you introduced artificial variable where necessary.
You also indicated that the greater or equal to (≥) constraints, because it has algebraic negative slack, will try to introduce an artificial variable in the simplex algorithm.
And you also noted that you have to reduce the number of artificial variable introduced in the problem because they don’t exist in the problem.
There are some other aspects of initialization in the problem you will see in this unit.
5.2 Objectives At the end of this unit, you should be able to; 1. initialize various aspects of simplex algorithm.
2. perform different aspects of iteration.
3. terminate as at when due with respect to the Simplex algorithm.
5.3 Main Content 5.3.1 Initialization Initialization deals with getting an initial basic feasible Solution for the given problem.
95  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION Identifying a set of basic variables with an identity coefficient matrix is the outcome of the initialization.
You have to consider the following aspects of initialization (in the same order as stated) - RHS values - Variables - Objective function - Constraints Considering each of them in detail, • The right hand side (RHS) value of every constraint should be non-negative.
It is usually a rational number.
If it is negative, you have to multiply the constraints by −1 to make the RHS non-negative.
The sign of the inequality will change.
• The variables can be of three types ≥ type, ≤ type and unrestricted.
Of the three, the ≥ type is desirable.
If you have the ≤ type variable, you replace it with another variable of the ≥ type as follows – If variable x ≤ 0, you replace it with variable x = −x , and x ≥ 0.
This k p k p change is Incorporated in all the constraints as well as in the Objective function.
– If variable xk is unrestricted, you replace it with, say xt − xtt, and incorporate in all k k the constraints as well as in the Objective function.
With the additional condition that xt , xtt ≥ 0.
If the unrestricted value be in the solution and has a positive value, k k then xktt will be in the solution and have a positive value.
Whereas if xk be in the solution and has a negative value, then xtt will be in the simplex table and will have k a positive value.
If x is not in the solution of the original problem then both xt and k k xtt will not appear as basic variables in the simplex.
This will be clearer when you k consider an example.
• The objective function can be either maximization or minimization.
If it is minimization, you multiply it with a −1 and convert it to a maximization problem and solve.
Constraints are of three types namely ≥ type, ≤ type and equation.
If a constraint is of ≤ type, you add slack variable and convert it to an equation.
If it is of ≥ type, you add a surplus variable (negative slack) and convert it to an equation.
For example, if you have x + 1 x ≥ 7, 2 then you convert the inequality t0 equation by introducing a surplus variable x and write 3 x1 + x2 − x3 = 7.
Now this −x3 does not qualify to be an initial basic variable , therefore you may need to add artificial variable If necessary you add artificial variables to identify a Starting basic feasible solution.
This is illustrated using some examples.
96  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION Example 5.3.1 Maximize z = 7x1 + 5x2 Subject to 2x + 3x = 7 1 2 = 5x1 + 2x2 ≥ 11. x , x ≥ 0 1 2 Convert the second constraint into an equation by Adding a negative slack variable x .
The 4 equations Are 2x1 + 3x2 = 75x1 + 2x2 − x3 = 11 The constraint coefficient matrix is ( l 2 3 0 5 2 −1 You don’t find variables with coefficients as in the Identity matrix.
You have to add two artificial variables a and a to get 1 2 2x + 3x + a = 75x + 2x − x + a = 11 1 2 1 1 2 3 1 You have to start the simplex table with a and a as basic variables and use either the big M 1 2 method.
or the two phase method to solve this problem.
So this is a case where you have an equation and an Inequality and you need to introduce two artificial variables.
Here is another example Example 5.3.2 Maximize z = 7x1 + 5x2 + 8x2 + 6x4 Subject to: 2x + 3x + x = 7 1 2 3 5x1 + 2x2 + x4 ≥ 11 x , x , x , x ≥ 0 1 2 3 4 In this example, you will add the surplus variable x to the second to convert it to an equation.
5 You get 2x + 3x + x = 7 1 2 3 5x + 2x + x − x = 11 1 2 4 5 Observe that variables x and x have coefficients of the identity matrix and you can start with 3 4 these as initial basic variables to have a basic feasible solution.
You need not use artificial variables in this case even though you have an equation and an inequality of the greater than or equal to type the constraints.
97  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION So you don’t just blindly add an artificial variable, rather try to convert them to a set of equation and check if there exist initial basic variable.
If there are, you use them and if there are not, you then add artificial variable.
For instance, if the second constraint was 5x1 +2x2 +2x4 ≥ 11, you can write it as 5/2x + x + x = 11/2, and then add the surplus variable and choose 1 2 4 x as the starting basic variable.
4 Thus the message here is that you do not necessarily have to add an artificial variable to every ≥-type constraints but you absolutely need to add a negative slack(i.e., surplus) variable to convert it to an equation.
If you are able to identify initial basic variables from there, you can use it, but if not, it is only then you will need to add an artificial variable.
In the process, you will minimize the number of artificial variables added to a problem.
The rules for adding artificial variables is summarized Below.
Adding artificial variables 1.
Ensure that the RHS value of every constraint is Nonnegative.
2.
If you have a ≤-constraint, you add a slack variable.
This automatically qualifies to be an initial basic variable.
3.
If you have a ≥-constraint, you add a negative slack to convert it to an equation.
This negative slack cannot qualify to be an initial basic variable.
4.
In the system of equations identify whether there exist variables with coefficients corre- sponding to the column of the identity matrix.
Such variables qualify to be basic variables.
Add minimum artificial variables otherwise to get a starting basic feasible solution.
5.3.2 Iteration-Degeneracy During iteration, only one issue needs to be addressed called Degeneracy.
Definition 5.3.1 (Degeneracy) A phenomenon of obtaining a degenerate basic feasible solution in a LPP is known as degeneracy Degeneracy in LPP may arise (i) at the initial stage (ii) at any subsequent iteration stage.
In the case of (i), at least one of the basic variables should be zero in the initial basic feasible solution.
Whereas in cas of (ii) at any iteration of the simplex method more than one variable is elligible to leave the basis, and hence the next simplex iteration produces a degenerate solution in which at least one basic variable is zero, i.e., the subsequent iteration may not produce im- provements in the value of the objective function.
As a result, it is possible to repeat the same sequence of simplex iteration endlessly without improving the solution.
The concept is known as cycling (tie).
98  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION 5.3.3 Methods to Resolve Degeneracy The following systematic procedure can be utilized to avoid cycling due to degeneracy in LPP.
Step 1 First find out the rows for which the minimum non-negative ratio is the same (tie); suppose there is a tie between first and third row.
Step 2 Now rearrange the columns of the usual simplex table so that the columns forming the original unit matrix come first in proper order.
Step 3 Find the minimum of the ratio, ( \ Elements of the first column of the unit matrix Corresponding elements of key column only for the tied rows, i.e., the first and third rows.
(i) If the third row has the minimum ratio then this row will be the key row and the element can be determined by intersecting the key row with key column.
(ii) If this minimum is also not unique, then go to the next step.
Step 4 Now find the minimum of the ratio, only for the tied rows, If this minimum ratio is unique for the first row, then this row will be the key row for determining the key element by intersecting with key column.
( \ Elements of the second column of the unit matrix Corresponding elements of key column If the minimum is also not unique, then go to the next step.
Step 5 Find the minimum of the ratio.
The above step is repeated till the minimum ratio is obtained so as to resolve the degeneracy.
After the resolution of this tie, simplex method is applied to obtain the optimum solution.
( \ Elements of the second column of the unit matrix Corresponding elements of key column Example 5.3.3 Solve the following LPP.
Maximize z = 3x1 + 9x2 Subject to: x + 4x ≤ 8 1 2 x + 2x ≤ 4 1 2 x , x ≥ 0 1 2 ☞ Solution.
Introducing slack variables x , x ≥ 0, you have 3 4 99  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION Maximize z = 3x1 + 9x2 + 0x3 + 0x4 Subject to: x + 4x + x = 8 1 2 3 x + 2x + x = 4 1 2 4 x , x ≥ 0 1 2 B x x x x x θ = x /x 1 2 3 4 B B 2\ x 1 4 1 0 8 8/4 = 2 3 tie x 1 2 0 1 4 4/2 = 2 4 z − c -3 -9 ↑ 0 0 0 j j Since the minimum of the ratio is not unique, the slack variables x , x leave the basis.
This 3 4 an indication for the existence of degeneracy in the given LPP.
So you would apply the above procedure to resolve this degeneracy (tie).
Rearrange the columns of the simplex table so that the initial identity matrix appears first.
B x x x x x θ = x /x 3 4 1 2 B 3 2 x 1 0 1 4 8 1/4 3 x 0 1 1 2 4 0 → 4 z − c 0 0 -3 -9 ↑ 0 j j Using Step 3 of the procedures given for resolving degeneracy, you find ( \ ( \ Elements of first column 1 0 min = min , = 0 Corresponding elements of key column 4 2 Hence, x leaves the basis and the key element is 2.
4 B x x x x x 3 4 1 2 B x 1 -2 -1 0 0 3 x 0 1/2 1/2 1 2 4 z − c 0 9/2 3/2 0 18 j j Since all z − c ≥ 0, the solution is optimum.
The optimal solution is x = 0, x = 2, and j j 1 2 max z = 18.
✍ Example 5.3.4 Solve 10  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION Maximize z = 2x1 + x2 Subject to 4x + 3x ≤ 12 1 2 4x + x ≤ 8 1 2 4x − x ≤ 8 1 2 x , x ≥ 0 1 2 ☞ Solution.
Introducing the slack variables x , x , x ≥ 0, the given problem can be 3 4 5 reformulated as shown below: Maximize z = 2x1 + x2 + 0x3 + 0x4 + 0x5 Subject to: 4x + 3x + x = 12 1 2 3 4x + x + x = 8 1 2 4 4x − x + x = 8 1 2 5 x , x , x , x , x ≥ 0 1 2 3 4 5 B x x x x x x θ = x /x 1 2 3 4 5 B B 1 x 4 3 1 0 0 12 12/4 = 3 3 \ x 4 1 0 1 0 8 8/4 = 2 4 tie x 4 -1 0 0 1 8 4/2 = 2 5 z − c -2 ↑ -1 0 0 0 0 j j Since the minimum ratio is the same for 2nd and 3rd rows, it is an indication of degeneracy.
Rearrange the columns in such a way that the identity matrix comes first.
B x x x x x x x /x x /x 3 4 5 1 2 B 3 1 4 1 x3 1 0 0 4 3 12 − − x 0 1 0 4 1 8 0/4 1/4 4 x 0 0 1 4 -1 8 0/4 0/4 → 5 z − c 0 0 0 -2 ↑ -1 0 j j Using the procedure of degeneracy, find ( \ Elements of first column of unit matrix min Corresponding elements of key column for 2nd and 3rd rows, min{0/4, 0/4} = 0 which is unique.
10  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION So again compute, ( \ Elements of first column of unit matrix min Corresponding elements of key column for 2nd and 3rd rows.
min{−, 1/4, 0/4} = 0, which occurs corresponding to the third row.
Hence, x leaves the basis.
5 B x x x x x x x /x 3 4 5 1 2 B B 2 x 1 0 -1 0 4 4 1 3 x4 0 1 -1 0 2 0 0 → x 0 0 1/4 1 -1/4 2 − 1 zj − cj 0 0 1/2 0 -3/2 ↑ 4 B x x x x x x x /x 3 4 5 1 2 B B 5 x3 1 -2 1 0 0 4 4 → x2 0 1/2 -1/2 0 1 0 − x 0 1/8 1/8 1 0 2 16 1 zj − cj 0 3/4 -1/4 ↑ 0 0 4 B x x x x x x 3 4 5 1 2 B x 1 -2 1 0 0 4 5 x 1/2 -1/2 0 0 1 2 2 x -1/8 3/8 0 1 0 3/2 1 z − c 1/4 1/4 0 0 0 5 j j Since all zj − cj ≥ 0, the solution is optimum and given by x1 = 3/2, x2 = 2, and max z = 5.
✍ Degeneracy In summary, • Degeneracy results in extra iterations that do not improve the objective function value.
– Since the tie for the leaving variable, leaves a variable with zero value in the next iterations, you do not have an increase in the objective function value • Sometimes degeneracy can take place in the intermediate iterations.
– In such cases, if the optimum exists, the simplex algorithm will come out of degen- eracy by itself and terminate at the optimum.
– In these case, the entering column will have a zero (or negative) value against the leaving row and hence that the ratio is not computed, resulting in a positive value of the minimum ratio.
10  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION • There is no proven way to eliminate degeneracy or to avoid it.
Sometimes a different tie breaking rule can result in a non-degenerate solution.
– In this example if you had chosen to leave x instead of x .
In the first, iterations, 3 4 the algorithm terminates and gives the optimum after one iteration.
5.3.4 Termination There are four aspects to be addressed while discussing termination conditions.
These are 1.
Alternate optimum 2.
Unboundedness 3. infeasibility 4.
Cycling For better understanding, an example is given for each of them.
5.3.5 Alternate Optimum Example 5.3.5 (Alternate Optimum) Maximize z = 4x1 + 3x2 Subject to 8x1 + 6x2 ≤ 25 3x1 + 4x2 ≤ 15 x1, x2 ≥ 0 Adding slack variables x and x you can start the simplex iteration with x and x as basic 3 4 3 4 variables.
This is shown table 5.1 B x x x x x  1 2 3 4 B x 8 6 1 0 25 25 /8  3 x 3 4 0 1 15 5 4 z −c -4 -3 0 0 0 j j B x x x x x θ 2 3 4 5 B x 1 ¾ 1/8 0 25/8 2 /5  1 x 0 7/4 -3/8 1 45/8 10 4 z −c 0 0 ½ 0 100/8 j j Table 5.1: 10  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION Observe that in the last tableau, the non-basic variables are x and x , and both of them do 2 3 not have a negative z − c , therefore there is no entering variable, so the algorithm terminates.
j j One important thing you could notice in this example, is that when the algorithm terminated, the non-basic variable x has the value 0 unlike in other ones where the non-basic variables have 2 a positive zj − cj -row entry when the algorithm terminates.
You know that if you enter a z − c value with a positive sign, it will bring down the value j j of the objective function unlike when you enter a negative z − c which will increase the value j j of the objective function.
Now the question is “can you enter this variable x which has a zero z − c entry?
And 2 j j what happens when you do so?” You can try to see what happens by entering the non-basic variable x2 which has a zero zj − cj value.
B x x x x x θ 2 3 4 5 B x 1 ¾ 1/8 0 25/8 25 /6  1 x 0 7/4 -3/8 1 45/8 45 /14  4 z −c 0 0  ½ 0 25 / 2 j j B x x x x x θ 2 3 4 5 B x 1 0 2/7 -3/7 5/7 2 /5  1 x 0 1 -3/14 4/7 45/14 10 2 z −c 0 0 ½ 0 25/2 j j Table 5.2: In this case you have the optimal solution (x , x , x , x ) = (5/7, 45/14, 0, 0) 1 2 3 4 Which gives a z-value of 25 z = 2 You notice that in the last table, the same z − c entries are repeated with the only exception j j that x now becomes a non-basic variable with a zero entry instead of x as in the formal optimal 4 2 tableau, and wants to enter.
Notwithstanding the value of the objective function z = 25/2 did not improve.
Now if you had entered the x in 5.1 you will also need to enter x in table 5.2.
2 4 If you do that, you will obtain exactly table 5.1.
This tells you that if you apply the termination condition strictly, you will succeed in getting an infinite loop.
This case the simplex algorithm terminates and yet you Still have a non-basic variable with a zero entry is what you call an alternate optimum Hence the termination condition has to be redefined to include the alternate optimum, that is the iteration terminates when you have an alternate optimum.
10  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION Observe that it is very necessary to compute other table in the case of an alternate optimum because, if you had stopped in the last example with optimum solution of (x , x , x , x ) = (25/8, 0, 0, 45/8), 1 2 3 3 then, since x and x are the decision variables, you must have produced 25/8 of one product 1 2 and you did not produce x .
Because the presence of the slack variable x , in the basis indicates 2 4 that the resources are not properly utilized.
So you still have the same number of resources available with you and you still made the same profit.
While for the solution (x , x , x , x ) = (5/7, 45/14, 0, 0), 1 2 3 3 you produced both items and had the same profit with the resources properly utilized.
So you can make a choice on how to produce.
From all indications, the first will be better, because you will end up saving some resources.
Another question is “In the case of the alternate optimum, is there only one solution or more?” You can answer this question by looking at the graphical solution of this problem.
See Figure (5.1) y=x2 8x+6y=25 5 4 3 2 z=12 1 x=x1 (0,0) 1 2 3 4 5 6 3x+4y=15 Figure 5.1: In Figure 5.1, the objective function line is drawn for z = 12.
As you can observe, this line is parallel to the line representing the constraint equation 8x + 6x = 25 so that, as the objective 1 2 10  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION function line moves, It will touch this line.
Therefore, the alternate optimum does not only exist at (5/7, 45/14) and (45/8, 0) but at infinitely many points on the line 8x +6x = 25, which lies 1 2 between these two points.
But the simplex algorithm will not show these other points because the simplex method only show corner points.
The fact the simplex want to switch between these two solutions indicates that every other points in between these two corner points is optimum.
5.3.6 Unboundedness (Or Unbounded Solution) In some LPP, the solution space becomes unbounded, so that the value of the objective func- tion also can be increased indefinitely without a limit.
However, it is not necessary that an unbounded feasible region should yield an unbounded value for the objective function.
The following example will illustrate these points.
Unboundedness is one of the aspects of termination which you proposed to consider.
For a better understanding, consider the following example.
Example 5.3.6 (Unboundedness) Maximize 4x1 + 3x2 x1 − 6x2 ≤ 5 3x1 ≤ 11 x1, x2 ≥ 0.
☞ Solution.
By addition of the two slack variables x and x to the constraints you have 3 4 the following equivalent problem Maximize 4x1 + 3x2 x1 − 6x2 + x3 = 5 3x + x = 11 1 4 x1, x2, x3, x4 ≥ 0.
With the initial basic feasible solution (x , x , x , x ) = (0, 0, 5, 11) 1 2 3 4 and solving the problem using simplex algorithm, you have In the second table, you observe that x with a negative z − c entry enters the basis.
Now 3 j j trying to get the departing variable, you have to compute as usual the ratio of the b-column and the entering column, and by doing so, you will observe that no variable leaves because (4/3)/(−6) gives a negative value and so you do not compute it and the other one is undefined because of division by zero.
As a result of these, the algorithm will terminate.
Since no variable departs, despite the fact that you have an entering variable.
✍ This phenomenon where the algorithm terminates because it was unable to find a departing variable is called Unboundedness.
Two cases of unboundedness are obtainable, namely, Unbounded optimal solution and Un- bounded feasible solution.
10  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION B x x x x x  1 2 3 4 B x 1 -6 1 0 5 5 3 x 4 3 0 0 1 11 11 / 3  z −c −4  -3 0 0 0 j j B x x x x x  1 2 3 4 B x 0 -6 1 -1/3 4/3 - 3 x 1 1 0 0 1/3 11/3 ∞ z −c 0 −3  0 4 / 3 44/3 j j Table 5.3: Unboundedness: (Unable to determine the leaving variable) Example 5.3.7 (Unbounded optimal solution) Maximize 2x1 + x2 x1 − x2 ≤ 10 2x1 − x2 ≤ 40 x1, x2 ≥ 0.
☞ Solution.
By addition of the two slack variables x and x to the constraints you have 3 4 the following equivalent problem Maximize 2x1 + x2 + 0x3 + 0x4 2x1 − x2 + x3 = 10 2x1 − x2 + x4 = 40 x1, x2, x3, x4 ≥ 0.
10  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION y=x 2 30 20 10 Fe asi ble regi on x=x 1 10 20 30 40 10 20 30 40 Figure 5.2: B x x x x x x /x 1 2 3 4 B B 1 x3 1 -1 1 0 10 10 → x 2 -1 0 1 40 20 4 zj − cj -2 ↑ -1 0 0 0 B x x x x x x /x 1 2 3 4 B B 2 x1 1 -1 1 0 10 − x4 0 1 -2 1 20 20 → zj − cj 0 -1 ↑ 2 0 20 B x x x x x 1 2 3 4 B x 1 0 -1 1 30 1 x 0 1 -2 1 20 2 z − c 0 0 -4 3 80 j j Since z3 − c3 = −4 < 0, the solution is not optimum.
But all the values in the key column are negative which is the indication of unbounded solution.
The feasible region is unbounded since it has all x negative.
Hence z can be made ar- 2 bitrarily large and the problem has no finite maximum value of z.
Therefore, the solution is unbounded.
✍ Example 5.3.8 (Unbounded feasible region but bounded optimal solution.)
10  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION Maximize z = 6x1 + 2x2 Subject to: 2x1 − x2 ≤ 2 x1 ≤ 4 x1, x2 ≥ 0 ☞ Solution.
By introducing slack variables x , x the standard form of LPP is, 3 4 Maximize z = 6x1 − 2x2 + 0x3 + 0x4 Subject to 2x1 − x2 + x3 = 2 x + x = 4 1 4 x1, x2, x3, x4 ≥ 0 Initial solution is given by x = 2, x = 4.
3 4 B x x x x x x /x 1 2 3 4 B B 1 x3 2 -1 1 0 2 1 → x 1 0 0 1 4 4 4 zj − cj -6 ↑ 2 0 0 0 B x x x x x x /x 1 2 3 4 B B 2 x1 1 -1/2 1/2 0 1 − x4 0 1/2 -1/2 1 6 6 → zj − cj 0 -1 ↑ 3 0 6 B x x x x x 1 2 3 4 B x 1 0 0 1 4 1 x 0 1 -1 2 6 2 z − c 0 0 2 2 12 j j Since all zj − cj ≥ 0, the solution is optimum.
The optimal solution is given by x = 4, x = 6 and max z = 12.
1 2 It is now interesting to note from the table that the element of x are negative or zero (-1, 2 and 0).
This is an immediate indication that the feasible region is not bounded.
From this you will conclude that a problem may have unbounded feasible region but still the optimal solution is bounded.
✍ Difference between unbounded region and Unbounded solution Suppose you draw the graph of the objective function, say for 4x + 3x = 12, and for 4x + 1 2 1 3x = 15 as you maximize, you will observe that the objective function will move in the upward 2 direction as shown because the region is unbounded.
So both x and x can go up to infinity.
1 2 On the other hand, if the problem has been that of minimization then the objective function will move in the downward direction and will terminate giving (x , x ) = (0, 0) as the optimum 1 2 solution and z = 0.
10  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION 2x−y=2 y=x2 3 f e as ible x=4 r e g io n 2 1 x=x1 1 2 3 −2 −1 Figure 5.3: Hence there are two aspects to unboundedness, namely you can have an unbounded region if the region is unbounded and an unbounded solution depending on the direction the objective function is moving.
In this example you have an unbounded feasible region and unbounded solution.
Notwithstanding, depending on the objective function, a region that is unbounded may still have a solution.
There is one more thing that you can do.
Up till now, you have consistently entered the non-basic variable with the smallest z − c entry (that is the z − c entry that has the j j j j highest negative entry), but now you have been able to understand that you can enter any non-basic variable with a negative z − c entry can enter and will improve the .
And by trying to apply j j that to this problem, you will discover early that an attempt to enter x with -3 as the z − c 2 j j entry instead of x with −4 as the z − c entry, will indicate unboundedness right in the very 1 j j first stage.
Summary At the end of the first iteration, you observed that the variable x with z − c = −3 can 2 2 2 enter the basis but you are unable to fix the leaving variable because all coefficients in the entering column are ≤ 0.
So the algorithm terminates because it is unable to find a leaving variable.
This phenomenon is called unboundedness, indicating that the variable x can take any 2 value and still still none of the present basic variable would become infeasible.
11  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION - By the nature of the first constraint, you can observe that x can be increased to any value 2 and yet the constraints are feasible.
- The value of the objective function is infinity.
In all simplex iterations, you enter the variable with the greatest negative value of z − c .
j j Based on this rule, you entered variable x in the first iteration.
Variable x also with a negative 2 2 value of −3 is a candidate and if you had decided to enter x in the first iteration you would 2 have realized the unboundedness at the first iteration itself.
Though most of the times you enter a variable with smallest z − c entry, there is no j j guarantee that this rule with minimum iterations.
Any non-basic variable with a negative value of zj − cj is a candidate to order.
Other rules for entering variable are 1.
Largest increase rule.
Here for every candidate for entering variable, the corresponding minimum θ is found and the increase in the objective function i.e., the product of zj − cj is found.
• The variable with the minimum increase (product) is chosen as entering variable.
2.
First negative zj − cj 3.
Random-A non basic variable is chosen randomly and the value of zj − cj is computed • It becomes the entering variable if the zj − cj Is negative • Otherwise another variable is chosen randomly.
This is repeated till an entering variable is found.
Coming back to unboundedness, you observe that unboundedness is caused when the fea- sible region is not bounded.
Sometimes, the nature of the objective function can be such that even if the feasible region is unbounded, the problem may have an optimum solution.
The un- boundedness defined here means that there is no finite optimum solution and the problem is unbounded.
Non Existing Feasible Solution One more aspect to be considered is called infeasibility.
In this case the feasible region is found to be empty, which indicates that the problem does not have a feasible solution.
In simplex method, if there exists at least one artificial variable in the basis at positive level and even though optimality conditions are satisfied, it is the indication of non-feasible solution.
Consider the following example.
Example 5.3.9 (Infeasibility) Maximize z = 4x1 + 3x2 Subject to x1 + 4x2 ≤ 3 3x1 + x2 ≥ 12 x1, x2 ≥ 0 11  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION ☞ Solution.
Adding slack variables x3 and x4 (surplus) and artificial variable a1 you can start the simplex algorithm using the big M method with x and a as basic variables you have 3 1 the following equivalent form.
Maximize z = 4x1 + 3x2 − M a1 Subject to x + 4x + x = 3 1 2 3 3x1 + x2 − x4 + a1 = 12 x1, x2, x3, x4, a1 ≥ 0 where M is a very large positive number.
Thus solving by simplex method you have B x x x x A x  1 2 3 4 1 B x 1 4 1 0 0 3 3 A1 3 1 0 -1 1 12 z −c −4 -3 0 0 M 0 j j B x x x x A x  1 2 3 4 1 B x 1 4 1 0 0 3 3  3 A1 3 1 0 -1 1 12 4 z −c −3M−4  − M −3 0 M 0 −12M j j B x x x x A x  1 2 3 4 1 B x 1 4 1 0 0 3 1 A1 0 -11 -3 -1 1 3 z −c 0 11M13 3M 4 M 0 3M 4 j j Table 5.4: Because all z − c ≥ 0, the algorithm terminates, since there is no other entering j j variable.
But since the artificial variable is still left as a basic variable, then the problem does not have an optimal solution because the artificial variable is not part of the original problem.
More general you would say that the problem has no feasible solution.
Hence the problem is said to be infeasible.
✍ To understand why the problem is infeasible, you can draw the graph of the constraints of this problem Figure 5.4.
You can observe that the constraints are moving away from each other, hence there is no feasible region.
11  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION y=x2 1 2 8 4 x+4y=3 x=x1 1 2 3 4 5 7 Figure 5.4: So this is a situation where the simplex method is able to show that the linear programming problem may not have an optimum solution at all.
Of course if a problem does not have a feasible region, obviously, it can not have a optimal solution.
The simplex method is able to detect this by allowing an artificial variable to remain in the basis even after the optimality condition is met.
Infeasibility is indicated by the presence of at least one artificial variable after the optimum conditions is satisfied.
Another thing you can observe from this problem is that a = 3.
This indicates that the 1 second constraint should have the RHS value reduced by 3 to get a feasible solution with x = 3.
1 Therefore, Simplex algorithm not only is capable of detecting infeasibility but also shows the extent of infeasibility.
Termination Conditions (Maximization objective) The termination conditions are summarized below as follows.
• All non-basic variables have positive z − c entry.
j j – Basic variables are either decision variable or slack(or surplus) variables.
Algorithm terminates indicating unique optimum solution.
• Basic variables are either decision variables or slack variables.
All non-basic variable have z − c ≥ 0. j j – At least one non-basic variable has z − c = 0, indicates alternate optimum proceed j j to find the other corner point and terminate.
• Basic variables are either decision variables or slack variables.
– This algorithm identifies an entering variable but is unable to identify leaving vari- able, because all values in the entering column are ≤ 0.
Indicates unboundedness and algorithm terminates.
11  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION • All non-basic variables have zj − cj ≥ 0.
Artificial variable still exists in the basis.
– Indicates infeasibility.
Algorithm terminates.
Cycling If the simplex algorithm fails to terminate (based on the above conditions) then it cycles.
You have seen so far that every iteration is characterised by a set of unique basic variables.
So far, you have not gone back, in any of the simplex iterations, to a particular set of basic variables.
The only time you came very close to doing this was when you had an alternate optimum.
A phenomenon by which, in the middle of simplex iteration, you have a set of basic variables and after about some iterations, you realise that you are back to the same set of basic variables, without satisfying any of the termination conditions, is called Cycling.
Cycling is a very rare phenomenon in linear programming i.e., there are not many cases of cycling in the simplex iterations.
In fact, so far, there has not been a linear programming problem formulated from a practical situation which cycles.
There are few examples you can find in books that shows the cycling phenomenon, notwithstanding it is not a very common phenomenon.
There are also some restrictions that says that for a problem to cycle, the problem must have at least 3 constraints, 6 variables and so on.
But in this book, you will not go deeper into cycling.
For further studies, you can visit some of the texts recommended at the end of this section.
5.3.7 Special examples In this section, you shall consider a few more things that simplex method can do.
One of them is that simplex method can be used to solve simultaneous linear equations of the solution has non-negative values.
Consider the following example.
Example 5.3.10 Solve 4x + 3x = 25 1 2 2x + x = 11 1 2 ☞ Solution.
Assume that this problem has a solution x1, x2 ≥ 0 Add artificial variables a1 and a and rewrite the equations as 2 4x + 3x + a = 25 1 2 1 2x + x + a = 11 1 2 2 Define the objective function (artificial objective function) as Minimize a1 + a2 11  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION so that the problem now becomes, by converting the minimization objective to a maximization objective, a linear programming problem of Maximize −a1 − a2 Subject to 4x + 3x + a = 25 1 2 1 2x + x + a = 11 1 2 2 x , x , a , a ≥ 0 1 2 1 2 If the original equations have a non-negative solution, then you should have feasible basis with x and x having z=0 for the linear programming problems.
The simplex iterations and are 1 2 shown in Table 5.5 ✍ B x x A A x  1 2 1 2 B A 2 3 1 0 6 2  1 A 2 4 6 0 1 12 2 z −c −6 −9  0 0 −18  j j B x x A A x  1 2 1 1 B x 2/3 1 1/3 0 2 3  2 A 2 0 0 -2 1 0 - z −c 0  0 3 0 0 j j B x x A A x  1 2 1 1 B x 1 3/2 ½ 0 3 1 A 2 0 0 -2 1 0 z −c 0 0 -3 0 0 j j Table 5.5: In the last table, all entries in the z − c row are non-negative, hence the algorithm termi- j j nates.
Notwithstanding an artificial variable a still remains in the basis, but more importantly, 2 you observe that its value is zero (i.e.
a = 0).
So when you solve a set of equations and the ar- 2 tificial variable remains in the basis, with value zero at optimum, then it means that the system of equations are linearly dependent.
Hence the simplex method is capable of also indicating linear dependency among these equations.
So the simplex method among other things is able to • detect if a linear programming problem has a feasible solution.
11  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION • solve a set of linear equations if it has a unique solution.
• detect a linearly dependent systems of equations.
Unrestricted Variable.
Here is another example to illustrate an unrestricted variable.
Example 5.3.11 Maximize 4x1 + 5x2 Subject to: 2x1 + 3x2 ≤ 8 x1 + 4x2 ≤ 10 x1, unrestricted, x2 ≥ 0 ☞ Solution.
Replace variable x1 by x3 − x4, and add slack variables x5 and x6 to get Maximize 4x3 − 4x4 + 5x2 Subject to: 2x3 − 2x4 + 3x2 + x5 = 8 x3 − x4 + 4x2 + x6 = 10 x2, x3, x4, x5, x6 ≥ 0 The simplex iterations are shown in the table 5.6 ✍ In the last table in table 5.6, you observe that all the entries in the z − c row are non- j j negative.
But value of the decision variable x = 0 which can enter.
But an attempt to enter this, 4 variable will reveal that there is no leaving variable.
Now the question is, “Does this indicate an alternate optimum because you have a zero which enters after the termination condition is met?” “Does it indicate unboundedness because you are unable to find a leaving variable?” This is what happens for problems that involves unrestricted variables.
It neither signify unboundedness nor alternate optimum rather it is signifies that the algorithm terminates for problems that involves unrestricted variables one of the variables will always want to enter and you should be aware of this.
11  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION B x x x x x x θ 2 3 4 5 6 B x 3 2 -2 1 0 8 8 / 3 5 x 6 4 1 -1 0 1 10 10 / 4  z −c −5  −4 4 0 0 0 j j B x x x x x x θ 2 3 4 5 6 B x 0 5/4 -5/4 1 -¾ ½ 2 /5  5 x2 1 -¼ -¼ 0 ¼ 5/2 10 z −c 0 −11 / 4  11 / 4 0 5/ 4 25 / 2 j j B x x x x x x θ 2 3 4 5 6 B x 3 0 1 -1 4 / 5 −3/5 2 /5 x2 1 0 0 −1 /5 2/5 12/5 6  z −c 0 0 0 11 / 3 −2 / 5 68/5 j j B x x x x x x θ 2 3 4 5 6 B x 3/2 1 -1 ½ 0 4 3 x 6 5/2 0 0 -½ 1 6 z −c 1 0 0 2 0 16 j j Table 5.6: 5.4 Conclusion In this section, you have considered the simplex algorithm - initialization, iteration and termi- nation.
And you have seen many conditions under which you can modify the initialization, the iteration or and the termination conditions.
5.5 Summary At the end of this unit, 1.
You are now able to initialize, iterate and terminate any LPP and state the optimal solution.
2.
Degeneracy is a phenomenon of obtaining a degenerate basic feasible solution in an LPP.
3.
You are able to resolve degeneracy if it occurs.
4.
The alternate optimum is indicated with the optimality or the termination condition been satisfied, you have a non-basic variable with a zero value of the z − c row which would j j 11  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION want to enter and entering will give the same value of the objective function but with a different solution.
You also need to perform the two iterations in other to maximize you profit and save some resource.
5. you also know that there are infinitely many solutions in the alternate optimum case.
Simplex will indicate only two corner points on the line of the constraint equation which is parallel to the objective function.
But every other point between the corner points is also optimum.
6.
Unboundedness is a phenomenon where the algorithm terminates because it was unable to find a departing variable.
7.
A problem is said to be Infeasible if the problem has no feasible solution.
8.
A phenomenon in LPP by which, in the middle of simplex iteration, you have a set of basic variables and after about some iterations, you realize that you are back to the same set of basic variables, without satisfying the termination condition is called Cycling 9.
You are also able to solve problems involving unrestricted variables.
5.6 Tutor Marked Assignemts (TMAs) Exercise 5.6.1 1.
The simplex algorithm is able to indicate infeasibility (a) by not having a feasible solution at at all.
(b) by having a slack variable as a basic variable.
(c) by the presence M in the z-value, after the optimum condition is met when using the big-M method.
(d) by the presence of an artificial variable after the optimum condition is met.
2.
While solving a set of equations, it was found that an artifical variable remains in the basis with value zero, at optimum.
this indicates that the system of equation is (a) linearly indpendent (b) linearly dependent (c) has no solution.
(d) has a unique solution.
3.
Unboundedness is bes detected in the simplex algorithm if (a) there is an entering variable but no departing variable.
(b) there is a decision variable with a zero entry in the z − c -row.
j j (c) all the entries in the z − c are nonpositive.
j j 11  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION (d) all the entries in the zj − cj -row are non-negative.
4.
Alternate optimum is best detected in the simplex algorithm if (a) there is an entering variable but no departing variable.
(b) there is a decision variable with a zero entry in the z − c -row.
j j (c) all the entries in the z − c are nonpositive.
j j (d) all the entries in the z − c -row are non-negative.
j j 5.
Solve the following problem by the two-phase simplex method.
Maximize 2x1 − x2 + x3 Subject to x + x − 2x ≤ 8 1 2 3 4x − x + x ≥ 2 1 2 3 2x + 3x − x ≥ 4 1 2 3 x , x , x ≥ 0 1 2 3 6.
Consider the following linear programming problem.
Maximize x1 + 2x2 Subject to x + x ≥ 1 1 2 −x + x ≤ 3 1 2 x ≤ 5 2 x , x ≥ 0 1 2 (a) Solve the problem geometrically.
(b) Solve the problem by the two-phase simplex method.
Show that the points generated by phase I correspond to basic solutions of the original system.
7.
Solve the following problem by the two-phase simplex method.
Minimize x1 + 3x2 − x3 Subject to x + x + x ≥ 3 1 2 3 −x + 2x ≥ 2 1 2 −x + 5x + x ≤ 4 1 2 3 x , x , x ≥ 0 1 2 3 11  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION 8.
Show how phase I of the simplex method can be used to solve n simultatneous linear equations in n unknowns.
Show how the following cases can be detected: (a) Inconsistency of the system.
(b) Redundancy of the equations.
(c) Unique solution.
Also show how the inverse matrix corresponding to the system of the equations can be found in (c).
Illustrated by solving the following system.
x + 2x + x = 4 1 2 3 −x − x + 2x = 3 1 2 3 x − x + x = 2 1 2 3 9.
Solve the following problem by the two-phase simplex method.
Minimize −x1 − 2x2 Subject to 3x + 4x ≤ 20 1 2 2x − x ≥ 2 1 2 x , x ≥ 0 1 2 10.
Solve the following problem by the two-phase method.
Maximize 5x1 − 2x2 + x3 Subject to x + 4x + x ≤ 6 1 2 3 2x + x + 3x ≥ 2 1 2 3 x , x ≥ 0 1 2 x unrestricted 3 11.
Solve the following problem by the two-phase simplex method.
Maximize 4x1 + 5x2 − 3x3 Subject to x + x + x = 10 1 2 3 x − x ≥ 1 1 2 2x + 3x + x ≤ 20 1 2 3 x , x , x ≥ 0 1 2 3 12  UNIT 5.
SIMPLEX ALGORITHM- INITIALIZATION AND ITERATION 12.
Use the big-M simplex method to solve the following problem.
Minimize −2x1 + 2x2 + x3 + x4 Subject to x + 2x + x + x ≤ 2 1 2 3 4 x − x + x + 5x ≥ 4 1 2 3 4 2x − x + x ≤ 2 1 2 3 x , x , x , x ≥ 0 1 2 3 4 13.
Solve the following LPP.
Maximize z = 5x1 − 2x2 + 3x3 Subject to 2x1 + 2x2 − x3 ≥ 2 3x1 − 4x2 ≤ 4 x − 3x ≤ 5 2 3 x , x , x ≥ 0 1 2 3 [Ans max z = 85/3, x = 23/3, x = 5, x = 0] 1 2 3 14.
Solve the following LPP.
Maximize z = 2x1 + 3x2 + 10x3 Subject to x + 2x = 0 1 3 x + x = 1 2 3 x1, x2, x3 ≥ 0 [Ans max z = 3, x = 0, x = 1, x = 0] 1 2 3 15.
Solve the following LPP.
Maximize z = x1 + 2x2 + x3 Subject to 2x + x − x ≤ 2 1 2 3 −2x + x − 5x ≥ −6 1 2 3 4x + x + x ≤ 5 1 2 3 x , x , x ≥ 0 1 2 3 [Ans max z = 10, x = 0, x = 4, x = 2] 1 2 3 12  Module III 122  UNIT 6 DUALITY IN LINEAR PROGRAMMING 6.1 Introduction Every LPP (called the primal) is associated with another LPP (called its dual).
Either problem can be considered as primal and the other one as dual.
The importance of the duality concept is because of two main reasons: 1.
If the primal contains a large number of constraints and a smaller number of variables, the labour of computation can be considerably reduced by converting it into the dual problem and then solving it.
2.
The interpretation of the dual variables from the cost or economic point of view, proves extremely useful in making future decisions in the activities being programmed.
6.2 Objective At the end of this unit, you should be able to (i) give the definition of a Dual problem.
(ii) Formulate the dual of any primal problem.
(iii) Solve Dual problems.
(iv) Use the Dual-simplex algorithm.
(v) Perform Sensitivity Analysis.
123  UNIT 6.
DUALITY IN LINEAR PROGRAMMING 6.3 Main Content 6.3.1 Formulation of Dual Problems For formulating a dual problem, first you have to bring the problem in the canonical form.
The following changes are used in formulating the dual problem.
(i) Change the objective function of maximization in the primal into minimization in the dual and vice versa.
(ii) The number of variables in the primal will be the number of constraints in the dual and vice versa.
(iii) The cost coefficient c , c , .
.
.
, c in the objective function of the primal will be the RHS 1 2 n constant of the constraints in the dual and vice versa.
(iv) In forming the constraints for the dual, you have to consider the transpose of the body matrix of the primal problem.
(v) The variables in both problems are non-negative.
(vi) If a variable in the primal is unrestricted in sign, then the corresponding constraint in the dual will be an equation and vice versa.
6.3.2 Definition of the Dual Problem Let the primal problem be, Maximize z = c1x1 + · · · + cnxn Subject to a11x1 + a12x2 + · · · + a1nxn ≤ b1 a21x1 + a22x2 + · · · + a2nxn ≤ b2 .
am1x1 + am2x2 + · · · + amnxn ≤ bm x , x , .
.
.
, x ≥ 0 1 2 n 124  UNIT 6.
DUALITY IN LINEAR PROGRAMMING Dual: The dual problem is defined as, Minimize w = b1y1 + b2y2 · · · + bmym Subject to a11y1 + a21y2 + · · · + am1ym ≥ c1 a12y1 + a22y2 + · · · + am2ym ≥ c2 .
a1ny1 + a2ny2 + · · · + amnym ≥ cm y , y , .
.
.
, y ≥ 0 1 2 m where y , y , y , .
.
.
, y are called dual variables 1 2 3 m Example 6.3.1 Write the dual of the following primal LP problem.
Maximize z = x1 + 2x2 + x3 Subject to: 2x + x − x ≤ 2 1 2 3 −2x + x − 5x ≥ − 1 2 3 6 4x1 + x2 + x3 ≤ 6 x1, x2, x3 ≥ 0.
☞ Solution.
Since the problem is not in the canonical form, you have to interchange the inequality of the second constraint, Maximize z = x1 + 2x2 + x3 Subject to: 2x + x − x ≤ 2 1 2 3 2x1 − x2 + 5x3 ≤ 6 4x1 + x2 + x3 ≤ 6 x1, x2, x3 ≥ 0.
Dual Let y , y , y be dual variables.
Thus the dual problem is given by 1 2 3 Minimize w = 2y1 + 6y2 + 6y3 Subject to: 2y1 + 2y2 + 4y3 ≥ 1 y1 − y2 + y3 ≥ 2 −y1 + 5y2 + y3 ≥ 1 y1, y2, y3 ≥ 0.
✍ Example 6.3.2 Find the dual of the following LPP.
125  UNIT 6.
DUALITY IN LINEAR PROGRAMMING Maximize z = 3x − x + x 1 2 3 Subject to: 4x − x ≤ 8 1 2 8x1 + x2 + 3x3 ≥ 12 5x1 − 6x3 ≤ 13 x1, x2, x3 ≥ 0.
☞ Solution.
Since the problem is not in the canonical form, you have to first of all interchange the inequality of the second constraint.
Maximize z = 3x1 − x2 + x3 Subject to: 4x − x ≤ 8 1 2 −8x1 − x2 − 3x3 ≤ −12 5x1 + 0x2 − 6x3 ≤ 13 x1, x2, x3 ≥ 0.
In matrix form you have Maximize z = cx Subject to: Ax ≤ b x ≥ 0       x 8 4 −1 0 1             Where c = (3 − 1 1), x =  x2 , b =  −12  and A =  −8 −1 −3        x 13 5 0 −6 3 Dual.
Let y , y , .
.
.
, y be the dual variables.
The dual problem is thus given as 1 2 3 Minimize w = bty Subject to: Aty ≥ ct y ≥ 0 126  UNIT 6.
DUALITY IN LINEAR PROGRAMMING i.e.,   y 1     Minimize w = (8 − 12 13)  y2    y3       4 −8 5 y 8 1             Subject to:  −1 −1 0   y2  ≥  −12        0 −3 6 y 13 3 That is Minimize w = 8y − 12y + 13y 1 2 3 Subject to: 4y − 8y + 5y ≥ 3 1 2 3 −y − y + 0y ≥ − 1 2 3 1 0y1 − 3y2 + 6y3 ≥ 1 y1, y2, y3 ≥ 0.
✍ Example 6.3.3 Write the dual of the following LPP Minimize z = 2x2 + 5x3 Subject to: x1 + x2 + 0x3 ≥ 2 −2x1 − x2 − 6x3 ≥ −6 x1 − x2 + 3x3 ≤ 4 x1 − x2 + 3x3 ≥ 4 x1, x2, x3 ≥ 0 ☞ Solution.
Again on rearranging the constraints, you have Minimize z = 0x1 + 2x2 + 5x3 Subject to: x + x + 0x ≥ 2 1 2 3 −2x1 − x2 − 6x3 ≥ −6 x1 − x2 + 3x3 ≥ 4 −x1 + x2 − 3x3 ≥ −4 x1, x2, x3 ≥ 0 Dual: Since there are four constraints in the primal, you have four dual variables namely y , y , yt , ytt.
1 2 3 3 Maximize w = 2y1 − 6y2 + 4y3t − 4y3t t Subject to: y − 2y + yt − ytt ≤ 0 1 2 3 3 y1 − y2 −2 y t + ytt ≤ 3 3 0y − 6y + 3yt − 3ytt ≤ 5 1 2 3 3 y1, y 2, yt3 , yt3t ≥ 0 127  UNIT 6.
DUALITY IN LINEAR PROGRAMMING Let y3 = yt3 − y3t t Maximize w = 2y1 − 6y2 + 4(y3t − y3t t) Subject to: y − 2y + (yt − ytt) ≤ 0 1 2 3 3 y1 − y2 − (y3t − 3y tt) ≤ 2 0y1 − 6y2 + 3(y3t − y3t t) ≤ 5 Finally, you have Maximize w = 2y1 − 6y2 + 4y3 Subject to: y − 2y + y ≤ 0 1 2 3 y1 − y2 − y3 ≤ 2 0y1 − 6y2 + 3y3 ≤ 5 y1, y2 ≥ 0, y3 is unrestricted.
✍ Example 6.3.4 Give the dual of the following problem: Maximize z = x + 2y Subject to: 2x + 3y ≥ 4 3x + 4y = 5 x ≥ 0 and y unrestricted.
☞ Solution.
Since the variable y is unrestricted, it can be expressed as y = yt − ytt, yt, ytt ≥ 0.
On reformulating the given problem, you have Maximize z = x + 2yt − 2ytt Subject to: −2x − 3(yt − ytt) ≤ − 4 3x + 4(yt − ytt) ≤ 5 3x + 4(y − ytt) ≥ 5 x, yt, ytt ≥ 0 Since the problem is not in the canonical form, you have to rearrange the constraints.
Maximize z = x + 2yt − 2ytt Subject to: −2x − 3yt + ytt ≤ − 4 3x + 4yt − 4ytt ≤ 5 −3x − 4y + 4ytt ≤ −5 x, yt, ytt ≥ 0 Dual Since there are three variables and three constraints in the primal, you have three variables, 128  UNIT 6.
DUALITY IN LINEAR PROGRAMMING namely y , yt , ytt.
1 2 3 Minimize w = −4y1 + 5w2t − 5w2t t Subject to: −2y + 3yt − 3ytt ≥ 1 1 2 2 −3y1 + 4y2t − 4y2t t ≥ 2 3y1 − 4y2t + 4 y2tt ≥ −2 y , yt , ytt ≥ 0 1 2 2 Let y = yt − ytt, so that the dual variables y is unrestricted in sign.
Finally the dual is 2 2 2 2 Minimize w = −4y1 + 5y2 Subject to: −2y + 3y ≥ 1 1 2 −3y1 + 4y2 ≥ 2 3y − 4y ≥ − 1 2 2 y1 ≥ 0, y2 is unrestricted or Minimize w = −4y + 5y 1 2 Subject to: −2y + 3y ≥ 1 1 2 −3y1 + 4y2 ≥ 2 −3y1 + 4y2 ≤ 2 y1 ≥ 0, y2 is unrestricted or Minimize w = −4y + 5y 1 2 Subject to: −2y + 3y ≥ 1 1 2 −3y1 + 4y2 = 2 y1 ≥ 0, y2 is unrestricted ✍ Example 6.3.5 Write the dual of the following primal LPP.
6.3.3 Important Results in Duality 1.
The dual of the dual is primal.
2.
If one is a maximization problem, the the other is of minimization.
3.
The necessary and sufficient condition for any LPP and its dual to have an optimal solu- tion is that both must have feasible solutions.
4.
Fundamental duality theorem states, if either the primal or dual problem has a finite opti- mal solution, then the other problem also has a finite optimal solution and also the optimal values of the objective function is both the problems are the same, i.e., max z = min w. The solution of the other problem can be read from zj − cj row below the columns of slack or surplus variables.
129  UNIT 6.
DUALITY IN LINEAR PROGRAMMING 5.
Existence theorems states that, if either problem has an unbounded solution then the other problem has no feasible solution.
6.
Complementary slackness theorem states that: (a) If a primal variable is positive, then the corresponding dual constraint is an equation at the optimum and vice versa.
(b) If a primal constraint is a strict inequality then the corresponding dual variable is zero at the optimum and vice versa.
Example 6.3.6 Solve the following LPP.
Maximize z = 6x1 + 8x2 Subject to: 5x + 2x ≤ 20 1 2 x1 + 2x2 ≤ 10 x , x ≥ 0 1 2 by solving its dual problem.
☞ Solution.
As there are two constraints in the primal, you have two dual variables y1 and y .
Thus the dual of this problem is given as.
2 Minimize w = 20y1 + 10y2 Subject to: 5y + y ≥ 6 1 2 2y1 + 2y2 ≥ 8 y1, y2 ≥ 0 You can solve the dual problem using the Big-M method.
Since this method involves artificial variables, the problem is reformulated and you have, Maximize wt = −20y − 10y + 0y − 0y − M A − M 1 2 3 4 1 A2 Subject to: 5y + y − y + A = 6 1 2 3 1 2y1 + 2y2 − y4 + A2 = 8 y1, y2, y3, y4, A1, A2 ≥ 0 130  UNIT 6.
DUALITY IN LINEAR PROGRAMMING B y1 y2 y3 y4 A1 A2 yB yB /y1 A1 5 1 -1 0 1 0 6 1.02 → A 2 2 0 -1 0 1 8 4 2 wj − cj -7M +20 -3M -10 M M 0 0 -14M ↑ B y y y y A A y y /y 1 2 3 4 1 2 B B 1 y1 1 1/5 -1/5 0 − 0 6/5 6 A2 0 8/5 2/5 -1 − 1 28/5 25/8 → wj − cj 0 - 85 M +6 - 25 M +4 M − 0 258 M +24 ↑ B y1 y2 y3 y4 A1 A2 yB y1 1 0 -1/5 1/8 − − 1/2 y2 0 1 1/4 -5/8 − − 7/2 w − c 0 0 5/2 15/4 − − -45 j j Since all wj − cj ≥ 0, the solution is optimum.
Therefore, the optimal solution of dual is, y = 1/2, y = 7/2, max wt = −45 1 2 Hence min w = 45 The optimum solution of the primal problem is given by the value of w − c in the optimal j j table corresponding to the column of surplus variables y and y .
i.e., 1 2 5 15 x = , x = 1 2 2 4 5 15 max z = 6 × + 8 × = 45 2 4 ✍ Example 6.3.7 Prove using duality theory that the following LPP has a feasible but not optimal solution.
Minimize z = x − x + x 1 2 3 Subject to: x − x ≥ 4 1 3 x1 − x2 + 2x3 ≥ 3 x1, x2, x3 ≥ 0 ☞ Solution.
Given the primal LPP Minimize z = x1 − x2 + x3 Subject to: x − x ≥ 4 1 3 x1 − x2 + 2x3 ≥ 3 x1, x2, x3 ≥ 0 131  UNIT 6.
DUALITY IN LINEAR PROGRAMMING Dual Since there are two constraints, there are two variables y and y in the dual, given by 1 2 Maximize w = 4y1 + 3y2 Subject to: y1 + y2 ≤ 1 0y − y ≤ − 1 2 1 −y1 + 2y2 ≤ 1 y1, y2 ≥ 0 To solve the dual problem Convert to standard form Maximize w = 4y1 + 3y2 Subject to: y + y + y = 1 1 2 3 0y1 + y2 − y4 + A1 = 1 −y1 + 2y2 + y5 = 1 y1, y2 ≥ 0 where y , y are slack variables, y the surplus variable and A the artificial variable.
3 5 4 1 B y1 y2 y3 y4 A1 y5 yB yB /y1 y 1 1 1 0 0 0 1 1 3 A 0 1 0 -1 1 0 1 1 1 y -1 2 0 0 0 1 1 1/2 → 5 wj − cj -4 -M -3 0 M 0 0 -M ↑ B y1 y2 y3 y4 A1 y5 yB yB /y1 y3 3/2 0 1 0 0 -1/2 1/2 1/3 → A 1/2 0 0 -1 1 -1/2 1/2 1 1 y -1/2 1 0 0 0 1/2 1/2 − 2 wj − cj - 12 M + 25 0 0 M 0 12 M + 32 - 21 M - 32 ↑ Table 6.1: Page 80-1 Since all w − c ≥ 0 and an artifical variable appears in the basis at positive level, j j the dual problem has no optimal basic feasible solution.
Therefore there exists no finite optimum solution to the given primal LPP (Unbounded solution) ✍ 6.3.4 Dual Simplex Method The dual simplex method is very similar to the regular simplex method.
The only difference lies in the criterion used for selecting a variable to enter and leave the basis.
In dual simplex method, you first select the variable to leave the basis and then the variable to enter the basis.
This method yields an optimal solution to the given LPP in a finite number of steps, provided no basis is repeated.
The dual simplex method is used to solve problems which start dual feasible (i.e., whose 132  UNIT 6.
DUALITY IN LINEAR PROGRAMMING primal is optimal but infeasible).
In this method the solution starts optimum, but infeasible 133  UNIT 6.
DUALITY IN LINEAR PROGRAMMING and remains infeasible until the true optimum is reached, at which the solution becomes feasi- ble.
The advantage of this method lies in its avoiding the artificial variables introduced in the constraints along with the surplus variables as all t ≥t constraints are converted into t ≤t type.
Dual Simplex Algorithm The iterative procedure for dual simplex method is listed below.
Step 1.
Convert the problem to maximization form if it is initially in the minimizatioin form.
Step 2.
Convert t ≥t type constraints if any to t ≤t type, by multiplying both sides by -1.
Step 3.
Express the problem in standard form by introducing slack variables.
Obtain the initial basic solution, display this solution in the simplex table.
Step 4.
Test the nature of z − c (optimal condition).
j j Case I.
If all z − c ≥ 0 and all x ≥ 0 then the current solution is an optimum j j Bi feasible solution.
Case II.
If all z − c ≥ 0 and at least x < 0 then the current solution is not j j Bi optimum basic feasible solution.
In this case go to te next step.
Case III.
If any z − c < 0 then the method fails.
j j Step 5.
In this step you have to find the leaving variable, which is the basic variable corre- sponding to the most negative value of x .
Let x be the leaving variable, i.e., x = Bi k Bk min{xBi , xBi < 0}.
To find out the variable entering the basis, you would compute the ratio between zj − cj row and the key row i.e.
compute max{zj − cj /cik , aik < 0} (Consider the ratios with negative Dr alone).
The entering variable is the one having the maximum ratio.
If there is no such ratio with negative Dr, then the problem does not have a feasible solution.
Step 6.
Convert the following element to unity and all the other elements of key column to zero, to get an improved solution.
Step 7.
Repeat steps (4) and (5) until either an optimum basic feasible solution is attained or an indication of no feasible solution is obtained.
Example 6.3.8 Use dual simplex method to solve the following LPP Maximize z = 3x1 − x2 Subject to: x + x ≥ 1 1 2 2x1 + 3x2 ≥ 2 x1, x2 ≥ 0 134  UNIT 6.
DUALITY IN LINEAR PROGRAMMING ☞ Solution.
Convert the given constraints into ≤ type.
Maximize z = 3x1 − x2 Subject to: −x − x ≤ − 1 2 1 −2x − 3x ≤ − 1 2 2 x1, x2 ≥ 0 Introducing slack variables x , x ≥ 0, you get 3 4 Maximize z = 3x1 − x2 + 0x3 + 0x4 Subject to: −x − x + x = −1 1 2 3 −2x1 − 3x2 + x4 = −2 x1, x2, x3, x4 ≥ 0 An initial basic (infeasible) solution of the modified LPP is x = −1, x = −2.
3 4 B x x x x x 1 2 3 4 B x3 -1 -1 1 0 -1 x4 -2 -3 0 1 -2 z j −c j 3 1 0 0 0 Table 6.2 Table 6.2: Since all z − c ≥ 0 and all x < 0, the current solution is not an optimum basic j j Bi feasible solution.
Since x = −2, the most negative, the corresponding basic variable x B2 4 leaves the basis.
Also since max{z − c /a , a < 0}, where x is the leaving variable, j j ik ik k max{3/ − 2, 1/ − 3} = −1/3 = z2 − c2/a22 the non-basic variable x2 enters the basis.
Drop x and introduce x .
4 2 First Iteration Since all z − c ≥ 0 and x = −1/3 < 0, the current solution is not optimum basic j j B1 feasible solution.
Therefore x = −1/3 the basic variable x leaves the basis.
Also since B1 3 max{z − c /a , a < 0} = max{(1/3)/(−1/3), .
.
.
, (1/3)/(−1/3)} = −1 corresponds j j i1 i1 to the non- basic variable x .
4 135  UNIT 6.
DUALITY IN LINEAR PROGRAMMING Therefore drop x and introduce x .
3 4 136  UNIT 6.
DUALITY IN LINEAR PROGRAMMING B x x x x x 1 2 3 4 B x -1/3 0 1 -1/3 -1/3 3 x 2/3 1 0 1 2/3 2 z −c 7 / 3 0 0 1 / 3 -2/3 j j Table 6.3 Table 6.3: Second Iteration B x x x x x 1 2 3 4 B 1 0 -3 1 1 x 4 1 -1 -1 0 1 x 2 z −c 2 0 1 0 -1 j j Table 6.4: Since all z − c ≥ and also x ≥ 0, an optimum basic feasible solution has been reached.
j j Bi The optimal solution to the given LPP is x = 0, x = 1, Maximum z = −1 ✍ 1 2 Example 6.3.9 Solve by the dual simplex method the following LPP.
Minimize z = 5x1 + 6x2 Subject to: x + x ≥ 2 1 2 4x1 + x2 ≥ 4 x1, x2 ≥ 0 ☞ Solution.
The given LPP is Maximize z = −5x1 − 6x2 Subject to: −x − x ≤ − 1 2 2 −4x − x ≤ − 1 2 4 x1, x2 ≥ 0 By introducing slack variables x , x the standard form of LPP becomes, 3 4 Maximize z = −5x1 − 6x2 + 0x3 + 0x4 Subject to: −x − x + x = −2 1 2 3 −4x − x + x = − 1 2 4 137  UNIT 6.
DUALITY IN LINEAR PROGRAMMING 4 x1, x2, x3, x4 ≥ 0 138  UNIT 6.
DUALITY IN LINEAR PROGRAMMING Initial table B x x x x x 1 2 3 4 B x 0 -3/4 1 0 -2 3 x -4 -1 0 1 -4 4 z −c 5 6 0 0 0 j j Table 6.5: Since all z − c ≥ 0 and x ≤ 0, the current solution is not an optimum basic j j Bi feasible solution.
Therefore x = −4, is most negative, the corresponding basic variable x B2 4 leaves the basis.
Also max{z − c /a , a < 0} = max{−5/4, 6/ − 1, .
.
. }
= −5/4 gives the non- j j i2 i2 basic variable, x enters into the basis.
1 First Iteration B x x x x x 1 2 3 4 B x 3 0 -3/4 1 -1/4 -1 x 1 ¼ 0 -¼ 1 1 z −c 0 19 / 4 0 5 / 4 -5 j j Table 6.6: Since all z − c ≥ 0 and also x = −1 < 0, the current basic feasible solution is j j B1 not optimum.
As x = −1 < 0 therefore, the basic variable x leaves the basis.
B1 3 ( \ ( \ Also, since max zj − cj , a < 0 = max 19/4 , 5/4 = 5 corresponds to the non- i1 ai1 −3/4 −1/4 4 basic variable x .
4 Therefore drop x and introduce x .
3 4 139  UNIT 6.
DUALITY IN LINEAR PROGRAMMING Second Iteration B x x x x x 1 2 3 4 B x 0 3 -4 1 4 4 x 1 1 -1 0 2 1 z −c 0 1 5 0 -10 j j Table 6.7: Since all z − c ≥ 0 and also all x ≥ 0, the current basic feasible solution is j j Bi optimum.
The optimal solution is given by x = 2, x = 0, max z = −10, i.e., min z = 10.
✍ 1 2 Example 6.3.10 Use dual simplex method to solve the LPP.
Maximize z = −3x1 − 2x2 Subject to: x + x ≥ 1 1 2 x1 + x2 ≤ 7 x1 + 2x2 ≥ 10 x2 ≤ 3 x1, x2 ≥ 0 ☞ Solution.
Interchanging the ≥ inequality of the constraints into ≤, the given LPP becomes Maximize z = −3x − 2x 1 2 Subject to: −x − x ≤ − 1 2 1 x1 + x2 ≤ 7 −x − 2x ≤ − 1 2 10 0x1 + x2 ≤ 3 By introducing the non-negative slack variables x , x , x , x , the standard form of the LPP 3 4 5 6 becomes, Maximize z = −3x1 − 2x2 + 0x3 + 0x4 + 0x5 + 0x6 Subject to: −x − x + x = −1 1 2 3 x + x + x = 7 1 2 4 −x1 − 2x2 + x5 = − 10 0x + x + x = 3 1 2 6 The initial solution is given by, 140  UNIT 6.
DUALITY IN LINEAR PROGRAMMING x = −1, x = 7, x = −10, x = 3 3 4 5 6 141  UNIT 6.
DUALITY IN LINEAR PROGRAMMING Initial table B x x x x x x x 1 2 3 4 5 6 B x 1 1 1 0 0 0 -1 3 x 1 1 0 1 0 0 7 4 x 5 -1 -2 0 0 1 0 -10 x 0 1 0 0 0 1 3 6 z −c 3 2 0 0 0 0 0 j j Table 6.8: Since all z − c ≥ 0 and some x ≤ 0, the current solution is not a basic feasible j j Bi solution.
Therefore x = −10 being the most negative, the basic variable x leaves the basis.
B3 6 Also, max{zj − cj /ai2, ai2 < 0} = max{3/ − 1, 2/ − 2} = −1, the non-basic variable x2 enters the basis.
First Iteration B x x x x x x x 1 2 3 4 5 6 B x -1/2 0 1 0 -1/2 0 4 3 x 1/2 0 0 1 1/2 0 2 4 x 2 1/2 1 0 0 -1/2 0 5 x -1/2 0 0 0 1/2 1 -2 6 z −c 2 0 0 0 1 0 -10 j j Table 6.9: 142  UNIT 6.
DUALITY IN LINEAR PROGRAMMING Second iteration.
Drop x and introduce x .
Therefore x = −2 < 0, x leaves the basis.
6 1 B4 6 ( \ ( \ max zj − cj , a1i < 0 = max 2 · · · = −4 a1i −1/2 Hence, x enters the basis.
1 B x x x x x x x 1 2 3 4 5 6 B x 0 0 1 0 -1 -1 2 3 x 0 0 0 1 1 1 0 4 x 2 0 1 0 0 -0 1 3 x 1 0 0 0 -1 -2 4 1 z −c 0 0 0 0 3 4 -18 j j Table 6.10: Since all z − c ≥ 0 and all x ≥ 0, the current solution is an optimum basic j j Bi feasible solution.
Therefore optimum solution is, max z = −18, x = 4, x = 3.
✍ 1 2 6.3.5 SENSITIVITY ANALYSIS The optimal values of the dual variables in a linear program can, be interpreted as prices.
In this section this interpretation is explored in further detail.
Consider the following problem.
minimize ctx subject to Ax = b (6.1) x ≥ 0 Suppose that the simplex method produced an optimal basis B.
How to make use of the opti- mality conditions (primal-dual relationships) in order to find the new optimal solution, if some of the problem data change, without resolving the problem from scratch.
In particular, the following variations in the problem will be considered.
1.
Change in the cost vector c. 143  UNIT 6.
DUALITY IN LINEAR PROGRAMMING 2.
Change in the right-hand side vector b.
3.
Change in the constraint matrix A.
4.
Addition of a new activity.
5.
Addition of a new constraint.
Change in the Cost Vector Given an optimal basic feasible solution, suppose that the cost coefficient of one (or more) of the variables is changed from c to ct .
The effect of this change on the final tableau will occur k k in the cost row; that is, dual feasibility may be lost.
Consider the following two cases.
Case I: x is non-basic k In this case cB is not affected, and hence zj = cBB−1aj is not changed for any j.
Thus zk − ck is replaced by zk − ckt .
Note that zk − ck ≤ 0 since the current point was an optimal solution of the original problem.
If z − ct = (z − c ) + (c − ct ) is positive, then x must be k k k k k k k introduced into the basis and the (primal) simplex method is continued as usual.
Otherwise the old solution is still optimal with respect to the new problem.
x is basic, say x ≡ x k k Bt Here c is replaced by ct .
Let the new value of z be zt .
Then zt − c is calculated as follows: Bt Bt j j j j ztj − cj = cBt B− 1 aj − cj = (cBB− 1a j − cj ) + (0, 0, .
.
.
, ctBt − cBt , 0, .
.
.
, 0)yj = (zj − cj ) + (cBt t − cBt )ytj for all j In particular for j = k, zk − ck = 0, and ytk = 1, and hence zkt − ck = ckt − ck .
As you would expect, z kt − ct k is still equal to zero.
Therefore the cost row can be updated by adding the net change in the cost of xBt ≡ xk times the current t row of the final tableau, to the original cost row.
Then ztk − ck is updated to zkt − ckt = 0.
Of course the new objective value ctB B− 1b = cBB−1b + (ctB t − cBt )bt will be obtained in the process.
Example 6.3.11 Consider the following problem.
minimize −2x1 + x2 − x3 subject to x + x + x ≤ 6 1 2 3 −x + 2x ≤ 4 1 2 x , x , x ≥ 0 1 2 3 144  UNIT 6.
DUALITY IN LINEAR PROGRAMMING B x x x x x x 1 2 3 4 5 B x 1 1 1 1 0 6 1 x 0 3 1 1 1 10 5 z −c 0 -1 -1 -2 0 -12 j j Table 6.11: The optimal tableau is given by the following.
The subsequent tableaux are not shown.
Next suppose that c = −2 is replaced by zero.
Since x is basic, then the new cost row, except 1 1 z − c is obtained by multiplying the row of x by the net change in c [that is, 0 − (−2) = 2] 1 1 1 1 and adding to the old cost row.
The new z − c remains zero.
Note that the new z − c is now 1 1 3 3 positive and so x enters the basis.
3 B x x x x x x 1 2 3 4 5 B x 1 1 1 0 6 1 1 x 0 3 1 1 1 10 5 z −c 0 -1 1 0 0 0 j j Table 6.12: And so on (The subsequent tableaux are not shown.)
Change in the Right-Hand-Side.
If the right-hand-side vector b is replaced by bt, then B−1b will be replaced by B−1bt.
The new right-hand side can be calculated without explicitly evaluating B−1bt.
This is evident by noting that B−1bt = B−1b + B−1(bt − b).
If the first m columns originally form the identity, then B−1(bt − b) = m y (bt − b ) and hence B−1bt = b¯ + m (bt − b ).
Since z − c ≤ 0 j=1 j j j j=1 j j j j for all non-basic variables (for a minimum problem), the only possible violation of optimality is that the new vector B−1b, may have some negative entries.
if B−1bt ≥ 0, then the same basis remains optimal, and the values of the basic variables are B−1bt and the objective has value c B−1bt.
Otherwise the dual simplex method is used to find the new optimal solution by B restoring feasibility.
( \ 3 Example 6.3.12 Suppose that the right-hand side of example (6.3.11) is replaced by .
4 145  UNIT 6.
DUALITY IN LINEAR PROGRAMMING ( l ( l ( l ( \ Note that B−1 = 1 0 and hence B−1bt = 1 0 3 = 3 .
Then B−1bt ≥ 0 1 1 1 1 4 7 and hence the new optimal solution is x = 3, x = 7, x = x = x = 0.
1 5 2 3 4 Change in the Constraint Matrix On the effect of changing some of the entries of the constraint matrix A.
Two cases are possible, namely, changes involving non-basic columns, and changes involving basic columns.
Case I: Changes in Activity Vectors for Non-basic Columns Suppose that the non-basic column a is modified to at .
Then the new updated column is B−1at j j j and zt − c = ct B−1 at − c .I f zt − c ≤ 0, then the old solution is optimal; otherwise the j j B j j j j simplex method is continued, after column j of the tableau is updated, by introducing the non- basic variable x .
j Case II: Changes in Activity Vectors for Basic Columns Suppose that the non-basic column a is modified to at .
This case can cause considerable trou- j j ble.
It is possible that the current set of basic vectors no longer form a basis after the change.
Even if this does not occur, a change in the activity vector for a single basic column will change B−1 and thus the entries in every column.
Assume that the basic columns are ordered from 1 to m. Let the activity vector for basic column j change from a to at .
Compute yt = B−1at where B−1 is the current basis inverse.
j j j j There are two possibilities.
If yt = 0, the current set of basic vectors no longer forms a basis.
j j In this case it is probably best to add an artificial variable to take the place of x in the basis and j resort to the two-phase method or the big-M method.
However, If ytj j /= 0, you may replace column j, which is currently a unit vector, by yt and pivot on yt .
The current basis continues j j j to be a basis.
However, upon pivoting you may have destroyed both primal and dual feasibility and, if so, must resort to one of the artificial variable (primal and dual) techniques.
( \ ( \ 1 2 Example 6.3.13 Suppose that in example 6.3.11, a is changed from to .
Then 2 2 5 ( \ ( \ ( \ 1 0 2 2 yt = B− 1a t = = 2 2 1 1 5 7 ( \ cBt B−1 a2t − c2 = (−1, 0) 27 − 1 = −5 Thus the current optimal tableau remains optimal with column x replaced by (−5, 2, 7)t. 2 ( \ ( \ 1 0 Next suppose that column a is changed from to .
Then 1 −1 −1 ( \ ( \ ( \ 1 0 0 0 y = B−1at = = 1 1 1 1 −1 −1 146  UNIT 6.
DUALITY IN LINEAR PROGRAMMING ( \ ctB B−1 at1 − c1 = (−2, 0) −01 − (−2) = 2 Here the entry in the x row of yt is zero, and so the current basic columns no longer span the 1 1 space.
Replacing column x1 by (2, 0, −1)t and adding the artificial variable A1 to replace x1 in the basis, you get the following tableau.
B x x x x x A x 1 2 3 4 5 1 B x 0 1 1 1 0 6 6 1 x -1 3 1 1 1 0 10 5 z − c 2 -3 -1 -2 0 − M -12 j j Table 6.13: After preliminary pivoting at row x and column A to get z − c = 0, that is, to get the 6 1 6 6 tableau in basic form, you may proceed with the big-M method.
( \ ( \ 1 3 Finally, suppose that column a is changed from to .
Then 1 −1 6 ( \ ( \ ( \ 1 0 3 3 yt = B− 1a t = = 1 1 1 1 6 9 ( \ 3 cBt B− 1a1t − c1 = (−2, 0) 9 − (−2) = −4 In this case the entry in the x1 row of yt1 is nonzero and so you should replace column x1 by (−4, 3, 9)t, pivot in the x1 column and x1 row, and proceed.
B x x x x x x 1 2 3 4 5 B x 1 1 1 0 6 1 3 x 9 3 1 1 1 10 5 z −c -4 -3 -1 -2 0 -12 j j Table 6.14: The subsequent tableaux are not shown.
147  UNIT 6.
DUALITY IN LINEAR PROGRAMMING Adding a New Activity Suppose that a new activity x with unit cost c and consumption column a is consid- n+1 n+1 n+1 ered for possible production.
Without resolving the problem, you can easily determine whether producing xn+1 is worthwhile.
First calculate zn+1 − cn+1.
If zn+1 − cn+1 ≤ 0 (for a mini- mization problem), then x∗ = 0 and the current solution is optimal.
On the other hand, if n+ 1 zn+1 − cn+1 > 0, then xn+1 is introduced into the basis and the simplex method continues to find the new optimal solution.
Example 6.3.14 Consider Example 6.3.11.
Your wish is to find the new optimal solution if a ( \ −1 new activity x6 ≥ 0 with c6 = 1, and a6 = 2 is introduced.
First, you will calculate z − c : 6 6 ( \ −1 z6 − c6 = wta6 − c6 = (−2, 0) 2 − 1 = 1 ( l ( l ( l 1 0 −1 −1 y = B−1a = = 6 6 1 1 2 1 Therefore x is introduced in the basis by pivoting at the x row and the x column.
The 6 5 6 B x x x x x x x 1 2 3 4 5 6 B x 1 1 1 1 0 -1 6 1 x5 0 3 1 1 1 1 10 z −c 0 -3 -1 -2 0 1 -12 j j Table 6.15: subsequent tableaux are not shown.
Adding a New Constraint Suppose that a new constraint is added to the problem.
If the optimal solution to the original problem satisfies the added constraint, it is then obvious that the point is also an optimal solution of the new problem.
If, on the other hand, the point does not satisfy the new constraint, that is, if the constraint “cuts away” the optimal point, you can use the dual simplex method to find the new optimal solution.
Suppose that B is the optimal basis before the constraint am+1x ≤ b is added.
The m+1 corresponding tableau is shown below.
148  UNIT 6.
DUALITY IN LINEAR PROGRAMMING z + (ct B−1N − c )x = ct B−1b B N N B (6.2) x + B−1Nx = B−1b B N The constraint am+1x ≤ bm+1 is rewritten as aBm +1xB + aNm +1xN + xn+1 = bm+1, where am+1 is decomposed into (am+1, am+1) and x is a non-negative slack variable.
Multiplying Equation B N n+1 (6.2) by am+1 and subtracting from the new constraint gives the following system: B z + (ctB B−1N − cN )xN = cB B−1b x + B−1Nx = B−1b B N (aNm +1− amB+ 1 B −1N)xN + xn+1 = bm+1 − amB+ 1 B − 1b These equations give us a basic solution of the new system.
The only possible violation of optimality of the new problem is the sign of b − am+1B−1b.
So if b − am+1B−1b ≥ m+1 m+1 0, B B then the current solution is optimal.
Otherwise, if bm+1 − aBm +1B−1b < 0, then the dual simplex method is used to restore feasibility.
Example 6.3.15 Consider Example 6.3.11 with the added restriction that −x + 2x ≥ 2.
Clearly the optimal 1 3 point (x , x , x ) = (6, 0, 0) does not satisfy this constraint.
The constraint −x + 2x ≥ 2 is 1 2 3 1 3 rewritten as x − 2x + x = −1, where x is a non-negative slack variable.
This row is 1 3 6 6 added to the optimal simplex tableau of Example 6.3.11 to obtain the following tableau.
B x x x x x x x 1 2 3 4 5 6 B x 1 1 1 1 0 0 6 1 x 0 3 1 1 1 0 10 5 x6 0 -1 -3 -1 0 1 -8 z −c 0 -3 -1 -2 0 0 -12 j j Table 6.16: Multiply row 1 by -1 and add to row 3 in order to restor the column x to a unit vector.
The 1 dual simplex method can then be applied to the resulting tableau below.
149  UNIT 6.
DUALITY IN LINEAR PROGRAMMING B x x x x x x x 1 2 3 4 5 6 B x 1 1 1 1 0 0 6 1 x 0 3 1 1 1 0 10 5 x6 0 -1 -3 -1 0 1 -8 z −c 0 -3 -1 -2 0 0 -12 j j Table 6.17: Subsequent tableaux are not shown.
Note that adding a new constraint in the primal problem is equivalent to adding a new variable in the dual problem and vice versa.
6.4 Conclusion In this unit, you considered the Dual problem, the dual simplex method and sensitivity analysis.
6.5 Summary Having gone through this unit, you are now able to (i) Formulate the dual of any problem.
(ii) Solve LPP problems using the dual simplex method/algorithm.
(iii) Perform sensitivity analysis of LPP using the dual simplex method.
((iv) You also know that the value of the slack/surplus variables in the z − c row at the optimal j j tableau of the simplex method for the dual problem gives you the value of the decision variable of the primal problem.
6.6 Tutor Marked Assignments(TMAs) Exercise 6.6.1 150  UNIT 6.
DUALITY IN LINEAR PROGRAMMING 1.
Consider the following problem Maximize −x1 + 2x2 Subject to 3x + 4x ≤ 12 1 2 2x − x ≥ 2 1 2 x , x ≥ 0 1 2 (a) Solve the problem graphically.
(b) State the dual and solve it graphically.
Utilize the theorem of duality to obtain the values of all the primal variables from the optimal dual solution.
2.
Consider the following problem.
Minimize 2x1 + 3x2 + 5x3 + 6x4 Subject to x + 2x + 3x + x ≥ 2 1 2 3 4 −2x + x − x + 3x ≤ −3 1 2 3 4 x , x , x , x ≥ 0 1 2 3 4 (a) Give the dual linear program.
(b) Solve the dual geometrically.
(c) Utilize information about the dual linear program and the theorems of duality to solve the primal problem.
3.
Solve the following linear program by a graphical method.
Maximize 3x1 + x2 + 4x3 Subject to 6x + 3x + 5x ≤ 25 1 2 3 3x + 4x + 5x ≤ 20 1 2 3 x , x , x ≥ 0 1 2 3 (Hint.
Utilize the dual problem.)
151  UNIT 6.
DUALITY IN LINEAR PROGRAMMING 4.
Give the dual of the following problem.
Minimize 2x1 + 3x2 − 5x3 Subject to x + x − x + x ≥ 5 1 2 3 4 2x + x ≤ 4 1 3 x + x + x = 6 2 3 4 x ≤ 0 1 x , x ≥ 0 2 3 x , unrestricted 4 5.
Consider the following problem.
Maximize 10x1 + 24x2 + 20x3 + 20x4 + 25x5 Subject to x + x + 2x + 3x + 5x ≤ 19 1 2 3 4 5 2x + 4x + 3x + 2x + x ≤ 57 1 2 3 4 5 x , x , x , x , x ≥ 0 1 2 3 4 5 (a) Write the dual problem and verify that (w , w ) = (4, 5) is a feasible solution.
1 2 (b) Use the information in part (a) to derive an optimal solution to both the primal and dual problems.
6.
Consider the following linear program.
P :Minimize 6x1 + 2x2 Subject to x + 2x ≥ 3 1 2 x ≥ 0 2 x unrestricted 1 (a) State the dual of P. (b) Draw the set of feasible solution for the dual of part (a).
(c) Convert P to canonical form by replacing x by xt − xtt with xt , xtt ≥ 0.
Give the 1 1 1 1 1 dual of this converted problem.
(d) Draw the set of feasible solutions of the dual of part (c).
(e) Compare parts (b) and (d).
What did the transformation of part (c) do to the dual of part (a)?
152  UNIT 6.
DUALITY IN LINEAR PROGRAMMING 7.
The following simplex tableau shows the optimal solution of a linear programming prob- lem.
It is known that x and x are the slack variables in the first and second constraints 4 5 of the original problem.
the constraints are of ≤ type.
B x x x x x x 1 2 3 4 5 B x 0 ½ 1 ½ 0 5/2 3 x 1 -½ 0 -1/6 1/3 5/2 1 z −c 0 -4 0 -4 -2 -40 j j Table 6.18: (a) Write the original problem.
(b) What is the dual of the original problem?
(c) Obtain the optimal solution of the dual from the above tableau.
8.
Consider the following linear programming problem.
Maximize 2x1 + 3x2 + 6x3 Subject to x + 2x + x ≤ 10 1 2 3 x − 2x + 3x ≤ 6 1 2 3 x , x , x ≥ 0 1 2 3 (a) Write the dual problem.
(b) Solve the foregoing problem by the simplex method.
At each iteration, identify the dual variables, and show which dual constraints are violated.
(c) At each iteration, identify the dual basis that goes with the simplex iteration.
Identify the dual basic and non-basic variables.
(d) Show that at each iteration of the simplex method, the dual objective is “worsened.” (e) Verify that at termination, feasible solutions of both problems are at hand, with equal objectives, and with complementary slackness.
9.
Consider the problem: Minimize ctx Subject to Ax = b x ≥ 0 153  UNIT 6.
DUALITY IN LINEAR PROGRAMMING where x is an n-vector, b is an m-vector and A is an n × m matrix.
Suppose that there exist an x such that Ax = b, under which of the following condi- 0 0 tions for m and n, b and c, and A is x is an optimal point.
0 (a) m = n, A = A−1 and c = b (b) m = n, A = At and c = bt (c) m < n, A = A−1 and c = bt (d) m < n, A = At and c = b 10.
The following are the initial and current tableaux of the linear programming problem.
B x x x x x x x x 1 2 3 4 5 6 7 B x 5 -4 13 b 1 1 0 20 6 x 1 -1 5 c 1 0 1 8 7 z −c 1 6 -7 a 5 0 0 0 j j B x x x x x x x x 1 2 3 4 5 6 7 B x 3 -1/7 0 1 -2/7 3/7 -1/7 4/7 12/7 x -12/7 1 0 -3/7 8/7 -5/7 13/7 4/7 2 z −c 72/7 0 0 11 / 7 8 /7 23 / 7 -50/7 60/7 j j Table 6.19: (a) Find a, b, and c. (b) Find B−1.
(c) Find ∂x /∂x .
2 5 (d) Find ∂x /∂b .
3 2 (e) Find ∂z/∂x .
6 (f) Find the compelementary dual solution.
11.
The following is an optimal simplex tableau (maximization and all ≤ constraints).
(a) Give the optimal solution.
(b) Give the optimal dual solution.
(c) Find ∂z/∂b .
Interpret this number.
1 (d) Find ∂x /∂x .
Interpret this number.
1 6 154  UNIT 6.
DUALITY IN LINEAR PROGRAMMING B x x x x x x x 1 2 3 4 5 6 B x 1 1 0 2 0 1 2 1 x 0 0 1 1 0 4 3/2 3 x 0 -2 0 1 1 6 1 5 z −c 0 0 0 4 0 9 5 j j Table 6.20: (e) If you could buy an additional unit of the first resource for a cost of 5 would you do 2 this?
Why?
(f) Another firm wishes to purchase one unit of the third resource from you.
How much is such a unit worth to you?
Why?
(g) Are there any alternate optimal solutions?
If not, why not?
If so, give one.
12.
Solve the following problem by the dual simplex method.
Maximize −4x1 − 6x2 − 18x3 Subject to x + 3x ≥ 3 1 3 x + 2x ≥ 5 2 3 x , x , x ≥ 0 1 2 3 Give the optimal values of the primal and dual variables.
Demonstrate that complemen- tary slackness holds.
13.
Consider the following linear programming problem.
Maximize 2x1 − 3x2 Subject to x + x ≥ 3 1 2 3x + x ≤ 6 1 2 x , x ≥ 0 1 2 You are told that the optimal solution is x1 = 32 and x2 = 32 .
Verify this statement by duality.
Describe two procedures for modifying the problem in such a way that the dual simplex method can be used.
Use one of thes procedures for solving the problem by the dual simplex method.
155  UNIT 6.
DUALITY IN LINEAR PROGRAMMING 14.
Solve the following linear program by the dual simplex method.
Minimize 2x1 + 3x2 + 5x3 + 6x4 Subject to x + 2x + 3x + x ≥ 2 1 2 3 4 −2x + x − x + 3x ≤ −3 1 2 3 4 x , x , x , x ≥ 0 1 2 3 4 15.
Consider the following problem.
Minimize 3x1 + 5x2 − x3 + 2x4 − 4x5 Subject to x + x + x + 3x + x ≤ 6 1 2 3 4 5 −x − x + 2x + x − x ≥ 3 1 2 3 4 5 x , x , x , x , x ≥ 0 1 2 3 4 5 (a) Give the dual problem.
(b) Solve the dual problem using the artificial constraint technique.
(c) Find the primal solution from the dual solution.
16.
Apply the primal-dual method to the following problem.
Minimize 9x1 + 7x2 + 4x3 + 2x4 + 6x5 + 10x6 Subject to x + x + x = 8 1 2 3 x + x + x = 5 4 5 6 x + x = 6 1 4 x + x = 4 2 5 x + x = 3 3 6 x , x , x , x , x , x ≥ 0 1 2 3 4 5 6 17.
Solve the following problem by the primal-dual algorithm.
Minimize x1 + 2x3 − x4 Subject to x + x + x + x ≤ 6 1 2 3 4 2x − x + 3x − 3x ≥ 5 1 2 3 4 x , x , x , x ≥ 0 1 2 3 4 156  UNIT 6.
DUALITY IN LINEAR PROGRAMMING 18.
Apply the primal-dual algorithm to the following problem.
Maximize 7x1 + 2x2 + x3 + 4x4 + 6x5 Subject to 3x + 5x − 6x + 2x + 4x = 27 1 2 3 4 5 x + 2x + 3x − 7x + 6x ≥ 2 1 2 3 4 5 9x − 4x + 2x + 5x − 2x = 16 1 2 3 4 5 x , x , x , x , x ≥ 0 1 2 3 4 5 19.
You have shown that the primal-dual algorithm converges in a finite number of steps in the absence of degeneracy.
What happens in the degenerate case?
How can you guarantee fi- nite convergence?
(Hint.
Consider applying the lexicographic simplex or the perturbation method to the restricted primal problem.)
20.
Consider the following linear programming problem and its optimal final tableau shown below.
Maximize 2x1 + x2 − x3 Subject to x + 2x + x ≤ 8 1 2 3 −x + x − 2x ≤ 4 1 2 3 x , x , x ≥ 0 1 2 3 Final Tableau B x x x x x x x 1 2 3 4 5 6 B x 1 2 1 1 0 1 12 1 x 0 3 -1 1 1 6 8 5 z −c 0 3 3 2 0 9 16 j j Table 6.21: (a) Write the dual problem and find the optimal dual variables from the foregoing tableau.
(b) Using sensitivity analysis, find the new optimal solution if the coefficient of x in 2 the objective function is changed from 1 to 5.
157  UNIT 6.
DUALITY IN LINEAR PROGRAMMING (c) Suppose that the coefficient of x in the second constraint is changed from -2 to 1.
3 Using sensitivity, find the new optimal solution.
(d) Suppose that the following constraint is added to the problem: x + x ≥ 2.
Using 2 3 sensitivity, find the new optimal solution.
(e) If you were to choose between increasing the right-hand side of the first and second constraints, which one would you choose?
Why?
What is the effect of this increase on the optimal value of the objective function?
(f) Suppose that a new activity x is proposed with unit return 4 and consumption vec- 6 tor a = (1, 2)t. Find the new optimal solution.
6 21. consider the following optimal tableau of the minimization problem where the constraint are of the ≤ type.
B x x x x x x x x x 1 2 3 4 5 6 7 8 B x 1 0 0 -1 0 ½ 1/5 -1 3 1 x 2 0 1 0 2 1 -1 0 ½ 1 x3 0 0 1 -1 -2 5 3/10 2 7 z −c 0 0 0 2 0 ½ 1/ 10 2 17 j j Table 6.22: where x , x and x are slack variables.
6 7 8 (a) Would the solution be altered if a new activity x with coefficients (2, 0, 3)t in the 9 constraints, and price of 5, were added to the problem?
(b) How large can x (the first constraint resource) be made without violating feasibil- B1 ity?
22.
Consider the tableau of exercise 21.
Suppose that you add the constraint x − x + 2x ≤ 1 2 3 10 to the problem.
Is the solution still optimal?
If not, find the new optimal solution.
¯ 23.
Consider the problem: Maximize cx subject to Ax = b, x ≥ 0.
Let z − c , y , and b j j ij i be the updated entries at some iteration of the simplex algorithm.
Indicate whether each of the following statements is true or false.
Discuss.
∂x (a) yi j = − Bi ∂x j ∂z (b) z − c = j j ∂x j (c) Dual feasibility is the same as primal optimality.
158  UNIT 6.
DUALITY IN LINEAR PROGRAMMING (d) Performing row operations on inequality systems yields equivalent systems.
(e) Adding artificial variables to the primal serves to restrict variables that are really unrestricted in the dual.
(f) Linear programming by the simplex method is essentially a gradient search.
(g) A linear problem can be solved by the two-phase method if it can be solved by the big-M method.
(h) There is a duality gap (difference in optimal objective values) when both the primal and the dual programs have no feasible solutions.
(i) Converting a maximization problem to a minimization problem changes the sign of the dual variables.
(j) If w is a dual variable, then i ∂z w = − i ∂b i (k) A linear program with some variables required to be greater than or equal to zero can always be converted into one where all variables are unrestricted, without adding any new constraints.
159  Module IV 156  UNIT 7 TRANSPORTATION PROBLEM 7.1 Introduction The transportation problem is one of the subcalsses of LPPs.
Here the objective is to transport various quantities of a single homogeneous commodity that are initially stored at various origins to different destinations in such a way that the transportation cost is minimum.
To achieve this you must know the amount and location of available supplies and the quantities demanded.
In addition, you must know the costs that result from transporting one unit of commodity from various origins to various destinations.
7.2 Objective At the end of this unit, you should be able to; (i) Give a mathematical formulation of a transportation problem.
(ii) Determine the initial solution of a transportation problem using any of (a) the North-West Corner Rule (NWCR) (b) Least Cost Method or Matrix Minima Method.
(c) Vogel’s Approximation Method (VAM) (iii) Perform optimality test on the initial solution use the MODI Method.
(iv) Resolve Degeneracy in transportation problem.
157  UNIT 7.
TRANSPORTATION PROBLEM 7.3 Transportation Problem 7.3.1 Mathematical Formulation (The Model) Consider a transportation problem with m origins (rows) and n-destinations (columns).
Let c ij be tht cost of transporting one unit of the product from the ith origin to jth destination, a the i quantities of commodity available at origin i, b the quantity of commodity needed at destination j j, x is the quantity transported from ith origin to jth destination.
The above transportation ij problem can be stated in the tabular form.
Destination 1 2 3 … n Capacity 1 C 11 C 12 C 13 C 1n a1 x x x x 11 12 13 1n 2 C 21 C 22 C 23 C 2n a 2 x x x x 21 22 23 2n Origin 3 x 31 C 31 x32 C 32 x11 C 33 x 3n C 3n a 3 C m1 C m2 C m3 C mn am m x x x x m1 m2 m3 mn Demand b b b b 1 2 3 n m n ∑ ai =∑ b j i= 1 j= 1 Table 7.1: The Linear programming model representing the transportation problem is given by m n Minimize z = c x ij ij i=1 j=1 n Subject to: x = a , (i = 1, 2, .
.
.
, n), (Row Sum) ij i j=1 m x = b , (j = 1, 2, .
.
.
, n) (Column Sum) ij j i=1 xij ≥ 0 for all i and j 158  UNIT 7.
TRANSPORTATION PROBLEM The given transportation problem is said to be balanced if m n a = b i j i=1 j=1 i.e., if the total supply is equal to the total demand.
7.3.2 Definitions Definition 7.3.1 Feasible Solution: Any set of non-negative allocations (x > 0) which satis- ij fies the row and column sum (rim requirement) is called a feasible solution.
Definition 7.3.2 Basic feasible solution A feasible solution is called a basic feasible solution if the number of non-negative allocations is equal to m + n − 1, where m is the number of rows and n the number of columns in a transportation table.
Definition 7.3.3 Non-degenerate basic feasible solution: Any feasible solution is to a trans- portation problem containing m origins and n destinations is said to be non-degenerate if it contains m + n − 1 occupied cells and each allocation is in an independent position.
The allocations are said to be in independent positions, if it is impossible to form a closed path.
A path which is formed by allowing horizontal and vertical lines and all the corner cells of which are occupied is called a closed path.
The allocations in the following tables are not in independent positions.
* * * * * * * * * * * * * Table 7.2: The allocations in the following table s are in independent positions.
Definition 7.3.4 Degenerate basic feasible solution: If a basic feasible solution contains less than m + n − 1 non-negative allocations, it is said to be ’degenerate’ 159  UNIT 7.
TRANSPORTATION PROBLEM * * * * * * * * * * Table 7.3: 7.3.3 Optimal Solution Optimal solution is a feasible solution (not necessary basic), which minimizes the total cost.
The solution iof a transportation problem can be obtained in two stages, namely initial and optimum solution.
Initial solution can be obtained by using any one of the three methods, viz., 1.
North-West Corner Rule (NWCR) 2.
Least Cost Method or Matrix Minima Method, 3.
Vogel’s Approximation Method (VAM).
VAM is preferred over the other two methods, since the initial basic feasible solution ob- tained by this method is either optimal or very close to the optimal solution.
The cells om the transportation table can be classified as occupied and unoccupied cells.
The allocated cells in the tranportation table are called occupied cells and the empty ones are called unoccupied cells.
The improved solution of the intial basic feasible solution is called ’optimal solution’, which is is the second stage of solution and can be obtained by MODI (modified distribution method).
7.3.4 North-West Corner Rule Step 1.
Starting with the cell at the upper left corner (north-west) of the transportation matrix, you allocate as much as possible so that either the capacity of the first row is exhausted or the destination requirement of the first column is satisfied i.e., x = min(a , b ).
11 1 1 Step 2.
If b > a , you move down vertically to the second row and make the second allocation 1 1 of magnitude x = min(a , b − x ) in the cell (2, 1).
22 2 1 11 If b < a , move right horizontally to the second column and make the second allocation 1 1 of magnitude x = min(a , x − b ) in the cell (1, 2).
12 1 11 1 160  UNIT 7.
TRANSPORTATION PROBLEM If b = a , there is a tie for the second allocation.
You make the second allocation of 1 1 magnitude x12 = min(a1 − a1, b1) = 0 in cell (1, 2).
or x21 = min(a2, b1 − b1) = 0 in the cell (2, 1) Step 3 Repeat steps 1 and 2, moving down toward the lower right corner of the transportation table until all the rim requirements are satisfied.
Example 7.3.1 Obtain the inital basic feasible solution of the transportation problem whose cost and rim requirement table is given below.
Origin/Destination D D D Supply 1 2 3 O 2 7 4 5 1 O 3 3 1 8 2 O 5 4 7 7 3 O 1 6 2 14 4 Demand 7 9 18 34 Table 7.4: ☞ Solution.
Since a = 34 = b , there exists a feasible solution to the transportation i j problem.
You obtain initial feasible solution as follows.
The first allocation is made in the cell (1, 1), the magnitude being x = min(5, 7) = 5.
11 The second allocation is made in the cell (2, 1) and the magnitude of the allocation is given by x21 = min(8, 7 − 5) = 2.
D D D Supply 1 2 3 O1 2 7 4 5 0 5 O 2 3 3 1 8 6 0 2 6 O3 5 4 7 7 4 0 3 4 1 6 2 O4 14 14 0 Demand 7 9 18 34 2 3 14 0 0 0 Table 7.5: 161  UNIT 7.
TRANSPORTATION PROBLEM The third allocation is made in the cell (2, 2), the magnitude being x = min(8 − 2, 9) = 6.
22 The magnitude of fourth allocation is made in the cell (3, 2) given by x = min(7, 9 − 6) = 3.
32 The fifth allocation is made in the cell (3, 3) with magnitude x = min(7 − 3, 14) = 4.
33 The final allocation is made in the cell (4, 3) with maginitude x43 = min(14, 18 − 4) = 14.
Hence you get the initial basic feasible solution to the given T.P.
which is given by, x = 5; x = 2; x = 6; x = 3; x = 4; x = 14 11 21 22 32 33 43 Total cost = 2 × 5 + 3 × 2 + 3 × 6 + 3 × 4 + 4 × 7 + 2 × 14 = 10 + 6 + 18 + 12 + 28 + 28 = $102 ✍ 7.3.5 Least Cost or Matrix Minima Method Step 1 Determine the smallest cost in the cost matrix of the transportation table.
Let it be c .
ij Allocate x = min(a , b ) in the cell (i, j).
ij i j Step 2 If x = a , cross of the ith row of the transportation table and decrease b by a.
Then ij i j i go to step 3.
If x = b , cross off the jth column of the transportation table and decrease a by b .
Go ij j i j to step 3.
If x = a = b , cross off either the ith row and the jth column but not both.
ij i j Step 3 Repeat steps 1 and 2 for the resulting reduced transportation table until all the rim re- quirements are satisfied.
Whenever the minimum cost is not unique, make an arbitrary choice among the minima Example 7.3.2 Obtain an initial feasible solution to the following TP using the matrix minima method.
D D D D Supply 1 2 3 4 O 1 2 3 4 6 1 O 4 3 2 0 8 2 O 0 2 2 1 10 3 Demand 4 6 8 6 24 Table 7.6: ☞ Solution.
Since a = b = 24, there exists a feasible solution to the TP.
Using the i j steps in the least cost method, the first allocation is made in the cell (3, 1) the magnitude being x = 4.
It satisfies the demand at the destination D and you will delete this column from the 31 1 table as it is exhausted.
162  UNIT 7.
TRANSPORTATION PROBLEM 1 2 3 4 Capacity 1 1 2 3 4 6 0 6 2 4 3 2 0 8 2 0 2 6 3 0 2 2 1 10 6 4 6 Demand 4 6 8 6 24 0 0 2 0 0 Table 7.7: The second allocation is made in the cell (2, 4) with magnitude x = min(6, 8) = 6.
Since 24 it satisfies the demand at the destination D , it is deleted from the table.
From the reduced table 4 the third allocation in made in the cell (3, 3) with magnitude x = min(8, 6) = 6.
The next 33 allocation is made in the cell (2, 3) with magnitude x of min(2, 2) = 2.
Finally the allocation 23 is made in the cell (1, 2) with magnitude x = min(6, 6) = 6.
Now all the rim requiremnts 12 have been satisfied and hence, initial feasible solution is obtained.
The solution is given by x = 6; x = 2; x = 6; x = 4; x = 6.
12 23 24 31 33 Since the total number of occupied cells = 5 < m + n − 1 = 6.
You get a degenerate solution.
Total cost = 6 × 2 + 2 × 2 + 6 × 0 + 4 × 0 + 6 × 2 = 12 + 4 + 12 = $28.
✍ Example 7.3.3 Determine an initial basic feasible soltuion for the following TP, using least cost method.
D D D D Supply 1 2 3 4 O 6 4 1 5 14 1 O 8 9 2 7 16 2 O 4 3 6 2 5 3 Demand 6 10 15 4 35 Table 7.8: 163  UNIT 7.
TRANSPORTATION PROBLEM ☞ Solution.
Since ai = bj , there exists a basic feasible solution.
Using the steps in least cost method, make the first allocation to the cell (1, 3) with magnitude x = 13 min(14, 15) = 14 (as it is the cell having the least cost).
This allocation exhausts the first row supply.
Hence, the first row is deleted.
From the reduced table the next allocation is made in the next least cost cell (2, 3) which is chosen arbi- trarily with magnitude x = min(1, 16) = 1, which exhausts the 3rd column destination.
23 From the reduced table, the next least cost cell is (3, 4) to which allocation is made with magnitude min(4, 5) = 4.
This exausts the destination D requirement, deleting the fourth 4 column from the table.
The next allocation is made in the cell (3, 2) with magnitude x = 32 min(1, 10) = 1, which exhausts the 3rd origin capacity.
Hence, the 3rd row is exhausted.
From the reduced table the next allocation is given to the cell (2, 1) with magnitude x = 21 min(6, 15) = 6.
This exhausts the first column requirement.
Hence, it is deleted from the table.
Finally the allocation is made to the cell (2, 2) with magnitude x = min(9, 9) = 9, which 22 satisfies the rim requirement.
The following table gives the initial basic feasible solution.
D D D D Capacity 1 2 3 4 O1 6 4 1 5 14 14 O2 8 9 2 7 16 6 9 1 O 3 4 3 6 2 1 4 5 Demand 6 10 15 4 35 Table 7.9: Solution is given by, x = 14; x = 6; x = 9; x = 1; x = 1; x = 4 13 21 22 23 32 34 Transportation cost = 14 × 1 + 6 × 8 + 9 × 9 + 1 × 2 + 3 × 1 + 4 × 2 = $156.
✍ 7.3.6 Vogel’s Approximation Method (VAM) The steps involved in this method for finding the initial solution are as follows.
Step 1 Find the penalty cost, namely the difference between the smallest and next smallest costs in each row and column.
Step 2 Among the penalties as found in step (1), choose the maximum penalty.
If this maximum penalty is more than one (i.e., if there is a tie), choose any one arbitrarily.
164  UNIT 7.
TRANSPORTATION PROBLEM Step 3 In the selected row or column as by step (2), find out the cell having the least cost.
Allocate to this cell as much as possible, depending on the capacity and requirements.
Step 4 Delete the row or column that is fully exhausted.
Again compute the column and row penalties for the reduced transportation table and then go to step (2).
Repeat procedure until all the rim requirements are satisfied.
Note If the column is exhausted, then there is a change in row penalty, and vice versa.
Example 7.3.4 Find the initial basic feasible solution for the following transportation problem by VAM.
Destination D D D D Supply 1 2 3 4 O1 11 13 17 14 250 Origin O 16 18 14 10 300 2 O 21 24 13 10 400 3 Demand 200 225 275 250 950 Table 7.10: ☞ Solution.
Since a = b = 950, the problem is balanced and there exists a feasible i j solution to the problem.
First you find the row and column penalty P as the difference between the least and 1 next least cost.
The maximum penalty is 5.
Choose the column arbitrarily.
In this column choose the cell having the least cost (1, 1).
Allocate to this cell with minimum magnitude (i.e., min(250, 200) = 200).
This exhausts the first column.
Delete this column.
Since the column is deleted, there is a change in row penalty P and column penalty P remains the same.
I I I I Continuing in this manner you get the remaining allocations as given in the table below.
165  UNIT 7.
TRANSPORTATION PROBLEM I allocation D D D D Capacit P IV allocation 1 2 3 4 y 1 D D Capacity P 3 4 IV O1 11 13 17 14 2 O 14 10 4 250 2 200 125 50 125 0  O2 16 18 14 10 4 O 13 10 3 3 00 3 400 O3 21 24 13 10 3 Demand 275 250 400 125 Deman 200 225 275 250 P 1 0 IV d 0 P 5  5 3 0 1 II allocation V allocation D D D Capacity P 2 3 4 II D D Capacity P 3 4 V O1 13 17 14 50 1 O 3 13 10 3 50 0 275 400 125 O2 18 14 10 300 4 Demand 275 125 0 O3 24 13 10 3 P 13  10 400 V Demand 225 275 250 175 P 5  1 0 II III allocation VI allocation D D D Capacity P D Capacity P 2 3 4 III 4 VI O2 18 14 10 4 O3 10 10 175 310205 125 410205  O3 24 13 10 3 Demand 125 400 0 Demand 175 275 250 P 10 VI 0 P 6  1 0 III Table 7.11: Finally, you arrive at the initial basic feasible solution, which is shown in the following table.
166  UNIT 7.
TRANSPORTATION PROBLEM D D D D Capacity 1 2 3 4 O1 11 13 17 14 250 200 50 O2 16 18 14 10 300 175 125 O3 21 24 13 10 275 125 400 Demand 200 225 275 250 Table 7.12: There are 6 positive independent allocations which are equal to m + n − 1 = 3 + 4 − 1.
This ensures that the solution is a non-degenerate basic feasible solution.
Therefore transportation cost = 11 × 200 + 13 × 50 + 18 × 175 + 10 × 125 + 13 × 275 + 10 × 125 = $12075 ✍ Example 7.3.5 Find the initial solution to the following TP using VAM.
Destination D D D D Supply 1 2 3 4 F1 3 3 4 1 100 Factory F 4 2 4 2 125 2 F 1 5 3 2 75 3 Demand 120 80 75 25 300 Table 7.13: ☞ Solution.
Since a = b , the problem is a balanced TP.
So there exists a feasible i j solution.
167  UNIT 7.
TRANSPORTATION PROBLEM D D D D Supply P P P P P P 1 2 3 4 1 II III IV V VI F 1 3 3 4 1 2 2 0 1 4 4 45 30 25 100   F 2 4 2 4 2 2 2 2 0 4 _ 125   80 45 F 3 1 5 3 2 1 _ _ _ _ _ 75 75 Demand 120 80 75 25 P 2  1 1 1 1 P 1 1 0 1 II P 1 1 0 - III P 1 - 0 - IV P - - 0 - V P - - 4  - VI Table 7.14: Finally you have the initial basic feasible solution as given in the following table.
D D D D Supply 1 2 3 4 F 1 3 3 4 1 45 30 25 100 F 2 4 2 4 2 125 80 45 F 3 1 5 3 2 75 75 Demand 120 80 75 25 Table 7.15: There are 6 independent non-negative allocations equal to m + n − 1 = 3 + 4 − 1 = 6.
This ensures that the solution is non-degenerate basic feasible.
Therefore The transportation cost = 3 × 45 + 4 × 30 + 1 × 25 + 2 × 80 + 4 × 45 + 1 × 75.
= 135 + 120 + 25 + 160 + 180 + 75 = $695.
✍ 168  UNIT 7.
TRANSPORTATION PROBLEM 7.3.7 Optimality Test Once the initial basic feasible solution has been computed, the next step in the problem is to determine whether the solution obtained is optimum or not.
Optimality test can be conducted on any initial basic feasible solution of TP provided such an allocation has exactly m+n-1, non-negative allocations.
Where m is the number of origins and n is the number of destinations.
Also these allocations must be in independent positions.
To perfom this optimality test, you shall be introduced to the modified distribution method (MODI).
The various steps involved in MODI method for performing the optimality test are given below.
7.3.8 MODI Method Step 1 Find the initial basic feasible solution of a TP by using any one of the three methods.
Step 2 Find out a set of numbers u and v for each row and column satisfying u + v = c for i j i j ij each occupied cell.
To start with, you assign a number ’0’ to any row or column having maximimum number of allocations.
If this maximum number of allocations is more than one, choose any one arbitrarily.
Step 3 For each empty (unoccupied) cell, you have to find the sum u and v written in the i j bottom left corner of that cell.
Step 4 Find out for each empty cell the net evaluation value ∆ = c − (u + v ), which is ij ij i j written at the bottom right corner of that cell.
This step gives the optimality conclusion.
(i) If all ∆ > 0 (i.e., all the net evaluation value), the solution is optimum and a ij unique solution exists.
(ii) If ∆ ≥ 0, then the solution is optimum, but an alternate solution exists.
ij (iii) If at least one ∆ < 0, the solution is not optimum.
In this case you have to go to ij the next step, to improve the total transportation cost.
Step 5 Select the empty cell having the most negative value of ∆ .
From this cell you draw ij a closed path by drawing horizontal and vertical lines with the corner cells occupied.
Assign sign + and − alternatively and find the minimum allocation from the cell having negative sign.
This allocation should be added to the allocation having positive sign and subtracted from the allocation having the negative sign.
Step 6 The above step yeilds a better solution by making on (or more) occupied cell as empty and one empty cell as occupied.
For this new set of basic feasible allocations repeat from step (2) onwards, till an optimum basic feasible solution is obtained.
Example 7.3.6 Solve the following transportation problem.
☞ Solution.
First find the initial basic feasible solution by using VAM.
Since a = b , i i the given TP is a balanced one.
Therefore, there exists a feasible solution.
169  UNIT 7.
TRANSPORTATION PROBLEM Destination P Q R S Supply A 21 16 25 13 11 Origin B 17 18 14 23 13 C 32 17 18 41 19 Demand 6 10 12 15 43 Table 7.16: P Q R S Supply P P P P P P 1 II III IV V VI A 21 16 25 13 3 _ _ _ _ _ 45 30 25 11 B 17 18 14 23 3 3 3 3 _ _ 80 45 13  C 32 17 18 48 1 1 1 1 1 17 75 19 Demand 6 10 12 15 P 4 1 4 10  1 P 15 1 4 18  II P 15  1 4  - P III - 1 4  - P IV - 17 18  - V P - 17  - - VI Table 7.17: P Q R S Supply A 21 16 23 13 11 11 B 17 18 14 23 13 6 3 4 C 32 17 18 48 10 9 19 Demand 6 10 12 15 43 Table 7.18: Finally you have the initial basic feasible solution as given in the followinig table.
From this table you see that the nuber of non-negative independent allocation is 6=m+n- 170  UNIT 7.
TRANSPORTATION PROBLEM 1=3+4-1.
Hence the solution is non-degenerate basic feasible.
Therefore The initial transportation cost = 11 × 13 + 3 × 14 + 4 × 23 + 6 × 17 + 17 × 10 + 18 × 9 = $711 To find the Optimal solution You will apply MODI method in order to determine the optimum solution.
Determine the set of numbers u and v for each row and column, with u + v = c for each occupied cell.
To start i j i j ij with, give u = 0 as the 2nd row has the maximum number of allocation.
2 c = u + v = 17 = 0 + v = 17 ⇒ v = 17 21 2 1 1 1 c = u + v = 14 = 0 + v = 14 ⇒ v = 14 23 2 3 3 3 c = u + v = 23 = 0 + v = 23 ⇒ v = 23 24 2 4 4 4 c = u + v = 13 = u + 23 = 13 ⇒ u = −10 14 1 4 1 1 c = u + v = 18 = u + 14 = 18 ⇒ u = 4 33 3 3 3 3 c = u + v = 17 = 4 + v = 17 ⇒ v = 4 32 3 2 2 2 Now you find the sum u and v for each empty cell and enter it at the bottom right corner of i j that cell.
P Q R S U i A 21 16 23 13 11 u1=−10 B 17 18 14 23 6 3 4 u 2=0 C 32 17 18 48 10 9 u 3=4 v v =17 v =13 v =14 v = 23 j 1 2 3 1 Table 7.19: Next you find the net evaluation ∆ = C − (u + v ) for each unoccupied cell and enter it ji ij i j at the bottom right corner of that cell.
Since all ∆ > 0, the solution is optimal and unique.
The optimum solution is given by ij x = 11, x = 6, x = 3, x = 4, x = 10, x = 9 14 21 23 24 32 33 171  UNIT 7.
TRANSPORTATION PROBLEM The min.
transportation cost = 11 × 13 + 17 × 6 + 3 × 14 + 4 × 23 + 10 × 17 + 9 × 18 = $711.
✍ Degeneracy in transportation problem.
In a TP, if the number of non-negative independent allocations is less than m+n-1, where m is the number of origins (rows) and n is the number of destinations (columns), there exists a degeneracy.
This may occur either at the initial stage or at subsequent iteration.
To resolve this degeneracy, you will adopt the following steps: 1.
Among the empty cells, you will choose an empty cell having the least cost, which is of an independent position.
If such cells are more than one, choose any one arbitrarily.
2.
To the cell as chosen in step (1), you will allocate a small positive quantity ε > 0.
You will treat the cell containing ε are treated like other occupied cells and degeneracy is removed by adding one (or more) accordingly.
For this modified solution, you will adopt the steps involved in MODI method till an optimum solution is obtained.
Example 7.3.7 Solve the transportation problem for minimization.
Destination 1 2 3 Capacity 1 2 2 3 10 Sources 2 4 1 2 15 3 1 3 1 40 Demand 20 15 30 65 Table 7.20: ☞ Solution.
Since a = b , the problem is a balanced TP.
Hence, there exists a j j feasible solution.
You found the initial solution by north-west corner rule as given below.
Since the number of occupied cells= 5 = m + n − 1 and all the allocations are indpendent, you got an initial basic feasible solution.
The initial transportation cost = 10 × 2 + 4 × 10 + 5 × 1 + 10 × 3 + 1 × 30 = $125.
172  UNIT 7.
TRANSPORTATION PROBLEM 1 2 3 Capacity 1 2 2 3 10 10 2 4 1 2 15 10 5 3 1 3 1 10 30 40 Demand 20 15 30 Table 7.21: To find the optimal solutions (MODI METHOD) You used the above table to apply MODI method.
You have found out a set of numbers u and i v for which u + v = c , only for occupied cells.
To start with, as the maximum number of j i j ij allocations is 2 in more than one row and column.
You chose arbitrarily column 1, and assign a number 0 to this column, i.e., v = 0.
The remaining numbers can be obtained as follows.
1 c = u + v = 2 ⇒ u + 0 = 2 11 1 1 1 c = u + v = 4 ⇒ u = 4 − 0 = 4 21 2 1 2 c = u + v = 1 ⇒ v = 1 − u = 1 − 4 = −3 22 2 2 2 2 c = u + v = 3 ⇒ u = 3 − v = 3 − (−3) = 32 3 2 3 2 6 c = u + v = 1 ⇒ v = 1 − u = 1 − 6 = − 33 3 3 3 3 5 Initial table Find the sum of u and v for each empty cell and write it at the bottom left corner of that cell.
i j Find net evaluation ∆ = c − (u + v ) for each empty cell and enter it at the bottom right ij ij i j corner of the cell.
The solution is not optimum as the cell (3, 1) has a negetive ∆ value.
The ij allocation is improved by making this cell namely (3, 1) as an allocated cell.
Draw a closed path from this cell and assign + and − signs alternately.
From the cell having negative sign you find the minimum allocation given by min(10, 10) = 10.
Hence, you get two occupied cells (2, 1)(3, 2) that become empty and the cell (3, 1) is occupied, resulting in a degenerate solution.
(Degeneracy in subsequent iteration).
Number of allocated cell = 4 < m + n − 1 = 5.
You get a degeneracy and to resolve it, you add the empty cell (1, 2) and allocate ε > 0.
This cell namely (1, 2) is added as it satisfies the two steps for resolving the degeneracy.
You 173  UNIT 7.
TRANSPORTATION PROBLEM 1 2 3 u i 1 2 2 3 u1=2 10 -1 3 -3 6 2 4 1 2 u = 4 10 - 5 + -1 3 2 3 1 3 1 6+ -5 10 - 30 u 3=6 v v = 0 v =−3 v =−5 j 1 2 3 Table 7.22: will assign a number 0 to the first row, namely u = 0, to get the remaining numbers as follows.
1 c = u + v = 2 ⇒ v = 2 − u = 2 − 0 = 2 11 1 1 1 1 c = u + v = 2 ⇒ v = 2 − u = 2 − 0 = 2 12 1 2 2 1 c = u + v = 1 ⇒ u = 1 − v = 1 − 2 = − 31 3 1 3 1 1 c = u + v = 1 ⇒ v = 1 − u = 1 − (−1) = 2 33 3 3 3 3 c = u + v = 1 ⇒ u = 1 − v = 1 − 2 = −1 22 2 2 2 2 Next, find the sum of u and v for the empty cell and enter it at the bottom left corner of the j j cell and also the net evaluation ∆ = c − (u + v ) for each empty cell and enter it at the ij ij i j bottom right corner of the cell.
I Iteration table 1 2 3 u i 1 2 2 3 0 10 ε 2 1 2 4 1 2 -1 1 3 15 1 1 3 1 3 1 10 30 -1 v 2 2 2 j Table 7.23: 174  UNIT 7.
TRANSPORTATION PROBLEM The modified solution is given in the following table.
This solution is also optimal and unique as it satifies the optimality conditon that all ∆ > 0. ij 1 2 3 Supply 1 2 2 3 10 10 ε 2 1 2 4 1 2 15 15 3 1 3 1 10 30 40 Demand 20 15 30 65 Table 7.24: x11 = 10; x12 = 15; x33 = 30. x12 = εj ; x31 = 10.
Total cost = 10 × 2 + 2 × E + 15 × 1 + 10 × 1 + 30 × 1 = 75 + 2ε = $75.
✍ Example 7.3.8 Solve the following transportation problem whose cost matrix is given below.
7.4 Conclusion In this unit, you studied the transportation problem, you saw different methods of obtaining the initial solution, learnt how to optimize the solution of a transportation problem using the MODI method and also learnt how to resolve degeneracy in a transportation problem.
7.5 Summary Having gone through this unit, you (i) can now give the mathematical formulation of a transportation problem.
(ii) Any set of non-negative allocations (x > 0) which satisfies the row and column sum ij (rim requirement) is called a feasible solution.
175  UNIT 7.
TRANSPORTATION PROBLEM (iii) A feasible solution is called basic feasible solution of the number of non-negative alloca- tions is equal to m+n-1, where m is the number of rows and n is the number of columns in a transportation table.
(iv) Any feasible solution in a transportion problem containing m origins and n destinatio is said to be non-degenerate if it contains m+n-1 occupied cells and each allocation is in an independent position.
(v) can now obtain initial solution of a transportation problem using any of (a) the North-West Corner Method (NWCR).
(b) the Least Cost method (LCM) (c) the Vogel’s Approximation Method (VAM) (vi) can optimize the solution of a transportation problem using the MODI Method.
(vii) can resolve degeneracy in a transportation problem.
7.6 Tutor Marked Assignments Exercise 7.6.1 1.
What do you understand by transportation model?
2.
Define feasible solution, basic solution, non-degenerate solution and optimal solution in a transportation problem.
3.
Explain the following briefly with examples: (i) North-West Corner Rule.
(ii) Least Cost Method.
(iii) Vogel’s Approximation Method.
4.
Explain degeneracy in a TP and how to resolve it.
5.
What do you mean by an unbalanced TP.
Explain how you would convert an unbalanced TP into a balanced one.
6.
Give the mathematical formulation of a TP.
7.
Explain an algorithm to solving a transportation problem.
8.
Obtain the initial solution for the following TP using (i) NWCR (ii) Least cost method (iii) VAM.
[Ans.
176  UNIT 7.
TRANSPORTATION PROBLEM Destination A B C Supply 1 2 7 4 5 2 3 3 1 8 Source 3 5 4 7 7 4 1 6 2 14 Demand 7 9 18 34 (i) X = 5, X = 3, X = 6, X = 3, X = 4, X = 14 and the transportation 11 21 22 32 33 43 cost is $102.
(ii) X = 3, X = 3, X = 8, X = 7, X = 7, X = 7 and transportation cost is 12 13 23 32 41 43 $83 (iii) X = 5, X = 8, X = 7, X = 2, X = 2, X = 10 and the transportation 11 23 32 41 42 43 cost is $80.]
9.
Solve the following TP where the cell entries denote the unit transportation costs (using the least cost method).
Destination A B C D Supply P 5 4 2 6 20 Origin Q 8 3 5 7 30 R 5 9 4 6 50 Demand 10 40 20 30 100 [Ans X = 10, X = 10, X = 30, X = 10, X = 10, X = 30 and The optimum 12 13 22 31 33 34 transportation cost is $420.]
10.
Solve the following TP (using the least cost method).
Destination 1 2 3 Capacity 1 2 2 3 10 Source 2 4 1 2 15 3 1 3 1 40 Demand 20 15 30 [Ans X = 10, X = 15, X = 20, X = 15, X = 5. and The transportation cost is 12 23 31 33 32 $100.]
11.
Find the minimum transportation cost (NWCR & MODI).
[Ans X = 5, X = 2, X = 2, X = 7, X = 6, X = 12 and The minimum 11 14 22 23 32 34 transportation cost is $743.]
177  UNIT 7.
TRANSPORTATION PROBLEM Warehouse D D D D Supply 1 2 3 4 F1 19 30 50 10 7 Factory F 70 30 40 60 9 2 F 40 8 70 20 18 3 Demand 5 8 7 14 12.
Solve the following TP.
Destination A B C D Supply 1 1 2 3 4 6 Source 2 4 3 2 0 8 3 0 2 2 1 10 Demand 4 6 8 6 [Ans X = 6, X = 2, X = 6, X = 4, X = ε, X = 6 and The minimum 12 23 24 31 32 33 transportation cost is $28.]
13.
Solve the following TP.
Destination A B C D Supply 1 11 20 7 8 50 Source 2 21 16 20 12 40 3 8 12 8 9 70 Demand 30 25 35 40 [Ans X = 35, X = 15, X = 10, X = 30, X = 30, X = 25, X and The 13 14 24 25 31 32 34=15 minimum transportation cost is $1, 160.]
14.
Solve the following TP to maximize the profit.
Destination A B C D Supply 1 40 25 22 33 100 Source 2 44 35 30 30 30 3 38 38 28 30 70 Demand 40 20 60 30 [Ans X = 20, X = 30, X = 50, X = 20, X = 10, X = 20, X = 50 and The 11 14 15 21 23 32 33 optimum profit is $5, 130.]
178  UNIT 8 INTEGER PROGRAMMING 8.1 Introduction In your study of linear programming problem, you allowed the decision variables to take non- negative real values as it is quite possible and appropriate that you can have fractional values in many situations.
There are several frequent occuring circumstances in business and industry that lead to planning models involving integer-valued variables.
For example, in production, manufacturing is frequently scheduled in terms of batches, lots or runs.
In allocation of goods, a shipment must involve a discrete number of trucks or aircrafts.
In such cases fractional values of variables may be meaningless in the context of the actual decision problem.
In this section, you will consider this special class of linear programming, whose decision variables are not only non-negative, but are also integers.
This type of linear programming problem is what you would call integer programming.
8.2 Objectives At the end of this unit, you should be able to; (i) Define an IPP problem.
(ii) Differentiate between Pure integer programming problem and Mixed integer program- ming.
(iii) solve IPP using any of (a) Gomory’s Cutting plane Method.
(b) Branch and Bound Method (Search Method) (iv) Solve Mixed Integer Programming problems.
179  UNIT 8.
INTEGER PROGRAMMING 8.3 Integer Programmining Model Definition 8.3.1 (Integer Programming Model) A linear programming problem in which all or some of the decision variables are constrained to assume non-negative values is called Integer Programming Problem(IPP) Mathematically, the model of an Integer Programming Problem is given as max z = cx Subject to: Ax ≤ b x ≥ 0 and some or all variables are integers In a linear programming problem, if all variables are required to take integral values then it is called Pure (all) Integer Programming problem (Pure IPP).
If all variable in the optimal solution of a LPP are restricted to assume non-negative integer values while the remaining vari- ables are free to take any non-negative values, then it is called a Mixed Integer Programming (Mixed IPP).
Further, if all the variables in the optimal solution are allowed to take values 0 or 1, then the problem is called 0-1 Programming Problem or Standard Discrete Programming Problem Integer programming is applied in business and industry.
All assignment and transporta- tion problems are integer programming problems, capital budgetting and production scheduling problems, and allocation problems involving the allocation of men or machines are examples of integer programming problems.
8.3.1 Methods of Solving Integer Programming Problem There are two methods you can use to solve IPP, these are (i) Gomory’s Cutting Plane Method.
(ii) Branch and Bound Method (Search Method).
8.3.2 Gomory’s Fractional Cut Algorithm or Cutting Plane Method for Pure (All) IPP This method consists of first solving the IPP as an ordinary LPP by ignoring the restriction of integer values and then introducing a new constraint to the problem such that the new set of feasible solution includes all the original feasible integer solutions, but does not include the optimum non-integer solution initially found.
This new constraint is called “Fractional cut” or “Gomorian constant”.
Then the revised problem is solved using the simplex method, till an optimum integer solution is obtained.
The steps involved in solving integer programming problems using the Cutting plane method are outlined below.
180  UNIT 8.
INTEGER PROGRAMMING Step 1 Convert the minimization IPP into an equivalent maximization IPP, Ignore the integrality condition.
Step 2 Introduce slack and/or surplus variables if necessary, to convert the given LPP in its stan- dard form and obtain the optimum solution of the given LPP by using simplex method.
Step 3 Test the integrality of the optimum solution.
(i) If all the x ≥ 0 and are integers, an optimum integer solution is obtained.
Bi (ii) If all the x ≥ 0 and at least one x is not an integer, then go to the next step.
Bi Bi Step 4 Rewrite each x as x = [x ] + f where [x ] is the integral part of x and f is the Bi Bi Bi i Bi Bi i positive fractional part of x 0 ≤ f < 1.
Bi i Choose the largest fraction of x ’s, i.e., Choose max(f ), if there is a tie, select arbitrary.
Bi i Let max(f ) = f , corresponding to x (the K th row is called the ’source row’).
i K BK Step 5 Express each negative fraction, if any, in the source row of the optimum simplex table as the sum of a negative and a non-negative fraction.
Step 6 Find the fractional cut constraint (Gomorian Constraint) n From the source row a x = x kj j Bi j=1 i.e., n ([akj ] + fkj )xj = [xBK ] + fK j=1 in the form n n fkj xj ≥ fK fkj xj ≤ −fK j=1 j=1 − or n − fkj xj + G1 = −fK j=1 where, G is the Gomorian slack.
1 Step 7 Add the fractional cut constraint obtained in step (6) at the bottom of the simplex table obtained in step (2).
Find the new feasible optimum solution using dual simplex method.
Step 8 Go to step (3) and repeat the procedure until an optimum integer solution is obtained.
181  UNIT 8.
INTEGER PROGRAMMING Example 8.3.1 Find the optimum integer solution to the following LPP.
Max z = x1 + x2 Subject to: 3x + 2x ≤ 5 1 2 x ≤ 2 2 x , x ≥ 0 and are integers.
1 2 ☞ Solution.
Introducing the non-negative basic slack variable x , x ≥ 0, the standard 3 4 form of the LPP becomes, Max z = x1 + x2 + 0x3 + 0x4 5Subject to: 3x + 2x + x = 5 1 2 3 x + x = 2 2 4 x , x , x , x ≥ 0 and are integers.
1 2 3 4 Ignoring the integrality condition, solve the problem by simplex method.
The initial basic feasible solution is given by, x = 5 and x = 2.
3 4 B x x x x x θ 1 2 3 4 B x3 3 2 1 0 5 5 / 3  x 0 1 0 1 2 - 4 z −c −1  -1 0 0 0 j j B x x x x x θ 1 2 3 4 B x 1 2 1/3 0 5/3 5/2 1 x 0 1 0 1 2 2  4 z −c 0 −1 /3  1 / 3 0 5 / 3 j j B x x x x x θ 1 2 3 4 B x 1 0 1/3 -2/3 1/3 1 x 0 1 0 0 2 2 z −c 0 0 1 / 3 1 / 3 7/ 3 j j Table 8.1: 182  UNIT 8.
INTEGER PROGRAMMING Since all zj − cj ≥ 0 an optimum solution is obtained, given by max z = 7/3, x = 1/3, x = 2.
1 2 To obtain an optimum integer solution, you have to add a fractional cut constraint in the opti- mum simplex table.
Since x = 1/3, the source row is the first row.
Expressing the negative fraction −2/3 as a B sum of negative integer and positive fraction, you get −2/3 = −1 + 1/3 Since x is the source row, you have 1 1/3 = x1 + 1/3x3 − 2/3x4 i.e., 1/3 = x1 + 1/3x3 + (−1 + 1/3)x4 The fractional cut (Gomorian) constraint is given by 1/3x + 1/3x ≥ 1/3 3 2 that is −1/3x − 1/3x ≤ − 3 2 1/3 which implies −1/3x − 1/3x + G = −1/3 3 2 1 where, G is the Gomorian slack.
Add this fractional cut constraint at the bottom of the above 1 optimal simplex table to obtain B x x x x G x 1 2 3 4 1 B x 1 0 1/3 -2/3 0 1/3 1 x 0 1 0 0 0 2 2 G 0 0 -1/3 -1/3 1 1 / 3  1 z −c 0 0 1 / 3  1 / 3 0 7/ 3 j j Table 8.2: Applying the dual simplex method.
Since G = −1/3, G leaves the basis.
To find the 1 1 entering variable you find ( \ ( \ max zj − cj , a < 0 = max 1/3 , 1/3 = max{−1, −1} = −1 ik aik −1/3 1/3 Choose x as the entering variabe arbitrarily.
3 183  UNIT 8.
INTEGER PROGRAMMING B x x x x G x 1 2 3 4 1 B x 1 0 0 -1 1 0 1 x 0 1 0 1 1 2 2 x 0 0 1 1 -3 1 3 z −c 0 0 0 0 1 2 j j Table 8.3: Since all z −c ≥ 0 and all x ≥ 0, you have obtained the optimal feasible integer j j Bi solution.
Therefore the optimal integer solution is max z = 2, x = 0, x = 2.
1 2 ✍ Here is another example for you.
Example 8.3.2 Solve the following integer programming problem.
maximize z = 2x1 + 20x2 − 10x3 Subject to: 2x1 + 20x2 + 4x3 ≤ 15 6x + 20x + 4x = 20 1 2 3 x1, x2, x3 ≥ 0, and are integers.
☞ Solution.
Introducing slack variable x ≥ 0 and an artificial variable a ≥ 0, the initial 4 1 basic feasible solution is x = 15, a = 20.
Ignoring the integer condition, solve the problem 4 1 maximize z = 2x1 + 20x2 − 10x3 + 0x4 + 0a1 Subject to: 2x + 20x + 4x + x = 15 1 2 3 4 6x + 20x + 4x + a = 20 1 2 3 1 x1, x2, x3, x4, a1 ≥ 0 by simplex method.
The optimal simplex tableu is given by B x x x x x 1 2 3 4 B x 0 1 1/ 5 3/ 40 5/ 8 2 x 1 0 0 -¼ ¼ 1 z −c 0 0 14 1 15 j j Table 8.4: 184  UNIT 8.
INTEGER PROGRAMMING Therefore the non-integer optimum solution is given by, x = 5/4, x = 5/8, x = 0, max z = 15 1 2 3 To obtain an integer optimum solution, you proceed as follows.
max{f , f } = max{5/8, 1/4} = 5/8.
1 2 Therefore the source row is the first row, namely, x row.
From this source row you have 2 5/8 = 0x + 1x + (1/5)x + (3/40)x .
1 2 3 4 The fractional cut constraint is given by, (1/5)x + (3/40)x ≥ 5/8 3 4 (−1/5)x − (3/40)x ≤ −5/8, i.e., (−1/5)x − (3/40)x + G = −5/8 3 4 3 4 1 where G is Gomorian slack.
1 Adding the additional constraint in the optimum simplex table, the new table is given below.
B x x x x G x 1 2 3 4 1 B x 0 1 1/ 5 3/ 40 0 −5 /8 2 x 1 0 0 -¼ 0 5/ 4 1 G 0 0 −1 /5 -3/40 1 −5 /8  1 z −c 0 0 14 1  0 15 j j Table 8.5: Apply the dual simplex method.
Since G = −5/8 leaves the basis.
Also 1 ( \ ( \ zj − cj 14 1 40 max , a < 0 = max , = − ik aik −1/5 −3/40 3 gives the non-basic variable x , this enters the basis.
4 185  UNIT 8.
INTEGER PROGRAMMING B x x x x G x 1 2 3 4 1 B x 0 1 0 0 1 0 2 x 1 0 2 / 3 0 -10/3 10 / 3 1 x 0 0 8/ 3 1 -40/3 25 /3 4 z −c 0 0 34 /3 0 40 / 3 20 / 3 j j Table 8.6: Again since the solution is non-integer, you add one more fractional cut constraint.
max{f } = max{0, 1/3, 1/3} i Since the max fraction is same for both the rows x and x , you choose x arbitrarily.
Therefore 1 4 4 from the source row you have, 25/3 = 0x1 + 0x2 + (8/3)x3 + 1x4 − (40/3)G1 Expressing the negative fraction as the sum of negative integer and positive fraction you have (8 + 1/3) = 0x1 + 0x2 + (2 + 2/3)x3 + 1x4 + (−14 + 2/3)G1 The corresponding fractional cut is given by, −2/3x − 2/3G + G = −1/3.
3 1 2 Add this second Gomorian constraint at the bottom of the above simplex table and apply dual simplex method.
B x x x x G G x 1 2 3 4 1 2 B x 0 1 0 0 1 0 0 2 x 1 0 2 / 3 0 -10/3 0 10 / 3 1 x 0 0 8/ 3 1 -40/3 0 25 /3 4 G 2 0 0 -2/3 0 -2/3 1 −2/ 3  z −c 0 0 34 /3  0 40 / 3 0 20 / 3 j j Table 8.7: Since G = −1/3, G leaves the basis, Also, 1 2 ( \ ( \ max zj − cj , a < 0 = max 34/3 , 40/3 = −17 ik aik −2/3 −2/3 gives the non-basic variable x which enters the basis.
Using the dual simplex method, introduce 3 x and drop G .
3 2 186  UNIT 8.
INTEGER PROGRAMMING B x x x x G G x 1 2 3 4 1 2 B x 0 1 0 0 1 0 0 2 x 1 0 0 0 -4 1 3 1 x 0 0 0 1 16 4 7 4 x 0 0 1 0 1 -3/2 ½ 3 z −c 0 0 0 0 2 13 1 j j Table 8.8: Since the solution is still a non-integer, a third fractional cut is required.
It is given from the source row (x row) as, 3 −1/2 = −1/2G2 + G3 Insert this additional constraint at the bottom of the table, the modified simplex tableau is show below.
B x x x x G G G x 1 2 3 4 1 2 3 B x 0 1 0 0 1 0 0 0 2 x 1 0 0 0 -4 1 0 3 1 x 0 0 0 1 16 4 0 7 4 x 0 0 1 0 1 -3/2 0 ½ 3 G3 0 0 0 0 0 -½ 1 1 / 2  z −c 0 0 0 0 2 17  0 1 j j Table 8.9: Using dual simplex method, you drop G and introduce G .
3 2 B x x x x G G G x 1 2 3 4 1 2 3 B x 0 1 0 0 0 0 0 0 2 x 1 0 0 0 -4 0 2 2 1 x 0 0 0 1 -16 0 8 3 4 x 0 0 1 0 -1 0 -3 2 3 G 0 0 0 0 6 1 -2 1 2 z −c 0 0 0 0 2 0 34 -16 j j Table 8.10: 187  UNIT 8.
INTEGER PROGRAMMING Since all zj − cj ≥ 0 and also the variables are integers, the optimum integer solution is obtained and given by x1 = 2, x2 = 0, x3 = 2 and max z = −16 ✍ 8.3.3 Mixed Integer Programming Problem In the mixed IPP only some of the variables are restricted to integer values, while the other variables may take integer or other real values.
Mixed Integer Cutting Plane Procedure The iterative procedure for the solution of mixed integer programming problem is as follows.
Step 1.
Reformulate the given LPP into a standard maximization form and then determine an optimum solution using simplex method.
Step 2.
Test the integrality of the optimum solution.
(i) If all x ≥ 0(i = 1, 2, .
.
.
, m) and are integers, then the current solution is an opti- Bi mum one.
(ii) If all x ≥ 0(i = 1, 2, .
.
.
, m) but the integer restricted variables are not integers, Bi then go to the next step.
Step 3 Choose the largest fraction among those x , which are restricted to integers.
Let it be Bi x = f (assume) Bk k Step 4.
Find the fractional cut constraints from the source row, namely K th row.
From the source row, n a = x kj Bk j=1 i.e., n ([akj ] + fki)rj = [xBK ] + fk j=1 in the form n f ki j∈j+ 188  UNIT 8.
INTEGER PROGRAMMING i.e., ( \ f fkj xj + k fkj xj ≥ +fk f j∈j+ k−1 j∈j− ( \ f − fkj xj − k fkj xj ≤ −fk f j∈j+ k−1 j∈j− ( \ f − fkj xj − k fkj xj + Gk = −fk f j∈j+ k−1 j∈j− where, G is Gomorian slack k j+ = [j/f ≥ 0] kj j− = [j/f < 0] kj Step 5 Add this cutting plane generated in step K at the bottom of the optimum simplex table obtained in step 1.
Find the new optimum solution using dual simplex method.
Step 6 Go to step 2 and repeat the procedure until all x ≥ 0(i = 1, 2, .
.
.
, m) and all restricted Bi variables are integers.
Here is an example for you Example 8.3.3 Solve the problem Maximize z = 4x1 + 6x2 + 2x3 Subject to.
4x1 − 4x2 ≤ 5 −x1 + 6x2 ≤ 5 −x1 + x2 + x3 ≤ 5 x1, x2, x3 ≥ 0, and x1, x3 are integers ☞ Solution.
Introducing slack variables x , x , x ≥ 0, the standard form of LPP, is 4 5 6 Maximize z = 4x1 + 6x2 + 2x3 + 0x4 + 0x5 + 0x6 Subject to.
4x1 − 4x2 + x4 = 5 −x1 + 6x2 + x5 = 5 −x1 + x2 + x3 + x6 = 5 x1, x2, x3, x4, x5, x6 ≥ 0, The initial basic feasible solution is given by x = 5, x = 5, x = 5.
Ignoring the integer 4 5 6 condition, the optimum solution of given LPP is obtained by the simplex method from the optimal simplex tableau 189  UNIT 8.
INTEGER PROGRAMMING B x x x x x x x 1 2 3 4 5 6 B x 1 0 0 3/ 10 1 / 5 0 5/2 1 x 0 1 0 1 / 20 1 / 5 0 5/4 2 x 0 0 1 ¼ 0 1 25/4 3 z −c 0 0 0 1 1 0 35/2 j j Table 8.11: Page 194 But the integer constrained variables x and x are non-integer.
1 3 x = 5/2 = 2 + 1/2 1 x = 25/4 = 6 + 1/4 2 max{f , f } = max{1/2, 1/4} = 1/2.
1 3 From the first row you have, (2 + 1/2) = x1 + 0x2 + 0x3 + (3/10)x4 + (1/5)x5 The Gomorian constraint is given by, 3/10x + 1/5x ≥ 1/2 or − 3/10x − 1/5x ≤ − 4 5 4 5 1/2 i.e., −3/10x − 1/5x + G = −1/2, where G is the Gomorian slack.
Introduce this 4 5 1 1 new constraint at the bottom of the above simplex table.
B x x x x x x G x 1 2 3 4 5 6 1 B x 1 0 0 3 / 10 1/5 0 0 5/ 2 1 x 0 1 0 1 / 20 1/5 0 0 5 / 4 2 x 0 0 1 ¼ 0 1 0 25 /5 3 G 0 0 0 -3/10 -1/5 0 1 1/ 2  1 z −c 0 0 0 2  2 0 0 30 j j Table 8.12: Using dual simplex method, since G = −1/2 < 0, G leaves the basis.
Also, 1 1   ( \   ( \ zj − cj  2 2  −20 −20 max , aik < 0 = max , = max , −10 = aik  − 3 − 1  3 3 10 5 190  UNIT 8.
INTEGER PROGRAMMING B x x x x x x G x 1 2 3 4 5 6 1 B x 1 0 0 0 0 0 1 2 1 x 0 1 0 0 1/6 0 1/ 6 7 / 6 2 x 0 0 1 0 -1/6 1 5 / 6 35 / 6 3 x 0 0 0 1 2/3 0 −10 / 3 5 / 3 4 z −c 0 0 0 0 2 / 3 2 20 / 3 80/ 3 j j Table 8.13: corresponding to x .
Therefore, the non-basic variable x enters the basics.
Drop G and intro- 4 4 1 duce x .
4 ✍ Since all z − c ≥ 0, the solution is optimum and also the integer restricted variable x = j j 3 35/6 is not an integer, therefore, you add another Gomorian constraint x = 35/6 = 5 + 5/6 3 The source row is the third row.
From this row you have, 5 1 5 5 + = 0x + 0x + x + 0x − x + x + G 6 1 2 3 4 6 5 6 6 1 The Gomorian constraint is given by,   5 ( \  6  −1 5 5  5  6 x5 + 6 G1 ≥ 6 − 1 6 5 5 5 5 5 5 x + G ≥ i.e., − x − G + G = − 6 5 6 1 6 6 5 6 1 2 6 where G is the Gomorian slack.
Add this second cutting plane constraint at the bottom of the 2 above optimum simplex table gives you, 191  UNIT 8.
INTEGER PROGRAMMING B x x x x x x G G x 1 2 3 4 5 6 1 2 B x 1 0 0 0 0 0 1 0 2 1 x 0 1 0 0 1/6 0 1 / 6 0 7/ 6 2 x 0 0 1 0 -1/6 1 5/ 6 0 35 / 6 3 x 0 0 0 1 2/3 0 −10 / 3 0 5/ 3 4 G 2 0 0 0 0 -5/6 0 -5/6 1 −5 /6  z −c 0 0 0 2 / 3 2 / 3  2 20 / 3 0 80 / 3 j j Table 8.14: Use dual simplex method, since G = −5/6 < 0, G leaves the basics.
Also, 2 2   2 20 max ( zj a−ik cj , aik < 0 \ = max  − 3 5 , −36 5  = max ( −5 4, −8\ = −45 6 which corresponds to x .
Drop G and introduce x .
Since all z − c ≥ 0 and also all 5 2 5 j j the restricted variables x and x , an optimum integer solution is obtained.
1 3 B x x x x x x G G x 1 2 3 4 5 6 1 2 B x 1 0 0 0 0 0 1 0 2 1 x 0 1 0 0 0 0 0 1/5 1 2 x 0 0 1 0 0 1 1 -1/5 6 3 x 0 0 0 1 0 0 -4 4/5 1 4 x 0 0 0 0 1 0 1 -6/5 1 5 z −c 0 0 0 0 0 2 20 / 3 4 / 5 26 j j Table 8.15: The optimum integer solution is, x = 2, x = 1, x = 6, and max z = 26 1 2 3 8.3.4 Branch And Bound Method This method is applicable to both, pure as well as mixed IPP.
Sometimes a few or all the vari- ables of an IPP are constrained by their upper or lower bounds.
The most general method for the solution of such constrained optimization problem is called ’Branch and Bound method’.
192  UNIT 8.
INTEGER PROGRAMMING This method first divides the feasible region into smaller subsets and then examines each of them successively, until a feasible solution gives an optimal value of objective function is obtained.
Consider the IPP Maximize z = cx Subject to Ax ≤ b (8.1) x ≥ 0 are integers In this method, you will first solve the problem by ignoring the integrality condition.
(i) If the solution is in integers, the current solution is optimum for the IPP (8.1).
(ii) If the solution is not in integers, say one of the variable x is not an integer, then x∗ < r r x < x∗ where x∗ , x are consecutive non-negative integers.
r ∗ r+1 r r+1 Hence, any feasible integer value of x must satisfy one of the two conditions.
r x ≤ x∗ or x ∗ .
r r r+1 These two conditions are mutually exclusive (both cannot be true simultaneously).
By adding thes two conditions separately to the given LPP, we form different sub-problems.
Sub-problem 1 Sub-problem 2 Maximize z = cx Maximize z = cx Subject to: Ax ≤ b Subject to: Ax ≤ b xr ≤ x∗ xr ≥ x∗ r r+1 x ≥ 0. x ≥ 0.
Thus, you have brached or partitioned the original problem into two sub-problems.
Each of these sub-problems is then solved separately as LPP.
If any sub-problem yields an optimum integer solution, it is not further branched.
But if any sub-problem yields a non-integer solution, it is further branched into two sub-problems.
This branching process is continued until each problem terminates with either an integer optimal solution or there is an evidence that it cannot yield a better solution.
The integer-valued solution among all the sub-problems, which gives the most optimal value of the objective function is then selected as the optimum solution.
Note: For minimization problem, the procedure is the same except that upper bounds are used.
The sub-problem is said to be fathomed and is dropped from further consideration if it yields a value of the objective function lower than that of the best available integer solution and it is useless to explore the problem any further.
Example 8.3.4 Use the branch and bound technique to solve the following: Maximize z = x1 + 4x2 Subject to 2x1 + 4x2 ≤ 7 5x1 + 3x2 ≤ 15 x1, x2 ≥ 0 and are integers.
193  UNIT 8.
INTEGER PROGRAMMING ☞ Solution.
Ignoring the integrality condition you solve the LPP, Maximize z = x1 + 4x2 Subject to 2x1 + 4x2 ≤ 7 5x1 + 3x2 ≤ 15 x1, x2 ≥ 0 Introducing slack variables x , x ≥ 0, the standard form of LPP becomes, 3 4 Maximize z = x1 + 4x2 + 0x3 + 0x4 Subject to 2x + 4x + x = 7 1 2 3 5x + 3x + 0x = 15 1 2 4 x1, x2, x3, x4 ≥ 0 B x x x x x θ 1 2 3 4 B x 3 2 4 1 0 7 7 / 4  x 5 3 0 1 15 5 4 z −c -1 −4  0 0 0 j j B x x x x x θ 1 2 3 4 B x 1/2 1 ¼ 0 7/4 2 x 7/2 0 3/4 1 4 4 z −c 1 0 1 0 7 j j Table 8.16: Since z − c ≥ 0, an optimum solution is obtained, j j x = 0, x = 7/4 and max z = 7 1 2 Since x = 7 , this problem should be branched into two sub-problems.
For 2 4 7 x = , 1 < x < 2; x ≤ 1, x ≥ 2 2 4 2 2 2 Applying these two conditions separately in the given LPP you get two sub problems.
Sub-problem 1 Sub-problem 2 Maximize z = x1 + 4x2 Maximize z = x1 + 4x2 Subject to: 2x1 + 4x2 ≤ 7 Subject to: 2x1 + 4x2 ≤ 7 5x1 + 3x2 ≤ 15 5x1 + 3x2 ≤ 15 x2 ≤ 1 x2 ≥ 2 x1, x2 ≥ 0. x1, x2 ≥ 0.
194  UNIT 8.
INTEGER PROGRAMMING Sub-Problem (1) B x x x x x x θ 1 2 3 4 5 B x 3 2 4 1 0 0 7 7/ 4 x 4 5 3 0 1 0 15 5 x 0 1 0 0 1 1 1  5 z −c -1 −4  0 0 0 0 j j B x x x x x x θ 1 2 3 4 5 B x 3 2 0 1 0 -4 3 3 / 2  x 4 5 0 0 1 -3 12 12/5 x 0 1 0 0 1 1 2 z −c −1  0 0 0 4 4 j j B x x x x x x θ 1 2 3 4 5 B x 1 0 ½ 0 -2 3/2 1 x 4 0 0 -5/2 1 7 9/2 x 0 1 0 0 1 1 2 z −c 0 0 ½ 0 2 11 / 2 j j Table 8.17: Since all z − c ≥ 0, the solution is optimum, given by x = 3/2, x = 1, and max z = j j 1 2 11/2.
Since x = 3/2 is not an integer, this sub-problem is branched again.
1 Sub-Problem (2) Maximize z = x1 + 4x2 Subject to: 2x1 + 4x2 ≤ 7 5x1 + 3x2 ≤ 15 x2 ≥ 2 x1, x2 ≥ 0.
In Table 8.18, since all z − c ≥ 0, and an artificial variable a is in the basis at positive j j 1 level, there exist no feasible solution.
Hence, this sub-problem is dropped.
In sub problem (1) Since, x1 = 3/2, you have, 1 ≤ x1 ≤ 2, and so x1 ≤ 1, x1 ≥ 2 Applying these two conditions separately in the sub-problem (1), you get two sub-problems.
195  UNIT 8.
INTEGER PROGRAMMING B x x x x x A x θ 1 2 3 4 5 1 B x 3 2 4 1 0 0 0 7 7/ 4  x 4 5 3 0 1 0 0 15 15/3 A 0 1 0 0 -1 1 1 2 1 z −c -1 − M −4  0 0 M 0 −2M j j B x x x x x A x θ 1 2 3 4 5 1 B x2 ½ 1 ¼ 0 0 0 7/4 x 4 7/2 0 -¾ 1 0 0 39/4 A -½ 0 -¼ 0 -1 1 ¼ 1 z j −c j M 1 0 M 1 0 M 0 7 − 5M 2 4 4 Table 8.18: Sub-problem (3) Sub-problem (4) Maximize z = x1 + 4x2 Maximize z = x1 + 4x2 Subject to: 2x1 + 4x2 ≤ 7 Subject to: 2x1 + 4x2 ≤ 7 5x1 + 3x2 ≤ 15 5x1 + 3x2 ≤ 15 x2 ≤ 1 x2 ≤ 2 x1 ≤ 1 x1 ≥ 2 x1, x2 ≥ 0. x1, x2 ≥ 0.
196  UNIT 8.
INTEGER PROGRAMMING Sub-Problem(3) B x x x x x x x θ 1 2 3 4 5 6 B x 2 4 1 0 0 0 7 7 / 4 3 x 5 3 0 1 0 0 15 15/3 4 x5 0 1 0 0 1 0 1 1  x 1 0 0 0 0 1 1 - 6 z −c -1 −4  0 0 0 0 0 j j B x x x x x x x θ 1 2 3 4 5 6 B x 2 0 1 0 -4 0 3 3/ 2 3 x 4 5 0 0 1 -3 0 12 12/5 x 0 1 0 0 1 0 1 - 2 x6 1 0 0 0 0 1 1 1  z −c −1  0 0 0 4 0 4 j j B x x x x x x x θ 1 2 3 4 5 6 B x 0 0 1 0 -4 -2 1 3 x 0 0 0 1 -3 -5 7 4 x 0 1 0 0 1 0 1 2 x 1 0 0 0 0 1 1 1 z −c 0 0 0 0 4 1 5 j j Table 8.19: Since all z − c , an optimum solution is obtained.
It is given by, x = 1, x = 1 and j j 1 2 max z = 5.
Since this solution is integer-valued this sub-problem cannot be branched further.
The lower bound of the objective function is 5.
197  UNIT 8.
INTEGER PROGRAMMING Sup-Problem (4) B x x x x x x A x θ 1 2 3 4 5 6 1 B x 2 4 1 0 0 0 0 7 7/ 2 3 x 5 3 0 1 0 0 0 15 3 4 x 0 1 0 0 1 0 0 1 - 5 A1 1 0 0 0 0 -1 1 2 2  z −c − M −1  −4 0 0 0 M 0 −2M j j B x x x x x x A x θ 1 2 3 4 5 6 1 B x 3 0 4 1 0 0 2 -2 3 ¾ x 4 0 3 0 1 0 5 -5 5 5/3 x 0 1 0 0 1 0 0 1 1 5 x 1 0 0 0 0 -1 1 2 - 1 z −c 0 −4  0 0 0 −2 1 M 2 j j B x x x x x x A x θ 1 2 3 4 5 6 1 B x 0 1 ¼ 0 0 ½ - ¾ 2 x 4 0 0 -¾ 1 0 7/2 - 11/4 x 0 0 -¼ 0 1 -½ - ¼ 5 x 1 0 0 0 0 -1 - 2 1 z −c 0 0 1 0 0 1 - 5 j j Table 8.20: Since all z − c ≥ 0, the optimum solution is given by, j j x = 2, x = 3/4 1 2 Since x2 = 3/4, 0 ≤ x2 ≤ 1, thus x2 ≤ 0, or x2 ≥ 1 Applying these two conditions in the sub-problem (4), you get two sub-problems.
Sub-problem (5) Sub-problem (6) Maximize z = x1 + 4x2 Maximize z = x1 + 4x2 Subject to: 2x1 + 4x2 ≤ 7 Subject to: 2x1 + 4x2 ≤ 7 5x1 + 3x2 ≤ 15 5x1 + 3x2 ≤ 15 x2 ≤ 1 x2 ≤ 2 x1 ≥ 1 x1 ≥ 2 x2 ≤ 0 x2 ≥ 1 x1, x2 ≥ 0. x1, x2 ≥ 0.
198  UNIT 8.
INTEGER PROGRAMMING Sub-Problem (5) B x x x x x x A x x θ 1 2 3 4 5 6 1 7 B x 2 4 1 0 0 0 0 0 7 7/ 2 3 x 5 3 0 1 0 0 0 0 15 3 4 x 0 1 0 0 1 0 0 0 1 - 5 A1 1 0 0 0 0 -1 1 0 2 2  x 0 1 0 0 0 0 0 1 0 - 7 z −c − M −1  −4 0 0 0 M 0 0 −2M j j B x x x x x x A x x θ 1 2 3 4 5 6 1 7 B x 0 4 1 0 0 2 - 0 3 ¾ 3 x 0 3 0 1 0 5 - 0 5 5/3 4 x 0 1 0 0 1 0 - 0 1 1 5 x 1 0 0 0 0 -1 - 0 1 - 1 x7 0 1 0 0 0 0 - 1 0 0  z −c 0 −4  0 0 0 -2 - 0 2 j j B x x x x x x A x x θ 1 2 3 4 5 6 1 7 B x 0 0 1 0 0 2 - 0 3 3/2 3 x 0 0 0 1 0 5 - 0 5 1  4 x 0 0 0 0 1 0 - -1 1 - 5 x 1 0 0 0 0 -1 - 0 2 - 1 x 0 1 0 0 0 0 - 1 0 - 2 z −c 0 0 0 0 0 −1  - 0 2 j j B x x x x x x A x x θ 1 2 3 4 5 6 1 7 B x 0 0 1 -2/5 0 0 - 0 1 3 x 0 0 0 1/5 0 1 - 0 1 6 x 0 0 0 0 1 0 - 0 1 5 x 1 0 0 1/5 0 0 - 0 3 1 x 0 1 0 0 0 0 - 1 0 2 z −c 0 0 0 3 / 5 0 0 - 4 3 j j Table 8.21: Since all z −c ≥ 0, the solution is optimum and is given by x = 3, x = 0 and max z = 3. j j 1 2 199  UNIT 8.
INTEGER PROGRAMMING This sub-problem yields an optimum integer solution.
Hence, this sub-problem is dropped.
Sub-problem (6) Maximize z = x1 + 4x2 Subject to: 2x1 + 4x2 ≤ 7 5x1 + 3x2 ≤ 15 x2 ≤ 2 This sub-problem has no feasible solution.
Hence, this problem x1 ≥ 2 x2 ≥ 1 x1, x2 ≥ 0. is also fathomed.
Original Problem max z = x  4x 1 2 Subject to : 2 x  4 x ≤7 1 2 5x 3x ≤1 1 2 x x ≥0 1, 2 Max z= 7, x = 0, x =7 / 4 1 2 x2 ≤ 2 x1 ≥ 1 Sub-Problem (1) Sub-problem (2) Max z =11 / 2 Infeasible x =3 / 2, x =1 Solution 1 2 fathomed x ≤1 x ≥ 2 1 2 Sub-Problem (4) Sub-Problem (3) Max z =5 Max z =5 x =3, x =1 x1= 2, x2 =3 / 4 1 2 fathomed x2≤ 0 x1≥1 Sub-problem (5) Sub-Problem (6) Max z= 3 Infeasible x1=3, x 2= 0 Solution fathomed Fathomed Table 8.22: 200  UNIT 8.
INTEGER PROGRAMMING Among the available integer-valued solutions, the best integer solution is given by sub- problem (3).
Therefore the optimum integer solution is, max z = 5, x = 1, and x = 1.
1 2 The best available integer optimal solution is max z = 5, x = 1, and x = 1.
1 2 ✍ 8.4 Conclusion In this unit, you were introduced to a special class of Linear Programming problem called Integer programming Problem (IPP).
You looked at two examples of IPP namely Pure IPP and Mixed IPP.
You also solve IPP problems using any of these two methods Gomory’s Cutting plane Method or what you may call the fractional cut algorithm and The Branch and bound Method also known as the Search Method.
8.5 Summary Having gone through this unit, You are now able to (i) Give the correct definition of a Integer Programming Model.
(ii) Differentiate between Pure IPP and Mixed IPP.
(iii) Solve IPP using the Gomory’s Cutting plane Method.
(iv) Solve IPP using the Branch and Bound Method.
201  UNIT 8.
INTEGER PROGRAMMING 8.6 Tutor Marked Assignments(TMAs) Exercise 8.6.1 Find the optimum integer solution of the following pure integer programming problems in prob- lem 1-4.
1.
Maximizez = 4x1 + 3x2 Subject to: x + 2x ≤ 4 1 2 2x1 + x2 ≤ 6 x1, x2 ≥ 0, and are integers.
[Ans.
x = 3, x = 0 and max z = 12] 1 2 2.
Maximizez = 3x1 + 4x2 Subject to: 3x + 2x ≤ 8 1 2 x1 + 4x2 ≥ 10 x1, x2 ≥ 0, and are integers.
[Ans.
x = 0, x = 4 and max z = 16] 1 2 3.
Maximizez = 3x1 − 2x2 + 5x3 Subject to: 4x1 + 5x2 + 5x3 ≤ 30 5x1 + 2x2 + 7x3 ≤ 28 x1, x2, x3 ≥ 0, and are integers.
[Ans.
x = x = 0, x = 4 and max z = 20] 1 2 3 4.
Minimizez = −2x1 − 3x2 Subject to: 2x1 + 2x2 ≤ 7 x1 ≤ 2 x2 ≤ 2 x1, x2 ≥ 0, and are integers.
[Ans.
x1 = 1, x2 = 2 and min z = −8] Solve the following mixed integer programming problems using Gomory’s cutting plane method.
5.
Maximizez = 7x1 + 9x2 Subject to: −x + 3x ≤ 6 1 2 7x1 + x2 ≤ 35 x1, x2 ≥ 0, and x1 is an integers.
[Ans.
x = 3, x = 2 and max z = 5 or x = 4, x = 1, max z = 5] 1 2 1 2 6.
Maximizez = 3x1 + x2 + 3x3 Subject to: −x + 2x + x ≤ 4 1 2 3 4x2 − 3x3 ≤ 2 x1 − 3x2 + 2x3 ≤ 3 x1, x2, x3 ≥ 0, where x1 and x3 are integers.
202  UNIT 8.
INTEGER PROGRAMMING [Ans.
x = 5, x = 11/4, x = 3 and max z = 107/4] 1 2 3 7.
Maximizez = x1 + x2 Subject to: 2x + 5x ≤ 16 1 2 6x1 + 5x2 ≤ 30 x1, x2 ≥ 0, and x1 is an integers.
[Ans.
x = 4, x = 6/5 and max z = 26/5] 1 2 8.
Minimizez = 10x1 + 9x2 Subject to: x ≤ 8 1 x2 ≤ 10 5x1 + 3x2 ≤ 45 x1, x2 ≥ 0, and are integers.
[Ans.
x = 8, x = 5/3 and min z = 95] 1 2 Use branch and bound method to solve the following problems: 9.
Maximizez = 3x1 + 4x2 Subject to: 7x + 16x ≤ 52 1 2 3x1 − 2x2 ≤ 18 x1, x2 ≥ 0, and are integers.
[Ans.
x = 5, x = 1 and max z = 19] 1 2 10.
Maximizez = 2x1 + 2x2 Subject to: 5x + 3x ≤ 8 1 2 x1 + 2x2 ≤ 4 x1, x2 ≥ 0, and are integers.
[Ans.
max z = 4, x = 1, x = 1, or x = 0, x = 2] 1 2 1 2 11.
Maximizez = 2x1 + 20x2 − 10x3 Subject to: 2x1 + 20x2 + 4x3 ≤ 15 6x + 20x + 4x = 20 1 2 3 x1, x2, x3 ≥ 0, and are integers.
[Ans.
x1 = 2, x2 = 0, x3 = 2 and max z = −16] 12.
Maximizez = 3x1 + 4x2 Subject to: 3x − x + x = 12 1 2 3 3x + 11x + x = 66 1 2 4 x1, x2, x3, x4 ≥ 0, and are integers.
[Ans.
x = 5, x = 4, and max z = 31] 1 2 203  Module V 204  UNIT 9 N BASIC CONCEPTS OF R 9.1 Introduction In this unit and subsequent units, you shall be considering another aspect of optimization prob- lems, different from the linear programming problem you have seen in previous units.
The theorems you shall develop here are more general to any given mathematical programming in which the objective function f : S ⊂ Rn → R defined on a subset S of Rn is nonlinear.
Also the constraints may or may not be linear in the decision variables and the non-negativity condition is also relaxed.
For a better understanding of optimization in Rn, you shall, in this unit, be introduced to some basic concepts and notions of the space Rn (also known as the real n-space).
These no- tions, can also be referred to as the topology of Rn.
Thus, you shall be considering notions like, Continuous functions, differentiability, partial derivatives, directional derivatives and higher or- der derivatives.
You will also consider quadratic forms: definite and semidefinite matrices and also see some results.
9.2 Objectives At the end of this unit, you should be able to (i) Define continuous functions, differentiability and continuous differentiable function in Rn.
(ii) Define and use the concept of partial derivatives and directional derivatives.
(iii) Find Higher order Derivatives of a function defined on a subset S of Rn.
(iv) Define quadratic forms and Definiteness.
205  UNIT 9.
BASIC CONCEPTS OF RN (v) Identify definiteness and semidefiniteness.
9.3 Functions Let S, T be subsets of Rn and Rl , respectively.
A function f from S to T denoted by f : S → T , is a rule that associates with each element of S, one and only one element of T .
The set S is called the domain of the function f, and the set T is range.
9.3.1 Continuous Functions Definition 9.3.1 Let f : S → T , where S ⊂ Rn and T ⊂ Rl .
Then, f is said to be continuous at x ∈ S if for all E > 0, there exists a δ > 0 such that y ∈ S and d(x, y) < δ implies that d(f (x), f (y)) < E. (Note that d(x, y) is the distance between x and y in Rn, while d(f (x), f (y)) is the distance in Rl .)
Another way you can define continuous function is by using sequences.
Definition 9.3.2 The function f : S → T is continuous at x ∈ Sif for all sequences {x } such k that x ∈ S for all k, and lim x = x, then lim f (x ) = f (x).
k k k k→∞ k→∞ Intuitively, f is continuous at x if the value of f at any point y that is “close” to x is a good approximation of the value of f at x.
Definition 9.3.3 (Discontinuous Function) f : S → T is called discontinous at x ∈ S if it is not continuous at x.
Example 9.3.1 (Continuous function) The identity function f (x) = x for all x ∈ R is contin- uous at each x ∈ R Example 9.3.2 The function f : R → R given by  0, x ≤ 0 f (x) =   1, x > 0 is continuous everywhere except at x = 0.
At x = 0, every open ball B(x, δ) with center x and radius δ > 0 contains at least one point y > 0.
At all such points, f (y) = 1 > 0 = f (x), and this approximation does not get better, no matter how close y gets to x (i.e., no matter how small you take δ to be).
Definition 9.3.4 A function f : S → T is said to be continuous on S if it is continuous at each point in S. Observe that if f :⊂ Rn → Rl , then f consists of l “component functions” (f 1, .
.
.
, f l ), i.e., there are functions f i : S → R, i = 1, .
.
.
, l, such that for each x ∈ S, you have f (x) = (f 1(x), .
.
.
, f l (x)).
206  UNIT 9.
BASIC CONCEPTS OF RN Proposition 9.3.1 f is continuous at x ∈ S (resp.
f is continuous on S) if and only if each f i is continuous at x (resp.
if and only if each f i is continuous on S).
Theorem 9.3.1 A function f : S ⊂ Rn → Rl is continuous at a point x ∈ S if and only if for all open set V ⊂ Rl such that f (x) ∈ V, there is an open set U ⊂ Rn such that x ∈ U, and f (z) ∈ V for all z ∈ U ∩ S. Proof.
Suppose f is continuous at x, and V is an open set in Rl containing f (x).
Suppose, by contradiction, that the theorem was false, so for any open set U containing x, there is y ∈ U ∩ S such that f (y) /∈ V. Let k ∈ {1, 2, 3, .
.
.
}, let U be the open ball with center x k and radius 1/k.
Let y ∈ U ∩ S be such that f (y ) /∈ V. The sequence {y } is clearly well k k k k defined, and since y ∈ U for all k, you have d(x, y ) < 1/k for each k, so y → x as k → ∞.
k k k k Since f is continuous at x by hypothesis, you also have f (y ) → f (x) as k → ∞.
However f k (y ) /∈ V for any k, and since V is open, V c is closed, so f (x) = lim f (y ) ∈ V c which k k contradicts k→∞ f (x) ∈ V. Conversely, suppose that for each open set V containing f (x), there is an open set U con- taining x such that f (y) ∈ V for all y ∈ U ∩ S. You will show that f is continuous at x.
Let E > 0 be given.
Define V to be the open ball in Rl with center f (x) and radius E. Then, there exists an open set U containing x such that f (y) ∈ V for all y ∈ U ∩ S. Pick any δ > 0 so that B(x, δ) ∈ U .
Then, by construction, it is true that y ∈ S and d(x, y) < δ implies f (y) ∈ V, i.e., that d(f (x), f (y)) < E. Since E > 0 is arbitrary, you have shown precisely that f is continuous at x.
As an immediate corollary, you have the following statement, which is usually abbreviated as: “a function is continuous if and only if the inverse image of every open set is open.” Corollary 9.3.1 A function f : S ⊂ Rn → Rl is continuous on S if and only if for each open set V ⊂ Rl , there is an open set U ⊂ Rn such that f −1(V ) = U ∩ S where f −1(V ) is defined by f −1(V ) = {x ∈ S|f (x) ∈ V } In particular, if S is an open set in Rn, f is continuous on S if and only if f −1(V ) is an open set in Rn for each open set V in Rl .
Finally, some observation.
Note that continuity of a function f at a point x is a local prop- erty, i.e., it relates to the behaviour of f near x. but tells you nothing about the behaviou of f elsewhere.
In particular, the continuity of f at x has no implicatioin even for the continuity of f at points “close” to x.
Indeed, it is easy to construct functions that are continuous at a given point x, but that are discontinous at every neighbourhood of x.
It is also important to note that, in general, functions need not be continuous at even a single point in their domain.
Consider f : R+ → R+ given by f (x) = 1, if x is a rational number, and f (x) = 0, otherwise.
This function is discontinuous everywhere on R .
+ 9.3.2 Differentiable and Continuously Differentiable Functions Throughout this subsection, S will denote an open set in Rn 207  UNIT 9.
BASIC CONCEPTS OF RN Definition 9.3.5 (Differentiability) A function f : S → Rm is said to be differentiable at a point x ∈ S if there exists an m × n matrix A such that for all E > 0, there is δ > 0 such that y ∈ S and x − y < δ implies f (x) − f (y) − A(x − y) < E x − y .
Equivalently, f is differentiable at x ∈ S if ( \ f (y) − f (x) − A(y − x) lim = 0 y→x y − x (The notation “y → x” is shorthand for “ for all sequences {yk } such that yk → x.”) The matrix A in this case is called derivative of f at x and is denoted Df (x).
Figure 9.1 provides a graphical illustration of the derivative.
In keeping with standard practice, you shall, in the sequel, denote Df (x) by f t(x) whenever n = m = 1, i.e., whenever S ⊂ R and f : S → R. Figure 9.1: The Derivative Remark 9.3.1 The definition of the derivative Df may be motivated as follows.
An affine func- tion from Rn to Rm is a function g is of the form g(y) = Ay + b, where A is an m × n matrix, and b ∈ Rm.
(When b = 0, the function g is called linear.)
Intuitively, the derivative of f at a point x ∈ S is the best affine approximation to f at x, i.e., the best approximation of f around the point x by an affine function g. Here, “best” means that the ratio ( \ f (y) − g(y) y − x goes to zero as y → x.
Since the values of f and g must coincide at x (otherwise g would be hardly be a good approximation to f at x), you must have g(x) = Ax + b = f (x), or b = f (x) − Ax.
Thus, you may write this approximating function g as g(y) = Ay − Ax + f (x) = A(y − x) + f (x).
Given this value for g(y), the task of identifying the best affine approximation to f at x now amounts to identifying a matrix A such that ( \ ( \ f (y) − g(y) f (y) − (A(y − x)) + f (x) = → 0 as y → x. y − x y − x This is precisely the definition of the derivative you have given.
208  UNIT 9.
BASIC CONCEPTS OF RN If f is differentiable at all points in S, then f is said to be differentiable on S. When f is differentiable on S, the derivative Df itself forms a function from S to Rm×n.
If Df : S → Rm×n is a continuous function, then f is said to be continuously differentiable on S, and you write f is C 1.
The following observations are immediate from the definitions.
A function f : S ⊂ Rn → Rm is differentiable at x ∈ S if and only if each of the m componet functions f i : S → R of f is differentiable at x, in which case you have Df (x) = (Df 1(x), .
.
.
, Df m(x)).
Moreover, f is C 1 on S if and only if each f i is C 1 on S. The difference between differentiability and continuous differentiability is non-trivial.
The following example shows that a function may be differentiable everywhere, but may still not be continuously differentiable.
Example 9.3.3 Let f : R → R be given by  0, if x = 0  f (x) =  ( )  x2 sin 1 if x /= 0. x2 For x /= 0, you have ( \ ( \ 1 2 1 f t(x) = 2x sin − cos .
x2 x x2 Since | sin(·)| ≤ 1 and | cos(·)| ≤ 1, but (2/x) → ∞ as x → 0, it is clear that the limit as x → 0 of f t(x) is not well defined.
However, f t(0) does exist!
Indeed, ( \ ( \ f (x) − f (0) 1 f t(0) = lim = lim x sin .
x→0 x − 0 x→0 x2 Since | sin(1/x2)| ≤ 1, you have |x sin(1/x2)| ≤ |x|, so x sin(1/x2) → 0 as x → 0.
This means f t(0) = 0.
Thus, f is not C 1 on R .
+ This example notwithstanding, it is true that the derivative of everywhere differentiable function f must possess a minimal amount of continuity.
This you shall see in the intermediate value theorem later in this unit.
You shall close this subsection with a statement of two important properties of the derivative.
First, given two functions f : Rn → Rm and g : Rn → Rm, define their sum (f + g) to be the function from Rn to Rm whose value at any x ∈ Rn is f (x) + g(x).
Theorem 9.3.1 If f : Rn → Rm and g : Rn → Rm are both differentiable at a point x ∈ Rn, so is (f + g) and, in fact, D(f + g)(x) = Df (x) + Dg(x).
Proof.
Obvious from the definition of differentiability.
Next, given functions f : Rn → Rm and h : Rk → Rn, define, their composition f ◦ h to be the function from Rk to Rm whose value at any x ∈ Rk is given by f (h(x)), that is, by the value of f evaluated at h(x).
209  UNIT 9.
BASIC CONCEPTS OF RN Theorem 9.3.2 Let f : Rn → Rm and h : Rk → Rn.
Let x ∈ Rk .
If h is differentiable at x, and f is differintiable at h(x), the f ◦ h is itself differetiable at x, and its derivative may be obtained throughout the “chain rule” as: D(f ◦ h)(x) = Df (h(x))Dh(x).
Proof.
See Rudin (1976, theorem 9.15, p.214).
Theorems 9.3.1 and 9.3.2 are only one-way implications.
For instance, while the differen- tiability of f and g at x implies the differentiability of (f + g) at x, (f + g) can be differentiable everywhere (even C 1) without f and g being differentiable anywhere.
For an example, let f : R → R be given by f (x) = 1 if x is rational, and f (x) = 0 otherwise, and let g : R → R be given by g(x) = 0 if x is rational, and g(x) = 1 otherwise.
Then, f and g are discontinuous everywhere, so are certainly not differentiable anywhere.
However, (f + g)(x) = 1 for all x, so (f + g)t(x) = 0 at all x, meaning (f + g) is C 1.
Similarly, the differeintiability of f ◦ h has no implications for the differentiability of f at h(x) or the differentiability of h at x.
9.3.3 Partial Derivatives and Differentiability Definition 9.3.6 Let f : S → R, where S ⊂ Rn is an open set.
Let ej denote the vector in Rn that has a 1 in the j − th place and zeros elsewhere (j = 1, .
.
.
, n).
Then the j − th partial derivative of f is said to exist at a point x if there is a number ∂f (x)/∂x such that j ( \ f (x + te ) − f (x) ∂f lim j = (x) t→0 t ∂xj Among the more pleasant facts of life are the following: Theorem 9.3.3 Let f : S → R, where S ⊂ Rn is open.
1.
If f is differentiable at x, then all partials ∂f (x)/∂x exist at x, and j Df (x) = [∂f (x)/∂x , .
.
.
, ∂f (x)/∂x ] 1 n 2.
If all the partials ∂f (x)/∂x exist and are continuous at x, then Df (x) exists and j Df (x) = [∂f (x)/∂x , .
.
.
, ∂f (x)/∂x ] 1 n 3. f is C 1 on S if and only if all partial derivatives of f exist and are continuous on S. Proof.
See Rudin (1976, Theorem 9.21, p219).
Thus, to check if f is C 1, you only need figure out if (a) the partial derivatives exist on S, and (b) if they are all continuous on S. On the other hand, the requirement that the partials not only exist but be continuous at x is very important for the coincidence of the vector of partials with Df (x).
In the absence of this condition, all partials could exist at some point without the function itself being differentiable at that point.
Consider the following example: 210  UNIT 9.
BASIC CONCEPTS OF RN Example 9.3.4 Let f : R2 → R be given by f (0, 0) = 0, and for (x, y) /= (0, 0) xy f (x, y) = ψ .
x2 + y2 You will show that f has all partial derivatives everywhere (including at (0, 0)), but that these partials are not continuous at (0, 0).
Then you have to show that f is differentiable at (0, 0).
☞ Solution.
Since f (x, 0) = 0 for any x /= 0, it is immediate that for all x /= 0, ∂f f (x, yˆ) − f (x, 0) x (x, 0) = lim = lim = 1.
∂y yˆ→0 yˆ yˆ→0 x2 + y2 Similarly, at all points of the form (0, y) for y /= 0, you have ∂f (0, y)/∂x = 1.
However, note that ∂f f (x, 0) − f (0, 0) 0 − 0 (0, 0) = lim = lim = 0, ∂x x→0 x x→0 x so ∂f (0, 0)/∂x exists at (0, 0), but is not the limit of ∂f (0, y)/∂x as y → 0.
Similarly, you also have ∂f (0, 0)/∂y = 0 = 1 = lim ∂f (x, 0)/∂y.
x→0 Suppose f were differentiable at (0, 0).
Then, the derivatives Df (0, 0) must conicide with the vector of partials at (0, 0) so you must have Df (0, 0) = (0, 0).
However, from the definition of the derivative, you must also have f (x, y) − f (0, 0) − Df (0, 0) · (x, y) lim = 0 (x, y) − (0, 0) (x,y)→(0,0) but this is impossible if Df (0, 0) = 0.
To see this, take any point (x, y) of the form (a, a) for some a > 0, and note that every neighbourhood of (0, 0) contains at least one such point.
Since f (0, 0) = 0, Df (0, 0) = (0, 0), and (x, y) = x2 + y2, it follows that f (a, a) − f (0, 0) − Df (0, 0) · (a, a) a2 1 = = (a, a) − (0, 0) 2a2 2 so the limit of this fraction as a → 0 cannot be zero.
✍ Intuitively, the feature that drives this example is that in looking at the partial derivative of f with respect to (say) x at a point (x, y), you are moving along only the line through (x, y) parallel to the x-axis (see the line denoted l in Figure 9.2).
Similarly, the partial with derivative 1 with respect to y involves holding the x variable fixed, and moving only on the line through (x, y) parallel to the y-axis (see the line denoted l in Figure 9.2).
On the other hand, in looking 2 at the derivative Df, both the x and y variables are allowed to vary simultaneously (for instance, along the dotted curve in Figure 9.2).
Lastly, it is worth stressing that although a function must be continuous in order to be dif- ferentiable (this is easy to see from the definitions), there is no implication in the other direction whatsoever.
Extreme examples exist of functions which are continuous on all of R, but fail to be differentiable at even a single point.
Such functions are by no means pathological; they play, for instance, a central role in the study of Brownian motion in probability theory (with probability one, a Brownian motion path is everywhere continuous and nowhere differentiable).
211  UNIT 9.
BASIC CONCEPTS OF RN Figure 9.2: Partial Derivatives and Differentiability 9.3.4 Directional Derivatives and Differentiability Let f : S → R, where S ⊂ Rn is open.
Let x be any point in S, and let h ∈ Rn.
The directional derivative of f at x in the direction h is defined as ( \ f (x + th) − f (x) lim t→0+ t when this limit exists, and is denoted Df (x; h).
(The notation t → 0+ is shorthand for t > 0, t → 0.)
When the condition t → 0+ is replaced with t → 0, you obtain what is sometimes called the “two-sided directional derivative.” Observe that partial derivatives are a special case of two- sided directional derivatives: when h = e for some i, the two-sided directional derivative at x i is precisely the partial derivative ∂f (x)/∂x .
i In the privious subsection, it was pointed out that the existence of all partial derivatives at a point x is not sufficient to ensure that f is differentiable at x.
It is actually true that no even the existence of all two-sided directional derivatives at x implies that f is differentiable at x.
However, the following relationship in the reverse direction is easy to show.
Theorem 9.3.4 Suppose f is differentiable at x ∈ S. Then, for any h ∈ Rn, the (one-sided) directional derivative Df (x; h) of f at x in the direction h exists, and, in fact, you have Df (x; h) = Df (x) · h. An immediate corollary is Corollary 9.3.2 If Df (x) exists, then Df (x; h) = −Df (x; −h).
Remark 9.3.2 What is the relationship between Df (x) and the two-sided directional deriva- tive of f at x in an arbitrary direction h?
9.3.5 Higher Order Derivatives Let f be a function from S ⊂ Rn to R, where S is an open set.
Throughout this sub- section, you will assume that f is differentiable on all of S, so that the derivative Df = [∂f /∂x , .
.
.
, ∂f /∂x ] itself defines a function from S to Rn.
1 n Suppose now that there is x ∈ S such that the derivative Df is itself differentiable at x, i.e., such that for each i, the function ∂f /∂x : S → R is differentiable at x. Denote the partial of i ∂f /∂x in the direction e at x by ∂2f (x)/∂x ∂x , if i /= j, and ∂2f (x)/∂x2, if i = j. i j j i i Then, you say that f is twice-differentiable at x, with second derivative D2f (x), where 212  UNIT 9.
BASIC CONCEPTS OF RN   ∂2f (x) ∂2f (x) · · ·    ∂x12 ∂x1∂xn      D2f (x) =  .
.
.
.
..         ∂2f (x) ∂2f (x)  · · · ∂xn∂x1 ∂x2n Once again, you shall follow standard practice and denote D2f (x) by f tt(x) whenever n = 1 (i.e., if S ⊂ R).
If f is twice-differentiable at each x in S, you say that f is twice-differentiable on S. When f is twice-differentiable on S, and for each i, j = 1, .
.
.
, n the cross-partial ∂2f /∂x∂x is a i j continuous function from S to R, you say that f is twice continuously differentiable on S, and you write f is C 2.
When f is C 2, the second-derivative D2f, which is also called the matrix of cross-partials (or the hessian of f at x), has the following useful property: Theorem 9.3.5 If f : D → Rn is a C 2 function, D2f is a symmetric matrix, i.e., you have ∂2f ∂2f (x) = (x) ∂xi∂xj ∂xi∂xj for all i, j = 1, .
.
.
, n and for all x ∈ D. Proof.
See Rudin (1976, Corollary to Theorem 9.41, p.236).
For an example where the symmetry of D2f fails because the fails to be continuous, see the Tutor Marked Assignemts(TMAs).
The condition that the partials should be continuous for D2f to be a symmetric matrix can be weakened a little.
In particular, for ∂2f ∂2f (y) = (y) ∂xj ∂xk ∂xk ∂xj to hold, it suffices just that (a) the partials ∂f /∂x and ∂f /∂x exist everywhere on D and j k (b) that one of the cross-partials ∂2f /∂x ∂x or ∂2f /∂x ∂x exist everywhere on D and be j k k j continuous at y.
Still higher derivatives (third, fourth, etc.)
may be defined for a function f : Rn → R. The underlying idea is simple: for instance, a function is thrice-differentiable at a point x if all the component functions of its second-derivative D2f (i.e., if all the cross-partial functions ∂2f /∂x ∂x ) are themselves differentiable at x; it is C 3 if all these component functions are i j continuously differentiable, etc.
On the other hand, the notation becomes quite complex unless n = 1 (i.e., f : R → R), and you do not have any use in this book for derivatives beyond the second, so you will not attempt formal definitions here.
213  UNIT 9.
BASIC CONCEPTS OF RN 9.4 Quadratic Forms: Definite and Semidefinite Matrices 9.4.1 Quadratic Forms and Definiteness Definition 9.4.1 A quadratic form on Rn is a function g on Rn of the form A n g (x) = xtAx = a x x A ij i j i,j=1 where A = (a ) is any symmetric n × n matrix.
ij Since the quadratic form g is completely specified by the matrix A, you henceforth refer to A A itself as the quadratic form.
your interest in quadratic forms arises from the fact that if f is a C 2 function, and z is a point in the domain of f, then the matrix of second partials D2f (z) defines a quadratic form (this follows from Theorem 9.3.5 on the symmetry property of D2f for a C 2 function f ).
Definition 9.4.2 A quadratic form A is said to be 1. positive definite if you have xtAx > 0 for all x ∈ Rn, x /= 0.
2. positive semidefinite if you have xtAx ≥ 0 for all x ∈ Rn, x /= 0.
3. negative definite if you have xtAx < 0 for all x ∈ Rn, x /= 0.
4. negative semidefinite if you have xtAx ≤ 0 for all x ∈ Rn, x /= 0 The terms “non-negative definite” and “nonpositive definite” are often used in place of “positive semidefinite” and “negative semidefinite” respectively.
For instance, the quadratic form A defined by ( l 1 0 A = 0 1 is positive definite, since for any x = (x , x ) ∈ R2, you have xtAx = x2 + x2, and this quantity 1 2 1 2 is positive whenever x /= 0.
On the other hand, consider the quadratic form ( l 1 0 A = 0 0 For any x = (x1, x2) ∈ R2, you have xtAx = x12 , so xtAx can be zero even if x /= 0.
(For example, xtAx = 0if x = (0, 1).)
Thus, A is not positive definite.
On the other hand, it is certainly true that you always have xtAx ≥ 0, so A is positive semidefinite.
Observe that there exist matrices A which are neither positive semidefinite nor negative semidefinite, and that do not, therefore, fit into any of the four categories you have identified.
Such matrices are called indefinite quadratic forms.
As an example of an indefinite quadratic form A, consider 214  UNIT 9.
BASIC CONCEPTS OF RN ( l 0 1 A = 1 0 For x = (1, 1), xtAx = 2 > 0, so A is not negative semidefinite.
But for x = (−1, 1), xtAx = − 2 < 0, so A is positive semidefinite either.
Given a quadratic form A and any t ∈ R, you have (tx)tA(tx) = t2xtAx, so the quadratic form has the same sign along lines through the origin.
Thus, in particular, A is positive definite (resp.
negative definite) if and only if it satisfies xtAx > 0 (resp.
xtAx < 0) for all x in the unit sphere C = {u ∈ Rn| u = 1}.
You will use this observation to show that if A is a positive definite (or negative definite) n × n matrix, so is any other quadratic form B which is sufficiently close to A. Theorem 9.4.1 Let A be a positive definite n × n matrix.
Then there is γ > 0 such that if B is any symmetric n × n matrix with |b − a | < γ for all j, k ∈ {1, .
.
.
, n}, then B is jk jk also positive definite.
A similar statement holds for negative definite matrices A.
Proof.
You will make use of the Weierstrass Theorem, which will be proved later.
The Weierstrass Theorem states that if K ⊂ Rn is compact, and f : K → R is a continuous function, then f has both maximum and minimum on K, i.e., there exist points kt and k∗ in K such that f (kt) ≥ f (k) ≥ f (k∗ ) for all k ∈ K. Now, the unit sphere C is clearly compact, and the quadratic form A is continuous on this set.
Therefore, by the Weierstrass Theorem, there is z ∈ C such that for any x ∈ C, you have ztAz ≤ xtAx.
If A is positive definite, then ztAz must be strictly positive, so there must exists E > 0 such that xtAx ≥ E > 0 for all x ∈ C. Define γ = E/2n2 > 0.
Let B be any symmetric n×n matrix, which is such that |b −a | < jk jk γ for all j, k = 1, .
.
.
, n. Then for any x ∈ C, n |xt(B − A)x| = (bjk − ajk) xj xk j,k=1 n ≤ |bjk − ajk ||xj ||xk | j,k=1 n < γ j,k=1 |xj ||xk | < γn2 = E/2.
Therefore, for any x ∈ C, xtBx = xtAx + xt(B − A)x ≥ E − E/2 = E/2 so B is positive definite, and the desired result is establised.
215  UNIT 9.
BASIC CONCEPTS OF RN A particular implication of this result, which you will use in the study of unconstrained optimization problems, is the following: Corollary 9.4.1 If f is a C 2 function such that at some point x, D2f (x) is a positive definite matrix, then there is a neighbourhood B(x, r) of x such that for all y ∈ B(x, r), D2f (y) is also a positive definite matrix.
A similar statement holds if D2f (x) is instead, a negative definite matrix.
Finally, it is important to point out that Theorem 9.4.1 is no longer true if “positive definite” is replaced with “positive semidefinite.” Consider, as a counter example, the matrix A defined by ( l 1 0 A = .
0 0 You have seen above that A is positive semidefinite (but not positive definite).
Pick any γ > 0.
Then, for E = γ/2, the matrix ( l 1 0 B = 0 −E satisfies |aij − bij | < γ for all i, j.
However, B is not positive semidefinite: for x = (x1, x2), you have xtBx = x21 − Ex22 , and this quantity can be negative (for instance, if x1 = 0 and x2 /= 0).
Thus, there is no neighbourhood of A such that all quadratic forms in that neighbourhood are also positive semidefinite.
9.4.2 Identifying Definiteness and Semidefiniteness From a practical standpoint, it is of interest to ask: what restrictions on the structure of A are imposed by the requirement that A be a positive (or negative) definite quadratic from?
The answers to this questions is provided in this section.
These results are, in fact, equivalence state- ments; that is, quadratic forms possess the required definiteness or semidefiniteness property if and only if they meet the condition outlined.
The first result deals with positive and negative definiteness.
Given an n × n symmetric matrix A, let A denote the k × k submatrix of A that is obtained when only the first k rows and k columns are retained, i.e., let   a · · · a 11 1k  .
 Ak =  .
.
.
.
 a · · · a k1 kk You will refer to A as the k-th natural ordered principal minor of A. k Theorem 9.4.2 An n × n symmetric matrix A is 1. negative definite if and only if (−1)k |A | > 0 for all k ∈ {1, .
.
.
, n}.
k 216  UNIT 9.
BASIC CONCEPTS OF RN 2. positive definite if and only if |Ak | > 0 for all k ∈ {1, .
.
.
, n}.
Moreover, a positive semidefinite quadratic form A is positive definite if and only if |A| /= 0, while a negative semidefinite quadratic form is negative definite if and only if |A| =/ 0.
Proof.
See Debreu (1952, Theorem 2, p.296).
A natural conjecture is that this theorem would continue to hold if the words “negative defi- nite” and “positive definite” were replaced with “negative semidefinite” and “positive semidef- inite,” respectively, provided the strict inequalities were replaced with weak ones.
This conjec- ture is false.
Consider the following example.
Example 9.4.1 Let ( l ( l 0 0 0 0 A = and B = 0 1 0 −1 Then, A and B are both symmetric matrices.
Moreover, |A1| = |A2| = |B1| = |B2| = 0, so if the conjecture were true, both A and B would pass the test for positive semidefiniteness, as well as the test for negative semidefiniteness.
However, for any x ∈ R2, xtAx = x2 and 2 xtBx = −x2.
Therefore, A is positive semidefinite but not negative seimidefinite, while B is 2 negative semidefinite, but not positive semidefinite.
Roughly speaking, the feature driving this counterexample is that, in both the matrices A and B, the zero entries in all but the (2, 2)-place of the matrix make the determinants of order 1 and 2 both zero.
In particular, no play is given to the sign of the entry in the (2, 2)-place, which is positive in one case, and negative in the other.
On the other hand, an examination of the expression xtAx and xtBx reveals that in both cases, the sign of the quadratic form is determined precisely by the sign of the (2, 2)-entry.
This problem points to the need to expand the set of submatrices that you are considering, if you are to obtain an analog of Theorem 9.4.2 for positive and negative semidefiniteness.
Let an n × n symmetric matrix A be given, and let π = (π , .
.
.
, π ) be a permutation of the integers 1 n {1, .
.
.
, n}.
Denote by Aπ the symmetric n × n matrix obtained by applying the permutation π to both the rows and columns of A :   aπ1 π1 · · · aπ1 πn     Aπ =  .
.
.
.
..      aπn π1 · · · aπn πn For k ∈ {1, .
.
.
, n}, let Aπ denote the k × k symmetric submatrix of Aπ obtained by retaining k only the first k rows and columns:   aπ1 π1 · · · aπ1 πn     Aπk =  .. .
.
.
..    aπk π1 · · · aπk πk 217  UNIT 9.
BASIC CONCEPTS OF RN Finally, let Π denote the set of all possible permutations of {1, .
.
.
, n} Theorem 9.4.3 A symmetric n × n matrix A is 1. positive semidefinite if and only if |Aπ | ≥ 0 for all k ∈ {1, .
.
.
, n} and for all π ∈ Π. k 2. negative semidefinite if and only if (−1)k |Aπ | ≥ 0 for all k ∈ {1, .
.
.
, n} and for all k π ∈ Π.
Proof.
See Debreu (1952, Theorem 7, p298).
One final remark is important.
The symmetry assumptions is crucial to the validity of these results.
If it fails, a matrix A might pass all the tests for (say) positive semidefiniteness without actually being positive semidefinite.
Here are two examples: Example 9.4.2 Let ( l 1 −3 A = 0 1 Note that |A | = 1, and |A | = (1)(1) − (−3)(0) = 1, so A passes the test for positive 1 2 definiteness.
However, A is not a symmetric matrix, and is not, in fact, positive definite: you have xtAx = x21 + x22 − 3x1x2 which is negative for x = (1, 1).
Example 9.4.3 Let ( l 0 1 A = .
0 0 There are only two possible permutations of the set {1, 2}, namely, {1, 2} itself, and {2, 1}.
This gives rise to four different submatrices, whose determinants you have to consider: ( l ( l a a a a [a ], [a ], 11 12 , and 11 12 11 22 a a a a 21 22 21 22 You can easily check that the determinants of all four of these are non-negative, so A passes the test for positive semidefiniteness.
However, A is not positive semidefinite: you have xtAx = x x , which could be positive or negative.
1 2 9.5 Some Important Results This section brings together some results of importance for the study of optimization theory.
These are, the separation theorems for convex sets in Rn, consequences of assuming continu- ity and/or differentiability of real-valued functions defined on Rn and two fundamental results known as the Inverse Function Theorem and the Implicit Function Theorem.
218  UNIT 9.
BASIC CONCEPTS OF RN 9.5.1 Separation Theorems Let p /= 0 be a vector in Rn, and let a ∈ R. The set H defined by H = {x ∈ Rn|p · x = a} is called a hyperplane in Rn, and will be denoted H (p, a).
A hyperplane in R2, for example, is simply a straight line: if p ∈ R2 and a ∈ R, the hyperplane H (p, a) is simply the set of points (x , x ) that satisfy p x + p x = a. Similary, a 1 2 1 1 2 2 hyperplane in R3 is a plane.
A set D in Rn is said to be bounded by a hyperplane H (p, a) if D lies entirely on one side of H (p, a), i.e., if either p · x ≤ a, for all x ∈ D or p · x ≥ a, for all x ∈ D If D is bounded by H (p, a) and D ∩ H (p, a) /= ∅, then H (p, a) is said to be a supporting hyperplane for D. Example 9.5.1 Let D = {(x, y) ∈ R2 |xy ≥ 1}.
Let p be the vector (1, 1), and let a = 2.
Then + the hyperplane H (p, a) = {(x, y) ∈ R2|x + y = 2} bounds D : if xy ≥ 1 and x, y ≥ 0, then you must have (x + y) ≥ (x + x−1) ≥ 2.
In fact, H (p, a) is a supporting hyperplane for D since H (p, a) and D have the point (x, y) = (1, 1) in common.
Two sets D and E in Rn are said to be separated by the hyperplane H (p, a) in Rn if D and E lie on opposite sides of H (p, a), i.e., if you have p · y ≤ a, for all y ∈ D p · z ≥ a, for all y ∈ D If D and E are separated by H (p, a) and one of the sets (say, E ) consists of just a single point x, you will indulge in a slight abuse of terminology and say that H (p, a) separates the set D and the point x.
A final definition is required before you would state the main results of this section.
Given a set X ⊂ Rn, the closure of X , denoted X ◦, is defined to be the intersection of all closed sets containing X , i.e., if ∆(X ) = {Y ⊂ Rn|X ⊂ Y} then n X ◦ = Y. Y∈∆(X ) 219  UNIT 9.
BASIC CONCEPTS OF RN Intuitively, the closure of X is the “smallest” closed set that contains X .
Since the arbitrary intersection of closed sets is closed, X ◦ is closed for any set X ◦.
Note that X ◦ = X if and only if X is itself closed.
The following results deal with the separation of convex sets by hyperplanes.
They play a significant role in the study of inequality-constrained optimization problems under convexity restriction.
Theorem 9.5.1 Let D be a nonempty convex set in Rn, and let x∗ be a point in Rn that is not in D. Then, there is a hyperplane H (p, a) in Rn with p /= 0 which separates D and x∗ .
You may, if you desire choose p to also satisfy p = 1.
Proof.
See Sundaram (1999, Theorem 1.67, p56) Theorem 9.5.2 Let D and E be convex sets in Rn such that D ∩ E = ∅.
Then, there exists a hyperplane H (p, a) in Rn which separates D and E .
You may, if you desire, choose p to also satisfy p = 1.
Proof.
Let F = D + (−E ), where, in obvious notation, −E is the set {y ∈ Rn| − y ∈ E }.
Since D and E are convex sets, F is also convex.
You can claim that 0 /∈ F .
For if you had 0 ∈ F , then there would exist points x ∈ D and y ∈ E such that x − y = 0.
But this implies x = y, so x ∈ D ∩ E , which contradicts the assumption that D ∩ E is empty.
Therefore, 0 /∈ F .
By 9.5.1, there exists p ∈ Rn such that p · 0 ≤ p · z, z ∈ F .
This is the same thing as p · y ≤ p · x, x ∈ D, y ∈ E It follows that sup p · y ≤ inf p · x.
If a ∈ {sup p · y, inf p · x}, the hyperplane H (p, a) y∈E x∈D y∈E x∈D separates D and E .
That p can also be chosen to satisfy p = 1 is established in the same way as in 9.5.1 9.5.2 The Intermediate and Mean Value Theorems The Intermediate Value Theorem asserts that a continuous real function on an interval assumes all intermediate values on the interval.
Figure 9.3 illustrates the result.
Figure 9.3: Theorem 9.5.3 (Intermediate Value Theorem) Let D = [a, b] be an interval in R and let f : D → R be continuous function.
If f (a) < f (b), and if c is a real number such that 220  UNIT 9.
BASIC CONCEPTS OF RN f (a) < c < f (b), then there exists x ∈ (a, b) such that f (x) = c. A similar statement holds if f (a) > f (b).
221  UNIT 9.
BASIC CONCEPTS OF RN Proof.
See Rudin (1976, Theorem 4.23, p.93).
Remark 9.5.1 It might appear at first glance that the intermediate value property actually char- acterizes continuous functions is and only if for any two points x < x and for any real number 1 2 c lying between f (x1) and f (x2), there is x ∈ (x1, x2) such that f (x) = c. The Intermediate Value Theorem shows that the “only if ” part is true.
You can show that the converse, namely the “if ” part, is actually false.
You have seen in Example 9.3.3 that a function may be differentiable everywhere, but may fail to be continuously differentiable.
The following result (which may be regarded as an In- termediate Value Theorem for the derivative) states, however, that the derivative must still have some minimal continuity properties, viz., that the derivative must assume all intermediate val- ues.
In particular, it shows that the derivative f t of an everywhere differentiable function f cannot have jump discontinuities.
Theorem 9.5.4 (Intermediate Value Theorem for the Derivative) Let D = [a, b] be an interval in R, and let f : D → R be a function that is differentiable everywhere on D. If f t(a) < f t(b), and if c is a real number such that f t(a) < c < f t(b), then there is a point x ∈ (a, b) such that f t(x) = c. A similar statement holds if f t(a) > f t(b).
Proof.
See Rudin (1976, Theorem 5.12, p.108) It is very important to emphasize that Theorem 9.5.4 does not assume that f is a C 1 func- tion.
Indeed, if f were C 1, the result would be a trivial consequence of the Intermediate Value Theorem, since the derivative f t would then be a continuous function on D. The next result, the Mean Value Theorem, provides another property that the derivative must satisfy.
A graphical representation of this result is provided in Figure 9.4.
As with theorem 9.5.4, it is assumed only that f is everywhere differentiable on its domain D, and not that it is C 1.
Figure 9.4: Theorem 9.5.5 (Mean Value Theorem) Let D = [a, b] be an interval in R, and let f : D → R be a continuous function.
Suppose f is differentiable on (a, b).
Then there exists x ∈ (a, b) such that f (b) − f (a) = (b − a)f t(x).
Proof.
See Rudin (1976, Theorem 5.10, p.108) The following generalizatioin of the Mean Value Theorem is known as the Taylor’s Theo- rem.
It may be regarded as showing that a many-times differentiable function can be approx- imated by a polynomial.
The notation f (k)(z) is used in the statement of Taylor’s Theorem to denote the k-th derivative of f evaluated at the point z.
When k = 0. f (k)(x) should be interpreted simply as f (x).
Theorem 9.5.6 Taylor’s Theorem Let f : D → R be a C m function, where D is an open interval in R, and m ≥ 0 is a non-negative integer.
Suppose also that f (m+1)(z) exists for every point z ∈ D. Then, for any x, y ∈ D, there is z ∈ (x, y) such that 222  UNIT 9.
BASIC CONCEPTS OF RN ( \ m f (k)(x)(y −x)k f (m+1)(z)(y −x)m+1 f (y) = + .
k (m + 1)!
k=0 Proof.
See Rudin (1976, Theorem 5.15, p.110) Each of the results you have stated in this subsection, with the obvious exception of the Intermediate Value Theorem for the Derivative, also has an n-dimensional version.
These ver- sions you will state here, deriving their proofs as consequences of the corresponding result in R. Theorem 9.5.7 (The Intermediate Value Theorem in Rn) Let D ⊂ Rn be a convex set, and let f : D → R be continuous on D. Suppose that a and b are points in D such that f (a) < f (b).
ˆ ˆ ˆ Then for any c such that f (a) < c < f (b), there is λ ∈ (0, 1) such that f ((1 − λ)a + λb) = c. Proof.
You could derive this result as a consequence of the intermediate Value Theorem in R. Let g : [0, 1] → R be defined by g(λ) = f ((1 − λ)a + λb), λ ∈ [0, 1].
Since f is a continuous function, g is evidently continuuous on [0, 1].
Moreover, g(0) = f (a) and g(1) = f (b), so g(0) < c < g(1).
By the Intermediate Value Theorem in R, there exists λˆ ∈ (0, 1) such that ˆ ˆ ˆ ˆ g(λ) = c. Since g(λ) = f ((1 − λ)a + λb), you are done with the proof.
An n-dimensional version of the Mean Value Theorem is similarly established: Theorem 9.5.8 (The Mean Value Theorem in Rn) Let D ⊂ Rn be open and convex, and let f : S → R be a function that is differentiable everywhere on D. Then, for any a, b ∈ D, there ˆ is λ ∈ (0, 1) such that ˆ ˆ f (b) − f (a) = Df ((1 − λ)a + λb) · (b − a).
Proof.
For notational ease, let z(λ) = (1 − λ)a + λb.
Define g : [0, 1] → R by g(λ) = f (z(λ)) for λ ∈ [0, 1].
Note that g(0) = f (a) and g(1) = f (b).
Since f is every- where differentiable by hypothesis, it follows that g is differentiable at all λ ∈ [0, 1], and in fact, gt(λ) = Df (z(λ)) · (b − a).
By the Mean Value Theorem for functions of one variable, therefore, there is λt ∈ (0, 1) such that g(1) − g(0) = gt(λt)(1 − 0) = gt(λt).
Substituting for g in terms of f, this is precisely the statement that f (b) − f (a) = Df (z(λt)) · (b − a).
You have proved the theorem.
Finally, is the Taylor’s Theorem in Rn.
A complete statement of this result requires some new notation, and is also irrelevant for the remainder of this book.
So you are confined to stating two special cases that are useful for your purposes.
Theorem 9.5.9 (Taylor’s Theorem in Rn) Let f : D → R, where D is an open set in Rn.
If f is C 1 on D, then it is the case that for any x, y ∈ D, you have f (y) = f (x) + Df (x)(y − x) + R1(x, y), 223  UNIT 9.
BASIC CONCEPTS OF RN where the remainder term R (x, y) has the property that 1 ( \ R (x, y) 1 lim = 0. y→x x − y If f is C 2, this statement can be strengthened to 1 f (y) = f (x) + Df (x)(y − x) + 2 (y − x)t D2 f (x)(y − x) + R2(x, y).
where the remainder term R (x, y) has the property that 2 ( \ R (x, y) lim 2 = 0 y→x x − y 2 Proof.
Fix any x ∈ D, and define the function F (·) on D by F (y) = f (x) + Df (x) · (y − x).
Let h(y) = f (y) − F (y).
Since f and F are C 1, so is h. Note that h(x) = Dh(x) = 0.
The first-part of the theorem will be proved if you show that h(y) → 0 as y → x, y − x or, equivalently, if you show that for any E > 0, there is δ > 0 such that y − x < δ implies |h(y)| < E x − y .
So let E > 0 be given.
By the continuity of h and Dh, there is δ > 0 such that |y − x| < δ implies|h(y)| < Eand Dh(y) < E. Fix any y satisfying |y − x| < δ.
Define a function g on [0, 1] by g(t) = h[(1 − t)x + ty].
Then g(0) = h(x) = 0.
Moreover, g is C 1 with gt(t) = Dh[(1 − t)x + ty](y − x).
Now note that |(1 − t)x + ty − x| = t|(y − x)| < δ for all t ∈ [0, 1], since |x − y| < δ.
Therefore, Dh[(1 − t)x + ty] < E for all t ∈ [0, 1], and it follows that |gt(t)| ≤ E y − x for all t ∈ [0, 1].
By Taylor’s Theorem in R, there is t∗ ∈ (0, 1) such that g(1) = g(0) + gt(t∗)(1 − 0) = gt(t∗ ).
Therefore, |h(y)| = |g(1)| = |gt(t∗)| ≤ E|y − x|.
Since y was an arbitrary point satisfying |y − x| < δ, the first part of the theorem is proved.
You can establish the second part analogously.
224  UNIT 9.
BASIC CONCEPTS OF RN 9.5.3 The Inverse and Implicit Function Theorems Here, you will state two results of much importance especially for “comparative statics” exer- cises.
The second of these results (The Implicit Function Theorem) also plays a central role in proving Lagrange’s Theorem on the first-order conditions for equality-constrained optimization problems.
Some new terminology is, unfortunately, required first.
Given a function f : A → B, you will say that the function f maps A onto B, if for every b ∈ B, there is some a ∈ A such that f (a) = b.
You will say that f is a one-to-one function if for any b ∈ B, there is at most one a ∈ A such that f (a) = b.
If f : A → B is both one-to-one and onto, then it is easy to see that there is a (unique) function g : B → A such that f (g(b)) = b for all b ∈ B.
(Note that you also have g(f (a)) = a for all a ∈ A.)
The function g is called the inverse function of f. Theorem 9.5.10 (Inverse Function Theorem) Let f : S → Rn be a C 1 function, where S ⊂ Rn is open.
Suppose there is a point y ∈ S such that n × n matrix Df (y) is invertible.
Let x = f (y).
Then: 1.
There are open sets U and V in Rn such that x ∈ U, y ∈ V, f is one-to-one on V, and f (V ) = U.
2.
The inverse function g : U → V of f isC 1 function on U, whose derivative at any point xˆ ∈ U satisfies Dg(xˆ) = (Df (yˆ))−1, where f (yˆ) = x Proof.
See Rudin (1976, Theorem 9.24, p.221).
Turning to the Implicit Function Theorem, the question this result addresses may be moti- vated by a simple example.
Let S = R2 , and let f : S → R be defined by f (x, y) = xy.
Pick ++ any point (x¯, y¯) ∈ S, and consider the “level set” C (x¯, y¯) = {(x, y) ∈ S|f (x, y) = f (x¯, y¯)}.
If you now define the function h : R++ → R by h(y) = f (x¯, y¯)/y, you have f (h(y), y) ≡ f (x¯, y¯)m y ∈ R .
++ Thus, the values of the x-variable on the level set C (x¯, y¯) can be represented explicitly in terms of the values of the y-variable on this set, through the function h. In general, an exact form for the original function f may not be specified-for instance, you may only know that f is an increasing C 1 function on R2-so you may not be able to solve for h explicitly.
The question arises whether at least an implicit representation of the function h would exist in such a case.
The Implicit Function Theorem studies this problem in a general setting.
That is it looks at sets of functions f from S ⊂ Rm to Rk , where m > k, and asks when the values of some of the variable in the domain can be represented in terms of the others, on a given level set.
Under very general conditions, it proves that at least a local representatioin is possible.
225  UNIT 9.
BASIC CONCEPTS OF RN The statement of the theorem requires a little more notation.
Given integers m ≥ 1 and n ≥ 1, let a typical point in Rm+n be denoted by (x, y), where x ∈ Rm and y ∈ Rn.
For a C 1 function F mapping some subset of Rm+n into Rn, let DF (x, y) denote that portion of the y derivative matrix DF (x, y) corresponding to the last n variables.
Note that DF (x, y) is an y n × n matrix.
DFx(x, y) is defined similarly.
Theorem 9.5.11 Implicit Function Theorem Let F : S ⊂ Rm+n → Rn be a C 1 function, where S is open.
Let (x∗ , y∗ ) be a point in S such that DF (x∗ , y∗ ) is invertible, and y let F (x∗ , y∗ ) = c. Then, there is a neighbourhood U ⊂ Rm of x∗ and a C 1 function g : U → Rn such that (i) (x, g(x)) ∈ S for all x ∈ U, (ii) g(x∗ ) = y∗ , and (iii) F (x, g(x)) ≡ c for all x ∈ U.
The derivative of g at any x ∈ U may be obtained from the chain rule: Dg(x) = (DF (x, y))−1 · DF (x, y) y x Proof.
See Rudin (1976, Theorem 9.28, p.224) 9.6 Conclusion In this unit, you have considered some basic concepts as regards to function in Rn, namely, continuity, differentiable and continuous differentiable functions, Partial derivatives and Differ- entiability, Directional Derivative and Differentiability and Higher Order Derivatives.
You also considered Quadratic forms, definite and semidefinite matrices ans some useful results, namely Separation Theorems, The intermediate and Mean value theorem and the inverse and implicit function theorems .
All these are great tools which you will use in optimization theory in Rn.
9.7 Summary Having read through this unit, you are able to (i) Define Continuous functions, differentiable and continuous differentiable functions, Par- tial derivatives and Differentiability, Directional derivatives and Differentiability and Higher Order Derivatives.
(ii) Define Quadratic forms and definiteness.
(iii) Identity Definiteness and Semidefiniteness.
(iv) State and Use the Separation Theorems, the Intermediate and Mean Value Theorems, and the Inverse and Implicit Function theorems.
9.8 Tutor Marked Assignments Exercise 9.8.1 226  UNIT 9.
BASIC CONCEPTS OF RN 1.
Let f : Rn → R be continuous at a point p ∈ Rn.
Assume f (p) > 0.
Which of the following statements is correct?
(a) For all open ball B ⊂ Rn such that p ∈ B, and for all x ∈ B, you have f (x) > 0.
(b) There is an open ball B ⊂ Rn such that p ∈ B, and for all x ∈ B, you have f (x) > 0.
(c) For all open ball B ⊂ Rn such that p ∈ B, and there exists x ∈ B, for which f (x) < 0.
(d) There is an open ball B ⊂ Rn such that p ∈ B, and for all x ∈ B, you have f (x) < 0.
2.
Suppose f : Rn → R is continuous function.
Then the set {x ∈ Rn|f (x) = 0} is (a) a closed set (b) an open set (c) both open and closed (d) none of the above.
3.
Let f : R → R be defined by  1 if 0 ≤ x ≤ 1 f (x) =   0 otherwise.
Find an open set O such that f −1(O) is not open and find a closed set C such that f −1(C ) is not closed.
4.
Give an example of a function f : R → R which is continuous at exactly two points (say, at 0 and 1), or show that no such function can exists.
5.
Show that it is possible for two function f : R → R and g : R → R to be continuous, but for their product f · g to be continuous.
What about their composition f ◦ g?
6.
Let f : R → R be a function which satisfies f (x + y) = f (x)f (y) for all x, y ∈ R. Show that if f is continuous at x = 0, then it is continuous at every point of R. Also show that if f vanishes at a single point of R, then f vanishes at every point of R. 7.
Let f : R → R be defined by +  0, x = 0 f (x) =   x sin(1/x), x /= 0 Show that f is continuous at 0.
227  UNIT 9.
BASIC CONCEPTS OF RN 8.
Let D be the unit square [0, 1] × [0, 1] in R2.
For (s, t) ∈ D, let f (s, t) be defined by f (s, 0) = 0, for all s ∈ [0, 1], and for t > 0,  ( l 2s t  s ∈ 0,  t 2    ( l f (s, t) = 2s t 2 − s ∈ , t  t 2      0 s ∈ (t, 1].
(Drawing a picture of f for a fixed t will help).
Show that f is a separately continuous function, i.e., for each fixed value of t, f is continuous as a function of s, and for each fixed value of s, f is continuous in t. Show also that f is not jointly continuous in s and t, i.e., show that there exists a point (s, t) ∈ D and a sequence (s , t ) in D converging n n to (s, t) such that lim f (s , t ) /= f (s, t).
n→ n n 9.
Let f : R → R be defined as  x If x is irrational f (x) =   1 − x if x is rational At what point x ∈ R is f continuous?
(a) x = 0 (b) x = 1 (c) x = 1 2 (d) x = x0, x0 ∈ R 10.
Let f : Rn → R and g : R → R be continuous functions.
Define h : Rn → R by h(x) = g[f (x)].
Show that h is continuous.
Is it possible for h to be continuous even if f and g are not?
11.
Show that if a function f : R → R satisfies |f (x) − f (y)| ≤ M (|x − y|)a for some fixed M > 0 and a > 1, then f is a constant function, i.e., f (x) is identically equal to some real number b at all x ∈ R. 12.
Let f : R2 → R be defined by f (0, 0) = 0, and for (x, y) /= (0, 0), xy f (x, y) = .
x2 + y2 Show that the two-sided directional derivative of f evaluated at (x, y) = (0, 0) exists in all directions h ∈ R2, but that f is not differentiable at (0, 0).
228  UNIT 9.
BASIC CONCEPTS OF RN 13.
Let f : R2 → R be defined by f (0, 0) = 0 and for (x, y) /= (0, 0) xy(x2 − y2) f (x, y) = .
x2 + y2 Show that the cross-partials ∂2f (x, y)/∂x∂y and ∂2f (x, y)/∂y∂x exist at all (x, y) ∈ R2, but that these partials are not continuous at (0, 0).
Show also that ∂2f (0, 0) ∂2f (0, 0).
∂x∂y ∂y∂x /= 14.
Show that an n × n symmetric matrix A is a positive definite matrix if and only if −A is a negative definite matrix.
(−A referes to the matrix whose (i, j)-th entry is −a .)
ij 15.
Prove the following statements or provide a counterexample to show it is false: If A is a positive definite matrix, then A−1 is a negative definite matrix.
16.
Give an example of matrices A and B which are each negative semidefinite but not nega- tive definite, and which are such that A + B is negative definite.
17.
Is it possible for a symmetric matrix A to be simultaneously negative semidefinite and positive semidefinite?
If yes, give an example.
If not, provide a proof.
18.
Examine the definiteness or semidefiniteness of the following quadratic forms:     0 0 1 1 2 3 A =  0 1 0  A =  2 4 6  1 0 0 3 6 0     1 0 1 −1 2 −1 A =  0 1 0  A =  2 −4 2  1 0 1 −1 2 −1 19.
Find the hessians D2f of each of the following functions.
Evaluate the hessians at the specified points, and examine if the hessian is positive definite, negative definite, positive semidefinite, negative semidefinite, or indefinite.
√ (a) f : R2 → R, f (x) = x2 + x , at x = (1, 1) 1 2 (b) f : R2 → R, f (x) = (x x )1/2, at an arbitrary point x ∈ R2 .
1 2 ++ (c) f : R2 → R, f (x) = (x x )2, at an arbitrary point x ∈ R2 .
1 2 ++ √ √ √ (d) f : R+3 → R, f (x) = x1 + x2 + x3, at x = (2, 2, 2) √ (e) f : R3 → R, f (x) = x x x , at x = (2, 2, 2).
+ 1 2 3 (f) f : R3 → R, f (x) = x x + x x + x x , at x = (1, 1, 1).
+ 1 2 2 3 3 1 (g) f : R+3 → R, f (x) = ax1 +bx2 +cx3 for some constants a, b, c ∈ R, at x = (2, 2, 2).
229  UNIT 10 N OPTIMIZATION IN R 10.1 Introduction This unit constitutes the starting point of your investigation into optimization theory.
You will first be introduced to the notation that you will use to represent abstract optimization problems and their solutions and afterwards, address the chief question of interest that will be examined over the book.
10.2 Objectives At the end of this unit, you should be able to; (i) Define an optimization problem.
(ii) Give the two types of optimization problems.
(iii) identify a set of conditions of f and D underwhich the existence of solutions of optimiza- tion problems is guaranteed.
10.3 Main Content 10.3.1 Optimization problems in Rn Definition 10.3.1 An optimization problem in Rn, or simply an optimization problem, is one when the values of a given function f : Rn → R are to be maximized or minimized over a given set D ⊂ Rn.
The function f is called the objective function, and the set D the contraint set.
229  UNIT 10.
OPTIMIZATION IN RN Notationally, you will represent these problems by Maximizef (x) subject to x ∈ D and Minimzef (x) subject to x ∈ D respectively.
Alternatively, and more compactly, you could also write max{f (x)|x ∈ D}, and min{f (x)|x ∈ D}.
Problems of the first sort are termed maximization problems and those of the second sort are called minimization problems.
Definition 10.3.2 (Solution of an Optimization Problem) A solution to the problem max{f (x)|x ∈ D} is a point x in D such that f (x) ≥ f (y) for all y ∈ D You will say that f attains a maximum on D at x, and also refer to x as a maximizer of f on D. Similarly, a solution to the problem min{f (x)|x ∈ D} is a point z in D such that f (z) ≤ f (y) for all y ∈ D. You will say in this case that f attains a minimum on D at z, and also refer to z as a minimizer of f on D. Definition 10.3.3 (Set of Attainable Values) The set of attainable values of f on D, denoted f (D), is defined by f (D) = {w ∈ R| there is x ∈ D such that f (x) = w}.
You will also refer to f (D) as the image of D under f. Observe that f attains a maximum on D (at some x) if and only if the set of real numbers f (D) has a well defined maximum, while f attains a minimum on D (at some z) if and only if f (D) has a well-defined minimum.
(This is simply a restatement of the definitions).
The following simple examples reveal two important points: first, that in a given maximiza- tion problem, a solution may fail to exist (that is, the problem may have no solution at all), and secondly, that even if a solution does exist, it need not necessarily be unique (that is, there could exist more than one solution).
Similar statements obviously also hold for minimization problems.
230  UNIT 10.
OPTIMIZATION IN RN Example 10.3.1 Let D = R+ and f (x) = x for x ∈ D. Then, f (D) = R+ and sup f (D) = +∞, so the problem max{f (x)|x ∈ D} has no solution.
Example 10.3.2 Let D = [0, 1] and let f (x) = x(1 − x) for x ∈ D. Then, the problem of maximizing f on D has exactly one solution, namely the point x = 1/2.
Example 10.3.3 Let D = [−1, 1] and f (x) = x2 for x ∈ D. The problem of maximizing f on D now has two solutions: x = −1 and x = 1.
Thus in the sequel, you will not talk of the solution of a given optimization problem, but of a set of solutions of the problem, with the understanding that this set could, in general, be empty.
The set of all maximizers of f on D will be denoted arg max{f (x)|x ∈ D} : arg max{f (x)|x ∈ D} = {x ∈ D|f (x) ≥ f (y) for all y ∈ D}.
The set, arg min{f (x)|x ∈ D} of minimizers of f on D is defined analogously.
This section shall be closed with two elementary, but important, observations, which is stated in form of theorems for ease of future reference.
The first shows that every maximization problem may be represented as a minimzation problem, and vice versa.
The second identifies a transformation of the optimization problem under which the solution set remains unaffected.
Theorem 10.3.1 Let −f denote the function whose value at any x is −f (x).
Then x is a maxi- mum of f on D if and only if x is a minimum of −f on D and z is a minimizer of f on D if and only if z is maximum of −f on D. Proof.
The point x maximizes f over D if and only if f (x) ≥ f (y) for all y ∈ D, while x minimizes −f over D if and only if −f (x) ≤ −f (y) for all y ∈ D. Since f (x) ≥ f (y) is the same as −f (x) ≤ −f (y), the first part of the theorem is proved.
The second part of the theorem follows from the first simply by noting that −(−f ) = f. Theorem 10.3.2 Let ϕ : R → R be a strictly increasing function, that is, a function such that x > y implies ϕ(x) > ϕ(y).
Then x is a maximum of f on D if and only if x is also a maximum of the composition ϕ ◦ f on D; and z is a minimum of f on D, if and only if z is also a minimum of ϕ ◦ f on D. Remark 10.3.1 As will be evident from the proof, it suffices that ϕ be a strictly increasing function on just the set f (D), i.e., that ϕ only satisfy ϕ(z ) > ϕ(z ) for all z , z ∈ f (D) with 1 2 1 2 z > z .
1 2 Proof.
You are dealing with the maximization problem here; the minimization problem is easily deduced using Theorem 10.3.1.
Suppose first that x maximizes f over D. Pick any y ∈ D. Then f (x) ≥ f (y), and since ϕ is strictly increasing, ϕ(f (x)) ≥ ϕ(f (y)).
Since y ∈ D was arbitrary, this inequality holds for all y ∈ D, which states precisely that x is a maximum of ϕ ◦ f on D. Now suppose that x maximizes ϕ ◦ f on D, so ϕ(f (x)) ≥ ϕ(f (y)) for all y ∈ D. If x did not also maximize f on D, there would exist y∗ ∈ D such that f (y∗ ) > f (x).
Since ϕ is 231  UNIT 10.
OPTIMIZATION IN RN a 232  UNIT 10.
OPTIMIZATION IN RN strictly increasing function, it follows that ϕ(f (y∗ )) > ϕ(f (x)), so x does not maximize ϕ ◦ f over D, a contradiction, completing the proof.
10.3.2 Types of Optimization problem In general, There are two types of optimization problem, namely; 1.
Unconstrained Optimization problem and 2.
Constrained optimization problem.
Unconstrained Optimization problem.
An Optimization problem is called unconstrained if it is of the form min f (x) x∈D or min(or max) f (x) Subject to: x ∈ D where x = (x1, .
.
.
, xn) ∈ Rn, f : D ⊂ Rn → R, and D is an open set in Rn Constrained Optimization Problem An optimization problem is called constrained if it is of the form min(or max) f (x) Subject to: g (x) ≥ 0 i = 1, .
.
.
, m i h (x) = 0, i = 1, .
.
.
, l i x ∈ D where f : D ⊂ Rn → R is called the Objective function, g , .
.
.
, g , h , .
.
.
, h : D ⊂ Rn → R 1 m 1 l are the constraint functions.
Let g = (g , .
.
.
, g ) : Rm → Rm, and h = (h , .
.
.
, h ) : Rn → Rl , then you can rewrite 1 m 1 l the constrained problem as follows 233  UNIT 10.
OPTIMIZATION IN RN min(or max) f (x) Subject to: g(x) ≥ 0 h(x) = 0 x ∈ D A detail study of each of the above problems is seen in the next two units.
10.3.3 The Objectives of Optimization Theory Optimization theory has two main objectives.
1.
The first is to identify a set of conditions on f and D underwhich the existence of solutions to optimization problems is guaranteed.
2.
Second objective lies in obtaining a characterization of the set of optimal points.
Broad categories of questions of interest here include the following: (a) The identification of conditions that every solution to an optimization problem must satisfy, that is, of conditions that are necessary for an optimum point.
(b) The identification of conditions such that any point that meets these conditions is a solution, that is, of conditions that are sufficient to identify a point as being optimal.
(c) The identification of conditions that ensure only a single solution exists to a given optimization problem, that is, of condition that guarantee uniqueness of solutions.
10.4 Existence of Solutions: The Weierstrass Theorem You will begin the study of optimization with the fundamental question of existence: under what conditions on the objective function f and the constraint set D are you guaranteed that solutions will always exist in optimization problems of the form max{f (x)|x ∈ D} or min{f (x)|x ∈ D}?
Equivalently, under what conditions on f and D is it the case that the set of attainable values f (D) contains it supremum and/or infimum?.
The answer to these questions is given in this section.
You will be introduced to two main theorems that gaurantees the existence of solution of an optimization problem.
But before that, the following definitions are very important.
Definition 10.4.1 Let f : D ⊂ Rn → R and let {x } be a sequence of elements in D. {x } is n n called a minimizing sequence of f in D if lim f (x ) = inf f (x) n n→+∞ x∈D 234  UNIT 10.
OPTIMIZATION IN RN Similarly {xn} would be called a maximizing sequence of f in D if lim f (x ) = sup f (x).
n n→+∞ x∈D Proposition 10.4.1 If D is a non-empty subset of Rn, then there exists a minimizing (resp.
maximizing) sequence {x } of f in D. n 10.4.1 The Weierstrass Theorem The following result, a powerful theorem credited to the mathematician Karl Weierstrass, is the main result that answers the questions on existence.
Theorem 10.4.1 (The Weierstrass Theorem) Let D ⊂ Rn be compact (i.e., closed and bounded), and let f : D → R be a continuous function on D. Then f attains a maximum and a minimum on D, i.e., there exists points z1 and z2 on D such that f (z ) ≥ f (x) ≥ f (z ), x ∈ D 1 2 Or you can write; f (z ) = max f (x) and f (z ) = min f (x) 1 2 x∈D x∈D Proof.
The theorem is proved for minimization problem, analogous proof for the maxi- mization problem is readily deduced using Theorem 10.3.1.
To proceed, Let, {x } be a mini- n mizing sequence of f in D. Since D is bounded, by Bolzano-Weierstrass theorem, {x } has a n subsequence {xnk } which converges to some point z1 ∈ R n. Since D is closed, you have that z1 ∈ D. Using the continuity of f at z1, it follows that lim f (x ) = f (z ) (10.1) nk 1 k→+∞ On the other hand, since {f (x )} is a subsequence of {f (x )}, you have nk n lim f (x ) = inf f (x) (10.2) k→+∞ nk x∈D Using (10.1) and 10.2 and the uniqueness of limit, it follows that f (z ) = inf f (x) = min f (x) 1 x∈D x∈D So z is a global minimum of f in D. 1 It is of the utmost importance to realize that the Weierstrass Theorem only provides sufficient conditions for the existence of optima.
The theorem has nothing to say about what happens if these conditions are not met, and, indeed, in general, nothing can be said, as the following examples illustrate.
Example 10.4.1 Let D = R, and f (x) = x3 for all x ∈ R. The f is continuous but D is not compact (it is closed, but not bounded).
Since f (D) = R, f evidently attains neither a maximum nor a minimum on D. 235  UNIT 10.
OPTIMIZATION IN RN Example 10.4.2 Let D = (0, 1) and f (x) = x for all x ∈ (0, 1).
Then f is continuous, but D again noncompact (this time it is bounded, but not closed).
The set f (D) is the open interval (0, 1), so, once again, f attains neither a maximum nor a minimum on D. Example 10.4.3 Let D = [−1, 1], and let f be given by ( 0, if x = −1 or x = 1 f (x) = x, if − 1 < x < 1 Then D is compact but f fails to be continuous at just the two points -1 and 1.
In this case, f (D) is the open interval (−1, 1); consequently, f fails to attain either a maximum or a minimum on D. Example 10.4.4 Let D = R , and let f : D → R be defined by ++ ( 1, if x is rational f (x) = 0, otherwise Then D is not compact (it is neither closed nor bounded), and f is discontinuous at every single point in R (it “chatters” back and forth between the values 0 and 1).
Nonetheless, f attains a maximum (at every rational number) and a minimum (at every irrational number).
To restate the point: if the conditions of the Weierstrass Theorem are met, a maximum and a minimum are guaranteed to exist, On the other hand, if one or more of the theorem’s conditions fails, maxima and minima may or may not exist, depending on the specific structure of the problem in question.
Next is the second theorem of existence.
But before that, here is an important definition and some propostions that will help you to prove it.
Definition 10.4.2 Let f : Rn → R be a real valued function.
f is said to be coercive if lim f (x) = +∞ l/xl/→+∞ Examples (a) Let f (x, y) = x2 + y2 = x 2.
Then lim f (x) = lim x 2 = ∞ l/xl/→∞ l/xl/→∞ Thus f (x, y) is coercive (b) Let f (x, y) = x4 + x4 − 3xy.
Note that ( \ 3xy f (x, y) = (x4 + y4) 1 − .
x4 + y4 If x is large, then 3xy/(x4 + y4) is very small.
Hence lim f (x, y) = lim (x4 + y4)(1 − 0) = +∞ l/(x,y)l/→∞ l/(x,y)l/→∞ 236  UNIT 10.
OPTIMIZATION IN RN (c) Let f (x, y, z) = ex2 + ey2 + ez2 − x100 − y100 − z100 then because exponential growth is much faster than the growth of any polynomial, it follows that lim f (x, y, z) = ∞ l/(x,y,z)l/→∞ Thus f (x, y, z) is coercive.
(d) Linear functions on R2 ar never coercive.
Such functions can be expressed as follows: f (x, y) = ax + by + c where either a /= 0 or b /= 0.
To see that f (x, y) is not coercive, simply observe f (x, y) is constrantly equal to c on the line ax + by = 0.
Since this line is unbounded on this line, the function f (x, y) is not coercive.
(e) If f (x, y, z) = x4 + y4 + z4 − 3xyz − x2 − y2 − z2, then as (x, y, z) = x2 + y2 + z2 → ∞ the higher degree terms dominate and force lim f (x, y, z) = ∞.
l/(x,y,z)l/→∞ Thus f (x, y, z) is coercive.
The following example helps us avoid some misleadings.
(f) Let f (x, y) = x2 − 2xy + y2.
Then (i) for each fixed y , you have lim f (x, y) = ∞.
0 |x|→∞ (ii) for each fixed x , you have lim = ∞; 0 |y|→∞ (iii) but f (x, y) is not coercive.
Properties (i) and (ii) above are more or less clear because in each case the quadratic term dominates.
For example, in case (i), you have for a fixed y .
0 f (x, y ) = x2 − xy + y2.
0 0 0 This function of x is a parabola that opens upward.
Therefore lim f (x, y0) = ∞.
|x|→∞ To see that f (x, y) is not coercive, factor to learn f (x, y) = x2 − 2xy + y2 = (x − y)2.
Therefore if (x, y) goes to ∞ on the line y = +x, you will see that f (x, y) = (x−x)2 = 0 and hence f (x, y) = 0 on the unbounded line y = x.
Therefore, lim f (x, y) /= ∞ l/(x,y)l/→∞ so f (x, y) is not coercive.
237  UNIT 10.
OPTIMIZATION IN RN The point of this last example is very important.
For f (x) to be coercive, it is not sufficient that f (x) → ∞ as each coordinate tends to ∞.
Rather f (x) must become infinite along any path for which x becomes infinite.
The reason why coercive functions are important in optimization theory is seen in the next theorem stated shortly.
Proposition 10.4.2 Let D be a nonempty close subset of Rn.
If f is coercive and continuous on some open set containing D, then 1. the function f is bounded below (resp.
bounded above) on D. 2. any minimizing (resp.
maximizing) sequence of f in D is bounded.
Proof.
The proof is given for minimization problem.
1.
Suppose that f is not bounded below on D. Then for all n ∈ N, there exists x ∈ D such n that f (x ) < −n.
So you get a sequence {x } in D satisfying: n n f (x ) < −n, for all n ∈ N. (10.3) n This sequence must be bounded because of the coercivity of f, otherwise it has a subse- quence {xnk } such that lim xnk = +∞.
k→∞ Since f is coercive, you have lim f (xnk ) = +∞.
k→+∞ But from (10.3), it follows that kli→m∞ f (xnk ) = −∞ and this is a contradiction by the uniqueness of limit.
Therefore {x } is bounded.
So by n Bolzano-Weierstrass, there exists a subsequence {x } of {x } that converges to some nk n point x¯ ∈ D. Using the continuity of f at x¯ it follows that lim f (x ) = f (x¯).
nk k→∞ From (10.3) you get kl→im∞ f (xnk ) = −∞ Therefore, by uniqueness of the limit, it follows that f (x¯) = −∞, a contradiction, so f is bounded below on D and this ends the proof of 1.
238  UNIT 10.
OPTIMIZATION IN RN 2.
Let {xn} be a minimizing sequence of f in D, that is lim f (x ) = inf f (x).
(10.4) n n→∞ x∈D You have to show that {x } is bounded.
By contradiction assume that {x } is not n n bounded, then there exists a subsequence {x } of {x } such that nk n lim xnk = +∞.
k→∞ Since f is coercive, you have lim f (x ) = +∞.
k→∞ nk Using (10.4), you have lim f (x ) = inf f (x).
k→∞ nk x∈D and this leads to inf f (x) = +∞.
x∈D This is a contradiction because of the fact that f is bounded below on D. Theorem 10.4.2 Let D be a nonempty closed subset of Rn (not necessary bounded).
Suppose f is continuous on some open set containing D. Then f has a global minimum on D. That is there exists at least one point x¯ ∈ D such that f (x¯) = min f (x) x∈D Proof.
Let {x } be a minimizing sequence of f in D. By 10.4.2, {x } is bounded, so by n n Bolzano-Weierstrass theorem {x } has a subsequence {x } which converges to some point n nk x¯ ∈ Rn.
Since D is closed you have x¯ ∈ D. Using the continuity of f at x¯, it follows that lim f (x ) = f (x¯).
(10.5) nk k→+∞ On the other hand since {f (x )} is a subsequence of {f (x )}, you have nk n lim f (x ) = inf f (x).
(10.6) nk k→+∞ x∈D Using (10.5), (10.6) and the uniqueness of limit, it follows that f (x¯) = inf f (x) x∈D So x¯ is a global minimum of f in D. 10.5 Conclusion In this unit you studied optimization in Rn.
You looked at what a solution to an optimization problem means and consider two main theorems that guaranteed existence of solution of an optimization problem.
239  UNIT 10.
OPTIMIZATION IN RN 10.6 Summary Having gone through this unit, you now know (i) A Typical Optimization Problem is Minimize(or Maximize) f (x) Subject to: x ∈ D where f : D ⊂ R → R is called the objective function and D is called the constraint set.
(ii) Optimization problems are of two types, namely Constrained and Unconstrained Prob- lems.
It is constrained if the constraint set D is made up of a set of inequalities and/or equations (iii) If for example in the problem min( or max) f (x) subject to x ∈ D that f is continuous and D is a bounded and closed subset of Rn, the there exist a solution for the problem.
This is the Weierstrass Existence theorem theorem.
(iv) A real valued function f : Rn → R is coercive if you have lim f (x) = +∞.
l/xl/→+∞ (v) If f is continuous and coercive on a closed set D ⊂ R then there exist x¯ ∈ D such that f (x¯) ≤ f (x) for all x ∈ D. (ii) the existence theorems for solution of an optimization problem.
10.7 Tutor Marked Assignments(TMAs) Exercise 10.7.1 1.
Prove the following statement or provide a counter example.
If f is a continuous function on a bounded (but not necessarily closed) set D, then sup f (D) is finite.
2.
Give an example of an optimization problem with an infinite number of solutions.
3.
Let D = [0, 1], Describe the set f (D) in each of the following cases, and identify sup f (D) and inf f (D).
In which cases does f attain its supremum?
What about its infimum?
(a) f (x) = 1 + x for all x ∈ D (b) f (x) = 1, if x < 1/2, and f (x) = 2x otherwise.
(c) f (x) = x, if x < 1 and f (1) = 2.
240  UNIT 10.
OPTIMIZATION IN RN (d) f (0) = 1, f (1) = 0, and f (x) = 3x for x ∈ (0, 1).
4.
Let D = [0, 1].
Suppose f : D → R is increasing on D, i.e., for x, y ∈ D if x > y, then f (x) > f (y).
[Note that f is assumed to be continuous on D.] If f (D) a compact set?
Prove your answer, or provide a counterexample.
5.
Find a function f : R → R and a collection sets S ⊂ R, k = 1, 2, 3, .
.
.
such that f k n∞ attains a maximum on each S , but not on S .
k k n=1 6.
Give an example of a function f : [0, 1] → R such that f ([0, 1]) is an open set.
7.
Give an example of a set D ⊂ R and a continuous function f : D → R such that f attains its maximum, but not a minimum, on D. 8.
Let D = [0, 1], Let f : D → R be an increasing function on D, and let g : D → R be a decreasing function on D. (That is, if x, y ∈ D with x > y then f (x) > f (y) and g(x) < g(y).)
Then, f attains a minimum and a maximum on D (at 0 and 1, respectively), as does g (at 1 and 0, respectively).
Does f + g necessarily attain a maximum and minimum on D?
9.
Identify the coercive function in the following list: (a) On R3, let f (x, y, z) = x3 + y3 + z3 − xy (b) On R3, let f (x, y, z) = x4 + y4 + z2 − 3xy − z.
(c) On R3, let f (x, y, z) = x4 + y4 + z2 − 7xyz2 f (d) On R3, let (x, y, z) = x4 + y4 − 2xy2.
(e) On R3, let f (x, y, z) = ln(x2y2z2) − x − y − z.
(f) On R3, let f (x, y, z) = x2 + y2 + z2 − sin(xyz).
241  UNIT 11 UNCONSTRAINED OPTIMIZATION 11.1 Introduction In the last unit, you defined an unconstrained optimization problem as follows min(or max)f (x) x ∈ D where f : D ⊂ Rn → R is called the objective function.
In this unit, you shall be dwelling in this kind of problem in detail.
11.2 Objectives At the end of this unit, you should be able to (i) Give the definition of the Local, Global and Strict Optima of an optimization problem.
(ii) State and proof and apply the first order optimality condition for unconstrained optimiza- tion problems.
(iii) State, and prove the second order necessary and sufficient condition for an optimization problem.
And also use it to solve optimization problems.
(iv) Define Convex sets.
(v) Give the definitions of a Convex function and a Concave function.
(vi) Apply convexity to optimization problems.
241  UNIT 11.
UNCONSTRAINED OPTIMIZATION 11.3 Main Content The notions, definitions and results you will be seeing hence forth is on the minimization prob- lem.
min f (x) x ∈ D (11.1) Obvious modifications can be made to yield similar results for maximization problem.
But for the sake of simplicity, you will always limit your discussion to minimizers while the minor task of interpreting the results for maximization problems by replacing f (x) by −f (x) 11.3.1 Gradients and Hessians Let f : D → R, where D ⊂ Rn is open, f is differentiable at x¯ ∈ D if there exists a vector ∇f (x¯) (called the gradient of f at x¯) such that for each x ∈ D f (x) = f (x¯) + ∇f (x¯)t(x − x¯) + x − x¯ α(x¯, x − x¯) (11.2) and lim α(x¯, y) = 0. f is differentiable on D if f is differentiable for all x¯ ∈ D. The gradient y → 0 vector is the vector of partial derivatives: ( ∂f ∂f \t ∇f (x) = (x¯), .
.
.
, (x¯) (11.3) ∂x1 ∂xn Example 11.3.1 Let f (x) = 3x2x3 + x2x3.
Then 1 2 2 3 ( ) ∇f (x) = 6x x3, 9x2x2 + 2x x3, 3x2x2 t 1 2 1 2 2 3 1 3 The directional derivative of f at x¯ in the direction d ∈ Rn is given by f (x¯ + λd) − f (x¯) lim = ∇f (x¯)td (11.4) λ→0 λ The function f is twice differentiable at x¯ ∈ D if there exists a vector ∇f (x¯) and an n × n symmetric matrix H f (x¯) (called the Hessian of f at x¯) such that for each x ∈ D 1 f (x¯) = f (x¯) + ∇f (x¯)t(x − x¯) + (x − x¯)tH f (x¯)(x − x¯) + x − 2α(x¯, x − x¯), (11.5) 2 x¯ and lim α(x¯, y) = 0. f is twice differentiable on Dif and only if f is twice differentiable for all y→0 x¯ ∈ D. The Hessian is a matrix of second partial derivatives: 242  UNIT 11.
UNCONSTRAINED OPTIMIZATION   ∂2f ∂2f ∂2f · · ·  ∂x12 ∂x1∂x2 ∂x1∂xn     ∂2f ∂2f ∂2f  H f =  ∂x2∂x1 ∂x22 · · · ∂x2∂xn  (11.6)      .. .. · · · ..       ∂2f ∂2f ∂2f  · · · ∂xn∂x1 ∂xn∂x2 ∂xn∂xn Example 11.3.2 Continuing Example 1, you have   6x23 18x1x22 0     H f (x¯) =  18x1x22 18x21 x2 + 2x33 6x2x32    0 6x2x32 6x22 x3 11.3.2 Local, Global and Strict Optima Definition 11.3.1 Suppose that f : D ⊂ Rn → R is a real-valued function defined on a subset D of Rn.
A point x¯ in D is: (a) a global minimizer for f on D if f (x¯) ≤ f (x) for all x ∈ D; (b) a strict global minimizer for f on D if f (x¯) < f (x) for all x ∈ D such that x /= x¯; (c) a local minimizer for f on D if there is a positive number δ such that f (x¯) ≤ f (x) for all x ∈ D for which x ∈ B(x¯, δ); (d) a strict local minimizer for f if there is a positive number δ such that f (x¯) < f (x) for all x ∈ D for which x ∈ B(x¯, δ) and x /= x¯; (e) a critical point for f if f is differentiable at x¯ and ∇f (x¯) = 0.
11.3.3 Optimality Conditions For Unconstrained Problems Before stating the first order optimality condition for the unconstrained problem, the following definition and theorem is needful.
¯ Definition 11.3.2 (Descent Direction) The direction d is called a descent direction of f at x = x¯ if ¯ f (x¯ + Ed) < f (x¯) for all E > 0 and sufficiently small 243  UNIT 11.
UNCONSTRAINED OPTIMIZATION A necessary condition for local optimality is a statement of the form: “If x¯ is a local mini- mum of (11.1), then x¯ must satisfy...” Such a condition will help you to identify all candidates for local optima.
Theorem 11.3.1 Suppose that f is differentiable at x¯.
If there is a vector d such that ∇f (x¯)td < 0, then for all λ > 0 and sufficiently small, f (x¯ + λd) < f (x¯), and hence d is a descent direction of f at x¯.
Proof.
Suppose there is a vector d ∈ Rn such that ∇f (x¯)td < 0.
Since f is differentiable at x¯, you have f (x¯ + λd) = f (x¯) + λ∇f (x¯)td + λ d α(x, λd).
where α(x¯, λd) → 0 as λ → 0.
Rearranging, you have f (x¯ + λd) − f (x¯) = f (x¯)td + d α(x¯, λd¯).
∇ λ Since ∇f (x¯)td < 0 and α(x¯, λd) → 0 as λ → 0, f (x¯ +λd)− f (x¯) < 0 for all λ > 0 sufficiently small.
Thus f (x¯ + λd) < f (x¯) for all λ > 0 sufficiently small.
Corollary 11.3.1 (First Order necessary Optimality condition) Suppose f is differentiable at x¯.
If x¯ is a local minimum then ∇f (x¯) = 0 Proof.
Suppose for contradiction that ∇f (x¯) /= 0, then d = −∇f (x¯) would be a descent direction, whereby x¯ would not be a local minimum.
Hence, you must have ∇f (x¯) = 0 The above corollary is a first order neccessary optimality condition for an unconstrained problem.
The following theorem is second order necessary optimality condition.
Theorem 11.3.2 (Second Order necessary Optimality Condition) Suppose that f is twice con- tinuously differentiable at x¯ ∈ D. I f x¯ is a local minimum, then ∇f (x¯) = 0 and H f (x¯) is positive semidefinite.
Proof.
From the first order necessary condition, ∇f (x¯) = 0.
Suppose H f (x¯) is not positive semidefinite.
Then there exists d such that dtH f (x¯)d < 0 you have: f (x¯ + λd) = f (x¯) + λ∇f (x¯)td + 1 λ2dtH f (x¯)d + λ2 d 2α(x¯, λd) 2 = f (x¯) + 1 λ2dtH f (x¯)d + λ2 d 2α(x¯, λd).
2 where α(x¯, λd) → 0 as λ → 0.
Rearranging, gives you f (x¯ + λd) − f (x¯) 1 = d tH f (x¯)d + d 2α(x¯, λd).
λ2 2 Since dtH f (x¯)d < 0 and α(x¯, λd) → 0 as λ → 0, f (x¯ + λd) − f (x) < 0 for all λ > 0 sufficiently small, yielding the desired condtradition.
Example 11.3.3 Let 1 f (x¯) = x2 + x x + 2x2 − 4x − 4x − x3.
2 1 1 2 2 1 2 2 244  UNIT 11.
UNCONSTRAINED OPTIMIZATION Then   x + x − 4 ∇f (x) =  1 2  x1 + 4x2 − 4 − 3x22 and   1 1 H f (x¯) =   1 4 − 6x 2 ∇f (x) = 0 has exactly two solutions: x¯ = (4, 0) and x¯ = (3, 1).
But   1 1 H f (x¯) =   1 −2 is indefinite, therefore, the only possible candidate for a local minimum is x¯ = (4, 0).
A sufficient condition for local optimality is a statement of the form: “If x¯ satisfies..., then x¯ is a local minimum of 11.1.” Such a condition allows you to automatically declare that x¯ is indeed a local minimum.
Theorem 11.3.3 (Second Order Sufficient Conditon) Suppose that f is twice differentiable at x¯.
If ∇f (x¯) = 0 and H f (x¯) is positive definite, then x¯ is a strict local minimum.
Proof.
1 f (x) = f (x¯) + (x − x¯)tH f (x¯)(x − x¯) + x − x¯ 2 2 Suppose that x¯ is not a strict local minimum.
Then there exists a sequence {x } which x → x¯ k k x − x¯ k as k → ∞ such that x /= x¯ and f (x ) ≤ f (x¯) for all k. Define d , then k k k = xk − x¯ ( \ 1 f (xk ) = f (x¯) + xk − x¯ 2 2 dtk H f (x¯)dk + α(x¯, xk −x ¯) .
and so 12 d tk H f (x¯)dk + α(x¯, xk − x¯) = f (xxk ) −− x¯f (2x¯ )≤ 0. k Since d = 1 for every k, there exists a subsequence of {d } converging to some point d such k k that d = 1.
Assume without loss of generality that d → d, then k 0 ≥ lim 1 dt H f (x¯)d + α(x¯, x − x¯) = 1 dtH f (x¯)d, k→∞ 2 k k k 2 which is a contradiction of the positive definiteness of H f (x¯).
Remark 11.3.1 Note that • If ∇f (x¯) = 0 and H f (x¯) is negative definite, then x¯ is a local maximum.
245  UNIT 11.
UNCONSTRAINED OPTIMIZATION • If ∇f (x¯) = 0 and H f (x¯) is positive semidefinite, you cannot be sure if x¯ is a local minimum.
Example 11.3.4 Continuing Example 11.3.3, by computing you have   1 1 H f (x¯) =   1 4 is positive definite.
To see this, note that for any d = (d , d ), you have 1 2 dtH f (x¯)d = d2 + 2d d + 4d2 = (d + d )2 + 3d2 > 0 for all d /= 0 1 1 2 2 1 2 2 Therefore, x¯ satifies the sufficient conditions to be a local minimum, and so x¯ is a local mini- mum.
Example 11.3.5 Let f (x) = x3 + x2.
1 2 Then   3x2 1 ∇f (x) =   2x 2 and   6x 0 1 H f (x) =   0 2 At x¯ = (0, 0), you have ∇f (x¯) = 0 and   0 0 H f (x¯) =   0 2 is positive semi-definite, but x¯ is not a local minimum, since f (−E, 0) = −E3 < 0 = f (0, 0) = f (x) for all E > 0.
Example 11.3.6 Let f (x) = x4 + x2.
1 2 Then   4x3 1 ∇f (x) =   2x2 2 and   12x2 0 1 H f (x) =   0 2 246  UNIT 11.
UNCONSTRAINED OPTIMIZATION At x¯ = (0, 0), you have ∇f (x) = 0 and   0 0 H f (x¯) =   0 2 is positive semidefinite.
Futhermore, x¯ is a local minimum, since for all x you have f (x) ≥ 0 = f (0, 0) = f (x¯).
FURTHER EXAMPLES The following examples applies what to problems on global minimization whose results are stated in the following theorem.
Theorem 11.3.4 Suppose that x¯ is a critical point of f (i.e., ∇f (x) = 0) is a critical point of a function f with continuous first and second partial derivatives on Rn and that H f (x) is the Hessian matrix of f. Then x¯ is: (a) global minimizer for f if H f (x) is positive semidefinite on Rn; (b) a strict global minimizer of f if H f (x) is positive definite on Rn; (c) a global maximizer for f if H f (x) is negative semidefinite on Rn; (d) a strict global maximizer for f if H f (x) is negative definite on Rn.
Here are four examples that summarizes the above result you now know.
Example 11.3.7 (a) Minimize the function f : R3 → R defined by f (x) = x2 + x2 + x2 − x x − x x − x x , for all x = (x , x , x ) ∈ R3 1 2 3 1 2 2 3 1 3 1 2 3 ☞ Solution.
The critical points of f are the solutions of the system     2x − x − x 0 1 2 3         ∇f (x) =  −x1 + 2x2 + x3  =  0      −x + x + 2x 0 1 2 3 The one and only solution to the system is x = 0, x = 0, x = 0 The Hessian of f (x) is 1 2 3 a constant marix   2 −1 −1     H f (x) =  −1 2 1      −1 1 2 247  UNIT 11.
UNCONSTRAINED OPTIMIZATION Note that ∆ = 2, ∆ = 3, ∆ = 4 so H f (x) is positive definite everywhere on every- 1 2 3 where on R3.
It follows for Theorem 11.3.4 that the critical point (0, 0, 0) is a strict global minimizer for f. Since f is defined and has continuous first partial derivatives everywhere on R3 and since (0, 0, 0) is the only critical point of f, it follows for Corollary 11.3.1 that f has no other minimizers or maximizers.
✍ (b) Find the global minimizer of f (x, y, z) = ex−y + ey−x + ex2 + z2.
☞ Solution.
To this end, compute   ex−y − ey−x + 2xe2x     ∇f (x, y, z) =  −ex−y + ey−x    2z and   ex−y + ey−x + 4x2ex2 + 2ex2 −ex−y− ey−x 0     H f (x, y, z) =  −ex−y − ey−x ex−y + ey−x 0    0 0 2 Clearly, ∆ > 0 for all x, y, z because all the terms of it are positive.
Also 1 ∆2 = (ex−y + ey−x)2 + (ex−y + ey−x)(4x2ex2 + 2ex 2 ) − (ex−y + ey−x)2 = (ex−y + ey−x)(4x2ex2 + 2ex2 ) > 0. because both factors are always positive.
Finally, ∆ = 2∆ > 0.
Hence H f (x, y, z) is 3 2 positive definite at all points.
Therefore by Theorem 11.3.4 f is strictly globally mini- mized by any critical point (x¯, y¯, z¯).
To find (x¯, y¯, z¯), solve   ex−y − ey−x + 2xe2x     0 = ∇f (x¯, y¯, z¯) =  −ex−y + ey−x    2z This leads to z¯ = 0, ex¯−y¯ = ey¯−x¯, hence 2x¯ex¯2 = 0.
Accordingly, x¯ − y¯ = y¯ x¯; that is, − x¯ = y¯ and x¯ = 0.
Therefore (x¯, y¯, z¯) = (0, 0, 0) is the strict global minimizer of f. ✍ (c) Find the global minimizers of f (x, y) = ex−y + ey−x 248  UNIT 11.
UNCONSTRAINED OPTIMIZATION ☞ Solution.
To this end, compute   ex−y − ey−x ∇f (x, y) =   −ex−y + ey−x and   ex−y + ey−x −ex−y − ey−x H f (x, y) =   −ex−y − ey−x ex−y + ey−x Since ex−y + ey−x > 0 for all x, y and det H f (x, y) = 0, then, by the Hessian H f (x, y) is positive semidefinite for all x, y.
Therefore, by 11.3.4, f (x, y) is minimized at any critical point (x¯, y¯) of f (x, y).
To find (x¯, y¯), solve   ex¯−y¯ − ey¯−x¯ 0 = ∇f (x¯, y¯) =   −ex¯−y¯ + ey¯−x¯ This gives ex¯−y¯ = ey¯−x¯ or x¯ − y¯ = y¯ − x¯; that is, 2x¯ = 2y¯.
This shows that all points of the line y = x are global minimizers of f (x, y).
✍ (d) Find the global minimizers of f (x, y) = ex−y + ex+y ☞ Solution.
In this case,   ex−y + ex+y ∇f (x, y) =   −ex−y + ex+y   ex−y + ex+y −ex−y + ex+y H f (x, y) =   .
−ex−y + ex+y ex−y + ex+y Since ex−y + ex+y > 0 for all x, y and det H f (x, y) > 0, then H f (x, y) is positive definite for all x, y.
Therefore, by Theorem 11.3.4, f (x, y) is minimized at any critical point (x¯, y¯).
To find (x¯, y¯), write   ex¯−y¯ + ex¯+y¯ 0 = ∇f (x¯, y¯) =   ex¯−y¯ + ex¯+y¯ 249  UNIT 11.
UNCONSTRAINED OPTIMIZATION Thus ex¯−y¯ + ex¯+y¯ = 0 and −ex¯−y¯ + ex¯+y¯ = 0 But ex¯−y¯ > 0 and ex¯+y¯ > 0 for all x¯, y¯.
Therefore the equality ex¯−y¯ + ex¯+y¯ = 0 is im- possible.
Thus f (x, y) has no critical points and hence f (x, y) has no global minimizers.
✍ 11.3.4 Coercive functions and Global Minimizers You could remember that in the preceeding unit, you said that a function f : Rn → R is coercive if lim f (x) = +∞ l/xl/→+∞ and you also stated a very important result on existence of global minimizers for coercive func- tions in Theorem 10.4.2 which says that if D is a closed set and f : D ⊂ Rn → R is continuous and coercive on some open set containing D, then there exists a global minimizer of f in D. In addition to this theorem, is that if the first partial derivatives of f exist on all of Rn, then these global minimizers can be found among the critical points of f. Here is an example to illustrate this notion.
Example 11.3.8 Minimize f (x, y) = x4 − 4xy + y4 on R2.
☞ Solution.
To this end, compute   4x3 − 4y ∇f (x, y) =   −4x + 4y3 and   12x2 −4 H f (x, y) =   −4 12y2 Note that   ( \ 3 −4 1 1 H f , =   2 2 −4 3 ( ) which is certainly not positive definite since det H 1 , 1 = 9 − 16 < 0.
Therefore the tests 2 2 from the last section are not applicable.
But all is not lost because f is coercive!
To see that f is coercive, note that ( \ 4xy f (x, y) = x4 + y4 1 − x4 + y4 250  UNIT 11.
UNCONSTRAINED OPTIMIZATION As (x, y) = x2 + y2 → +∞, the term 4xy/(x4 + y4) → 0.
Hence lim f (x, y) = lim (x4 + y4)(1 − 0) = +∞.
l/(x,y)l/→∞ l/(x,y)l/→∞ Thus f is coercive.
According to Theorem 10.4.2 f has a global minimizer at one of the critical points.
Setting ∇f (x, y) = 0, you get y = x3, and x = y3.
Hence x = x9 and x(x8 − 1) = 0.
This produces three critical points (0, 0), (1, 1), (−1, −1) Now f (0, 0) = 0, f (1, 1) = −2 f (−1, −1) = − 2 Therefore ( − 1, − 1) and (1, 1) are both global minimizers of f. ✍ 11.4 Convex Sets and Convex Functions It is necessary at this point that you study convexity briefly because of some of its important considerations in optimization theory.
Which include First, Convex functions occur frequently and naturally in many optimization problems that arise in statistical, economical, or industrial applications.
Second, convexity often make it unnecessary to test the Hessians of functions for positive definiteness, a test which can be difficult in practice as you have seen in the preceeding section.
You will be introduce to a very basic concept of Convexity and then state some important result which will help you minimize a function.
11.4.1 Convex Sets Definition 11.4.1 A set C in Rn is convex if for every x, y ∈ C, the line segment joining x and y remains inside C. The line segment [x, y] joining x and y is defined by [x, y] = {λx + (1 − λ)y : 0 ≤ λ ≤ 1}.
Therefore, a subset C in Rn is convex if and only if for every x and y in C and every λ with 0 ≤ λ ≤ 1, the vector λx + (1 − λ)y is also in C. Examples of Convex Sets 251  UNIT 11.
UNCONSTRAINED OPTIMIZATION (a) Let x and v be vectors in Rn.
The line L through x in the direction of v L = {x + λv, λ ∈ R} is convex set in Rn.
252  UNIT 11.
UNCONSTRAINED OPTIMIZATION (b) Any linear subspace M of Rn is a convex set since linear subspaces are closed under addition and scalar multiplication.
(c) If x¯ ∈ Rn and α ∈ R, then the closed half-spaces F + = {y ∈ Rn : x¯ · y ≥ α}F − = {y ∈ Rn : x¯ · y ≤ α} determined by x¯ and α are all convex sets.
(d) If x¯ ∈ Rn and r > 0 then the ball centered at x¯ with radius r Bt(x, r) = {x ∈ Rn : x − x¯ ≤ r} is a convex set in Rn.
Theorem 11.4.1 Let C be a convex subset in Rn.
Let x1, .
.
.
, xm be points in C. If λ1, .
.
.
, λm are non-negative numbers whose sum is 1 then the conves combination λx1 + · · · + λmxm is also in C. Proof.
Assume that the nonempty set C is convex, you have to show that C contains all its convex combinations.
You can proceed by induction as follows.
Define the property P as n follows; n n Pn : λixi ∈ C for all x1, ..., xn ∈ C, λi ≥ λi = 1 i=1 0, i=1 1.
The property obviously hold for n = 1, i.e., (P ) is fulfilled.
1 2.
Assume that properties (P ), ..., (P ) holds.
Let x , ..., x , x ∈ C, λ ≥, λ ≥ 0, ..., λ ≥ 1 n 1 n n+1 1 2 n 0, λn+1 ≥ 0with n+1 λ = 1 i i=1 Of course, if λ = 1, then n+1 n+1 λ x = x ∈ C, i i n+1 i=1 because λ1 = · · · = λn = 0 in this case.
And so n+1 λ x ∈ C. i i i=1 253  UNIT 11.
UNCONSTRAINED OPTIMIZATION Assume that λn+1 /= 1.
This allows you to write n+1 n λ x = λ x + λ x i i i i n+1 n+1 i=1 i=1 (11.7) \ n λ i = (1 − λn+1) i=1 1 − λn +1 xi + λn+1xn+1.
You have n λ 1 n 1 n +1 i = λi = (1 − λn +1 ) = 1, since λi = 1 i=1 1 − λn+1 1 − λn+1 i=1 1 − λn+1 i=1 and λ i ≥0 and x1, ..., xn ∈ C, 1 − λn hence by induction assumption, n λ xt := i x ∈ C i 1 − λ i=1 n+1 Since yt := xn+1 ∈ C by assumption you get that (1 − λ )xt + λ yt ∈ C (11.8) n+1 n+1 because λ ∈ [0, 1].
Combining (11.7) and (11.8) you can conclude that n+1 n+1 λ x ∈ C i i i=1 This completes the proof.
The preceeding argument demonstrates that if C contains any convex combination of two of its points, then it must also contain any convex combination of three of its points.
11.4.2 Convex Functions Definition 11.4.2 Let C be a convex nonempty subset of Rn and f a real-valued function from C to R. Then (a) the function f is a convex function if f (λx + (1 − λ)y) ≤ λf (x) + (1 − λ)f (y) for all x, y ∈ C, and all λ with 0 ≤ λ ≤ 1.
254  UNIT 11.
UNCONSTRAINED OPTIMIZATION (b) the function f is a strictly convex function if f (λx + (1 − λ)y) ≤ λf (x) + (1 − λ)f (y) for all x, y ∈ C with x /= y and all λ with 0 < λ < 1.
(c) the function f is concave function if f (λx + (1 − λ)y) ≥ λf (x) + (1 − λ)f (y) for all x, y ∈ C and for all λ with 0 ≤ λ ≤ 1.
(d) the function f is a strictly concave function if f (λx + (1 − λ)y) ≥ λf (x) + (1 − λ)f (y) for all x, y ∈ C with x /= y and all λ with 0 < λ < 1 Remark 11.4.1 Note that f is convex (resp.
strictly convex) on a convex set C if and only if −f is a concave (resp.
strictly concave) on C. Because of this close connection, all results are formulated in terms of convex functions only.
Corresponding results for concave functions will be clear.
Example 11.4.1 1.
Any linear function of n variables is both convex and concave on Rn.
2.
The function f (x) = (a · x)2 where a is a fixed vector in Rn is convex on Rn.
Theorem 11.4.2 Suppose that f is a convex function defined on a convex subset C of Rn.
If λ1, .
.
.
, λm are non-negative numbers with sum 1 and if x1, .
.
.
, xm are points of C, then \ m m f λk xk ≤ λk f (xk ) (11.9) k=1 k=1 If f is strictly convex on C and if all the λk ’s are positive then equality holds in (11.9) if and only if all the x ’s are equal.
k 11.4.3 Convexity and Optimization The results proved in this section link convexity to optimization.
Theorem 11.4.3 Suppose C is a convex subset of Rn, f : C → R is a convex function and x¯ is a local minimum of f. Then x¯ is also a global minimum of f in C. In addition, if f is a strictly convex function, then x¯ is a unique global minimum of f in C. 255  UNIT 11.
UNCONSTRAINED OPTIMIZATION Proof.
Suppose that x¯ is a local minimizer of f in C. Then there exists a positive number r such that f (x¯) ≤ f (x), for all x ∈ C ∩ B(x¯, r) Given x ∈ C, you have to show that f (x¯) ≤ f (x).
To this end, select λ, with 0 < λ < 1 and so small that x¯ + λ(x − x¯) = λx + (1 − λ)x¯ ∈ C ∩ B(x¯, Then r) f (x¯) ≤ f (x¯ + λ(x − x¯)) = f (λx + (1 − λ)x¯) ≤ λf (x) + (1 − λ)f (x¯) because f is convex.
Now subtract f (x¯) from both sides of the preceeding inequality and divide the result by λ to obtain 0 ≤ f (x) − f (x¯).
This establishes that x¯ is a global minimum.
Now suppose f is strictly convex.
Let x and x be two different minimizers of f and let λ 1 2 with 0 < λ < 1.
Because of the strict convexity of f and the fact that f (x ) = f (x ) = min f (x) 1 2 x∈C you have f (x ) ≤ f (λx + (1 − λ)x ) < λf (x ) + (1 − λ)f (x ) = f (x ) 1 1 2 1 2 1 which is a contradiction, therefore, x = x .
1 2 Remark 11.4.2 • If f is a concave function, then a local maximum is a global maximum.
• If f is a strictly concave function, then a local maximum is a unique global maximum.
Theorem 11.4.4 (Gradient Inequality) Suppose that f has continuous first partial derivatives on some open set containing the convex set C. Then 1.
The function f is convex if and only if f (y) ≥ f (x) + ∇f (x)t(y − x) for all x, y ∈ C (11.10) 2.
The function f is strictly convex if and only if f (y) > f (x) + ∇f (x)t(y − x) for all x, y ∈ C (11.11) Proof.
The proof of no.
1 is given here.
Suppose that f is convex on C. Let x, y ∈ C and λ with 0 < λ < 1.
Then f (x + λ(y − x)) = f (λy + (1 − λ)x) ≤ λf (y) + (1 − λ)f (x) so that f (x + λ(y − x)) − f (x) ≤ f (y) − f (x).
λ If you let λ → 0, you obtain 256  UNIT 11.
UNCONSTRAINED OPTIMIZATION ∇f (x) · (y − x) ≤ f (y) − f (x) 257  UNIT 11.
UNCONSTRAINED OPTIMIZATION Therefore f (y) ≥ f (x) + ∇f (x)t(y − x) for all x, y ∈ C. Conversely, suppose that inequality (11.10) holds for all x, y ∈ C. Let w and z be any two points in C. Let λ ∈ [0, 1], and set x = λw + (1 − λ)z.
Then f (w) ≥ f (x) + ∇f (x)t(w − x) and f (z) ≥ f (x) + ∇f (x)t(z − x) Taking a convex combination of the above inequalities, you obtain λf (w) + (1 − λ)f (z) ≥ f (x) + ∇f (x)t(λ(w − x) + (1 − λ)(z − x)) = f (x) + ∇f (x)t0 = f (λw + (1 − λ)z), which shows that f is convex.
The following striking result is an immediate consequence of Theorem 11.4.4.
It is the most important and useful result in this chapter.
Corollary 11.4.1 If f is a convex function with continuous first partial derivatives on some open set containing the convex set C, then any critical point of f in C is a global minimizer of f. Proof.
Suppose that x¯ ∈ C is a critical point of f. Let x ∈ C. Then ∇f (x¯) = 0 and (11.10) imply that f (x¯) = f (x¯) + ∇f (x¯)t(x − x¯) ≤ f (x).
Consequently, x¯ is a global minimizer of f on C. Although the definitions of convex and strictly convex functions and the gradient inequal- ities provide useful tools for deriving important information concerning their properties, they are not very useful for recognizing convex and strictly convex functions in concrete examples.
For instance, the function f (x) = x2 is certainly convex (even strictly convex) function on Rn, yet it is cumbersome to verify this fact by using definition or the gradient inequality of con- vex function.
The next two theorems will provide you with an effective means for recognizing convex functions in specific examples.
Theorem 11.4.5 Suppose that f has continuous second partial derivatives on some open con- vex set C in Rn.
Let H f (x) be the Hessian matrix of f. then f is convex on C if and only if H f (x) is positive semidefinite for all x ∈ C. Proof.
Suppose f is convex.
Let x¯ ∈ C and d be any direction.
Then for λ > 0 sufficiently small, x¯ + λd ∈ C. You have: 1 f (x¯ + λd) = f (x¯) + ∇f (x¯)t(λd) + (λd)tH f (x)(λd) + λd 2α(x¯, λd), 2 258  UNIT 11.
UNCONSTRAINED OPTIMIZATION where α(x¯, y) → 0 as y → 0.
Using the gradient inequality, you obtain ( \ 1 λ2 dtH f (x¯)d + d 2α(x¯, λd) ≥ 0.
2 Dividing by λ2 > 0 and letting λ → 0, you obtain dtH f (x¯)d ≥ 0, i.e., H f (x¯) is positive semidefinite.
This completes the proof of this direction.
Conversely, suppose that H f (z) is postive semidefinite for all z ∈ C. Let x, y ∈ C be arbitrary.
Invoking the second-order version of Taylor’s theorem, you have: 1 f (y) = f (x) + ∇f (x)t(y − x) + (y − x)tH f (z)(y − x) 2 for some z which is a convex combination of x and y (and hence z ∈ C).
Since H f (z) is positive semidefinite, this means that f (y) ≥ f (x) + ∇f (x)t(y − x).
Therefore the gradient inequality holds, and hence f is convex.
The following example illustrates how Theorem 11.4.5 can be applied to test convexity.
Example 11.4.2 Consider the function f defined on R3 by f (x , x , x ) = 2x2 + x2 + x2 + 2x x .
1 2 3 1 2 3 2 3 The Hessian of f is   4 0 0 H f (x) =  0 2 2  .
0 2 2 The principal minors of H f (x) are ∆ = 4, ∆ = 8, ∆ = 0, Which implies that H f (x) 1 2 3 is positive semidefinite, and so f is convex by Theorem 11.4.5.
Since H f (x) is not positive definite, it is not possible to conclude from Theorem 11.4.5 that f is strictly convex on R3.
As a matter of fact, since f (x , x , x ) = 2x2 + (x + x )2, 1 2 3 1 2 3 you see that f (x) = 0 for all x on the line where x = 0 and x = −x , so f is not strictly 1 3 2 convex.
The discussion above shows that many of the results of the preceeding section, are subsumed under the general heading of convex functions.
But you must note that verifying that the Hessian is postive semidefinite is sometimes difficult.
For instance, the function f (x, y, z) = ex2 +y+z − ln(x + y) + 3z2 is convex on R3 but its Hessian is a mess.
Fortunately, there are ways other then checking the Hessian to show that a function is convex.
The next group of results points in this direction.
The following theorem shows that convex functions can be combined in a variety of ways to produce new convex functions.
259  UNIT 11.
UNCONSTRAINED OPTIMIZATION Theorem 11.4.6 (a) If f , .
.
.
, f are convex functions on a convex set C in Rn, then 1 m f (x) = f (x) + · · · + f (x) 1 m is convex.
Moreover, if at least one f (x) is strictly convex on C, then the sum f is strictly i convex.
(b) If f is convex (resp.
strictly convex) on a convex set C in Rn and if α is a positive number, then αf is convex (resp.
strictly convex) on C. (c) If f is convex (resp.
strictly convex) function defined on a convex set C in Rn, and if ϕ is an increasing (resp.
strictly increasing) convex function defined on the range of f in R, then the composite function ϕ ◦ f is convex (resp.
strictly convex).
Proof.
(a) To show that any finite sum of convex function on C is convex on C, it suffices to show that the sum (f + f ) of two convex functions f and f on C is again convex on C. If, 1 2 1 2 y, z belong to C and 0 ≤ λ ≤ 1, then (f + f )(λy + (1 − λ)z) = f (λy + (1 − λ)z) + f (λy + (1 − λ)z) 1 2 1 2 ≤ λf (y) + (1 − λ)f (z) + λf (y) + (1 − λ)f (z) 1 1 2 2 = λ(f + f )(y) + (1 − λ)(f + f )(z).
1 2 1 2 Hence, (f + f ) is convex on C. Moreover, it is clear from this computation that if either 1 2 f or f is strictly convex, then (f + f ) is strictly convex because strict convexity of 1 2 1 2 either function introduces a strict inequality at the right place.
(b) This result follows by an argument similar to that used in (a).
(c) If y, z belong to C and 0 ≤ λ ≤ 1, then f (λy + (1 − λ)z) ≤ λf (y) + (1 − λ)f (z) since f is convex on C. Consequently, since ϕ is an increasing, convex function on the range of f, it follows that ϕ(f (λy + (1 − λ)z)) ≤ ϕ(λf (y) + (1 − λ)f (z)) ≤ λϕ(f (y)) + (1 − λ)ϕ(f (z)).
Thus, the composite function ϕ ◦ f is convex on C. If f is strictly convex and ϕ is strictly increasing, the first inequality in the preceding computation is strict for y /= z and 0 < λ < 1, so ϕ ◦ f is strictly convex on C. 260  UNIT 11.
UNCONSTRAINED OPTIMIZATION Examples (a) The function f defined on R3 by f (x1, x2, x3) = ex12 +x22 +x32 is strictly convex.
At first glance, it might semm that the most direct path to verify that f is strictly convex on R3 would be to show that the Hessian H f (x) of f is positive definite on R3.
However, the Hessian turns out to be   (2 + 4x2)ex2 2 4x x e 1 2 3 4x x e 1 2 3 1 +x2 +x23 x2 +x2 +x2 x2 +x2 +x2 1 1 2 1 3     H f (x) =  4x1x2ex12 + x22 + x32 (2 + 4x22) ex12 + x22 +x32 4x 2x 3e x12 + x22 + x32    4x1x3ex12 + x22 + x32 4x2x3ex12 + x22 + x32 (2 + 4x23) ex12 + x22 + x32 Obviously, proving that the Hessian is positive definite for all x ∈ Rn will involve quite tedious algebra.
No matter there is much simpler way to handle the problem.
First note that h(x , x , x ) = x2 + x2 + x2 1 2 3 1 2 3 is strictly convex since its Hessian   2 0 0     H h(x , x , x ) =  0 2 0  1 2 3     0 0 2 is obviously positive definite.
Also, ϕ(t) = et is strictly increasing (since ϕt(t) = et > 0 for all t ∈ R) and strictly convex (since ϕtt(t) = et > 0 for all t ∈ R).
Therefore by Theorem 11.4.6(c), f = ϕ ◦ h is strictly convex on R3.
(b) Suppose a(1), .
.
.
, a(m) are fixed vectors in Rn and that c , .
.
.
, c are positive real num- 1 m bers.
Then the function f defined on Rn by m f (x) = ciea( i) ·x i=1 is convex.
To prove this statement, first observe that the functions g on Rn defined by i g (x) = a(i) · x, i = 1, .
.
.
, m i are linear and therefore convex on Rn.
Since h(t) = et is increasing and convex on R, it follows from theorem 11.4.6(c) that the functions h(gi(x)) = ea( i) ·x, i = 1, .
.
.
, m 261  UNIT 11.
UNCONSTRAINED OPTIMIZATION are all convex on Rn.
Since c , .
.
.
, c are positive real numbers, you can apply Theorem 1 m 11.4.6(a) and (b) to conclude that m f (x) = ciea( i) ·x i=1 is convex on Rn.
(c) The function f defined on R2 by f (x , x ) = x2 − 4x x + 5x2 − ln x x 1 2 1 1 2 2 1 2 is strictly convex on C = {x ∈ R2 : x > 0, x > 0}.
1 2 In fact f (x) = g(x) + h(x) where g(x , x ) = x2 − 4x x + 5x2, h(x , x ) = − ln(x x ) 1 2 1 1 2 2 1 2 1 2 so Theorem 11.4.6(a) will imply that f is strictly convex once you are able to show that g and h are convex and at least one of these functions is strictly convex on C. But the Hessian of g is   2 −4   −4 10 principal minors of this matrix are ∆ = 2, ∆ = 4, g is strictly convex on R2.
Conse- 1 2 quently, all that you need to do now is to show that h is convex on C. But h(x1, x2) = − ln x1 − ln x2 and the function ϕ(t) = − ln t (t > 0) is strictly convex since ϕtt(t) = 1/t2, so h is convex on C by Theorem 11.4.6(c).
11.5 Conclusion In this section, you looked at Unconstrained optimization problem.
You learnt the first order necessary optimality condition and the second order necessary and sufficient optimality con- dition.
You were also introduced to the notion of convex sets and convex functions.
And you proved some results in optimization problems defined on a convex set.
11.6 Summary Having gone through this unit, you now know the following (i) x¯ is a local minimizer of f in D if there exists r > 0 such that f (x¯) ≤ f (x) for all x ∈ D ∩ B(x¯, r) 262  UNIT 11.
UNCONSTRAINED OPTIMIZATION (ii) x¯ is a global minimizer of f in D if f (x¯) ≤ f (x) for all x ∈ D Reversing the inequalities in (i) and (ii) gives you the the definitions of local maximizer and global maximizer respectively of f. You also have the definition of strict optimas’ if the inequalities are made to be strict.
(iii) If x¯ is a local minimizer, then x¯ is a critical point, (i.e., ∇f (x¯) = 0).
This is the first order necessary optimality condition.
(iv) x¯ is a local minimizer if and only if the hessian of f at x¯ i.e., H f (x¯) is semipositive definite.
This the second order necessary and sufficient optimality condition.
(v) If f is a convex function, then every local minimizer is also a global minimizer.
In addition if f is a strictly convex function, then x¯ is a unique global minimizer 11.7 Tutor Marked Assignments (TMAs) Exercise 11.7.1 1.
Find the local and global minimizers and maximizers of the following functions (a) f (x) = x2 + 2x.
(b) f (x) = x2e−x2 .
(c) f (x) = x4 + 4x3 + 6x2 + 4x.
(d) f (x) = x + sin x.
2.
Classify the following matrices according to whether they are positive or negative definite or semidefinite or indefinite.
  1 0 0 (a)  0 3 0  0 0 5   −1 0 0 (b)  0 −3 0  0 0 −2   7 0 0 (c)  0 −8 0  0 0 5   3 1 2 (d)  1 5 3  2 3 7 263  UNIT 11.
UNCONSTRAINED OPTIMIZATION   −4 0 1 (e)  0 −3 2  1 2 −5   2 −4 0 (f)  −4 8 0  0 0 −3 3.
Write the quadratic form Q (x) associated with each of the following matrices A : A ( \ −1 2 (a) A = 2 3 ( \ 2 −3 (b) A = −3 0   1 −1 0 (c)  −1 −2 0  0 2 3   −3 1 2 (d)  1 2 −1  2 −1 4 4.
Write the following quadratic forms in the form x · Ax where A is an appropriate sym- metric matrix.
(a) 3x2 − x x + 2x2.
1 1 2 2 (b) x21 + 2x22 − 3x32 + 2x1x2 − 4x1x3 + 6x2x3.
(c) 2x12 − 4x32 + x1x2 − x2x3.
5.
Suppose f is defined on R3 by f (x) = c x2 + c x2 + c x2 + c x x + c x x + c x x .
1 1 2 2 3 3 4 1 2 5 1 3 6 2 3 Show that f is the quadratic form associated with 1 H f. Discuss generalizations to higher 2 dimensions.
6.
Show that the principal minors of the matrix ( \ 1 −8 A = 1 1 are positive, but that there are x /= 0 in R2 such that xT Ax < 0.
What conclusion can you draw from this?
7.
Use the principal minor criteria to determine (if possible) the nature of the critical points of the following functions: (a) f (x , x ) = x3 + x3 − 3x − 12x + 20.
1 2 1 2 1 2 (b) f (x , x , x ) = 3x2 + 2x2 + 2x2 + 2x x + 2x x + 2x x .
1 2 3 1 2 3 1 2 2 3 1 3 264  UNIT 11.
UNCONSTRAINED OPTIMIZATION (c) f (x , x , x ) = x2 + x2 + x2 − 4x x .
1 2 3 1 2 3 1 2 (d) f (x1, x2) = x41 + x42 − x12 − x22 + 1.
(e) f (x1, x2) = 12x13 − 36x1x2 − 2x2 3 + 9x22 − 72x1 + 60x2 + 5.
8.
Show that the functions f (x , x ) = x2 + x3, 1 2 1 2 and g(x , x ) = x2 + x4.
1 2 1 2 both have a critical point at (0, 0), both have positive semidefinite Hessians at (0, 0), but (0, 0) is a local minimizer for g(x , x ) but not for f (x , x ).
1 2 1 2 9.
Find the global maximizers and minimizers, if they exist, for the following functions: (a) f (x , x ) = x2 − 4x + 2x2 + 7.
1 2 1 1 2 (b) f (x1, x2) = e−(x21 +x22 ).
(c) f (x , x ) = x2 − 2x x + 1 x3 − 4x .
1 2 1 1 2 3 2 2 (d) f (x , x , x ) = (2x − x )2 + (x − x )2 + (x − 1)2.
1 2 3 1 2 2 3 3 (e) f (x , x ) = x4 + 16x x + x8.
1 2 1 1 2 2 10.
Show that although (0, 0) is a critical point of f (x , x ) = x5 − x x6, it is neither a local 1 2 1 1 2 maximizer nor a local minimizer of f (x , x ).
1 2 11.
Define f (x, y) on R2 by f (x, y) = x4 + y4 − 32y2 (a) Find a point in R2 at which H f is indefinite.
(b) Show that f (x, y) is coercive.
(c) Minimize f (x, y) on R2.
12.
Define f (x, y, z) on R3 by f (x, y, z) = ex + ey + ez + 2e−x−y−z (a) Show that H f (x, y, z) is positive definite at all points of R3.
(b) Show that (ln 2/4, ln 2/4, ln 2/4) is the strict global minimizer of f (x, y, z) on R3.
13.
(a) Show that no matter what values of a is chosen, the function f (x , x ) = x3 − 3ax x + x3 1 2 1 1 2 2 has no global maximizers.
(b) Determine the nature of the critical points of this function for all values of a.
265  UNIT 12 CONSTRAINED OPTIMIZATION 12.1 Introduction It is not often that optimization problems have unconstrained solutions.
Typically, some or all of the constraints will matter.
Through out this unit, you will be concerned with examining necessary conditions for optima in such a context.
12.2 Objectives At the end of this unit, you should be able to (i) Give the definition of a constrained optimization problem.
(ii) Solve Equality constained problems.
(iii) Apply the Lagrange’s theorem.
(iv) State and apply the first order necessary conditions.
(v) State and apply the second order necessary and sufficient conditions.
(vi) Solve Inequality constrained problems 12.3 Constrained Optimization Problem Just as defined in unit 10, An optimization problem is called constrained if it is of the form 264  UNIT 12.
CONSTRAINED OPTIMIZATION min(or max) f (x) Subject to: h (x) = 0, i = 1, .
.
.
, m gi(x) ≥ 0, i = 1, .
.
.
, l (12.1) i x ∈ U.
Where f : U → R, U is an open set of Rn is called the Objective function, g1, .
.
.
, gk , h1, .
.
.
, hl : U ⊂ Rn → are the constraint functions.
If you define g = (g , .
.
.
, g ) : Rn → Rk and h = (h , .
.
.
, h ) : Rn → Rl , then you can 1 k 1 l rewrite the constrained problem as follows min(or max) f (x) Subject to: h(x) = 0 (12.2) g(x) ≥ 0 x ∈ U.
If you define in the sequel that the constraint set D as D = U ∩ {x ∈ Rn : h(x) = 0, g(x) ≥ 0}, (12.3) Then, Problem (12.2) reduces to min(or) max) f (x) (12.4) Subject to: x ∈ D Many problems in economic theory can be written in this form.
For example you can readily see that if f, g and h are linear functions, then the problem (12.2) becomes a linear programming problem, to which, if solution exist, you can use the simplex method, discussed in previous units, to solve.
Nonnegativity constraints are easily handled: if a problem requires that x ∈ Rn , + this may be accomplished by defining the function hj : Rn → R g (x) = x , j = 1, .
.
.
, n, j j and using the n inequality constraints g (x) ≥ 0 j More generally, requirements of the form α(x) ≥ a, β(x) ≤ b, or ψ(x) = c (where a, b and c are constants), can all be expressed in the desired form by simply writing them as α(x) − a ≥ 0, b − β(x) ≥ 0, or c − ψ(x) = 0.
Your study in this unit, is divided into two parts namely; 1.
Equality-Constrained optimization problems.
2.
Inequality-constrained optimization problems.
You will now take it one after the other and study them.
265  UNIT 12.
CONSTRAINED OPTIMIZATION 12.4 Equality-Constraint Coming back to the study of minimization with constraints.
More specifically, you will tackle, in this section, the following problem Minimize f (x) subject to h (x) = 0 1 h2(x) = 0 (12.5) .
h (x) = 0 m where x ∈ D ⊂ R, and the function f, h , h , .
.
.
, h are continuous, and usually assumed to 1 2 m be in C 2 (i.e., with continuous second partial derivatives).
Observe that when f and h ’s are linear, the problem is a linear programming one and can j be solved using the simplex algorithm.
Hence you would like to focus on the case that these functions are nonlinear.
In order to gain some intuition, you can consider the case where n = 2 and m = 1.
The problem becomes minimize f (x, y) subject to h(x, y) = 0, (x, y) ∈ R2.
The constraint h(x, y) = 0 defines a curve as shown below.
Differentiate the equation with respect to x : ∂h ∂h ∂h + = 0.
∂x ∂y ∂x The tangent of the curve is T (x, y) = (1, dy ).
And the gradient of the curve is ∇h = ( ∂h , ∂h ).
dx ∂x ∂y So the above equation states that T · ∇h = 0; namely, the tangent of the curve must be normal to the gradient at all the time.
Suppose you are at a point on the curve.
To stay on the curve, any motion must be along the tangent T .
∇ h h   x , y  =0 T Figure 12.1: 266  UNIT 12.
CONSTRAINED OPTIMIZATION In order to increase or decrease f (x, y), motion along the constraint curve must have a component along the gradient of f, that is, ∇f · T /= 0.
∇ f h   x , y  =0 T −∇ f Figure 12.2: At an extremum of f, a differential motion should not yield a component of motion along ∇f.
Thus T is orthogonal to ∇f ; in other words, the condition ∇f · T = 0 must hold.
Now T is orthogonal to bot gradients ∇f and ∇h at an extrema.
This means that ∇f and ∇h must be parallel.
Phrased differently, there exists some λ ∈ R such that ∇f + λ∇h = 0.
(12.6)   x y   2, 2 h   x , y  =0   x y   1, 1 ∇ f   x ∗ , y ∗   ∇ h f = c1 f = c∗ f = c3 f = c4 f = c5 Figure 12.3: the figure above explains condition (12.6) by superposing the curve h(x, y) = 0 onto the family of level curves of f (x, y), that is, the collection of curves f (x, y) = c, where c is any real number in the range of f. In the figure, c > c > c > c∗ > c .
The tangent of a level 5 4 3 1 267  UNIT 12.
CONSTRAINED OPTIMIZATION curve is always orthogonal to the gradient ∇f.
Otherwise moving along the curve would result in an increase or decrease of the value of f. Imagine a point moving on the curve h(x, y) = 0 from (x , y ) to (x , y ).
Initially, the motion has a component along the negative gradient 1 1 2 2 direction −∇f, resulting in the decrease of the value of f. This component becomes smaller and smaller.
When the moving point reaches (x∗ , y∗ ), the motion is orthogonal to the gradient.
From that point on, the motion starts having a component along the gradient ∇f so the value of f increases.
Thus at (x∗ , y∗ ), f achieves its local minimum.
The motion is in the tangential direction of the curve h(x, y) = 0, which is orthogonal to the gradient ∇h.
Therefore at the point (x∗ , y∗ ) the two gradients ∇f and ∇h must be collinear.
This is what equation (12.6) says.
Let c∗ be the local minimum achieved at (x∗ , y∗ ).
It is clear that the two curves f (x, y) = c∗ and h(x, y) = 0 are tangent at (x∗ , y∗ ).
Suppose you find the set S of points satisfying the equations h(x, y) = 0 ∇f + λ∇h = 0 for some λ Then S contains the external points of f to the constraints h(x, y) = 0.
The above two equa- tions constitute a nonlinear system in the variables x, y, λ.
It can be solved using numerical techniques, for example, Newton’s method.
12.4.1 Lagrangian It is convenient to introduce the Lagrangian associated with the constrained problem, defined as F (x, y, λ) = f (x, y) + λh(x, y) Note  ∂f + λ ∂h T ∂x ∂x ∇F =  ∂f + λ ∂h  = (∇f + λh, h).
∂y ∂y h Thus setting ∇F = 0 yields the same system of nonlinear equations you derived earlier.
The value of λ is known as the Lagrange multiplier.
The approach of constructing the Lagrangians and setting its gradient to zero is know as the method of Lagrange multipliers.
Example 12.4.1 Find the extremal values of f (x, y) = xy subject to the constraint x2 y2 h(x, y) = + − 1 = 0 8 2 ☞ Solution.
First construct the Lagrangian and find its gradient: ( x2 y2 \ F (x, y, λ) = xy + λ + − 1 , 8 2   y + λx 4 ∇F (x, y, λ) =  x + λy  = 0 x2 + y2 − 1 8 2 268  UNIT 12.
CONSTRAINED OPTIMIZATION The above leads to three equations λx y + = 0, (12.7) 4 x + λy = 0, (12.8) x2 + 4y2 = 8.
(12.9) combining (12.7) and (12.8) yields λ2 = 4 and λ = ±2 Thus x = ±2y.
Substituting this equation into (12.9) gives you y = ±1 and x = ±2.
So there are four extremal points of f subject to the constraint h : (2, 1), (−2, −1), (2, −1), and (−2, −1).
The maximum value 2 is achieved at the first two points while the minimum value −2 is achieved at the last two points.
Figure 12.4: Graphically, the constraint h defines an ellipse.
The constraint contours of f are the hyper- bolas xy = c, with |c| increasing as the curves move out from the origin.
✍ 269  UNIT 12.
CONSTRAINED OPTIMIZATION 12.4.2 General Formulation Now you would generalize to the cawe with multiple constraints.
Let h = (h , .
.
.
, h )T be a 1 m function from Rn to Rm.
Consider the constrained optimization problem below.
minimize f (x) subject to h(x) = 0 Each constraint equation h (x) = 0 defines a constraint hypersurface S in the space Rn.
And j this surface is smooth provided h (x) ∈ C 1. j A curve on S is a family of points x(t) ∈ S with a ≤ t ≤ b.
The curve is if ddx(itf)f erentiable dx exists, and twice differentiable if exists.
The curve passes through a point x∗ if dt dt2 x∗ = x∗ (t) for some t∗, a ≤ t∗ ≤ b.
The tangent space at x∗ is the subspace of Rn spanned by the tangents dx (t∗ ) of all curves dt x(t) on S such that x(t∗ ) = x∗ .
In other words, the tangent space is the set of the derivatives at x∗ of all surface curves through x∗ .
Denote this subspace as T .
A point x satisfying h(x) = 0 is a regular point of the constraint if the gradient vectors ∇h1(x), .
.
.
, ∇hm(x) are linearly independent.
From your previous intuition, you would expect that ∇f · v = 0 for all v ∈ T at an extremum.
This implies that ∇f lies in the orthogonal complement T ⊥ of T .
Claim that ∇f can be composed from a linear combination of the ∇h ’s.
This is only valid provided that these i gradients span T ⊥, which is true when the extremal point is regular.
Theorem 12.4.1 At a regular point x of the surface S defined by h(x) = 0, the tangent space is the same as {y = |∇h(x)y = 0} where the matrix   ∇h1   ∇ h =  .
 ∇hm The rows of the matrix ∇h(x) are the gradient vectors ∇h (x), j = 1, .
.
.
, m. The theo- j rem says that the tangent space at x is equal to the nullspace of ∇h(x).
Thus its orthogonal complement T ⊥ must equal the row space of ∇h(x).
Hence the vectors ∇h (x) span T ⊥.
j Example 12.4.2 Suppose h(x1, x2) = x1.
Then h(x) = 0 yields the x2 axis.
And ∇h = (1, 0) at all points.
So every x ∈ R2 is regular.
The tangent space is also the x2 axis and has dimension 1.
If instead h(x1, x2) = x2, then h(x) = 0 still defines the x2 axis.
On this ∇h = (2x1, 0) = (0, 0).
Thus 1 no point is regular.
The dimension of T , which is the x axis, is still one, but the dimension of the space 2 {y|∇h · y = 0} is two.
Lemma 12.4.1 Let x∗ be a local extremum of f subject to the constraints h(x) = 0.
Then for all y in the tangent space of the constraint surface at x∗ , ∇f (x∗ )y = 0.
270  UNIT 12.
CONSTRAINED OPTIMIZATION The next theorem states that the Lagrange multiplier method as a necessary condition on an extremum point.
Theorem 12.4.2 (First-Order Necessary Conditions) Let x∗ be a local extremum point of f subject to the constraints h(x) = 0.
Assume further that x∗ is a regular point of these con- straints.
Then there is a λ ∈ Rn such that ∇f (x∗ ) + λT ∇h(x∗ ) = 0.
The first order necessary conditions together with the constraints h(x∗ ) = 0 give a total of n + m equations in n + m variables x∗ and λ.
Thus a unique solution can be determined at least locally.
Example 12.4.3 You can construct a cardboard box of maximum volume, given a fixed area of card- board.
Denoting the dimension of the box by x, y, z, the problem can be expressed a maximize xyz subject to xy + yz + xz = c , 2 where c > 0 is the given area of cardboard.
Consider the Lagrangian xyz + λ(xy + yz + xz − c ).
The 2 first-order necessary conditions are easily found to be yz + λ(y + z) = 0, (12.10) xz + λ(x + z) = 0, (12.11) xy + λ(x + y) = 0.
(12.12) together with the original constraint.
Before solving the equation above, note that their sum is (xy + yz + xz) + 2λ(x + y + z) = 0, which, given the constraint, becomes c/2 + 2λ(x + y + z) = 0.
Hence it is clear that λ /= 0.
Neither of x, y, z can be zero since if either is zero, all must be so according to (12.10)-(12.12).
To solve the equations (12.10)-(12.12), multiply (12.10) by x and (12.11) by y, and then subtract the two to obtain λ(x − y)z = 0 Operate similarly on the second and third to obtain λ(y − z)x = 0.
Since no variables can be zero, it follows that c x = y = z = 6 is the unique solution to the necessary conditions.
The box must be a cube.
271  UNIT 12.
CONSTRAINED OPTIMIZATION You can derive the second-order conditions for constrained problems, assuming f and h are twice continuously differentiable.
Theorem 12.4.3 (Second-Order Necessary Conditions) Suppose that x∗ is a local minimum of f subject to h(x) = 0 and that x∗ is a regular point of these constraints.
Then there is a λ ∈ Rm such that ∇f (x∗ ) + λT ∇h(x∗ ) = 0.
The matrix m L(x∗ ) = H f (x∗ ) λ H h (x) (12.13) i i + i=1 is positive semidefinite on the tangent space {y|∇h(x∗ )y = 0}.
Theorem 12.4.4 (Second-Order Sufficient Conditions) Suppose there is a point x∗ satisfying h(x∗ ) = 0, and a λ such that ∇f (x∗ ) + λT h(x∗ ) = 0.
Suppose also that the matrix L(x∗ ) defined in (12.13) is positive definite on the tangent space {y|∇h(x∗ )y = 0}.
Then x∗ is a strict local minimum of f subject to h(x) = 0.
Example 12.4.4 Consider the problem minimize x1x2 + x2x3 + x1x3 subject to x + x + x = 3 1 2 3 The first order necessary conditions become x + x + λ = 0 2 3 x + x + λ = 0 1 3 x + x + λ = 0.
1 2 You can solve these equations together with the one constraint equation and obtain x = x = x = 1 and λ = −2 1 2 3 Thus x∗ = (1, 1, 1)T .
Now you need to resort to the second-order sufficient conditions to determine if the problem achieves a local maximum and minimum at x = x = x = 1.
You will find the matrix 1 2 3 L(x∗ ) = H f (x∗ ) + λH h(x∗ )   0 1 1 =  1 0 1  1 1 0 is neither positive nor negative definite.
On the tangent space M = {y|y1 + y2 + y3 = 0}, however, you note that yT Ly = y (y + y ) + y (y + y ) + y (y + y ) 1 2 3 2 1 3 3 1 2 = −(y2 + y2 + y2) 1 2 3 < 0, for all y /= 0.
Thus L is negative definite on M and the solution 3 you found is atleas a local maximum.
272  UNIT 12.
CONSTRAINED OPTIMIZATION 12.5 Inequality Constraints Finally, you will address the problems of the general form Minimize f (x) subject to h(x) = 0 g(x) ≥ 0 where h = (h , .
.
.
, h )T and g = (g , .
.
.
, g )T .
1 m 1 p A fundamental concept that provides a great deal of insight as well as simplifies the required theoretical development is that of an active constraint.
An inequality constraint g (x) ≤ 0 is i said to be active at a feasible point x if g (x) = 0 and inactive at x if g (x) = 0.
By convention i i you refer to any equality constraint h (x) = 0 as active at any feasible point.
The constraints i active at a feasible point x restrict the domain of feasibility in neighbourhood of x.
Therefore, in studying the properties of a local minimum point, it is clear that attention can be restricted to the active constraints.
This is illustrated in the figure below where local properties satisfied by the solution x∗ obviously do not depend on the inactive constraints g and g .
2 3 Assume that the function f, h = (h , .
.
.
, h )T , g = (g , .
.
.
, g )T are twice continuously 1 m 1 p differentiable.
Let x∗ be a point satisfying the constraint.
h(x∗ ) = 0 and g(x∗ ) ≤ 0, and let J = {j|g (x∗ ) = 0}.
Then x∗ is said to be a regular point of the above constraints if j the gradient vectors ∇h (x∗ ), ∇g (x∗ ), 1 ≤ i ≤ m, j ∈ J are linearly independent.
Now i j suppose this regular point x∗ is also a relative minimum point for the original problem (12.6).
Then it is shown that there exists a vector λ ∈ Rm and a vector µ ∈ Rp with µ ≥ 0 such that ∇f (x∗ ) + λT ∇h(x∗ ) + µT ∇g(x∗ ) = 0 µT g(x∗ ) = 0 Since µ ≥ 0 and g(x∗ ) ≤ 0, the second constraint above is equivalent to the statement that a component of µ may be nonzero only if the corresponding constraint in active.
To find a solu- tion, you can enumerate various combinations of active constraints, that is, constraints where equalities are attained at x∗ , and check the signs of the resulting Lagrangian multipliers.
There are a number of distinct theories concerning this problem, based on various regular- ity conditions or constraint qualifications, which are directed toward obtaining definite general statements of necessary and sufficient conditions.
One can by no means pretend that all such re- sults can be obtained as minor extensions of the theory for problems having equality constraints only.
To date, however, their use has been limited to small-scale programming problems of two or three variables.
12.6 Conclusion 273  UNIT 12.
CONSTRAINED OPTIMIZATION In this unit, you were introduced to constrained optimization problems, which could be equality, inequality, or mixed constraints.
You looked at the theorem of Lagrange for local optimum of a 274  UNIT 12.
CONSTRAINED OPTIMIZATION constrained problem.
12.7 Summary Having gone through this unit, you now (i) define equality and inequality constrained optimization problem.
(ii) state and use the lagrange theorem.
(iii) State and apply the First-Order Necessary Conditions.
(iv) State and apply the second-order necessary and sufficient conditions.
12.8 Tutor Marked Assignments(TMAs) Exercise 12.8.1 1.
Find the minimum and maximum of f (x, y) = x2 − y2 on the unit circle x2 + y2 = 1 using the Lagrange multipliers method.
Using the substitution y2 = 1 − x2, solve the same problem as a single variable unconstrained proble.
Do you get the same results?
Why or Why not?
2.
Show that the problem of maximizing f (x, y) = x3 + y3 on the constraint set D = {(x, y)|x + y = 1} has no solution.
Show also that if the Lagrangian method were used on this problem, the critical points of the Lagrangian have a unique solution.
Is the point identified by this solution either a local maximum or a (local or global) minimum?
3.
Find the maxima and minima of the following functions subject to the specified con- straints: (a) f (x, y) = xy subject to x2 + y2 = 2a2.
(b) f (x, y) = 1/x + 1/y subject to (1/x)2 + (1/y)2 = (1/a)2.
(c) f (x, y, z) = x + y + z subject to (1/x) + (1/y) + (1/z) = 1.
(d) f (x, y, z) = xyz subject to x + y + z = 5 and xy + xz + yz = 8.
(e) f (x, y, z) = x + y for xy = 16 (f) f (x, y, z) = x2 + 2y − z2 subject to 2x − y = 0 and x + z = 6.
4.
Maximize and minimize f (x, y) = x + y on the lemniscate (x2 − y2)2 = x2 + y2.
5.
Consider the problem min x2 + y2 subject to (x − 1)3 − y2 = 0.
(a) Solve the problem geometrically.
275  UNIT 12.
CONSTRAINED OPTIMIZATION (b) Show that the method of Lagrange multipliers does not work in this case.
Can you explain why?
6.
Consider the following problem where the objective function is quadratic and the con- straints are linear 1 max cT x + xT Dx subject to Ax = b x 2 where c is a given n-vector.
D is a given n × n symmetric, negative definite matrix, and A is a given m × n matrix.
(a) Set up the Lagrangean and obtain the first-order condtions.
(b) Solve for the optimal vector x∗ as a function of A, b, c and D. 7.
Solve the problem max f (x) = xT Ax subject to x · x = 1 where A is a given symmetric matrix.
8.
Solve the following maximization problem: Maximize ln x + ln y Subject to x2 + y2 = 1 x, y ≥ 0.
276
