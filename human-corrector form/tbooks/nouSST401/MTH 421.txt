 MTH 421 NATIONAL OPEN UNIVERSITY OF NIGERIA SCHOOL OF SCIENCE AND TECHNOLOGY COURSE CODE: MTH421 COURSE TITLE: ORDINARY DIFFERENTIAL EQUATIONS  MTH 421 ORDINARY DIFFERENTIAL EQUATIONS COURSE WRITER Prof. OSISIOGOR School of Science and Technology National Open University of Nigeria Lagos.
COURSE EDITOR DR. AJIBOLA.
S. O.
School of Science and Technology National Open University of Nigeria Lagos.
PROGRAMME LEADER DR. AJIBOLA.
S. O.
School of Science and Technology National Open University of Nigeria Lagos.
NATIONAL OPEN UNIVERSITY OF NIGERIA  National Open University of Nigeria Headquarters 14/16 Ahmadu Bello Way Victoria Island Lagos Abuja Annex 245 Samuel Adesujo Ademulegun Street Central Business District Opposite Arewa Suites Abuja e-mail: centralinfo@nou.edu.ng URL: www.nou.edu.ng National Open University of Nigeria 2011 First Printed ISBN All Rights Reserved Printed by …………….. ii  Course Materials These include: 1.
Course Guide 2.
Study Units 3.
Recommended Texts 4.
Tutor Marked Assignments.
5.
Presentation Schedule Study Units There are thirteen study units in this course: MODULE ONE: UNIT 1: Ordinary Differential Equations UNIT 2: Existence and Uniqueness Theorems UNIT 3: Properties of Solutions MODULE TWO: UNIT 4: Linear Systems UNIT 5: Adjoint Systems MODULE THREE UNIT 6: Stum-Liouville Boundary Value Problems UNIT 7: Linear Operator on Hilbert Spaces UNIT 8: Stability Theory iii  MODULE 1 UNIT 1: ORDINARY DIFFERENTIAL EQUATIONS Contents 1 Introduction 1 2 Objectives 2 3 Main Content 2 3.1 First Order ODEs 2 3.1.1 Concept of Solution 2 3.1.2 Initial Value Problem (IVP) 3 3.1.3 Separable ODEs 4 3.1.4 Exact ODEs 6 3.1.5 Linear ODEs.
Bernoulli Equation 10 3.2 Second Order Linear ODEs 14 3.2.1 Homogeneous Linear ODEs with Constant Coefficients 18 3.2.2 Non-homogeneous ODEs 22 3.2.3 Solution by Variation of Parameters 26 3.3 Higher Order Linear ODEs 27 4 Conclusion 28 5 Summary 28 6 Tutor Marked Assignments (TMAs) 30 1 Introduction An ordinary differential equation (ODE) is an equation that contains one or several derivatives of an unknown function, which could be called y(x) (or sometimes y(t) if the independent variable is time t).
The equation may also contain y itself, known functions of x (or t), and constants.
For example 1  2 Objectives ORDINARYDIFFERENTIAL EQUATION (1) y = cos x (2) y + 9y = 0 (3) x2y y + 2exy = (x2 + 2)y2 are ordinary differential equations (ODEs).
An ODE is said to be of order n if the nth derivative of the unknown function y is the highest derivative of y in the equation.
The concept of order gives a useful classification into ODEs of first order, second order, and so on.
Thus, (1) is of first order, (2) is of second order, and (3) of third order.
In this unit, you shall be introduced to first, and second order ordinary differential equations and also you shall have a brief grasp of systems of ordinary differential equations.
2 Objectives At the end of this unit, you should be able to (i) Solve first order ordinary differential equations of different kinds.
(ii) Solve second order ordinary differential equations, both homogeneous and non homogeneous equa- tions.
(iii) Solve systems of ordinary differential equations.
3 Main Content 3.1 First Order ODEs A first order ordinary differential equation is an equation that contains only the first derivative y and may contain y and any given function of x.
Such equations can be of the following forms y = f (x, y) (1) when written explicitly, and F (x, y, y ) = 0 (2) in its implicit form.
For instance, the implicit first order ODE x­3y ­ 4y2 = 0 (x /= 0) can be written explicitly as y = 4x3y2 3.1.1 Concept of Solution A function y = h(x) is called a solution of a given ODE (1) on some open interval a < x < b if h(x) is defined and differentiable throughout the interval and is such that y = h (x) 2  3.1 First Order ODEs ORDINARYDIFFERENTIAL EQUATION Example 3.1 Verify that y = h(x) = c/x, x /= 0 is a solution of xy = ­y, where c is an arbitrary constant.
Solution.
To verify this, you have to differentiate, y = h (x) = ­c/x2, and multiply by x to get xy = ­c/x = ­y.
Thus xy = ­y, the given ODE.
Example 3.2 The ODE y = dy = cos x can be solved directly by integration on both sides.
Indeed by dx calculus, you have y = cos xdx = sin x + c where c is an arbitrary constant.
Observe that in each of the ODEs given in the above examples, the solution contain arbitrary constant.
Such a solution containing arbitrary constant c is called general solution of the ODE.
While a solution of an ODE that does not contain an arbitrary constant c is called a particular solution of the ODE.
For instance in Example 2, if you fix c = 3, then y = sin x + 3 is a particular solution of the ODE y = cos x.
3.1.2 Initial Value Problem (IVP) The value y(x ) = y (3) 0 0 given at an initial value x of x in the interval a < x < b is called an inital condition.
An ODE 0 y = f (x, y), y(x ) = y (4) 0 0 with an initial condition is called an initial value problem (IVP).
Example 3.3 Solve the initial value problem y = dy = 3y, y(0) = 5.7 dx Solution.
The general solution to the above differential equation is y = ce3x.
From this solution an the inital condition, you have y(0) = ce0 = c = 5.7.
Hence the initial value problem has y(x) = 5.7e3x as the particular solution.
In what follows, you will learn different approaches to solving different kinds first order ordinary dif- ferential equations.
3  3.1 First Order ODEs ORDINARYDIFFERENTIAL EQUATION 3.1.3 Separable ODEs.
Many practically useful ODEs can be reduced to the form g(y)y = f (x) (5) by purely algebraic manipulations.
Then you can integrate on both sides with respect to x, to obtain g(y)y dx = f (x)dx + c. (6) But y = dy , so that y dx = dy, and by substitution in (6) you have dx g(y)dy = f (x)dx + c (7) If f and g are continuous functions, the integral in (7) exist, and by evaluating them you obtain a general solution of (5).
This method of solving ODEs is called the method of separating variables, and (5) is called a separable equation, because in (7) the variables are now separated; x appears only on the right and y only on the left.
Example 3.4 Solve the ODE y = 1 + y2.
Solution.
This ODE is separable because it can be written as dy dy = dx.
Thus by integration, = dx + c 1 + y2 1 + y2 you obtain, arctan y = x + c or y = tan(x + c) Example 3.5 Solve the initial value problem y = ky, y(0) = y0 where k is a constant.
Solution.
By separation of varibles and integrating, you have dy dy y = kdx, y = kdx, so that ln |y| = kt + c˜, i.e., y = cekt Using the initial condition, you have that c = y .
Hence 0 y = y0ekx is the solution of the initial value problem.
4  3.1 First Order ODEs ORDINARYDIFFERENTIAL EQUATION Reduction to Separable Form Certain nonseparable ODEs can be made separable to transformations that introduce for y a new unknown function.
This technique is discussed for a class of ODEs of practical importance, namely, for equations y y = f (8) x Here, f is any (differentiable) function of y/x, such as sin(y/x), (y/x)4, and so on.
(Such an ODE is sometimes called a homogeneous ODE, a term that shall be reserved for a more important purpose.)
For this form of an ODE, you shall set y/x = u; thus, y = ux and by product differentiation, y = u x + u Substituting into y = f (y/x) then gives u x + u = f (u) or u x = f (u) ­ u.
You can see that this can be separated as follows; du dx = (9) f (u) ­ u x Example 3.6 Solve 2xyy = y2 ­ x2 Solution.
To get the usual explicit form, divide the given equation by 2xy, y2 ­ x2 y x y = = ­ 2xy 2x 2y Now let y = ux, and as before, y = u x + y Thus substiting for y and y and then simplifying by subtracting u on both sides gives you u 1 u 1 ­u2 ­ 1 u x + u = ­ , u x = ­ ­ = 2 2u 2 2u 2u You see that in the last equation you can now separate the variables, 1 1 12u+duu2 = ­d xx .
By integration, ln(1 + u 2) = ­ ln |x| + c˜ = ln 11 x 1 + c˜.
Take exponets on both sides to get 1 + u2 = c/x or 1 + (y/x)2 = c/x.
Multiply the last equation by x2 to obtain x2 + y2 = cx.
Thus x ­ c 2 + y2 = c 2 .
2 4 5  3.1 First Order ODEs ORDINARYDIFFERENTIAL EQUATION 3.1.4 Exact ODEs.
You remember from calculus that if a function u(x,y) has continuous partial derivatives, its differential (also called its total differential) is ∂u ∂u du = dx + dy.
∂x ∂y From this it follows that if u(x, y) = c = const, then du = 0 For example, if u = x + x2y3 = c, then du = (1 + 2xy3)dx + 3x2y2dy = 0 or dy 1 + 2xy3 y = = ­ dx 3x2y2 an ODE that you can solve by going backward.
This idea leads to powerful solution method as follows.
A first-order ODE M (x, y) + N (x, y)y = 0, written as (use dy = y dx) M (x, y)dx + N (x, y)dy = 0 (10) is called an exact differential equation if the differential form M (x, y)dx + N (x, y)dy is exact, that is, this form is the differential ∂u ∂u du = dx + dy (11) ∂x ∂y of some function u(x,y).
Then (10) can be written du = 0.
By integration you immediately obtain the general solution of (1) in the form u(x, y) = c. (12) This is called an implicit solution, in contrast with a solution y = ϕ(x) as defined earlier, which is also called an explicit solution, for distinction.
Comparing (10) and (11), you see that (10) is an exact differential equation if there is some function u(x, y) such that ∂u ∂u (a) = M, (b) = N (13) ∂x ∂y From this, you can derive a formula for checking whether (10) is exact or not, as follows.
Let M and N be continuous and have continuous first partial derivatives in a region in the xy-plane whose boundary is a closed curve without self-intersections.
Then by partial differentiation of (13), ∂M ∂2u ∂N ∂2u = , = .
∂y ∂y∂x ∂x ∂x∂y 6  3.1 First Order ODEs ORDINARYDIFFERENTIAL EQUATION By the assumption of continuity, the two second partial derivatives are equal.
Thus ∂M ∂N = .
(14) ∂y ∂x This condition is not only necessary but also sufficient for (10) to be an exact differential equation.
If (10) is exact, the function u(x, y) can be found by inspection or in the following systematic way.
From (13a) you have by integration with respect to x u = M dx + k(y) (15) in this integration, y is to be regarded as a constant, and k(y plays the role of a “constant” of integration.
To determine k(y), you have to derive ∂u/∂y from (15), use (13b) to get dk/dy, and integrate dk/dy to get k. Formula (15) was obtained from (4a).
Instead of (4a), you may equally use (13b).
Then instead of (15) you will first have by integration with respect to y that u = N dy + l(x).
(15∗ ) To determine l(x), you can derive ∂u/∂x from (6∗), use (4a) to get dl/dx, and integrate.
The following are examples for illustration Example 3.7 Solve cos(x + y)dx + (3y2 + 2y + cos(x + y))dy = 0 (16) Solution.
Step 1.
Test for exactness.
Our equation is of the form (10) with M = cos(x + y) N = 3y2 + 2y + cos(x + y) Thus ∂M ∂N = ­ sin(x + y) = ­ sin(x + y) ∂y ∂x From this and (14), you see that (16) is exact.
Step 2.
Implicit general solution.
From (15) you obtain by integration u = M dx + k(y) = cos(x + y)dx + k(y) = sin(x + y) + k(y) (17) To find k(y), differentiate this formula with respect to y and use formula (13b), to obtain ∂y dy ∂u dk = cos(x + y) + 7  3.1 First Order ODEs ORDINARYDIFFERENTIAL EQUATION = N = 3y2 + 2y + cos(x + y) 8  3.1 First Order ODEs ORDINARYDIFFERENTIAL EQUATION Hence dk/dy = 3y2 + 2y.
By integration, k = y3 + y2 + c˜.
Inserting this result into (17) and observing (12), you obtain the answer u(x, y) = sin(x + y) + y3 + y2 = c Step 3.
Checking an implicit solution.
You can check by differentiating the implicit solution u(x, y) = c implicitly and see whether this leads to the given ODE (16): ∂u ∂u du = dx + dy = cos(x + y)dx + (cos(x + y) + 3y2 + 2y)dy = 0 (18) ∂x ∂y This completes the check.
Example 3.8 WARNING!
Breakdown in the Case of Nonexactness The equation ­ydx + xdy = 0 is not exact because M = ­y and N = x, so that in (14), ∂M/∂y = ­1 but ∂N/∂x = 1.
You can show that in such a case the present method does not work.
From (15), ∂u dk u = M dx + k(y) = ­xy + k(y), hence = ­x + .
∂y dy Now, ∂u/∂y should equal N = x, by (13b).
However, this is impossible because k(y) can depend only on y.
Try (15∗); it will also fail.
Solve the equation by another method that is discussed below.
Reduction to Exact Form.
Integrating Factors The ODE in Example 3.8 is ­ydx + xdy = 0.
It is not exact.
However, if you multiply it by 1/x2, you will get an exact equation [check exactness by (14)!
], ­ydx + xdy y 1 y = ­ dx + dy = d = 0 (19) x2 x2 x x Integration of (19) then gives the general solution y/x = c = const.
This example gives the idea.
All you did was multiply a given nonexact equation, say, P (x, y)dx + Q(x, y)dy = 0 (20) by a function F that, in general, will be a function of both x and y.
The result was an equation F P dx + F Qdy = 0 (21) that is exact, so you can solve it as just discussed.
Such a function F (x, y) is then called an integrating factor of (20).
Example 3.9 Integrating Factor The integrating factor in (19) is F = 1/x2.
Hence in this case the exact equation (21) is F P dx + F Qdy = ­ydx + xdy = d y = 0.
Solution y = c. x2 x x These are straight lines y = cx throught the origin.
It is remarkable that you can readily find other integrating factors for the equation ­ydx + xdy = 0, namely, 1/y2, 1/(xy), and 1/(x2 + y2), because x x ­ydx + xdy x ­ydx + xdy x ­ydx + xdy y = d , = ­d ln , = d arctan .
(22) y2 y xy y x2 + y2 x 9  3.1 First Order ODEs ORDINARYDIFFERENTIAL EQUATION How to Find Integrating Factors In simpler cases you may find integrating factors by inspection or perhaps after some trials, keeping 22 in mind.
In the general case, the idea is the following.
For M dx + N dy = 0 the exactness condition (13) is ∂M/∂y = ∂N/∂x.
Hence for (13), F P dx + F Qdy = 0, the exactness condition is ∂ ∂ (F P ) = (F Q).
(23) ∂y ∂x By the product rule, with subscripts denoting partial derivatives, this gives F P + F P = F Q + F Q .
y y x x In the general case, this would be complicated and useless.
So following the Golden Rule: If you cannot solve your problem, try to solve a simpler one - the result may be useful (and may also help you later on).
Hence you look for an integrating factor depending only on one; fortunately, in many practical cases, there are such factors, as you shall see.
Thus, let F = F (x).
Then F = 0, and F = F = dF /dx, so that (23) y x becomes F Py = F Q + F Qx Dividing by FQ and reshuffling terms, you have x 1 dF 1 ∂P ∂Q = R, where R = ­ (24) F dx Q ∂y ∂x This proves the following theorem.
Theorem 3.1 Integrating Factor F (x) If (20) is such that the right side R of (24), depends only on x, then (20) has an integrating factor F = F (x), which is obtained by integrating (24) and taking exponents on both sides, F (x) = exp R(x)dx.
(25) Similarly, if F ∗ = F ∗ (y), then instead of (24) you get x 1 dF ∗ 1 ∂Q ∂P = R∗ , where R∗ = ­ (26) F ∗ dy P ∂x ∂y and you have the companion Theorem 3.2 Integrating Factor F ∗ (y) If (20) is such that the right side R∗ of (26) depends only of y, then (20) has an integrating factor F ∗ = F ∗ (y) which is obtained from (26) in the form F ∗ (y) = exp R∗ (y)dy.
(27) Example 3.10 Application of Theorems 1 and 2.
Initial Value Problem Using Theorem 1 or 2, find an integrating factor and solve the initial value problem (ex+y + yey )dx + (xey ­ 1)dy = 0, y(0) = ­1 (28) 10  3.1 First Order ODEs ORDINARYDIFFERENTIAL EQUATION Solution.
Step 1.
Nonexactness.
The exactness check fails: ∂P ∂ ∂Q ∂ = (ex+y + yey ) = ex+y + ey + yey but = (xey ­ 1) = ey ∂y ∂y ∂x ∂x Step 2.
Integrating factor.
General solution.
Theorem 1 fails because R [the right side of (16)] depends on both x and y, x 1 ∂P ∂Q 1 R = ­ = (ex+y + ey + yey ­ ey ).
Q ∂y ∂x xey ­ 1 Try Theorem 2.
The right side of (26) is x 1 ∂Q ∂P 1 R∗ = ­ = (ey ­ ex+y ­ ey ­ yey ) = ­1 P ∂x ∂y ex+y + yey Hence (27) give the integrating factor F ∗ (y) = e­y .
From this result and (28) you get the exact equation (ex + y)dx + (x ­ e­y )dy = 0.
Test for exactness: you will get on both sides of the exactness condition.
By integration, using (13a).
u = (ex + y) dx = ex + xy + k(y) Differentiate this with respect to y and use (13b) to get ∂u dk dk = x + = N = x ­ e­y , = ­e­y , k = e­y + c∗.
∂y dy dy Hence the general solution is u(x, y) = ex + xy + e­y = c. Step 3.
Particular solution.
The initial condition y(0) = 1 gives u(0, ­1) = 1 + 0 + e = 3.72.
Hence the answer is ex + xy + e­y = 1 + e = 3.72.
Step 4.
Checking.
Check by substitution that the answer satisfies the given equation as well as the initial condition.
3.1.5 Linear ODEs.
Bernoulli Equation.
Linear ODEs or PDEs that can be transformed to linear form are models for various phenomena, for in- stance, in physics, biology, population dynamics, and ecology, as you shall see.
A first-order ODE is said to be linear if it can be written y + p(x)y = r(x) (29) The defining feature of this equation is that it is linear in both the unknown function y and its derivative y = dy/dx, whereas p and r may be any given functions of x.
If in an application the independent variable is time, you should write t instead of x.
11  3.1 First Order ODEs ORDINARYDIFFERENTIAL EQUATION If the first term is f (x)y (instead of y ), divide the equation by f (x) to get the “ standard form” (1), with y as the first term, which is practical.
For instance, y cos x + y sin x = x is a linear ODE, and its standard form is y + y tan x = x sec x.
The function r(x) on the right may be a force, and the solution y(x) a displacement in a motion or an electrical current or some other physical quantity.
In engineering, r(x) is frequently called input, and y(x) is called the output or the response to the input (and, if given, to the initial condition).
Homogeneous Linear ODE.
You are expected to solve (29) in some interval a < x < b, call it I .
Two cases are possible for r(x) = 0; i.e., either r(x) ≡ 0 or r(x) /= 0.
If r(x)=0, then the ODE (29) becomes y + p(x)y = 0 (30) and is called homogeneous.
By separating variables and integrating you obtain dy = ­p(x)dx, thus ln |y| = ­ p(x)dx + c ∗ .
y Takin exponents on both sides, you obtain the general solution of the homogeneous ODE(30), R y(x) = ce­ p(x)dx (c = ±ec∗ when y ≷ 0) (31) here you may choose c=0 and obtain the trivial solution y(x) = 0 for all x in the interval I. Nonhomogeneous Linear ODE.
The next is to consider the case r(x) /= 0 in (29) for all x in the interval I considered.
In this case, the ODE(29) is called nonhomogeneous.
It turns out that in this case, (29) has a pleasant property; namely, it has an integrating factor depending only on x.
You can find this factor F (x) by theorem 3.1 in the last section.
For this purpose you write (29) as (py ­ r)dx + dy = 0 This is P dx + Qdy = 0, where P = py ­ r and Q = 1.
Hence the right side of (24) is simply 1(p-0)=p, so that (24) becomes 1 dF = p(x) F dx Separation and integration gives dF = pdx and ln |F | = pdx.
F Taking exponents on both sides, gives the desired integrating factor F(x), R F (x) = e pdx 12  3.1 First Order ODEs ORDINARYDIFFERENTIAL EQUATION Now, multiply (29) on both sides by this F. Then by the product rule, R R R e pdx( y + py) = (e pdx y) = e pdxr.
By integrating the second and third of these three expressions with respect to x, you get R R e pdxy = e pdx rdx + c. R J Dividing this equation by e pdx and denoting the exponent pdx by h, you obtain x y(x) = e­h ehrdx + c , h = pxdx.
(32) (The constant of integration in h does not matter.)
Formula (32) is the general solution of (29) in the form of an integral.
Thus, solving (29) is now reduced to the evaluation of an integral.
Example 3.11 First-Order ODE, General Solution Solve the linear ODE y ­ y = e2x Solution.
Here p = ­1, r = e2x, h = pdx = ­x and from (32) you obtain the general solution x y(x) = ex e­xe2xdx + c = ex(ex + c) = cex + e2x.
In simpler cases, such as the present, you may not need the general formula (32), but may wish to proceed directly, multiplying the given equation by eh = e­x.
This gives (y ­ y)e­x = (ye­x) = e2xe­x = ex.
Integrating on both sides, you obtain the same result as before; ye­x = ex + c, hence y = e2x + cex Example 3.12 First-Order ODE, Initial Value Problem.
Solve the initial value problem y + y tan x = sin 2x, y(0) = 1.
13  3.1 First Order ODEs ORDINARYDIFFERENTIAL EQUATION Here p = tan x, r = sin 2x = 2 sin x cos x, and pdx = tan xdx = ln | sec x|.
From this you see that in (32), eh = sec x, e­h = cos x, ehr = (sec x)(2 sin x cos x) = 2 sin x, and the general solution of our equation is x y(x) = cos x 2 sin xdx + c = c cos x ­ 2 cos2 x.
From this and the initial condition, 1 = c · 1 ­ 2 · 12, thus c = 3 and the solution of our initial value problem is y = 3 cos x ­ 2 cos2 x.
Reduction to Linear Form.
Bernoulli Equation Numerous application can be modeled by ODE’s that are nonlinear but can be transformed to linear ODEs.
One of the most useful ones of these is the Bernoulli equation.
y + p(x)y = g(x)ya a ∈ R (33) If a = 0 or a = 1, Equation (33) is linear.
Otherwise it is nonlinear.
Then you will set u(x) = [y(x)]1­a.
Differentiating this and substituting y from (33), you obtain u = (1 ­ a)y­ay = (1 ­ a)y­a(gya ­ py).
Simplification gives u = (1 ­ a)(g ­ py1­a), where y1­a = u on the right, so that you get the linear ODE u + (1 ­ a)pu = (1 ­ a)g. (34) Example 3.13 Logistic Equation.
Solve the following Bernoulli equation, known as the logistic equation (or Verhulst equation) y = Ay ­ By2 (35) Solution.
14  3.2 Second Order Linear ODEs ORDINARYDIFFERENTIAL EQUATION Write (34) in the form (35) in the form (33), that is, y ­ Ay = B ­ By2 to see that a = 2, so that u = y1­a = y­1.
Differentiating this u and substitute y from (35), u = ­y­2y = ­y­2(Ay ­ By2) = B ­ Ay ­1 The last term is ­Ay­1 = ­Au.
Hence you have obtained the linear ODE u + Au = B The general solutionis [by (32)] u = ce­At + B/A.
Since u=1/y, this gives the solution of (35), 1 1 y = = (36) u ceAt + B/A Directly from (35) you see that y ≡ 0 (y(t) = 0 for all t) is also a solution.
3.2 Second Order Linear ODEs A second-order ODE is called linear if it can be written in the form y + p(x)y + q(x)y = r(x) (37) and nonlinear if it cannot be written in this form.
The distinctive feature of this equation is that it is linear in y and its derivativs, whereas the function p, q and r on the right may be any given functions of x.
If the equation begins with say f (x)y then divide by f (x) to have the standard form (37) with y as the first term, which is practical.
If r(x) ≡ 0 (that is, r(x) = 0 for all x considered; read “r(x) is identically zero”), then (37) is reduced to y + p(x)y + q(x)y = 0 (38) and is called homogeneous.
If r(x) /= 0, then (1) is called nonhomogeneous.
For instance, a nonhomogeneous linear ODE is y + 25y = e­x cos x and a homogeneous linear ODE is 1 xy + y + xy = 0, in standard form y + y + y = 0. x An example of a non linear ODE is y y + y 2 = 0 The functions p and q in (37) and (38) are called the coefficients of the ODEs.
Solutions are defined similarly as for first-order ODEs in section.
A function y = h(x) is called a solution of a (linear or nonlinear) second-order ODE on some open interval I if h is defined and twice differentiable throughout that interval and is such that the ODE becomes an identity if you replace 15  3.2 Second Order Linear ODEs ORDINARYDIFFERENTIAL EQUATION the unknown y by h, the derivative y by h , and the second derivative y by h .
Examples are given below.
16  3.2 Second Order Linear ODEs ORDINARYDIFFERENTIAL EQUATION Homogeneous Linear ODEs: Superposition Principle Linear ODEs have a rich solution structure.
For the homogeneous equation the back bone of this structure is the superposition principle or linearity principle, which says that you can obtain further solutions from given ones by adding them or by multiplying them with any constants.
Of course, this is a great advantage of homogeneous linear ODEs.
The following is an example.
Example 3.14 Homogeneous Linear ODEs: Superposition of Solutions The functions y = cos x and y = sin x are solutions of the homogeneous linear ODE y + y = 0 for all x.
You can verify this by differentiation and substitution.
This gives you (cos x) = ­ cos x; hence y + y = (cos x) + cos x = ­ cos x + cos x = 0 Similarly for y = sin x.
You can go an important step further.
You multiply cos x by any constan, for instance, 4.7 and sin x by say, ­2, and take the sum of the results, claiming that it is a solution.
Indeed differentiation and substitution gives (4.7 cos x ­ 2 sin x) + (4.7 cos x ­ 2 sin x) = ­4.7 cos x + 2 sin x + 4.7 cos x ­ 2 sin x = 0 In this example you have obtained from y (= cos x) and y (= sin x) a function of the form 1 2 y = c y + c y (c , c arbitrary constants).
(39) 1 1 2 2 1 2 This is called a linear combination of y and y .
In terms of this concept you can now formulate the result 1 2 suggested by your example, often called the superposition principle or linearity principle.
Theorem 3.3 Fundamental Theorem for the Homogeneous Linear ODE (38) For a homogeneous linear ODE (38), any linear combination of two solutions on an open interval I is again a solution of (38) on I.
In particular, for such an equation, sums and constant multiples of solutions are again solutions.
Proof.
Let y and y be solutions of (38) on I .
Then by substituting y = c y + c y and its derivatives 1 2 1 1 2 2 into (38), and using the familiar rule of derivatives, you get y + py + qy = (c y + c y ) + p(c y + c y ) + q(c y + c y ) 1 1 2 2 1 1 2 2 1 1 2 2 = c y + c y + p(c y + c y ) + q(c y + c y ) 1 2 1 1 2 2 1 1 2 2 = c (y + py + qy ) + c (y + py + qy ) = 0 1 1 1 2 2 2 2 since in the last line, (· · · ) = 0 because y1 and y2 are solutions, by assumption.
This shows that y is a solution of (38) on I .
Remark 3.1 You should not forget that this highly important theorem holds forhomogeneous linear ODEs only but does not hold for nonhomogeneous linear or nonlinear ODEs, as the following example illustrate.
17  3.2 Second Order Linear ODEs ORDINARYDIFFERENTIAL EQUATION Example 3.15 A Nonhomogeneous Linear ODE Verify by substitution that the functions y = 1 + cos x and y = 1 + sin x are solutions of the nonhomogeneous linear ODE y + y = 1 but their sum is not a solution.
Neither is, for instance 2(1 + cos x)or5(1 + sin x).
Example 3.16 A Nonlinear ODE Verify by substitution that the functions y = x2 and y = 1 are solutions of the nonlinear ODE y y ­ xy = 0 but their sum is not a solution.
Neither is ­x2, so you cannot even multiply by ­1!
Initial Value Problem.
Basis.
General Solution Recall that from section 3.1, that for a first-order ODE, an initial value problem consists of the ODE and one initial condition y(x ) = y .
The initial condition is used to determine the arbitrary constant c in the 0 0 general solution of the ODE.
This results in a unique solution as you need it in most applications.
That solution is called a particular solution of the ODE.
These ideas extend to second-order equations as follows.
For a second-order homogeneous linear ODE (38) an initial value problem consists of (38) and two initial conditions y(x ) = K , y (x ) = K .
(40) 0 0 0 1 These conditions prescribe given values K and K of the solution and its first derivative (the slope of its 0 1 curve) at the same given x = x in the open interval considered.
0 The conditions (40) are used to detem the two arbitrary constants c and c in general solution 1 2 y = c y + c y (41) 1 1 2 2 of the ODE; here, y and y are suitable solutions of the ODE, with “suitable” to be explained after the 1 2 next example.
This results in a unique solution, passing through the point (x , K ) with K as the tangent 0 0 1 direction (the slope) at that point.
That solution is called a particular soluion of the ODE (38).
Example 3.17 Initial Value Problem Solve the initial value problem y + y = 0, y(0) = 3.0, y (0) = ­0.5.
Solution.
Step 1.
General solution.
The functions cos x and sin x are solutions of the ODE (by example 3.14), and you can take y = c cos x + c sin x 1 2 This will turn out to be the general solution as defined below.
Step 2.
Particular solution.
You need the derivative y = c sin x + c cos x.
From this and the initial 1 2 values you will obtain, since cos 0 = 1 and sin 0 = 0, y(0) = c1 = 3.0 and y (0) = c2 = ­0.5.
18  3.2 Second Order Linear ODEs ORDINARYDIFFERENTIAL EQUATION This gives as the solution of your initial value problem the particular solution y = 3.0 cos x ­ 0.5 sin x.
Definition 3.1 General Solutin, Basis, Particular Solution A general solution of an ODE(38) on an open interval I is a solution (41) in which y and y are solutions 1 2 of (38) on I that are not proportional, and c and c are arbitrary constants.
These y , y are called the basis 1 2 1 2 (or a fundamental system) of solutions of (38) on I .
A particular solution of (38) on I is obtained if you assign specific values to c and c in (41).
1 2 Note that y and y are called proportional on I if for all x on I , 1 2 (a) y = ky or (b) y = ly (42) 1 2 2 1 where k and l are numbers, zero or not.
(Note (a) implies (b) if and only if k /= 0).
Actually, you can reformulate your definition of a basis by using a concept of general importance.
Namely, two functions y and y are called linearly independent on an interval I where they are defined if 1 2 k y (x) + k y (x) = 0 everywhere on I implies k = 0 and k = 0.
(43) 1 1 2 2 1 2 And y and y are called linearly dependent on I if (43) holds for some constants k , k not both zero.
1 2 1 2 Then if k1 /= 0 k2 /= 0, you can divide and see that y1 and y2 are proportional, k k y 1 = ­k 2y 2 or y2 = ­k 1 y1.
1 2 In contrast, in the case of linear independence these funcitons are not proportional because then you cannot divide in (43).
This gives the following Definition 3.2 Basis (Reformulated) A basis of solutions of (38) on an open interval I is a pair of linearly independent solutions of (38) on I .
If the coefficients p and q of (38) are continuous on some open interval I , then (38) has a general solution.
It yields the unique solution of any initial value problem (38), (40).
It includes all solutions of (38) on I ; hence (38) has no singular solutions (solutions not obtainable from the general solution).
Example 3.18 cos x and sin x in example 3.17 from a basis of solutions of the ODE y + y = 0 for all x because their quotient is cot x /= const (or tan x /= const).
Hence y = c1 cos x + c2 sin x is a general solution.
The solution y = 3.0 cos x ­ 0.5 sin x of the initial value problem is a particular solution.
Example 3.19 Verify by substitution that y1 = ex and y2 = e­x are solutions of the ODE y ­ y = 0.
Then solve the initial value problem y ­ y = 0, y(0) = 6 y (0) = ­2.
Solution.
(ex) ­ ex = 0 and (e­x) ­ e­x = 0 shows that ex and e­x are solutions.
They are not proportional, because ex/e­x /= const.
Hence ex, e­x form a basis for all x.
You now write down the corresponding general solution and its derivatives and equate their values at 0 to the given initial conditions, y = c1ex + c2e­x, y = c1ex ­ c2e­x, y(0) = c1 + c2 = 6, y (0) = c1 ­ c2 = ­2 By addition and subtraction, c = 2, c = 4, so that the answer is y = 2ex + 4e­x.
This is the 1 2 particular solution satisfying the two initial conditions.
19  3.2 Second Order Linear ODEs ORDINARYDIFFERENTIAL EQUATION 3.2.1 Homogeneous Linear ODEs with Constant Coefficients In this section, you shall study second-order homogeneous linear ODEs whose coefficients a and b, y + ay + by = 0.
(44) How to solve (44)?
You remember that the solution of the first-order linear ODE with a constan coefficient k y + ky = 0 is an exponential function y = ce­kx.
This gives you the idea to try as a solution of (44) the function y = eλx.
(45) Substitutin (45), and its derivative y = λeλx and y = λ2eλx into your equation (44), you obtain (λ2 + aλ + b)eλx = 0.
Hence if λ is a solution of the important characteristic equation (or auxiliary equation) λ2 + aλ + b = 0 (46) then the exponential function (45) is a solution of the ODE (44).
Now from elementary algebra you recall that the roots of this quadratic equation (46) are 1 √ 1 √ λ1 = 2 (­a + ­ 4b), λ1 = 2 (­a ­ ­ 4b) (47) a2 a2 (46) and (47) will be basic because our derivation shows that the functions y = eλ1 x and y = eλ2 x (48) 1 2 are solutions of (44).
Verify by substituting (48) into (44).
From algebra you further know that the quadratic equation (46) may have three kinds of roots, depending on the sign of the discriminant a2 ­ 4b, namely, (Case I) Two real and distinct roots if a2 ­ 4b > 0, (Case II) A real and repeated root if a2 ­ 4b = 0, (Case III) Complex conjugate roots if a2 ­ 4b < 0.
20  3.2 Second Order Linear ODEs ORDINARYDIFFERENTIAL EQUATION Case I.
Two Distinct Real Roots λ1 and λ2 In this case, a basis of solutions of (44) on any interval is y1 = eλ1 x and y2 = eλ2 x because y and y are defined (and real) for all x their quotient is not constant.
The corresponding general 1 2 equation is y = c eλ1 x + c eλ2 x (49) 1 2 Example 3.20 You can now solve y ­ y = 0 in Example 3.19 systematically.
The characteristic equation is λ2 ­ 1 = 0.
Its roots are λ1 = 1 and λ2 = ­1.
Hence a basis of solutions is ex and e­x and gives the same general solution as before.
y = c ex + c e­x.
1 2 Example 3.21 Solve the initial value problem y + y ­ 2y = 0, y(0) = 4, y (0) = ­5 Solution.
Step 1.
General solution.
The characteristic equation is λ2 + λ ­ 2 = 0.
Its roots are √ √ λ1 = 12 (­1 + 9) = 1 and λ2 =2 1 (­1 ­ 9) = ­2 so that you obtain the general solution y = c ex + c e­2x.
1 2 Step 2.
Particular solution.
Since y (x) = c1ex ­ 2c2e­2x, you obtain from the general solution and the initial conditions y(0) = c + c = 4 1 2 y (0) = c1 ­ 2c2 = ­5 Hence c = 1 and c = 3.
This gives the answer y = ex + 3e­2x.
1 2 21  3.2 Second Order Linear ODEs ORDINARYDIFFERENTIAL EQUATION Case II.
Real Double Root λ = ­a/2 If the discriminant a2 ­ 4b is zero, you see directly from (47) that you get only one root, λ = λ1 = λ2 = ­a/2, hence only one solution, y = e­(a/2)x.
1 To obtain a second independent solution y (needed for a basis), you use the method of reduction of order 2 discussed in the last section, setting y = uy .
Substituting this and its derivatives y = u y + uy and y 2 1 2 1 1 2 into (44), you first have (u y + 2u y + uy ) + a(u y + uy ) + buy = 0 1 1 1 1 1 1 Collecting terms in u , u , and u, as in the last section, you obtain u y + u (2y + ay ) + u(y + ay + by ) = 0.
1 1 1 1 1 1 The expression in the last parentheses is zero, since y is a solution of (44).
The expression in the first 1 parentheses is zero, too, since 2y1 = ­ae­ax/2 = ­ay1.
You are thus left with u y = 0.
Hence u = 0.
By two integrations, u = c x + c .
To get a second 1 1 2 independent solution y = uy , you can simply choose c = 1, c = 0 and take u = x.
Then y = xy .
2 1 1 2 2 1 Since these solution are not proportional, they form a basis.
Hence in the case of a double root of (46) a basis of solutions (44) on any interval is e­ax/2, xe­ax/2, The corresponding general solution is y = (c + c x)e­ax/2 (50) 1 2 Example 3.22 The characteristic equation of the ODE y + 6y + 9y is λ2 + 6λ + 9 = (λ + 3)2 = 0.
It has the double root λ = ­3.
Hence a basis is e­3x and xe­3x.
The corresponding general solution is y = (c + c x)e­3x.
1 2 Example 3.23 Solve the initial value proble y + y + 0.25y = 0, y(0) = 3.0, y (0) = ­3.5 Solution.
The characteristic equation is λ2 + λ + 0.25 = (λ + 0.5)2 = 0.
It has the double root λ = ­0.5.
This gives the general solution y = (c + c x)e­0.5x.
1 2 You need it derivative y = c2e­0.5x ­ 0.5(c1 + c2x)e­0.5x.
From this and the initial conditions you obtain y(0) = c1 = 3.0, y (0) = c2 ­ 0.5c1 = ­3.5; hence c2 = ­2.
The particular solution of the initial value problem is y = (3 ­ 2x)e­0.5x 22  3.2 Second Order Linear ODEs ORDINARYDIFFERENTIAL EQUATION Case III.
Complex Roots ­ 1 a + iω and ­ 1 a ­ iω 2 2 This case occurs if the discriminant a2 ­ 4b of the characteristic equation (46) is negative.
In this case, the roots of (46) and thus the solutions of the ODE (44) come at first out complex.
However, you show that from them you can obtain a basis of real solutions y = e­ax/2 cos ωx, y = eax/2 sin ωx (ω > 0) (51) 1 2 where ω2 = b ­ 1 a2.
It can be verified by substitution that these are solutions in the present case.
You can 4 derive them systematically after the two examples by using the complex exponential function.
They form a basis on any interval since their quotient cot ωx is not constant.
Hence a real general solution in Case III is y = eax/2(A cos ωx + B sin ωx) (A, B, arbitray).
(52) Example 3.24 Solve the inital valued problem y + 0.4 + 0.4y = 0, y(0) = 0 y (0) = 3.
Solution.
Step 1.
General solution.
The characteristic equation is λ2 + 0.4λ + 9.04 = 0.
It has the roots ­0.2 ± 3i.
Hence ω = 3, and the genral solution (52) is y = e­0.2x(A cos 3x + B sin 3x).
Step 2.
Particular solution.
The first initial condition gives y(0) = A = 0.
The remaining expresion is y = Be­0.2x sin 3x.
You need the derivative (chain rule!)
y = B(­0.2e­0.2x sin 3x + 3e­0.2x cos 3x).
From this and the second initial condition, you should obtain y (0) = 3B = 3.
Hence B = 1.
Your solution is then y = e­0.2x sin 3x.
Example 3.25 Complex Roots A general solution of the ODE y + ω2y = 0 (ω constant, not zero) is y = A cos ωx + B sin ωx.
With ω = 1, this comfirms example 3.17.
23  3.2 Second Order Linear ODEs ORDINARYDIFFERENTIAL EQUATION 3.2.2 Nonhomogeneous ODEs Method of Undetermined Coefficients In this section you will be introduced to nonhomogeneous linear ODEs y + p(x)y + q(x)y = r(x) (53) where r(x) /= 0.
You will see that a “general solution” of (53) is the sum of a general solution of the corresponding homogeneous ODE y + p(x)y + q(x)y = 0 (54) and a “particular solution” of (53).
These two new terms “general solution of (53)” and a particular solution of (53)“ are defined as follows.
Definition 3.3 General Solution, Particular Solution A general solution of the nonhomogeneous ODE (53) on an open interval I is a solution of the form y(x) = y (x) + y (x); (55) h p here, y = c y + c y is a general solution of the homogeneous ODE (54) on I and y is any solution of h 1 1 2 2 p (53) on I containing no arbitrary constants.
A Particular solution of (53) on I is a solution obtained from (55) by assigning specific values to the arbitrary constants c and c in y .
1 2 h Your task is now two fold, first to justify these definitions and then to develop a method for finding a solution y of (53).
p Accordingly, you should first show that a general solution as just defined satisfied (53) and that the solution of (53) and (54) are related in a very simple way.
Theorem 3.4 Relations of Solutions of (53) to Those of (54) (a) The sum of a solution y of (53) on some open interval I and a solution y˜ of (54) on I is a solution (53) on I .
In particular, (55) is a solution of (53) on I .
(b) The difference of two solutions of (53) on I is a solution of (54) on I.
Proof.
(a) Let L[y] denote the left side of (53).
Then for any solutions y of (53) and y˜ of (54) on I , L[y + y˜] = L[y] + L[y˜] = r + 0 = r. (b) For any solutions y and y∗ of (53) on I you have L[y ­ y∗ ] = L[y] ­ L[y∗ ] = r ­ r = 0.
Now for homogeneous ODEs (54) you know that general solutions include all solutions.
You show that the same is true for nonhomogeneous ODEs (53).
24  3.2 Second Order Linear ODEs ORDINARYDIFFERENTIAL EQUATION Theorem 3.5 A General Solution of a Nonhomogeneous ODE includes All Solutions If the coefficients p(x), q(x), and the function r(x) in (53) are continuous on some open interval I , then every solution of (53) on I is obtained by assigning suitable values to the arbitrary constants c and c in a 1 2 general solution (55) on I .
Proof.
Let y∗ be any solution of (53) on I and x and x in I .
Let (55) be any general solution of (53) 0 on I This solution exists Indeed, y = c y + c y exists (why?)
because of the continuity assumption, and h 1 1 2 2 yp exists according to a construction (how?)
Now, by theorem 1(b) just proved, the difference Y = y∗ ­ yp is a solution of (54) on I .
At x you have 0 Y (x0) = y∗ (x0) ­ yp(x0), Y (x0) = y∗ (x0) ­ yp(x0).
Existence and uniqueness theorem (proved in the next unit) implies that for these conditions, as for any other initial conditions in I , there exists a unique particular solution of (54) obtained by assigning suitable values to c , c in y .
From this and y∗ = Y + y the statement follows.
1 2 h p Method of Undetermined Coefficients Your discussion suggests the following.
To solve the nonhomogeneous ODE (53) or an initial value problem for (53), you have to solve the homogeneous ODE (54) and find any solution y of (53), so that you obtain p a general solution (55) of (53) How can you find a solution y of (53)?
One method is the so-called method of undetermined coeffi- p cients.
It is much simpler than another, more general method, (which may not be discussed in this book).
Since it applies to models of vibrational systems and electric circuits.
It is frequently used in engineering.
More precisely, the method of undetermined coefficients is suitable for linear ODEs with constant coefficients a and b y + ay + by = r(x) (56) when r(x) is an exponential function, a power of x, a cosine or sine, or sums or products of such functions.
These functions have derivatives similar to r(x) itself.
This gives the idea.
You choose a form for y similar p to r(x), but with unknown coefficients to determined by substituting that y and its derivatives into the p ODE.
Table 1 shows the choice of y for practically important forms of r(x).
Corresponding rules are as p follows.
Table 1: Method of Undetermined Coeffients Term in r(x) Choice fory (x) p keγx Ceγx kxn (n = 0, 1, · · · ) Knxn + Kn ­ 1 xn­1 + · · · + K 1 x + K0 k cos ωx K cos ωx + M sin ωx k sin ωx keαx cos ωx eαx(K cos ωx + M sin ωx) keαx sin ωx 25  3.2 Second Order Linear ODEs ORDINARYDIFFERENTIAL EQUATION Example 3.26 Application of the Basic Rule (a) Solve the initial value problem y + y = 0.001x2, y(0) = 0, y (0) = 1.5.
(57) Solution.
Step 1.
General solution of the homogeneous ODE.
The ODE y + y = 0 has the general solution y = A cos x + B sin x. h Step 2.
Solution y of the nonhomogeneous ODE.
First try y = K x2.
Then y = 2K.
By substitu- p p p tion.
By substitution, 2K + K x2 = 0.001x2.
For this to hold for all x. the coefficient of each power of x (x2 and x0) must be the same on both sides; thus K = 0.001 and 2K = 0, a contradiction.
The second line in Table 1 suggests the choice y = K x2 + K x + K .
Then y + y = 2K + K x2 + K x + K = 0.001x2.
p 2 1 0 p p 2 2 1 0 Equating the coefficients of x2, x, x0 on both sides, you have K = 0.001, K = 0.2K + K = 0.
2 1 2 0 Hence K0 = ­2K2 = ­0.002.
This gives yp = 0.001x2 ­ 0.002, and y = yh + yp = A cos x + B sin x + 0.001x2 ­ 0.002.
Step 3.
Solution of the initial value problem.
Setting x=0 and using the first initial condition gives y(0)=A-0.002=0, hence A=0.002.
By differentiation and from the second initial condition.
y = y + y = ­A sin x + B cos x + 0.002x and y (0) = B = 1.5. h p This gives the answer y = 0.002 cos x + 1.5 sin x + 0.001x2 ­ 0.002.
Example 3.27 Application of the Modification Rule (b) Solve the initial value problem y + 3y + 2.25y = ­10e­1.5x, y(0) = 1, y (0) = 0.
(58) Solution.
Step 1.
General solution of the homogeneous ODE.
The characteristic equation of the homogeneous ODE is λ2 + 3λ + 2.25 = (λ + 1.5)2 = 0.
Hence the homogeneous ODE has the general solution y = (c + c )e­1.5x.
h 1 2 Step.
2 Solution y of the nonhomogeneous ODE.
The function e­1.5x on the right would normally p require the choice C e­1.5x.
But you see from y that this function is a solution of the homogeneous h ODE, which corresponds to a double root of the characteristic equation.
Hence, according to the Modification Rule you have to multiply you2r6 c hoice function by x2.
That is, you choose  3.2 Second Order Linear ODEs ORDINARYDIFFERENTIAL EQUATION yp = C x2e­1.5x Then yp = C (2x ­ 1.5x2)e1.5x, y = C (2 ­ 3x ­ 3x + 2.25x2)e­1.5x.
p Substituting these expressions into the give ODE and omit the factor e­1.5x.
This yields C (2 ­ 6x + 2.25x2) + 3C (2x ­ 1.5x2) + 2.25C x2 = ­10.
Comparing the coefficients of x2, x, x0 gives 0 = 0, 0 = 0, 2C = ­10, hence C = ­5.
This gives the solution yp = ­5x2e­1.5x.
Hence the given ODE has the general solution y = yh + yp = (c1 + c2)e­1.5x ­ 5x2e­1.5x.
Step 3.
Solution of the initial value problem.
Setting x = 0 in y and using the first initial condition, you obtain y(0) = c = 1.
Differentiation of y gives 1 y = (c2 ­ 1.5c1 ­ 1.5c2x)e­1.5x ­ 10xe­1.5x + 7.5x2e­ 1.5x From this and the second initial condition you have y (0) = c2 ­ 1.5c1 = 0.
Hence c2 = 1.5c1 = 1.5.
This gives the answer y = (1 + 1.5x)e­1.5x ­ 5x2e­1.5x = (1 + 1.5x ­ 5x2)e­ 1.5x.
Example 3.28 Application of the Sum Rule (c) Solve the initial value problem y + 2y + 5y = e0.5x + 40 cos 10x ­ 190 sin 10x, y(0) = 0.16 y (0) = 40.08 (59) Solution.
Step 1.
General solution of the homogeneous ODE.
The characteristic equation λ2 + 2λ + 5 = (λ + 1 + 2i)(λ + 1 ­ 2i) = 0 shows that a real general solution of the homogeneous ODE is y = e­x(A cos 2x + B sin 2x) h Step 2.
Solution of the nonhomogeneous ODE.
Write y = y + y , where y corresponds to the p p1 p2 p1 exponential term and y to the sum of the order two terms.
Set p2 y = C e0 .5x then y = 0.5C e 0.5x and y = 0.25C e 0.5x.
p1 p1 p1 27  3.2 Second Order Linear ODEs ORDINARYDIFFERENTIAL EQUATION Substitution into the given ODE and omission of the exponential factor gives (0.25 + 2.05 + 5)C = 1, hence C = 1/6.25 = 0.16, and yp1 = 0.16e 0.5x.
Now set y = K cos 10x + M sin 10x, as in Table 1, and obtain p2 y = ­10K sin 10x + 10M cos 10x, y = ­100K cos 10x ­ 100M sin 10x.
p2 p2 Substitution into the given ODE gives for the cosine terms and for the sine terms ­100K + 2 · 10M + 5K = 40, ­100M ­ 2 · 10K + 5M = ­190 The solution is K = 0, M = 2.
Hence y = 2 sin 10x.
Together, p2 y = y + y + y = e­x(A cos 2x + B sin 2x) + 0.16e 0.5x + 2 sin 10x.
h p1 p2 Step 3.
Solution of the initial value problem.
From y and the first initial condition, y(0) = A+0.16 = 0.16, hence A = 0.
Differentiation gives y = e­x(­A cos 2x ­ B sin 2x ­ 2A sin 2x + 2B cos 2x) + 0.08e0.5x + 20 cos 10x.
From this and the second initial condition you have y 0 = ­A + 2B + 0.08 + 20 = 40.08, hence B = 10.
This gives the solution 10e­x sin 2x + 0.16e0.5x + 2 sin 10x.
3.2.3 Solution by Variation of Parameters Here is a continuation of the discussion of nonhomogeneous linear ODEs y + p(x)y + q(x)y = r(x).
(60) In previous sections you have seen that a general soluton of (60) is the sum of the general solution y of h the corresponding homogeneous ODE and any particular solution y of (60).
To obtain y when r(x) is not p p too complicated, you can often use the method of undetermined coefficients, as you have shown in the last section.
However, since this method is restricted to functions r(x) whose derivatives are of a form similar to r(x) itself (powers, exponential functions, etc.
), It is desirable to have a method valid for more general ODEs (53), which you shall now develop.
It is called the method of variation of parameters and is credited to Lagrange.
Here p, q, r in (1) may be variable (given functions of x), but you should assume that they are continuous on some open interval I .
Lagrange’s method gives a particular solution y of (53) on I in form p y r y r yp(x) = ­y1 W2 dx + y2 W1 dx (61) where y , y form a basis of solutions of the corresponding homogeneous ODE 1 2 y + p(x)y + q(x)y = 0 (62) 28  4 Conclusion ORDINARYDIFFERENTIAL EQUATION on I , and W is the Wronskian of y , y , 1 2 x y y W = det y1 y2 = y1y2 ­ y2y1 (63) 1 2 Example 3.29 Method of Variation of Parameters Solve the nonhomogeneous ODE 1 y + y = sec x = .
cos x Solution.
A basis of solutions of the homogeneous ODE on any interval is y = cos x, y = sin x.
This gives 1 2 the Wronskian W (y1, y2) = cos x cos x ­ sin x(­ sin x) = 1.
From (61), choosing zero constant of integratio, you get the particular solution of the given ODE yp = ­ cos x sin x sec x dx + sin x cos x sec x dx = cos x ln | cos x| + x sin x From y and the general solution y = c y + c y of the homogeneous ODE you obtain the answer p h 1 1 2 2 y = yh + yp = (c1 + ln | cos x|) cos x + (c2 + x) sin x.
Had you included integration constants ­c1, c2 in (61), then (61) would have given the additional c cos x + c sin x = c y + c y , that is, a general solution of the given ODE directly from (61).
This 1 2 1 1 2 2 will always be the case.
3.3 Higher Order Linear ODEs Recall that an ODE is of nth order if the nth derivative y(n) = dny/dxn of the unknown function y(x) is the highest occurring derivative.
Thus the ODE is of the form x d ny F (x, y, y , ..., y(n)) = 0 y(n) = dxn where lower order derivatives and y itself may or may not occur.
Such an ODE is called linear if it can be written y(n) + pn­ 1 (x)y(n­1) + · · · + p1 (x)y + p0 (x)y = r(x).
(64) (For n = 2 you return to second order equation with p = p and p = q).
The coefficients p , ..., p and 1 0 0 n­1 the function r on the right are any given functions of x, and y is unknown.
y(n) has coefficient 1.
This is 29  3.3 Higher Order Linear ODEs ORDINARYDIFFERENTIAL EQUATION practical, and it is called the standard form.
(If you have p (x)y(n)), divide by p (x) to get this form.)
An n n nth-order ODE that cannot be written in the form (64) is called nonlinear.
If r(x) is identically zero, r(x) ≡ 0 (zero for all x considered, usually in some open interval I ), then (64) becomes y(n) + pn­ 1 (x)y(n­1) + · · · + p1 (x)y + p0 (x)y = 0 (65) and is called homogeneous.
If r(x) is not identically zero, then the ODE is called nonhomogeneous.
A solution of an nth-order (linear or nonlinear) ODE on some open interval I is a function y = h(x) that is defined and n times differentiable on I and is such that the ODE becomes an identity if you replace the unknown function y and its derivatives by h and its corresponding derivatives.
The extension of the concepts and methods of section 3.2 for linear ODEs from order n=2 to arbitrary order n is easily obtained.
This is straightforward and needs no new ideas.
However, the formulas become more involved, the variety of roots of the characteristic equation becomes much larger with increasing n, and the Wronskian plays a more prominent role.
For a detailed study on higher order ODE, see unit 3.
4 Conclusion In this unit, you have studied ordinary differential equations (ODEs) of first order, second order and of higher order (n > 2).
You have used different approach in solving some first order differential equation and second order ordinary differential equation.
You have also proved some important theorem of higher order differential equation, which are obvious extensions of the theorems proved for second order ordinary differential equations.
5 Summary Having gone through this unit, you now know that (i) first order ODEs are equations of the form F (x, y, y ) = 0 or in explicit form y = f (x, y) involving the derivative y = dy/dx of an unknown function y, given functions of x, and, perhaps, y itself.
If the independent variable x is time, you denote it by t. (ii) A general solution, of a first-order ODE is a solution involving an arbitrary constant, which you denoted by c. (iii) unique solutions can be found by determining a value of c from an initial condition y(x ) = y .
0 0 (iv) An ODE together with an initial condition is called an initial value problem y = f (x, y), y(x ) = y (x , y given numbers) 0 0 0 0 and its solution is a particular solution of the ODE.
30  6 Tutor Marked Assignments(TMAs) ORDINARYDIFFERENTIAL EQUATION (v) A separable ODE is one that you can put into the form g(y)dy = f (x)dx and solve by integrating both sides (vi) An exact ODE is of the form M (x, y)dx + N (x, y)dy = 0 where M dx + N dy is the differential du = u dx + u dy x y of a function u(x, y), so that from du=0 you immediately get the implicit general solution u(x, y) = c. This methods extend to nonexact ODEs that can be made exact by multiplying then by some function F (x, y), called the integrating factor (vii) Linear ODEs are such of the form y + p(x)y = r(x) (viii) The Bernoulli equation are equations of the form y + p(x)y = g(x)ya (ix) A second-order ODE is called linear if it can be written y + p(x)y + q(x)y = r(x) (x) it is homogeneous if r(x) is zero for all x considered, usually in some open interval; this is written r(x) ≡ 0.
Then y + p(x)y + q(x)y = 0.
(xi) If r(x) /= 0 for some x considered, then the second order linear ODE is called nonhomogeneous.
(xii) by superposition principle the linear combination y = ky + ly of two solutions y , y is again a 1 2 1 2 solution.
(xiii) Two linearly independent solutions y , y of a homogeneous ODE on an open interval I form a basis 1 2 (or fundamental system) of solutions on I and y = c y + c y with arbitrary constants c , c is a 1 1 2 2 1 2 general solution of the homogeneous ODE on I .
From it you can obtain a particular solution if you specify numeric values (numbers) for c and c , usually by prescribing two initial conditions 1 2 y(x ) = K , y (x ) = K (x , K , K are given numbers) 0 0 0 1 0 0 1 a second order ODE together with an initial conditions form an initial value problem.
(xiv) the general solution of a nonhomogenous ODE is of the form y = yh + yp where y is a general solution of the homogeneous part and y is a particular solution of the nonhomo- h p geneous part obtained by a general method, variation of parameters, or in many practical cases by 31  5 Summary ORDINARYDIFFERENTIAL EQUATION the method of undetermined coefficients.
The latter applies when second order ODE has constant coefficients p and q, and r(x) is a power of x, sine, cosine, etc.
Then you can write the second order ODE as y + ay + by = r(x) The corresponding homogeneous ODE y + ay + by = 0 has solutions y = eλx, where λ is a root of λ2 + aλ + b = 0.
Hence there are three cases which are Case Type ofRoots GeneralSolution I Distinct realλ1,λ2 y = c1eλ1 x +c2eλ2 x II Double ­ 1 a y = (c1 + c2x)e­ax/2 2 III Complex ­ 1 a ±iω∗ y = e­ax/2(A cos ω∗x + B sin ω∗x) 2 6 Tutor Marked Assignments(TMAs) Exercise 6.1 First-Order ODEs Find the general solution using suitable method.
1. y = x2(1 + y2) (a) y = 1 tan(2x + c) 2 (b) y = tan(x3 + c) (c) y = 2 tan(x3 ­ c) (d) y = tan( x3 + c) 3 2. yy + xy2 = x √ (a) y = 1 + ce­x2 (b) y = 1 + ce­x2 (c) y = 1 + ce­x √ (d) y = 1 + ce­x 3. y + y sin x = sin x (a) y = cecos x + 1 (b) y = ce­ cos x + 1 (c) y = cesin x + 1 (d) y = ce­ sin x + 1 4.
3 sin 2ydx + 2x cos 2ydy = 0 32  6 Tutor Marked Assignments(TMAs) ORDINARYDIFFERENTIAL EQUATION (a) sin 2y = ­cx3 (b) sin y = cx3 (c) sin 2y = cx­3 (d) sin 2y = c x3 2 5.
(y cos xy ­ 2x)dx + (x cos xy + 2y)dy = 0 (a) sin y ­ x2 + xy = c (b) sin xy ­ x2 + y2 = c (c) sin xy ­ x2 + y = c (d) sin y2 ­ xy + y2 = c 6. sin(y ­ x)dx + [cos(y ­ x) ­ sin(y ­ x)]dy = 0 (a) ex sin(y ­ x) = c (b) ey cos(y ­ x) = c (c) ey sin(y ­ x) = c (d) ex cos(y ­ x) = c Solve the following initial value problems using suitable method in each case.
7. yy + x = 0, y(3) = 4 (a) y2 + x2 = 16 (b) y2 + x2 = 25 (c) y2 ­ x2 = 16 (d) y2 ­ x2 = 25 8. y = 1 + y2, y( 1 π) = 0 4 (a) y = tan(x ­ 1 π) 4 (b) y = tan(x + 1 π) 4 (c) y = tan(2x ­ 1 π) 4 (d) y = tan(2x + 1 x) 4 9.
(2xy2 ­ sin x)dx + (2 + 2x2y)dy = 0, y(0) = 1 (a) x2y + sin x + 2y = c (b) x2y + cos x + 2y = c (c) x2y2 + sin x + 2y = c (d) x2y2 + cos x + 2y = c Exercise 6.2 Second Order ODEs Find a general solution in the following 33  6 Tutor Marked Assignments(TMAs) ORDINARYDIFFERENTIAL EQUATION 1. y ­ 2y ­ 8y = 52 cos 6x (a) c1e4x + c2e­2x ­ 1.1 cos 6x + 0.3 sin 6x (b) c1e4x + c2e­2x + 1.1 cos 6x ­ 0.3 sin 6x (c) c1e4x + c2e­2x ­ 1.1 cos 6x ­ 0.3 sin 6x (d) c e4x + c e­2x + 1.1 cos 6x + 0.3 sin 6x 1 2 2. y + 8y + 25y = 26 sin 3x (a) e­4x(A cos 3x + B sin 3x) ­ 3 cos 3x ­ 1 sin 3x 4 2 (b) e­4x(A cos 3x + B sin 3x) ­ 3 cos 3x + 1 sin 3x 4 2 (c) e­4x(A cos 3x + B sin 3x) ­ 3 sin 3x + 1 cos 3x 4 2 (d) e­4x(A cos 3x + B sin 3x) + 3 sin 3x ­ 1 cos 3x 4 2 Solve the following initial value problems.
3. y + 5y ­ 14y = 0, y(0) = 6, y (0) = ­6 (a) y = 4e2x ­ 2e­7x (b) y = 4e2x + 2e­7x (c) y = 4e2x + 2e7x (d) y = 4e2x ­ 2e7x 4. x2y ­ xy ­ 24y = 0, y(1) = 15, y (1) = 0 (a) y = 9x­4 + 6x6 (b) y = 9x4 + 6x6 (c) y = 9x­4 + 6x­6 (d) y = 9x4 + 6x­6 5. y + 5y + 6y = 108x2, y(0) = 18, y (0) = ­26 (a) y = e­2x ­ 2e­3x + 18x2 ­ 30x + 19 (b) y = e­2x + 2e­3x + 18x2 ­ 30x + 19 (c) y = e­2x ­ 2e­3x + 18x2 + 30x + 19 (d) y = e­2x ­ 2e­3x + 18x2 ­ 30x ­ 19 Exercise 6.3 Higher-Order ODEs Solve the given ODE.
1.
4x2y + 12xy + 3y = 0 (a) c + c x1/2 + c x­1/2 1 2 3 (b) c1 + c2x1/2 + c3x1/2 34  6 Tutor Marked Assignments(TMAs) ORDINARYDIFFERENTIAL EQUATION (c) c1 + c2x­1/2 + c3x­1/2 35  6 Tutor Marked Assignments(TMAs) ORDINARYDIFFERENTIAL EQUATION (d) c1 + c2x­1/2 + c3x1/2 2.
8y + 12y ­ 2y ­ 3y = 0 (a) c e­0.5x + c e0.5x + c e1.5x 1 2 3 (b) c e0.5x + c e­0.5x + c e­1.5x 1 2 3 (c) c e­0.5x + c e0.5x + c e­1.5x 1 2 3 (d) c e0.5x + c e0.5x + c e1.5x 1 2 3 Solve the given initial value problem.
3. x3y + 7x2y ­ 2xy ­ 10y = 0, y(1) = 1, y (1) = ­7, y (1) = 44 (a) 0.5x­1 ­ 1.5x­5 (b) 0.5x­1 + 1.5x­5 (c) ­0.5x­1 ­ 1.5x­ 5 (d) ­0.5x­1 + 1.5x ­5 36  UNIT 2: EXISTENCE AND UNIQUENESS THEOREM Contents 1 Introduction 34 2 Objectives 34 3 Main Content 35 3.1 Existence and Uniqueness Theorem of First-Order Equations 35 3.1.1 Some Concepts from Real Function Theory 35 3.1.2 Existence and Uniqueness of Solutions 40 3.1.3 Dependence of Solutions on Initial Condition and on the Function f 45 3.2 Existence and Uniqueness Theorem of Linear Differential Equations 47 3.2.1 The Basic Existence Theorem 47 3.2.2 Basic Existence and Uniqueness theorems on Linear Systems 49 4 Conclusion 52 5 Summary 53 6 Tutor Marked Assignments (TMAs) 53 1 Introduction In Unit 1, you were introduced to basic methods of obtaining solutions of some nth order (n _ 1) ordinary differential equation.
In this unit, your attention shall be directed to the more theoretical aspects of differential equation.
2 Objectives At the end of this unit, the student should be able to; (i) say when a first order ODE has a solution, a unique solution or no solutions.
34 None 3 Main Content (ii) say when a function of two variables satisfies a Lipschitz condition on the second variable.
(iii) approximate a solution of an ODE using the Picard’s iteration.
(iv) describe the dependence of a solution on initial condition on the function f. (v) state and apply the existence theorem for linear differential equations.
3 Main Content 3.1 Existence and Uniqueness Theorem of First-Order Equations In order to fully understand the proof of this theorem and those which follow, you will need to be familiar with certain concepts of real function theory.
Since you may not be familiar with all these topics, the first section will be devoted to a brief survey of some of them.
3.1.1 Some Concepts from Real Function Theory Uniform Convergence Definition 3.1 (Convergent Sequence of Real Numbers) A sequence {xn} of real numbers is said to converge to the limit x if, given any E > 0, there exists a positive number N such that |xn ­ x| < E for all n > N. This you can indicate by writing lim x = x. n n→∞ Definition 3.2 (Pointwise Convergence) A sequence {fn} of real valued functions fn : I ⊂ R → R (n ≥ 1) defined on an interval I of R is said to converge to a real valued function f : I → R if given any E > 0, and x ∈ I , there exists N = N (E, x) ∈ N such that |fn(x) ­ f (x)| ≤ E for all n ≥ N Definition 3.3 (Uniform Convergence) A sequence {fn} of real valued functions fn : I ⊂ R → R (n ≥ 1) defined on an interval I of R is said to converge to a real valued function f : I → R if given any E > 0, there exists N = N (E) ∈ N such that |fn(x) ­ f (x)| ≤ E for all n ≥ N and for all x ∈ I .
Example 3.1 Consider the sequence of functions {fn} defined for all x on the real interval 0 ≤ x ≤ 1 by nx2 fn(x) = nx + 1 0 ≤ x ≤ 1, (n = 1, 2, 3, ...) Solution.
35  3.1 Existence and Uniqueness Theorem ofFirst-Order Equations For x = 0, The corresponding sequence {fn(0)} of real numbers is 0, 0, 0, ... and lim fn(0) = 0.
For every x n→∞ such that 0 < x ≤ 1, you have nx2 f (x) = and lim f (x) = x n nx + 1 n→∞ n Thus the sequence {fn} converges pointwise on 0 ≤ x ≤ 1 to the limit function f defined by f (x) = x, 0 ≤ x ≤ 1.
Futher the convegence is uniform on 0 ≤ x ≤ 1.
To this, consider nx2 x |fn(x) ­ f (x)| = ­ x = nx + 1 nx + 1 x 1 1 Given E > 0, you have ≤ E provided n > ­ .
But for x such that 0 ≤ x ≤ 1, you have nx + 1 E x 1 1 1 1 1 1 ­ ≤ ­ 1.
Thus if you choose N = ­ 1, you have that n > ­ for all n > N. Hence, given E > E x E E E x 0, there exists N = 1E ­ 1 (depending only upon E and not on x) such that |fn(x) ­ f (x)| < E for all n > N for every x such that 0 ≤ x ≤ 1.
In other words, the convergence is uniform on 0 ≤ x ≤ 1.
The following are two important theorems on uniformly convergent sequences which shall be used in the proof of existence theorem.
You can find the proofs of this theorem in most texts on advanced calculus and real analysis.
Theorem 3.1 Let {fn} be a sequence of real valued functions which converges uniformly to f on the interval a ≤ x ≤ b.
Suppose each function fn(n = 1, 2, 3, ...) is continuous on a ≤ x ≤ b.
Then the limit function f is continuous on a ≤ x ≤ b.
Example 3.2 In Example 3.1 you saw that the sequence of functions {fn} defined on the real interval 0 ≤ x ≤ 1 by nx2 f (x) = , (n = 1, 2, 3, ...) n nx + 1 converges uniformly to a limit function f on 0 ≤ x ≤ 1.
Further, each function fn(n = 1, 2, 3, ...) is continuous on 0 ≤ x ≤ 1.
By theorem 3.1, you could conclude at once that the limit function f is also continuous on 0 ≤ x ≤ 1.
Indeed, in this example, the limit function f is that defined by f (x) = x, 0 ≤ x ≤ 1, and clearly this function f is continuous on 0 ≤ x ≤ 1 Theorem 3.2 Let {fn} be a sequence of real functions which converges uniformly to f on the interval a ≤ x ≤ b. Suppos each function fn(n = 1, 2, 3, ...) is continuous on a ≤ x ≤ b.
Then for every α and β such that a ≤ α < β ≤ b, β β lim f (x)dx = lim f (x)dx n n n→∞ α α n→∞ Example 3.3 You could illustrate this theorem by again considering the sequence of functions {fn} dis- cussed in Examples 3.1 and 3.2 and defined by nx2 fn(x) = nx + 1 , 0 ≤ x ≤ 1, (n = 1, 2, 3, ...) The hypothesis of Theorem 3.2 is identical with that of theorem 3.1, and you have already noted in Example 3.2 that the sequence under consideration satisfies this hypothesis on 0 ≤ x ≤ 1.
Thus you could 3 Main Content conclude that 1 1 lim f (x)dx = lim f (x)dx n 36 n n→∞ 0 0 n→ß 37 3.1 Existence and Uniqueness Theorem ofFirst-Order Equations Since lim f (x) = f (x) = x in this example, you conclusion here would be that n n→∞ 1 nx2 1 lim dx = xdx n→∞ 0 nx + 1 0 You could verify this directly, r 1 1 nx2 1 1 1 dx = x ­ + dx nx + 1 n n(nx + 1) 0 0 x2 x 1 1 = ­ + ln(nx + 1) = 1 ­ 1 + ln(n+1) 2 n n2 2 n n 2 0 This r 1 1 nx2 1 1 ln(n + 1) 1 lim dx = lim ­ + = n→∞ 0 nx + 1 n→∞ 2 n n2 2 1 1 Clearly xdx = , also, and your conclusion is thus verified.
2 0 Next is to consider briefly the uniform convergence of an infinite series of real functions, each of which is defined on a real interval a ≤ x ≤ b.
)∞ Definition 3.4 Consider the infinite series u of real functions u (n = 1, 2, 3, ...), each of which is n n n=1 defined on a real interval a ≤ x ≤ b.
Consider the sequence {fn} of so-called partial sums of this series, defined as follows: (cid:31) (cid:31) f1 = u1 (cid:31) (cid:31) (cid:31)(cid:31) f2 = u1 + u2 (cid:31) (cid:31) (cid:31)(cid:31) f3 = u1 + u2 + u3 (cid:31) (cid:31) · · · · · · · (cid:31) (cid:31) (cid:31) (cid:31) fn = u1 + u2 + u3 + · · · + un (cid:31) (cid:31) (cid:31) · · · · · · · )∞ The infinite series un is said to uniform uniformly to f on a ≤ x ≤ b if its seqeunce of partial sums n=1 {fn} converges uniformly to f and a ≤ x ≤ b.
The following theorem gives you a very useful test for uniform convergence of series.
Theorem 3.3 (Weierstrass M-Test) Let {Mn} be a sequence of positive constants such that the series of )∞ )∞ constants Mn converges.
Let un be a series of real functions such that |un(x)| ≤ Mn, for all x such n=1 n=1 )∞ that a ≤ x ≤ b and for n = 1, 2, 3, .... Then the series un converges uniformly on a ≤ x ≤ b. n=1  3.1 Existence and Uniqueness Theorem ofFirst-Order Equations )∞ sinnx 1 Example 3.4 Consider the series on the interval 0 ≤ x ≤1.
The sequence is a sequence n2 n2 n=1 )∞ of positive constants which is such that the series 1 is convergent.
n2 n=1 You can take M = 1 and observe that n n2 sin nx 1 |un(x)| = n2 = n2 = Mn )∞ sinnx for all x such that 0 ≤ x ≤ 1 and for each n = 1, 2, 3, ...
Thus by theorem 3.3, the series x n=1 converges uniformly on 0 ≤ x ≤ 1.
Functions of Two Real Variables; the Lipschitz Condition.
Definition 3.5 1.
A set of points A of the xy plane will be called connected if any two points of A can be joined by a continuous curve which lies entirely in A.
2.
A set of points A of the xy plane is called open if each point of A is the center of a circle whose interior lies entirely in A.
3.
A open, connected set in the xy plane is called a domain.
4.
A point P is called a boundary point of a domain D if every circle about P contains both points in D and points not in D. 5.
A domain plus its boundary points will be called a closed domain.
Example 3.5 The set of all points (x, y) lying within the ellipse x2 +2y2 = 1 and characterized by x2 +y2 < 1 is a domain D. The boundary points of D are the points of the ellipse itself.
The set of points (x, y) such that x2 + 2y2 ≤ 1 within and on the ellipse is a closed domain.
It is assumed that you are somewhat familiar with functions f of two real variables x and y, defined on a domain of the xy plane or on such a domain plus its boundary.
The following are few concepts and results.
Definition 3.6 Let f be a real function defined on a domain D of the xy plane, and let (x , y ) be an 0 0 (interior) point of D. The function f is said to be continuous at (x , y ) if, given any E > 0, there exists a 0 0 δ > 0 such that |f (x, y) ­ f (x0, y0)| < E for all (x, y) ∈ D such that |x ­ x0| < δ and |y ­ y0| < δ Definition 3.7 Let f be a real function defined on D, where D is either a domain or a closed domain of the xy plane.
The function f is said to be bounded on D if there exists a positive number M such that |f (x, y)| ≤ M for all (x, y) in D. 39 3.1 Existence and Uniqueness Theorem ofFirst-Order Equations 38  3.1 Existence and Uniqueness Theorem ofFirst-Order Equations Theorem 3.4 Let f be defined and continuous on a closed rectangle R : a ≤ x ≤ b, c ≤ y ≤ d Then the function f is bounded on R. Example 3.6 The function f defined by f (x, y) = x2 + y2 is continuous on the closed rectangle R : 0 ≤ x ≤ 1, 0 ≤ y ≤ 2.
Thus by theorem 3.4, the function f is bounded on R. In fact, you have |f (x, y)| = |x2 + y2| ≤ 5 for all (x, y) ∈ R. Having disposed of these preliminaries, you would now be introduced to a concept which will be of paramount importance in the existence and uniqueness proof.
Definition 3.8 Let f be defined on D, where D is either a domain or a closed domain of the xy plane.
The function f is said to satisfy a Lipschitz Condition (with respect to y) in D if there exist a constant k > 0 such that |f (x, y1) ­ f (x, y2)| ≤ k|y1 ­ y2| (1) for every (x, y ) and (x, y ) which belong to D. The constant k is called the Lipschitz Constant.
1 2 The following theorem will help you to determine when a function f satisfies the Lipschitz condition.
∂f Theorem 3.5 Let f be such that exists and is bounded for all (x, y) ∈ D, where D is a domain or ∂y closed domain such that the line segment joining any two points of D lies entirely within D. Then f satisfies a Lipschitz Condition (with respect to y) in D, where the Lipschitz Constant is given by ∂f (x, y) k = sup (x,y)∈D ∂y Example 3.7 Consider the function f defined by f (x, y) = y2, where D is the rectangle defined by |x| ≤ a, ∂f (x, y) ∂f |y| ≤ b.
= 2y, and so exists and is bounded for all (x, y) ∈ D. Thus by theorem 3.5, ∂y ∂y Then the function f satisfies a Lipschitz Condition in D, where the Lipschitz Constant k is given by 2b.
If you directly apply the definition of Lipschitz condition instead of theorem 3.5, you would find that |f (x, y1) ­ f (x, y2)| = |y2 ­ y2| = |y1 + y2||y1 ­ y2| ≤ 2b|y1 ­ 1 2 y2| for all (x, y1), (x, y2) ∈ D. Note that the sufficient condition of theorem 3.5 is not necessary for f to satisfy a Lipschitz condition in D. That is, there exist functions f such that f satisfies a Lipschitz condition (with respect to y) in D but such that the hypothesis of theorem 3.5 is not satisfied.
Example 3.8 Consider the function f defined by f (x, y) = x|y|, where D is the rectangle defined by |x| ≤ a, |y| ≤ b.
Note that |f (x, y1) ­ f (x, y2)| = |x|y1| ­ x|y2|| ≤ |x||y1 ­ y2| ≤ a|y1 ­ 3.1 Existence and Uniqueness Theorem ofFirst-Order Equations y2| for all (x, y1), (x, y2) ∈ D. Thus f satisfies a Lipschitz Condition (with respect to y) in D. However the ∂f partial derivative does not exist at any point (x, 0) ∈ D for which x I= 0.
∂y 39  3.1 Existence and Uniqueness Theorem ofFirst-Order Equations 3.1.2 Existence and Uniqueness of Solutions The Basic Problem and a Basic Lemma The basic problem with which this unit is primarily concerned is formulated below as follows.
Let D be a domain in the xy plane and let (x , y ) be an (interior) point of D. Consider the differential 0 0 equation dy = f (x, y) (2) dx where f is a continuous real valued function defined on D. Consider the following problem.
Your wish is to determine: 1. an interval α ≤ x ≤ β of real x axis such that α < x0 < β, and 2. a differentiable real function φ defined on this interval [α, β] satisfying the following three require- ments: (a) (x, φ(x)) ∈ D, an thus f (x, φ(x)) is defined, for all x ∈ [α, β].
dφ(x) (b) = f [x, φ(x)], an thus φ satisfies the differential equation (2), for all x ∈[α, β].
dx (c) φ(x0) = y0 You should call this problem the initial-value problem associated with the differential equation (2) and the point (x , y ).
And denote it briefly by 0 0 (cid:31) dy (cid:31) (cid:31) = f (x, y) dx (3) (cid:31) (cid:31) y(x ) = y , 0 0 and call a function φ satisfying the above requirements on an interval [α, β] a solution of the problem on the interval [α, β].
If φ is a solution of the problem on [α, β], then the requirement (b) shows that φ has a continuous first derivative φ1 on [α, β].
In ordet to investigate this problem you shall need the following basic lemma.
Lemma 3.1 Let f be a continuous function defined on a domain D of the xy plane.
Let φ be a continuous function defined on a real interval α ≤ x ≤ β and such that [x, φ(x)] ∈ D for all x ∈ [α, β].
Let x0 be any dy real number such that α < x < β.
Then φ is a solution of the differential equation = f (x, y) on [α, β] dx and is such that φ(x ) = y if and only if φ satisfies the integral equation 0 0 x φ(x) = y0 + f [t, φ(t)]dt (4) x0 for all x ∈ [α, β].
dy dφ(x) Proof.
If φ satisfies the differential equation = f (x, y) on [α, β], then = f [x, φ(x)] for all dx dx x ∈ [α, β] and the integration yields at once x φ(x) = f [t, φ(t)]dt + c 40 x0  3.1 Existence and Uniqueness Theorem ofFirst-Order Equations If also φ(x0) = y0, then you have c = y0 and so φ satisfies the integral equation (4) for all x ∈ [α, β].
Conversely, if φ satisfies the integral equation (4) for all x ∈ [α, β], then differentiation yields dφ(x) = f [x, φ(x)] dx dy for all x ∈ [α, β] and so φ satisfies the differential equation = f (x, y) on [α, β]; also the equation (4) dx shows that φ(x ) = y .
0 0 The Existence and Uniqueness Theorem.
The following is the statement of the main theormem of this chapter.
Theorem 3.6 Let D be a domain of the xy plane, and let f be a real function satisfying the following two requirments (i) f is continuous in D; and (ii) f satisfies a Lipschitz Condition (with respect to y) in D; that is, there exists a constant k>0 such that |f (x, y1) ­ f (x, y2)| ≤ k|y1 ­ y2| for all (x, y ), (x, y ) in D. 1 2 Let (x0, y0) be an (interior) point of D; let a and b be such that the rec tangle R : |x ­ x0| ≤ a, |y ­ y0| ≤ b, b lies in D; let M = max |f (x, y)| for (x, y) ∈ R; and let h = a, .
M Then there exists a unique solution φ of the initial-value problem (cid:31) dy (cid:31) (cid:31) = f (x, y) dx (5) (cid:31) (cid:31) y(x0) = y0 on the interval |x ­ x0| ≤ h. That is, there exists a unique differentiable real function φ defined on the interval |x ­ x0| ≤ h which is such that dφ(x) (i) = f [x, φ(x)] for all x on this interval; and dx (ii) φ(x0) = y0 Remark 3.1 Since R lies in D, f satisfies the requirements (i) and (ii) of the Hypothesis in R. In paticular, since f is thus continuous in the rectangular closed domain R, the constant M defined in the second hypothesis actually does exist.
If you examine more closely the number h defined in the second hypothesis b of the theorem, you would discover if a < , then h = a and the solution φ is defined for all x in the M b b interval |x ­ x0 | ≤ a used in defining the rectangle R. If, however, M < a, then h = M < a and so the solution φ is assured only for all x in the smaller interval |x ­ x0| ≤ h < a associated with the smaller rectangle R1 defined by |x ­ x0| ≤ h < a, |y ­ y0| < b.
Due to the lengthy nature of the proof of this theorem, you shall be refered to more advanced textbooks on Ordinary Differential Equations.
The ones given in the reference could be of help.
But you shall be given the method and steps of proof.
41  3.1 Existence and Uniqueness Theorem ofFirst-Order Equations Method of Proof You shall prove this theorem by the method of successive approximations.
Let x be such that |x ­ x0| ≤ h. You could define the sequence of functions φ , φ , φ , ..., φ , ... 1 2 3 n called the successive approximations or (Picards Iterants) as follows: (cid:31) x (cid:31) φ (x) = y + f [t, y ]dt (cid:31) 1 0 0 (cid:31)(cid:31) x0 (cid:31) (cid:31) x (cid:31) φ (x) = y + f [t, φ (t)]dt (cid:31) 2 0 1 (cid:31) x0 (6) (cid:31) x (cid:31) φ (x) = y + f [t, φ (t)]dt (cid:31) 3 0 2 (cid:31)(cid:31) ..........x..0 (cid:31) (cid:31) x (cid:31)(cid:31) φn( x) = y0 + f [t, φn ­1( t)]dt x0 The proof is divided into five main steps in which you would show the following 1.
The functions {φn} defined by (6) actually exist, have continuous derivatives, and satisfy the inequal- ity |φn(x) ­ y0| ≤ b on |x ­ x0| ≤ h; and thus f [x, φn(x)] is defined on this interval.
2.
The functiions {φn} satisfy the inequlity M (kh)n |φn(x) ­ φn­1(x)| k · n!
on |x ­ x0| ≤ h. ≤ 3.
As n → ∞, the sequence of functions {φn} converges uniformly to a continuous function φ on |x ­ x0| ≤ h. dy 4.
The limit function φ satisfies the differential equation = f (x, y) on |x ­ x0| ≤ h and is such that dx φ(x ) = y .
0 0 5.
This function φ is the only differentiable function on |x ­ x0| ≤ h which satisfies the differential dy equation = f (x, y) and is such that φ(x ) = y .
0 0 dx Remarks and Examples Notice carefully that Theorem 3.6 is both an existence theorem and a uniqueness theorem.
It tells you that if (i) f is continuous, and (ii) f satisfies a Lipschitz condition (with respect to y) in the rectangle R, Then 3.1 Existence and Uniqueness Theorem ofFirst-Order Equations 42  3.1 Existence and Uniqueness Theorem ofFirst-Order Equations dy (a) there exists a solution φ of dx = f (x, y), defined on |x ­ x0 | ≤ h, which is such that φ(x0 ) = y0 ; and (b) this solution φ is unique solution satisfying these conditions.
Example 3.9 Consider the initial-value problem (cid:31) dy (cid:31)(cid:31) = y 13 dx (7) (cid:31) (cid:31) y(0) = 0.
Here f (x, y) = y 31 is continuous in the rectangle R : |x| ≤ a, |y| ≤ b about the origin.
Thus there exists at dy 1 leat one solution of = y 3 on |x| ≤ h such that y(0) = 0. dx Being assured of the existence of a solution of problem (7), you can now examine the uniqueness aspect.
If f satisfies a Lipschitz Condition on R, then Theorem 3.6 will apply and uniqueness will also be assured.
You have 1 1 f (x, y1) ­ f (x, y2) = |y13 ­ y23 y1 ­ y2 y1 ­ y2 If you choose y1 = δ > 0 and y2 = ­δ, this becomes δ 31 ­ (­δ1 3 ) = 1 δ ­ (­δ) δ 23 Since this becomes unbounded as δ approches zero, you see that f does not satisfy a Lipschitz Condition throughout any domain containing the line y = 0, and hence not in R. Thus you can not apply theorem 3.6 to obtain a uniqueness conclusion here.
On the other hand, you must not conclude that uniqueness is impossible simply because a Lipschitz Condtion is not satisfied.
The simple truth is that at this point you can draw no conclusion one way or the other about uniqueness in this problem.
In fact, the problem does not have a unique solution; for you can actually exhibit two solutions.
Indeed, the functions φ and φ defined, respectively, by φ (x) = 0 for all x and 1 2 1 (cid:31) 3 (cid:31)(cid:31) 2 x 2 , x ≥ 0 3 φ (x) = 1 (cid:31) (cid:31) 0, x ≤ 0, are both solutions of problem (7) on the interval ­∞ < x < ∞ You can observe that theorem 3.6 is a “local” existence theorem and an existence theorem “in the small.” For it states that if f satisfies the given hypothesis in a domain D and if (x , y ) is a point of D, then there 0 0 exists a solution φ of (cid:31) dy (cid:31) (cid:31) = f (x, y) dx (cid:31) (cid:31) y(x0) = y0 defined on an interval |x ­ x0| ≤ h, where h is sufficiently small.
It does not assert that φ is defined for all x, even if f satisfies the given hypotheses for all (x, y).
Existence “in the large” can not be asserted unless additional, very specialized restrictions are placed upon f. If f is linear in y, then an existence theorem in the large may be proved.
43  3.1 Existence and Uniqueness Theorem ofFirst-Order Equations Example 3.10 Consider the initial value problem (cid:31) dy (cid:31) = y2 dx (8) (cid:31) (cid:31) y(1) = ­1 ∂f (x, y) Here f (x, y) = y2 and = 2y are both continuous for all (x, y).
Thus using theorem 3.5 you ∂y observe that f satisfies the hypothesis of theorem 3.6 in every rectangle |x ­ 1| ≤ a, |y + 1| ≤ b, b about the point (1, ­1).
As in theorem 3.6, let M = max |f (x, y)| for (x, y) ∈ R, and h = min a, .
M Then theorem 3.6 asserts that the initial-value problem (8) possesses a unique solution defined on |x ­ 1| ≤ h. Now in this case M = (­1 ­ b)2 = (b + 1)2 and so r 1 b h = min a, (b + 1)2 b 1 ­ b Now consider F (b) = .
From F 1(b) = , you see that the maximum value of F (b) (b + 1)2 (b + 1)3 b fo r b > 0 occurs at b = 1; and you find F (1) = 1 .
Thus if a ≥ 1 ≤ a for all b > 0 and so , 4 4 (b + 1)2 b 1 h = ≤ , regardless of the value of a.
If, however, a < 1 , then certainly h < 1 .
Thus in any case (b + 1)2 4 4 4 r 1 b h ≤ 1 .
For b = 1, a ≥ 1 , h = min a, = min(a, 1 ) = 1 .
4 4 (b + 1)2 4 4 This is the “best possible” h, according to the theorem.
That is, at best theorem 3.6 assures us that the initial-value problem (8) possesses a unique solution on an interval 3 ≤ x ≤ 5 .
Thus, although 4 4 the hypotheses of theorem 3.6 are satisfied for all (x, y), the theorem only assures us of a solution to our problem on the “small” interval |x ­ 1| ≤ 1 .
4 On the other hand, this not necessarily mean that the actual solution of problem (8) is defined only on this small interval and nowhere outside of it.
It may actually be defined on a much larger interval which includes the small |x ­ 1| ≤ 1 on which it is guaranteed by the theorem.
Indeed, the solution of problem 4 (8) is readily found to be y = ­ 1 , and this is actually defined and possesses a continuous derivatives on the x interval 0 < x < ∞.
Theorem 3.7 Let f be continuous in the unbounded domain D : a < x < b, ­∞ < y < +∞.
Let f satisfy a Lipschitz Condition (with respect to y) in this unbounded domain.
That is, assume there exists k > 0 such that |f (x, y1) ­ f (x, y2)| ≤ k|y1 ­ y2| for all (x, y1), (x, y2) ∈ D. dy Then a solution φ of = f (x, y) such that φ(x ) = y , where (x , y ) is any point of D, is defined 0 0 0 0 dx on the entire open interval a < x < b.
In particular, if a = ­∞ and b = +∞, then φ is defined for all x, ­∞ < x < +∞.
For example, a solution of the initial-value problem dy = F (x)y, y(x ) = y , dx 0 0 3.1 Existence and Uniqueness Theorem ofFirst-Order Equations where F is continuous for ­∞ < x < +∞, is de4fi4ned for all x, ­∞ < x < +∞.
3.1 Existence and Uniqueness Theorem ofFirst-Order Equations 3.1.3 Dependence of Solutions on Initial Condition and on the Function f dy You shall be introduce to how the solution of the differential equation = f (x, y) depends upon a slight dx change in the initial conditions or upon a slight change int function f. It would seem that slight changes would cause only slight changes in the solution.
In the first place, you shall consider the result of a slight change in the initial condition y(x ) = y .
Let 0 0 f be continuous and satisfy a Lipschitz Condition with respect to y in a domain D, and let (x , y ) be a 0 0 fixed point of D. Then by theorem 3.6 the initial-value problem (cid:31) dy (cid:31) (cid:31) = f (x, y) dx (cid:31) (cid:31) y(x0) = y0 has a unique solution φ defined on some sufficiently small interval |x ­ x0| ≤ h0.
Now suppose the initial y value is changed from y to Y .
Our first concern is whether or not the new initial-value problem.
0 0 (cid:31) dy (cid:31) (cid:31) = f (x, y) dx (9) (cid:31) (cid:31) y(x0) = Y0 also has a unique solution on some sufficiently small interval |x ­ x0| ≤ h1.
If Y0 is such that |Y0 ­ y0| is sufficiently small then you can be certain that the problem (9) does posses a unique solution on some such interval |x ­ x0| ≤ h1.
In fact, let the rectangle R : |x ­ x0| ≤ a, |y ­ y0| ≤ b, lie in D and let Y0 be b such that |Y0 ­ y0| .
Then an application of theroem 3.6 to problem (9) shows that this problem has a 2 ≤ b unique solution ψ which is defined and contained in R for |x ­ x0| ≤ h1, where h1 = min a, 2M and M = max |f (x, y)| for (x, y) ∈ R. Thus you may assume that there exists δ > 0 and h > 0 such that for each Y0 satisfying |Y0 ­ y0| ≤ δ problem (9) possesses a unique solution φ(x, Y0) on |x ­ x0| ≤ h The following is the basic theorem concerning the dependence of solutions on initial conditions.
You can obtain the proofs of these theorems in most advanced book on Ordinary differential Equations.
Theorem 3.8 Let f be continuous and satisfy a Lipschitz Condition with respect to y, with Lipschitz Con- stant k, in a domain D of the xy plane; and let (x , y ) be a fixed point of D. Assume there exists δ > 0 and 0 0 h > 0 such that for each Y0 satisfying |Y0 ­ y0| ≤ δ the initial-value problem (cid:31) dy (cid:31) (cid:31) = f (x, y) dx (10) (cid:31) (cid:31) y(x0) = Y0 possesses a unique solution φ(x, Y0) defined and contained in D on |x ­ x0| ≤ h. If φ denotes the unique solution of (10) when Y = y , and φ denotes the unique solution of (10) when 0 0 Y0 = y˜0, where |y˜0 ­ y0| = δ1 ≤ δ, then |φ˜(x) ­ φ(x)| ≤ δ1ekh on |x ­ x0| ≤ h. 3.1 Existence and Uniqueness Theorem ofFirst-Order Equations Thus the solution φ(x, Y ) of problem (10) is a continuous function of the initial value Y at Y = y .
0 0 0 0 45  3.1 Existence and Uniqueness Theorem ofFirst-Order Equations Thus under the conditions stated, if the initial values of the two solutions φ and φ˜ differ by a sufficiently small amount, then their values will differ by an arbitrary small amount at every point of |x ­ x0| ≤ h. dy The following shows how the solution of = f (x, y) will change if the function f is slightly changed.
dx In this connection you have following theorem.
Theorem 3.9 1.
In a domain D of the xy plane, assume that (i) f is continuous and satisfies a Lipschitz Condition with respect to y, with Lipschitz constant k. (ii) F is continuous.
(iii) |F (x, y) ­ f (x, y)| ≤ E for (x, y) ∈ D. 2.
Let (x , y ) be a point of D, and let 0 0 (i) φ be the solution of the initial-value problem (cid:31) dy (cid:31) (cid:31) = f (x, y), dx (cid:31) (cid:31) y(x ) = y , 0 0 (ii) ψ be a solution of the initial-value problem (cid:31) dy (cid:31) (cid:31) = f (x, y), dx (cid:31) (cid:31) y(x ) = y , 0 0 (iii) [x, φ(x)] and [x, ψ(x)] in D for |x ­ x0| ≤ h. Then |φ(x) ­ ψ(x)| ≤ E (ekh ­ 1) on |x ­ x0| ≤ h. k Thus, under the hypothesis stated, if E is sufficiently small, the difference between the solutions φ and ψ will be arbitrary small on |x ­ x0| ≤ h. The following example illustrates how this result can be used to advantage.
Example 3.11 Consider the initial-value problem.
(cid:31) dy (cid:31) = x2 + y2 + y + 1, dx (11) (cid:31) (cid:31) y(0) = 0 The differential equation of this problem may not be solved explicitly by any of the methods which you dy know, but the differential equation = y + 1 can be.
If x and y are sufficiently small, the difference dx |(x2 + y2 + y + 1) ­ (y + 1)| = |x2 + y2| will be less than or equal to any given E > 0.
Thus the solution of problem (11) will differ from that of the problem (cid:31) dy (cid:31) (cid:31) = y + 1 dx (12) (cid:31) (cid:31) y(0) = 0 by an arbitrarily small amount if x and y are sufficiently small.
You can thus use the explicit solution of problem (12) to obtain information about the solution of the problem (11) in a sufficiently small neighbour- hood of (0, 0).
46  3.2 Existence and Uniqueness Theorem ofLinear Differential Equations 3.2 Existence and Uniqueness Theorem of Linear Differential Equations This section is an extension of what you have studied in the previous section about existence and uniqueness theorem of first order equation to that of nth other Linear Differential Equations.
3.2.1 The Basic Existence Theorem The first concern here is the basic existence theorem for an initial value problem involving the nth order linear differential equation dny dn­1y dy a0(x) dxn + a1(x) dxn­1 + · · · + an­1(x) dx + an(x)y = b(x) (13) where a0, a1, ..., an­1, an, and b are continuous on a real interval a ≤ x ≤ b, and a0(x) I= 0 on a ≤ x ≤ b.
Recall that in the last section you obtained an existence theorem for the general first-order initial value dy problem = f (x, y), y(x ) = y , by means of the method of successive approximations.
As a first step 0 0 dx toward obtaining an existence theorem for above mentioned existence theorem of the section 3.1 to obtain a similar theorem concerning a system of n first-order differential equations in n unknowns.
Specifically, you have to consider a system of n first-order differential equations of the form (cid:31) (cid:31) dy1 = f (x, y , y , ..., y ) (cid:31) dx 1 1 2 n (cid:31) (cid:31) (cid:31) (cid:31) dy 2 = f (x, y , y , ..., y ) (14) dx 2 1 2 n (cid:31) .
(cid:31)(cid:31) .
(cid:31)(cid:31)(cid:31) dyn = f (x, y , y , ..., y ) n 1 2 n dx the n unknowns y , y , ..., y , where f , f , ..., f are n continuous real functions defined in some domain 1 2 n 1 2 n D of real (n + 1)­dimensional x, y1, y2, ..., yn space.
Definition 3.9 By a solution of the system you would mean an ordered set of n differential real functions (φ , φ , ..., φ ) 1 2 n defined on some real x interval a ≤ x ≤ b such that [x, φ1(x), φ2(x), ..., φn(x)] ∈ D and (cid:31) dφ (x) (cid:31) 1 = f [x, φ (x), φ (x), ..., φ (x)] (cid:31) dx 1 1 2 n (cid:31) (cid:31) (cid:31) (cid:31) dφ2(x) = f [x, φ (x), φ (x), ..., φ (x)] 2 1 2 n (cid:31) dx (cid:31) .. (cid:31) (cid:31)(cid:31) dφ (x) (cid:31) n = f [x, φ (x), φ (x), ..., φ (x)] n 1 2 n dx for all x such that a ≤ x ≤ b.
Corresponding to theorem 3.6, you have the followiing theorem dealing with the system (14).
Since its proofs parallels that of theorem 3.6 you would merely have the outline of the major steps of the proof and 3.2 Existence and Uniqueness Theorem ofLinear Differential Equations omit the details.
47  3.2 Existence and Uniqueness Theorem ofLinear Differential Equations Theorem 3.10 Let the functions f1, f2, ..., fn be continuous in the (n+1)­dimensional rectangle R defined by |x ­ x0| ≤ a, |y1 ­ c1| ≤ b1, ..., |yn ­ cn| ≤ b n where (x0, c1, ..., cn) is a point of real (n + 1)­dimensional (x, y1, ..., yn) space and a, b1, ..., bn are positive constants.
Let M be such that |fi(x, y1, y2, ..., yn)| ≤ M for i = 1, 2, ..., n for all (x, y1, y2, ..., yn) ∈ R. Let h = min a, b1 , b2 , · · · , bn .
M M M Let the function f (i = 1, 2, ..., n) satisfy a Lipschitz condition with Lipschitz constant k in R. That is, i assume there exists a constant k > 0 such that |fi(x, y¯1, y¯2, ..., y¯n) ­ fi(x, y˜1, y˜2, ..., y˜n)| ≤ k(|y¯1 ­ y˜1| + |y¯2 ­ y˜2| + · · · + |y¯n ­ y˜n|) (15) for any two points (x, y¯1, y¯2, ..., y¯n), (x, y˜1, y˜2, ..., y˜n) ∈ R, and for i = 1, 2, ..., n. There exists a unique solution φ1, φ2, ..., φn of the system (cid:31) (cid:31) dy1 = f (x, y , y , ..., y ) (cid:31) dx 1 1 2 n (cid:31) (cid:31) (cid:31) (cid:31) dy 2 = f (x, y , y , ..., y ) (16) dx 2 1 2 n (cid:31) .
(cid:31) .
(cid:31) (cid:31)(cid:31)(cid:31) dyn = f (x, y , y , ..., y ) n 1 2 n dx such that φ (x ) = c , φ (x ) = c , ..., φ (x ) = c , 1 0 1 2 0 2 n 0 n defined for |x ­ x0| ≤ h. Outline of Proof.
First of all define functions φi,j by φ (x) = c (i = 1, 2, ..., n) i,0 i and φi,j (x) = ci + fi[t, φ1,j­1(t)...., φn, j ­ 1(t)]dt x0 (i = 1, 2, ..., n; j = 1, 2, 3, ...).
Then prove by mathematical induction that all of the functions φ so defined are continuous and satisfy the i,j relations |φi,j (x) ­ φi,j­1(x)| M (kn)j­j1!| x ­ x0|j ≤ (i = 1, 2, 3, ..., n; j = 1, 2, 3, ...; |x ­ x0| ≤ h).
Thus also M (knh)j |φi,j (x) ­ φi,j­1(x)| ≤ j!
(17) kn (i = 1, 2, 3, ..., n; j = 1, 2, 3, ...).
This would enable you to conclude that for each i = 1, 2, ..., n, the sequence {φi,j } defined by 3.2 Existence and Uniqueness Theorem ofLinear Differential Equations )j φi,j (x) = φi,0(x) + [φi,p(x) ­ φi,p­ 1(x)], (j = 1, 2, 3, ...) p=1 48  3.2 Existence and Uniqueness Theorem ofLinear Differential Equations converges uniformly to a continuous function φ .
You may then show that each φ (i = 1, 2, ..., n) satisfy i i the integral equation x φ (x) = c + f [t, φ (t), ..., φ (t)]dt, i i i 1 n x0 on |x ­ x0| ≤ h. From this you have at once that dφ(x) = f [t, φ (t), ..., φ (t)] i 1 n dx on |x ­ x0| ≤ h and φi(x0) = ci(i = 1, 2, ..., n).
Our outline of the existence proof is thus completed.
It is clear that it parallels that for the case n = 1 given for theorem 3.6.
Th proof of the uniqueness in the present case also parallels that of theorem 3.6, and you expected to make necessary changes and complete the present outline.
Theorem 3.10 can be used to obtain an existence and uniqueness theorem for the basic initial-value problem associated with an nth order differential equation of the form ( l y(n) = f x, y, y1, ..., y(n­1) (18) Definition 3.10 Consider the differential equation y(n) = f [x, y, y1, ..., y(n)], (19) where f is a continuous real function defined in a domain D of real (n+1)­dimensional (x, y, y1, ..., y(n­1))- space.
By a solution of the equation (10) you mean a real function φ having an nth derivative (and hence all lower ordered derivatives) on a real interval a ≤ x ≤ b such that f [x, φ(x), φ1(x), ..., φ(n­1)(x)] ∈ D and φ(n)(x) = f [x, φ(x), φ1(x), ..., φ(n­1) (x)] for all x such that a ≤ x ≤ b. Theorem 3.11 Consider the differential equation y(n) = f [x, y, y1, ..., y(n)] (20) where the functiion f is continuous and satisfies a Lipschitz Condition of the form (15) in a domain D of real (n + 1)­dimensional (x, y, y1, ..., y(n­1))-space.
Let (x0, c0, c1, ..., cn­ 1) be a point of D. Then there exists a unique solution φ of the nth-order differential equation such that φ(x0) = c0, φ1(x0) = c1, ..., φ(n­1)(x0) = cn­ 1, (21) defined on some interval |x ­ x0| ≤ h about x = x0.
3.2.2 Basic Existence and Uniqueness theorems on Linear Systems Now, your attention will be shifted to the linear system (cid:31) (cid:31) y11 = a11(x)y1 + a12(x)y2 + · · · + a1n(x)yn + b1(x) (cid:31) (cid:31) (cid:31)(cid:31) y21 = a21(x)y1 + a22(x)y2 + · · · + a2n(x)yn + b2(x) (22) (cid:31) .......... (cid:31) (cid:31) (cid:31) (cid:31) y1n = an1(x)y1 + an2(x)y2 + · · · + ann(x)yn + bn(x) where the coefficients aij and the functions bi are continuous on the interval a ≤ x ≤ b.
The following lemma is of great importance.
49  3.2 Existence and Uniqueness Theorem ofLinear Differential Equations Lemma 3.2 Let the functions aij and bi(i = 1, 2, ..., n; j = 1, 2, ..., n) be continuous on the interval a ≤ x ≤ b.
Then the functions f defined by i fi(x, y1, y2, ..., yn) = ai1(x)y1 + ai2(x)y2 + · · · + ain(x)yn + bi(x), (i = 1, 2, ..., n), satisfy a Lipschitz Condition on a ≤ x ≤ b, ­∞ < yi < +∞(i = 1, 2, ..., n).
That is, there exists a constant k > 0 such that |f (x, y¯1, y¯2, ..., y¯n) ­ f (x, y˜1, y˜2, ..., y˜n)| ≤ k(|y¯1 ­ y˜1| + |y¯2 ­ y˜2| + · · · + |y¯n ­ y˜n|) for all x such that a ≤ x ≤ b and any two sets of real numbers y¯1, y¯2, ..., y¯n and y˜1, y˜2, ..., y˜n (i = 1, 2, ..., n).
Proof.
Since each of the functions aij is continuous on a ≤ x ≤ b, corresponding to each of these functions there exists a constant kij such that |aij (x)| ≤ kij for all x ∈ [a, b], (i = 1, 2, ..., n; j = 1, 2, ..., n).
Let k = max{kij } for i = 1, 2, ..., n; j = 1, 2, ..., n. Then |aij (x)| ≤ k for all x ∈ [a, b].
Then for every x ∈ [a, b] and any two sets of real numbers y¯1, y¯2, ..., y¯n and y˜1, y˜2, ..., y˜n, you have |fi(y¯1, y¯2, ..., y¯n) ­ fi(y˜1, y˜2, ..., y˜n)| ≤ |ai1(x)y¯1 + ai2(x)y¯2 + · · · + ain(x)y¯n + bi(x) ­ai1(x)y˜1 ­ ai2(x)y˜2 ­ · · · ­ ain(x)y˜n ­ bi(x)| = |ai1(x)[y¯1 ­ y¯1] + ai2(x)[y¯2 ­ y¯2] + · · · + ain(x)[y¯n ­ y¯n]| ≤ |ai1(x)||y¯1 ­ y˜1| + |ai2(x)||y¯2 ­ y˜2| + · · · + |ain(x)||y¯n ­ y˜n| ≤ k(|y¯1 ­ y˜1| + |y¯1 ­ y˜1| + · · · + |y¯1 ­ y˜1|).
The following gives you the existence theorem concerning the linear system (22).
Theorem 3.12 Let the coefficients a and the functions b , (i, j = 1, 2, ..., n) in the linear system (22) be ij i continuous on the real interval a ≤ x ≤ b.
Let x0 be a point of the interval a ≤ x ≤ b, and let c1, c2, ..., cn be a set of n real constants.
Then there exists a unique solution φ1, φ2, ..., φn of the system (22) such that φ (x ) = c , φ (x ) = c , ..., φ (x ) = c , 1 0 1 2 0 2 n 0 n and this solution is defined on the entire interval a ≤ x ≤ b.
Outline of Proof.
The system (22) is a special case of the system (16) with which theorem 3.10 is concerned, and the present outline of proof parallels that given for theorem 3.10.
You would first of all define the functions φ by i,j φ (x) = c (i = 1, 2, ..., n) i,0 i and φ (x) = c + i,j i 3.2 Existence and Uniqueness Theorem ofLinear Differential Equations x [a i 50 ( 1 t) φ 1 ,j ­ ( 1 t) + · · · + a i ( n t) φ n ,j ­ ( 1 t) + b ( i t)] dt (23) x 0  3.2 Existence and Uniqueness Theorem ofLinear Differential Equations (i = 1, 2, ..., n; j = 1, 2, 3, ...) on a ≤ x ≤ b.
The functions φi,j so defined are continuous on the entire interval a ≤ x ≤ b.
Also, by hypothesis there exists M > 0 such that |ai1(x)c1 + · · · + ain(x)cn + bi(x)| ≤ M, (i = 1, 2, ..., n), a ≤ x ≤ b.
By the lemma the functions defined by ai1(x)y1 + ai2(x)y2 + · · · + ain(x)yn + bi(x) satisfy a Lipschitz condition on a ≤ x ≤ b.
You can thus use the formulas (23) and this Lipschitz condition to obtain by induction the inequality |φi,j (x) ­ φi,j­1(x)| M (kn)j­1|x ­ x0|j j!
≤ (i = 1, 2, ..., n; j = 1, 2, 3, ...) on the entire interval a ≤ x ≤ b.
Thus also M (knH )j |φi,j (x) ­ φi,j­1(x)| ≤ j!
(24) kn (i = 1, 2, ..., n; j = 1, 2, 3, ...), a ≤ x ≤ b, where H = max(|a ­ x0|, |b ­ x0|).
The inequality (24) here corresponds to the inequality (17) in the proof of theorem 3.10.
The remainder of the proof outlined for theorem 3.10 now carries over to the present case for a ≤ x ≤ b and you would obtain the desired conclusion.
Now you are in a position to obtain the basic existence theorem for the initial value problem associated with the nth-order linear differential equation (13).
Theorem 3.13 Consider the differential equation of (13) where a , a , ..., a , a , and b are continuous 0 1 n­1 n on the interval a ≤ x ≤ b and a0(x) I= 0 on a ≤ x ≤ b.
Let x0 be a point of the interval a ≤ x ≤ b, and let c0, c1, ..., cn­1 be a set of n real constants.
Then there exists a unique solution φ of (13) such that φ(x0) = c0, φ1(x0) = c1, ..., φ(n­1)(x0)cn­ 1, (25) and this solution is defined over the entire interval a ≤ x ≤ b.
Proof.
Let dy dn­1 y = y, y = , ..., y = .
1 2 dx n dxn­1 Then the nth order linear differential equation (13) is equivalent to the linear system (cid:31) (cid:31) y11 = y2 (cid:31) (cid:31) (cid:31) (cid:31)(cid:31)(cid:31) y21 = y3 .
(26) (cid:31) y1 = y (cid:31) n ­1 n (cid:31) (cid:31)(cid:31)(cid:31)(cid:31) yn1 = ­a an ((xx)) y1 ­a an ((xx)) y1 ­ · · · ­a na( x()x ) y1 ­b (ax )( x) 0 0 0 0 3.2 Existence and Uniqueness Theorem ofLinear Differential Equations If φ is a solution of (13) which satisfies the conditions (25), then the ordered set of functions φ , φ , ..., φ , 1 2 n where φ = φ, φ = φ1, ..., φ = φ(n­1), is a solution of the linear system (26) which satisfies the conditions 1 2 n φ1(x0) = c0, φ2(x05)1= c1, ..., φn(x0) = cn­1, (27)  5 Summary Conversely, if φ , ..., φ is a solution of (26) which satisfies (27), then the function φ = φ is a solution of 1 n 1 the differential equation (13) which satisfies conditions (25).
The system (26) is simply a special case of the linear system (22) to which theorem 3.12 applies.
Thus the system (26) possesses a unique solution φ1, ..., φn defined on the entire interval a ≤ x ≤ b which satisfies the conditions (27).
Thus if you set φ = φ , the above-noted equivalence of (13) and (25) with (26) 1 and (27) gives the desired conclusion.
Example 3.12 Consider the initial-value problem: (cid:31) d2y dy 1 (cid:31)(cid:31)(cid:31) (x2 ­ x ­ 6) dx2 + (x2 + 4) d x+ 2x + 3 y = e­x (cid:31) y(2) = 0 (cid:31) (cid:31) (cid:31) (cid:31) y(2) = 4 The coefficient of y is continuous except at x = ­3/2.
The remaining coefficients and the non-homogeneous term are continuous for all values of x, ­∞ < x < ∞.
The leading coefficients (x2 ­ x ­ 6) equals zero at x = ­2 and x = 3.
Thus the hypothesis of theorem 3.13 is satisfied in every closed interval a ≤ x ≤ b such that ­3/2 < a < x0 = 2 < b < 3.
Therefore the given initial-value problem has a unique solution, and you are assured that this solution is defined over every such closed interval a ≤ x ≤ b.
An important corollary to this theorem concerning the homogeneous equation d(n)y d(n­1)y dy a0(x) dxn + a1(x) dxn­1 + · · · + an­1(x) dx + an(x)y = 0 (28) This corollary, is stated and proved below Corollary 3.1 The function φ is a solution of the homogeneous equation such that φ(x ) = 0, φ1(x ) = 0, ..., φ(n­1)(x ) = 0, (29) 0 0 0 where x0 is a point of an interval a ≤ x ≤ b on which the coefficients a0, a1, ..., an are all continuous and a0(x) I= 0.
Then φ(x) = 0 for all x such that a ≤ x ≤ b.
Proof.
First not that φ such that φ(x) = 0 for all x ∈ [a, b] is indeed a solution of the differential equation (28) which satisfies the initial conditions (29).
But by theorem (3.13) the initial-value problem composed of Equation (28) and conditions (29) has a unique solution on a ≤ x ≤ b.
Hence the stated conclusion follows.
4 Conclusion In this unit you have studied the Existence and Uniqueness theorem of Ordinary Differential Equations of First order and Linear System.
This has enabled you to know when a given Ordinary differential equation has a solution, a unique solution or no solutions.
52  4 Conclusion 5 Summary Having gone through this section, you are now able to (i) say when a first order ODE has a solution, a unique solution or no solutions.
(ii) say when a function of two variables satisfies a Lipschitz condition on the second variable.
(iii) approximate a solution of an ODE using the Picard’s iteration.
(iv) describe the dependence of a solution on initial condition on the function f. (v) state and apply the existence theorem for linear differential equations.
6 Tutor Marked Assigments(TMAs) Exercise 6.1 1.
Consider the initial-value problem dy = y4/3, y(x ) = y .
0 0 dx (a) Discuss the existence of a solution of this problem.
(b) Discuss the uniqueness of a solution of this problem.
2.
For each of the following initial-value problems show that there exists a unique solution of the prob- lem if y0 I= 0.
In each case discuss the existence and uniqueness of a solution if y0 = 0. dy (a) = y2/3, y(x ) = y .
0 0 dx dy (b) = | y|, y(x 0) = y0 dx 3.
For each of the following initial-value problems find the largest interval |x| ≤ h on which theorem 3.6 guarantees the existence of a unique solution.
In each case find the unique solution and show that it actually exists over a larger interval that that guaranteed by the theorem.
dy (a) = 1 + y2, y(0) = 0. dx dy = e2y , y(0) = 0.
(b) dx 4.
Show that theorem 3.6 guarantees the existence of a unique solution of the initial-value problem dy = x2 + y2, y(0) = 0 dx √ 2 on the interval |x| ≤ 2 5.
Which of the following sequences of functions {fn} defined on 0 ≤ x ≤ 1 does not converge uniformly on 0 ≤ x ≤ 1.
1 (a) fn(x) = x + n , 0 ≤ x ≤ 1, (n = 15,32, 3, ...).
6 Tutor Marked Assigments(TMAs) xn (b) fn(x) = x ­ , 0 ≤ x ≤ 1, (n = 1, 2, 3, ...).
n 1 (c) fn(x) = nx + 1 , 0 ≤ x ≤ 1, (n = 1, 2, 3, ...).
nx2 (d) fn(x) = nx + 1 , 0 ≤ x ≤ 1, (n = 1, 2, 3, ...).
6.
Which of the following functions does not satisfy a Lipschitz Condition in the rectangle D defined by |x| ≤ a, |y| ≤ b.
(a) f (x, y) = x2 + y2.
(b) f (x, y) = x sin y + y cos x.
(c) f (x, y) = x2ex+y .
(d) f (x, y) = y 2 3 7.
Consider the third-order differential equation d3y = x2 + y dy + d2y 2 dx3 dx dx2 of the form (20) of the text.
(a) Does there exist a unique solution φ of the given equation such that φ(0) = 1, φ1(0) = ­3, φ11(0) = 0?
Explain precisely why or why not.
(b) Find the system of three first-order equations to which the given third order equation is equiva- lent.
8.
Does there exist a solution of the initial value problem (cid:31) d4y d2y (cid:31)(cid:31) (x2 ­ 4) + 2x + (sin x)y = 0 dx4 dx2 (cid:31) (cid:31) y(0) = 0, y1(0) = 1, y11(0) = 1, y111(0) = ­1?
If so, is the solution unique and over what interval are you assured that it is defined?
Explain precisely.
9.
Give that each of the functions f and f defined for all x by 1 2 )∞ (­1)n+1x2n­1 f (x) = sin x and f (x) = 1 2 (2n ­ 1)!
n=1 are solutions of the initial-value problem (cid:31) d2y (cid:31)(cid:31) + y = 0 dx2 (cid:31) (cid:31) y(0) = 0, y1(0) = 1 For all x, ­∞ < x∞, what theorem enables us to conclude that f1(x) = f2(x) for all x, ­∞ < x < ∞?
Explain.
54  6 Tutor Marked Assigments(TMAs) 10.
Consider the differential equation d2y dy a (x) + a (x) + a (x)y = 0 (30) 0 dx2 1 dx 2 where a0, a1 and a2 are continuous for all x, ­∞ < x < ∞, and a0(x) I= 0 for all values of x.
(a) Let f be a nontrivial solution of differential equation (30), let f 1 denote the derivatives and let x0 ∈ [a, b].
Prove that if f (x0) = 0, then f 1(x0) I= 0.
(b) Let f and g be two distinct solutions of differential equation (30), and suppose there exists x0 ∈ [a, b] such that f (x0) = g(x0) = 0.
Prove that there exists a constant c such that f = cg.
[Hint: Observe that the function h defined by h(x) = Af (x) ­ Bg(x), where A = g1(x0) and B = f 1(x ), is also a solution of differential equation (30).]
0 55  UNIT 3: PROPERTIES OF SOLUTIONS OF LINEAR DIFFEREINTIAL EQUATIONS Contents 1 Introduction 56 2 Objectives 57 3 Main Content 57 3.1 Basic Theory of Linear Differential Equations 57 3.1.1 Definition and Basic Existence Theorem 57 3.1.2 The Homogeneous Equations 58 3.1.3 Nonhomogeneous Equation 62 3.2 General Theory for Linear Differential Equations with Constant Coefficent 63 3.2.1 Homogeneous Linear Equations with Constant Coefficients 64 3.2.2 Case I.
Distinct Real Roots 64 3.2.3 Case II.
Repeated Real Roots 65 3.2.4 Case III.
Conjugate Complex Roots 68 3.2.5 An Initial-Value Problem 69 3.2.6 The Method of Undetermined Coefficients 70 3.2.7 Variation Of Parameters 73 4 Conclusion 76 5 Summary 77 6 Tutor Marked Assignments(TMAs) 77 1 Introduction The subject of linear ordinary differential equations is one of great theoretical and practical importance.
Theoretically, the subject is one of simplicity and elegance.
Practically, linear differential equations originate in a variety of applications to science and engineering.
Fortunately many of the linear differential  2 Objectives equations which thus occur are of a special type, linear with constant coefficients, for which explicit meth- ods of solution are available.
2 Objectives At the end of this unit, you should be able to; (i) Use certain methods to obtain solutions of linear ordinary differential equations with constant coeffi- cient.
(ii) know some basic theorems which could be used to solve such problems.
3 Main Content 3.1 Basic Theory of Linear Differential Equations 3.1.1 Definition and Basic Existence Theorem Definition 3.1 A Linear differential equation of order n is an equatio of the form a0(x)y(n) + a1(x)y(n−1) + · · · + an −1(x)yl + an (x)y = b(x) (1) where a is not identically zero.
It shall be assumed that a , a , ..., a and b are continuous real functioins 0 0 1 n on a real interval a ≤ x ≤ b and that a (x) /= 0 for any x on a ≤ x ≤ b.
0 The right hand member is called the nonhomogeneous term.
If b is identically zero the equation reduces to a (x)y(n) + a (x)y(n−1) + · · · + a yl + a (x)y = 0 0 1 n −1 n and is then called homogeneous.
Example 3.1 yll + 3xyl + x3y = ex is a linear differential equation of the second order.
Example 3.2 ylll + xyll + 3x2yl − 5y = sin x is a linear differential equation of the third order.
You can recall from the last unit the following basic existence theorem for initial-value problems asso- ciated with an nth order linear differential equation: Theorem 3.1 Consider a0(x)y(n) + a1(x)y(n−1) + · · · + an −1(x)yl + an (x)y = b(x) (1) where a , a , ..., a and b are continuous real functions of a real interval a ≤ x ≤ b and a (x) /= x for any 0 1 n 0 x on a ≤ x ≤ b.
Let x be any point of the interval a ≤ x ≤ b, and let c , c , ..., c be n arbitrary constants.
0 0 1 n−1 Then there exists a unique solution f of (1) such that f (x0) = c0 f l(x0) = c1, ..., f (n−1)(x0) = cn −1, and this solutiion is defined over the entire interval a ≤ x ≤ b.
57  3.1 Basic Theory of Linear Differential Equations Example 3.3 Consider the initial-value problem (cid:31) yll + 3xyl + x3y = ex (cid:31) (cid:31) (cid:31) y(1) = 2 (cid:31) (cid:31) (cid:31) yl(1) = 5 The coefficients 1, 3x and x2 as well as the nonhomogeneous term ex, in this second-order differential equation are all continuous for all values of x, −∞ < x < ∞.
The point x here is the point 1, which 0 certainly belongs to this interval; and the real numbers c and c are 2 and −5, respectively.
Thus theorem 0 1 3.1 tells you that a solution of the given problem exists, is unique, and is defined for all x, −∞ < x < ∞.
Example 3.4 Consider the initial-value problem (cid:31) 2ylll + xyll + 3x2yl − 5y = sin x (cid:31) (cid:31) (cid:31) (cid:31) y(4) = 3 (cid:31) (cid:31) yl(4) = 5 (cid:31) (cid:31) (cid:31)(cid:31) 7 (cid:31) yll(4) = − 2 Here you have a third-order problem.
The coeffiecients 2, x, 3x2, and −5, as well as the nonhomogeneous term sin x, are all continuous for all x, −∞ < x < ∞.
The point x = 4 certainly belongs to this interval; 0 the real numbers c , c and c in this problem are 3, 5 and − 7 , respectively.
Theorem 3.1 tells you that this 0 1 2 2 problem has a unique solution which is defined for all x, −∞ < x < ∞.
A useful corollary to theorem 3.1 is the following: Corollary 3.1 Let y be a solution of the homogeneous equation a0(x)y(n) + a1(x)y(n−1) + · · · + an −1yl + an (x)y = 0 (2) such that y(x ) = 0, yl(x ) = 0, ..., y(n−1)(x ) = 0, where x is a point of the interval a ≤ x ≤ b in which 0 0 0 0 the coefficients a , a , ..., a are all continuous and a (x) /= 0.
0 1 n 0 Then y(x) = 0 for all x on a ≤ x ≤ b.
Example 3.5 The solution y of the third-order homogeneous equation ylll + 2yll + 4xyl + x2y = 0 which is such that y(2) = yl(2) = yll(2) = 0 is the trivial solution y such that y(x) = 0 for all x.
3.1.2 The Homogeneous Equations Here you shall be considering the fundamental results concerning the homogeneous equations (2).
First is the statement of the basic theorem: 58  3.1 Basic Theory of Linear Differential Equations Theorem 3.2 Basic Theorem on Linear Homogeneous Differential Equations Let y , y , ..., y be any 1 2 m m solutions of the homogeneous linear differential equation (2).
Then c y + c y + · · · + c y is also a solution of (2), where c , c , ..., c are arbitrary constants.
1 1 2 2 m m 1 2 m You could put this theorem in a very simple form by means of the concept of linear combination, which is now introduced to you.
Definition 3.2 If y , y , ..., y are m given functions, and c , ..., c are constants, the the expression 1 2 m 1 m c1y1 + c2y2 + · · · + cmym is called a linear combination of y , y , ..., y .
1 2 m In terms of this concept, theorem (3.2) may be stated as follows: Theorem 3.3 (Theorem 3.2 restated) Any linear combination of solutions of the homogeneous linear dif- ferential equation is also a solution of (2) Example 3.6 You could verify that sin x and cos x are solutions of yll + y = 0.
Theorem 3.2 states that c sin x + c cos x is also a solution for any constants c and c .
For example, 1 2 1 2 5 sin x + 6 cos x is a solution.
Example 3.7 You should be able to verify that ex, e−1, and e2x are solutions of ylll − 2yll − yl + 2y = 0 Theorem 4.2 states that y(x) = c ex + c e−x + c e2x is a solution for any constants c , c and c .
For 1 2 3 1 2 3 example, 2 y(x) = 2ex − 3e−x + e2x 3 is a solution.
Here you shall consider what constitutes the general solution of 4.2.
To understand this, you would first be introduced to the concepts of linear dependence and linear independence.
Definition 3.3 Then n functions y , y , ..., y are called linearly dependent on a ≤ x ≤ b if there exists 1 2 n constants, c , c , ..., c , not all zero such that 1 2 n c y (x) + c y (x) + · · · + c y (x) = 0 1 1 2 2 n n for all x such that a ≤ x ≤ b.
In particular, two functions y and y are linearly dependent on a ≤ x ≤ b if there exists constants 1 2 c , c , not both zero, such that 1 2 c y (x) + c y (x) = 0 1 1 2 2 for all x such that a ≤ x ≤ b.
59  3.1 Basic Theory of Linear Differential Equations Example 3.8 You could observe that x and 2x are linearly dependent on the interval 0 ≤ x ≤ 1.
For there exists constants c and c not both zero such that 1 2 c x + c (2x) = 0 1 2 for all x on the interval −1 ≤ x ≤ 2.
For example, let c = 2, c = −2.
1 2 Example 3.9 You could observe that sin x, 3 sin x, and − sin x are linearly dependent on the interval −1 ≤ x ≤ 2 for there exists constants c , c , c , not all zero, such that 1 2 3 c sin x + c (3 sin x) + c (− sin x) = 0 1 2 3 for all x on the interval −1 ≤ x ≤ 2.
For example, let c = 1, c = 1, c = 4.
1 2 3 Definition 3.4 The n functions y , ...y are called linearly independent on the interval a ≤ x ≤ b if they 1 n are not linearly dependent there.
That is, the function y , ..., y are linearly independent on a ≤ x ≤ b if 1 n the relation c y + · · · + c y = 0 1 1 n n for all x such that a ≤ x ≤ b implies that c = c = · · · = c = 0.
1 2 n (in other words, the only identically vanishing linear combination of y , ..., y is the “trivial” linear combi- 1 n nation 0 · y + 0 · y + · · · + 0 · y ).
1 2 n Example 3.10 You could observe that x and x2 are linearly independent on 0 ≤ x ≤ 1, since c x+c x2 = 0 1 2 for all x on 40 ≤ x ≤ 1 implies that both c = 0 and c = 0.
1 2 Theorem 3.4 The nth order homogeneous linear differentia equation (2) always possesses n solutions which are linearly independent.
Further, if y , y , ..., y are n linearly independent solutions of (2), then 1 2 n every solution y of (2) can be expressed as a linear combination y = c1y1 + · · · + cnyn of these n linearly independent solutions by proper choice of the constants, c1, ..., cn The above theorem helps us to formulate the meaning of a general solution of an nth order homogeneous linear differential equation as follows: Definition 3.5 (General Solution) If y , y , ..., y are n linearly independent solutions of the nth order 1 2 n homogeneous linear differential equation (2) on a ≤ x ≤ b, then the function y defined by y(x) = c y (x) + · · · + c y (x), a ≤ x ≤ b, 1 1 n n where c , ..., c are arbitrary constants, is called a general solution of (2) on a ≤ x ≤ b.
1 n Thus if you can find n linearly independent solutions of (2), you can at once write the general solution of (2) as a linear combination of these n solutions.
60  3.1 Basic Theory of Linear Differential Equations Example 3.11 You have observed that sin x and cos x are solutions of yll + y = 0 for all x, −∞ < x < ∞.
Further, you can verify that these two solutions are linearly independent.
Thus the general y solution may be expressed as the linear combination y(x) = c sin x + c cos x 1 2 where c and c are arbitrary constants.
1 2 Example 3.12 The solutions ex, e−1 and e2x of ylll − 2yll − yl + 2y = 0 may be shown to be linearly independent for all x, −∞ < x < ∞.
Thus the general solution y may be expressed as the linear combination y(x) = c ex + c e−x + c e2x, 1 2 3 where c , c , and c are arbitrary constants.
1 2 3 The next theorem gives you a simple criterion for determining whether or not n solutions of (2) are linearly independent.
Before that, you need the following concept.
Definition 3.6 Let y , ..., y be n real functions each of which has an (n − 1)st derivative on a real interval 1 n a ≤ x ≤ b.
The determinant y1 y2 · · · yn yl yl · · · yl 1 2 n W (y , y , ..., y ) = 1 2 n · · · · · · · · · · · · y(n−1) y(n−1) · · · y(n−1) 1 2 n in which primes denote derivatives, is called the Wronskian of these n functions.
You can observe that W (y , y , ..., y ) is itself a real function defined on a ≤ x ≤ b.
Its value at x is denoted by W (y , y , ..., y )(x).
1 2 n 1 2 n Theorem 3.5 The n solutions y , y , ..., y of the nth order homogeneous linear differential equation (2) 1 2 n are linearly independent on a ≤ x ≤ b if and only if the Wronskian of y , y , ..., y is different from zero for 1 2 n some x on the interval a ≤ x ≤ b.
You have further: Theorem 3.6 The Wronskian of n solutions y , y , ..., y of (2) is either identically zero on a ≤ x ≤ b or 1 2 n else is never zero on a ≤ x ≤ b.
Thus if you can find n solutions of (2), you can apply the theorems (3.5) and (3.6) to determine whether or not they are linearly independent.
If they are linearly independent, then you can form the general solution as a linear combination of these n linearly independent solutions.
In the case of the general second-order homogeneous linear differential equation a (x)yll + a (x)yl + a (x)y = 0, 0 1 2 the Wronskian of two solutions y and y is the second-order determinant 1 2 y1 y2 = y yl − yl y .
yl 1 2 1 2 61 3.1 Basic Theory of Linear Differential Equations yl 1 2  3.1 Basic Theory of Linear Differential Equations Example 3.13 You can apply theorem 3.5 to show that the solutions sin x and cos x of yll + y = 0 are linearly independent.
sin x cos x W (sin x, cos x) = = − sin2 x − cos2 x = −1 /= 0. cos x − sin x Thus since W (sin x, cos x) /= 0, you would conclude that sin x and cos x are indeed linearly independent.
Example 3.14 The solutions ex, e−x, and e2x of ylll − 2yll − yl + 2y = 0 are linearly independent, for ex e−x e2x 1 1 1 W (ex, e−x, e2x) = ex −e−x 2e2x = e2x 1 −1 2 = −6e2x /= 0. ex e−x 4e2x 1 1 4 3.1.3 Nonhomogeneous Equation You shall now consider breifly the nonhomogeneous equation a0(x)y(n) + a1(x)y(n−1) + · · · + an −1(x)yl + an (x)y = b(x) (1) The basic theorem dealing with this equation is the following Theorem 3.7 Let v be a any soluton of the given (nonhomongeneous) nth-order linear differential equation (1).
Let u be any solution of the corresponding homogeneous equation a0(x)y(n) + a1(x)y(n−1) + · · · + an −1(x)yl + an (x)y = 0 (2) Then y=u+v is a solution of the given (nonhomogeneous) equation (1).
Example 3.15 Observet that y = x is a solution of the nonhomogeneous equation yll + y = x. and that y = sin x is a solution of the corresponding homogeneous equation yll + y = 0.
The by theorem 3.7, the sum y = sin x + x is also a solution of the given nonhomogeneous equation yll + y = x.
You can check that this is indeed true.
62  3.2 General Theory for Linear Differential Equationswith ConstantCoefficent Definition 3.7 Consider the nth-order (nonhomogeneous) linear differential equation a0(x)y(n) + a1(x)y(n−1) + · · · + an −1(x)yl + an (x)y = b(x) (1) and the corresponding homogeneous equation a0(x)y(n) + a1(x)y(n−1) + · · · + an −1(x)yl + an (x)y = 0 (2) 1.
The general solution of (2) is called the complementary function of equation (1) and is denoted by y .
c 2.
Any particular solution of (1) involving no arbitrary constants is called a particular integral of (1), denoted by y .
p 3.
The solution y = y + y of (1), where y is the complementary function and y is a particular integral c p c p of (1) is called the general solution of (1).
Thus to find the general solution of (1), you need merely find: (a) The complementary function, that is the general linear combination of n linearly independent solutions of the corresponding homogeneous equation (2); and (b) a particular integral, that is, any particular solution of (1) involving no arbitrary constants.
Example 3.16 Consider the differential equation.
yll + y = x The complementary function is the general solution y = c sin x + c cos x c 1 2 of the corresponding homogeneous equation yl + y = 0.
In particular integral is given by y = x. p Thus the general solutionof the given equation may be written y = y + y = c sin x + c cos x + x. c p 1 2 The remaining sections of this unit, shall be devoted to study methods.
of obtaining the two constituents parts of the general solutions.
3.2 General Theory for Linear Differential Equations with Constant Coefficent The general form of an nth order linear differential equation is given by a0y(n) + a1y(n−1) + · · · + an −1yl + an y = b(x) (3) where a , a , ..., a , a are constants and b is a function of x.
If b(x) ≡ 0 then (3) becomes of 0 1 n−1 n a0y(n) + a1y(n−1) + · · · + an −1yl + an y = 0 (4) and is called homogeneous otherwise, it is said to6b3e nonhomogeneous.
3.2 General Theory for Linear Differential Equationswith ConstantCoefficent 3.2.1 Homogeneous Linear Equations with Constant Coefficents.
As you have already said, the general form of a homogeneous linear Ordinary Differential Equation with constant coefficients is given by (4) i.e., a0y(n) + a1y(n−1) + · · · + an −1yl + an y = 0 (4) where a , a , ..., a , a are constants.
0 1 n−1 n In order to solve this equation, you would first of all assume a trial solution of the form y(x) = eλx (5) Differentiating and substituting this in (4), gives you a0λneλx + a1λn−1eλx + · · · + an −1λeλx + an eλx = 0 or eλx(a0λn + a1λn−1 + · · · + an −1λ + an ) = 0.
Since eλx /= 0, you obtain that the polynomial equation in the unknown λ : a0λn + a1λn−1 + · · · + an −1λ + an = 0 (6) This equation is called the auxilliary equation or the characteristic equation of the given differential equa- tion (6).
If y = eλx is a solution of (4) then you see that the constant λ satisfy (6).
Hence to solve (5), you write the auxiliary equation (6) and solve it for λ.
Observe that (6) is formally obtained form (4) by merely replacing the kth derivative in (4) by λk (k = 1, 2, ..., n).
Three cases arises, according as the roots of (6) are real and distinct, real and repeated, or complex.
3.2.2 Case I.
Distinct Real Roots Suppose the roots of (6) are the n distinct real numbers λ1, λ2, ..., λn Then eλ1 x, eλ2 x, ..., eλx are n distinct solutions of (4).
Further, using the Wronskian determinant one may show that these n solutions are linearly independent.
Thus you have the following result.
Theorem 3.8 Consider the nth-order homogeneous linear differential equation (4) with constant coeffi- cients.
If the auxilliary equation (6) has the n distinct real roots λ , λ , ..., λ , then the general solution of 1 2 n (6) is y = c1eλ1 x + c2eλ2 x + · · · + cneλn x where c , c , ..., c are arbitrary constants.
1 2 n Example 3.17 yll − 3yl + 2y = 0 The auxiliary equation is λ2 − 3λ + 2 = 0.
Hence (λ − 1)(λ − 2)64= 0, λ1 = 1, λ2 = 2.
3.2 General Theory for Linear Differential Equationswith ConstantCoefficent The roots are real and distinct.
Thus ex and e2x are solutions and the general solution may be written y = c1ex + c2e2x You can verify that ex and e2x are indeed linearly independent.
Their Wronskian is ex e2x W (ex, e2x) = = e3x /= 0.
Thus by theorem 3.5, you are sure of their linear independence.
ex 2e2x Example 3.18 ylll − 4yll + yl + 6y = 0.
The auxilliary equation is λ3 − 4λ2 + λ + 6 = 0.
You could observe that λ = −1 is a root of this equation.
By sythetic division, you obtain by factorization (λ + 1)(λ2 − 5λ + 6) = 0 or (λ + 1)(λ − 2)(λ − 3) = 0 Thus the roots are the distinct real numbers λ = −1, λ = 2, λ = 3 1 2 3 and the general solution is y = c e−x + c e2x + c e3x.
1 2 3 3.2.3 Case II.
Repeated Real Roots For a better understanding, you can begin the study of this case by considering a simple example.
Example 3.19 An introductory Example.
Consider the differential equation yll − 6yl + 9y = 0.
(7) the auxilliary equation is λ2 − 6λ + 9 = 0 or (λ − 3)2 = 0 The roots of this equation are λ = 3, λ = 3.
1 2 (real but not distinct).
Corresponding to the root λ , you have the solution e3x, and corresoponding to λ you 1 2 have the same solution e3x.
The linear combination c e3x + c e3x of these “two” solutions is clearly not the 1 2 general solution of the differential equation (7), for it not a linear combination of two linearly independent solutions.
Indeed, you may write the combination c e3x + c e3x as simply c e3x, where c = c + c ; and 1 2 0 0 1 2 clearly y = c e3x, involving one arbitrary constant, is not the general solution of the given second-order 0 equation.
You must find a linearly independent solution; but how can you proceed to do so?
Since you already know the one solution e3x, you may set y = e3xu (8) where u is to be determined.
Then 65  3.2 General Theory for Linear Differential Equationswith ConstantCoefficent yl = e3xu61 + 3eexu.
yll = e3xull + 6e3xul + 9e3xu.
Substituting into equation (7) you have (e3xull + 6e3xul + 9e3xu) − 6(e3xu61 + 3eexu) + 9e3xu.
or e3xyll = 0 Letting w = ul, you have the first-order equation e3xwl = 0 Or simply wl = 0 The general solution of this first-order equation is simply w = c, where c is an arbitrary constant.
Choosing the particular solution w = 1 and recalling that ul = w, you find u = x + c0 where c is an arbitrary constant.
For any constant c , you could verify that ue3x = (x + c )e3x is a solution 0 0 0 of the given second order equation (7).
Now you can also verify that this solution and the previously known solution e3x are linearly independent.
Choosing c = 0, you obtain the solution 0 y = xe3x, and thus corresponding to the double root 3 you find the linearly independent solutions e3xandxe3x of equation (7) Thus the general solution of equation (7) may be written y = c e3x + c xe3x (9) 1 2 or y = (c + c x)e3x.
(10) 1 2 With this example as a guide, you can return to the general nth-order equation (4).
If the auxilliary equation (6) has the double real root λ, you would surely expect that eλx and xeλx would be the corresponding linearly independent solutions.
This is indeed the case.
Specifically, suppose the roots of (6) are the double real root λ and the (n − 1) distinct real λ1, λ2, ..., λn−2 Then linearly independent solutions of (4) are eλx, xeλx, eλ1 x, eλ2 x, ..., eλn−2 x and the general solution may be written y = c1eλx + c2xeλx + c3eλ1 x + c4eλ2 x + · · · + cneλn−2 x. or y = (c1 + c2x)eλx + c3eλ1 x + c4eλ2 x + · · · + cneλn−2 x.
In like manner, if the auxilliary equation (6) has the triple real root λ, corresponding linearly independent solutions are 66  3.2 General Theory for Linear Differential Equationswith ConstantCoefficent eλx, xeλxandx2eλx.
The corresponding part of the general solution may be written (c + c x + c x2)eλx.
1 2 3 Proceeding further in like manner, you could summarize case II in the following theorem: Theorem 3.9 (i) Consider the nth order homogeneous linear differential equation (4) with constant coefficients.
If the auxilliary equation (6) has the real root λ recurring k times, then the part of the general solution of (4) corresponding to this k-fold repeated root is (c + c x + c x2 + · · · + c xk−1)eλx.
1 2 3 k 1.
(ii) If, further, the remaining roots of the auxiliary equation (6) are the distinct real numbers λ , ..., λ , k+1 n then the general solution of (4) is y = (c + c x + c x2 + · · · + c xk−1)eλx + c eλk+1 x + · · · + c eλn x.
1 2 3 k k+1 n 2.
If, however any of the remaining roots are also repeated, then the parts of the general solution of (4) corresponding to each of these other repeated roots are expressions similar to that corresponding to λ in part (i) Here are some examples Example 3.20 Find the general solution of ylll − 4yll − 3yl + 18y = 0 The auxilliary equation.
λ3 − 4λ2 − 3λ + 18 = 0 has roots 3, 3, −2.
The general solution is y = c1e3x + c2xe3x + c3e−2x or y = (c + c x)e3x + c e−2x.
1 2 3 Example 3.21 Find the general solution of y(iv) − 5ylll + 6yll + 4yl − 8y = 0.
The auxilliary equation is λ4 − 5λ3 + 6λ2 + 4λ − 8 = 0 with roots 2, 2, 2, −1.
The part of the general solution corresponding to the threefold root 2 is y = (c1 + c2x + c3x2)e2x and that corresponding to the simple root −1 is simply y = c4e−x Thus the general solution is y = (c1 + c2x67+ c3x2)e2x + c4e−x  3.2 General Theory for Linear Differential Equationswith ConstantCoefficent 3.2.4 Case III.
Conjugate Complex Roots Now suppose that the auxiliary equation has the complex number a + bi (a, b real, i2 = −1, b /= 0) as a nonrepeated root.
Then, sinc the coefficients are real, the conjugate complex number a − bi is also a nonrepeated root.
The corresponding part of the general solution is k e(a+bi)x + k e(a−bi)x, 1 2 where k and k are arbitrary constants.
The solutions defined by e(a+bi)x and e(a−bi)x are complex functions 1 2 of the real variable x.
It is desirable to replace these by two real linearly independent solutions.
This can be accomplished by using Euler’s Formula, eiθ = cos θ + i sin θ which holds for all real θ.
Using this you have: k e(a+bi)x + k e(a−bi)x = k eaxebix + k eaxe−bix 1 2 1 2 = eax[k eibx + k e−ibx] 1 2 = eax[k (cos bx + i sin bx) + k (cos bx − i sin bx)] 1 2 = eax[(k + k ) cos bx + i(k − k ) sin bx] 1 2 1 2 = eax[c sin bx + c cos bx] 1 2 where c = i(k − k ), c = k + k are two new arbitrary constants.
Thus the part of the general solution 1 1 2 2 1 2 corresponding to the nonrepeated conjugate complex roots a + bi is eax[c sin bx + c cos bx].
1 2 Combining this with the results of case II, you have the following theorem covering case III.
Theorem 3.10 1.
Consider the nth order homogeneous linear differential equation (4) with constant coefficients.
If the auxiliary equation (6) has the conjugate complex roots a+bi and a-bi, neither repeated, then the corresponding part of the general solution of (4) may be written y = eax(c sin bx + c cos bx).
1 2 2.
If, however, a+bi and a-bi are each k-fold roots of the auxiliary equation (6), then the corresponding part of the general solution of (4) may be written y = eax[(c + c x + c x2 + · · · + c xk−1) sin bx + (c + c x + c x2 + · · · + c xk−1) cos bx] 1 2 3 k k+1 k+2 k+3 2k Here are some several examples.
Example 3.22 Find the general solution of yll + y = 0 You have already used this equation to illustrate the theorems of section 3.1.
You could now obtain its solution using theorem 3.10.
The auxiliary equation λ2 + 1 = 0 has the roots λ = ±i.
this are the pure imaginary complex numbers a ± bi, where a = 0, b = 1.
The general solution is thus y = r0x(c sin 1 · x + c cos 1 · x), 1 2 which is simply y = c sin x + c cos x 1 68 2  3.2 General Theory for Linear Differential Equationswith ConstantCoefficent Example 3.23 Find the general solution of yll − 6yl + 25y = 0 The auxiliary equation is λ2 − 6λ + 25 = 0.
Solving it, you find √ 6 ± 36 − 100 6 ± 8i λ = = = 3 ± 4i.
2 2 Here the roots are the conjugate complex numbers a ± bi, where a = 3, b = 4.
The general solution may be written y = e3x(c sin 4x + c cos 4x).
1 2 Example 3.24 Find the general solutio of y(iv) − 4ylll + 14yll − 20yl + 25y = 0 The auxiliary equation is m4 − 4m3 + 14m2 − 20m + 25 = 0.
The solution of this equation presents some ingenuity and labor.
Since our purpose in this example is not to display your mastery of the solution of algebraic equation but rather to illustrate the above principles of determining the general solution of differential equation, you can verify that the roots are 1 + 2i, 1 − 2i, 1 + 2i, 1 − 2i Since each pair of conjugate roots is double, the general solution is y = ex[(c + c ) sin 2x + (c + c ) cos 2x] 1 2 3 4 3.2.5 An Initial-Value Problem Here is an application of the results concerning general solutions of homogeneous linear equation with constants to an initial-value problem involving such an equation.
Example 3.25 Solve the initial-value problem yll − 6yl + 25y = 0 (11) y(0) = −3 (12) yl(0) = −1 (13) First note that by theorem 3.1, this problem has a unique solution defined for all x, −∞ < x < ∞.
You can now proceed to find this solution; that is, you seek the particular solution of the differential equation (11) which satisfies the two initial conditions (12) and (13).
You have already found the general solution of the differential equation (11) in example 3.23.
It is y = e3x(c sin 4x + c cos 4x).
(14) 1 2 From this, you find yl = e3x[(3c − 4c ) sin 4x + (4c + 3c ) cos 4x].
(15) 1 2 1 2 You can now apply the initial conditions.
Applying condition (12), y(0) = −3.
to equation (14), you find −3 = e0(c619sin 0 + c2 cos 0)  3.2 General Theory for Linear Differential Equationswith ConstantCoefficent which reduces at once to c = −3 (16) 2 Applying condition (13), yl(0) = −1, to Equation (15), you obtain −1 = e0[(3c − 4c ) sin 0 + (4c + 3c ) cos 0] 1 2 1 2 which reduces to 4c + 3c = −1 (17) 1 2 Solving Equation (16) and (17), you find (cid:31) (cid:31) c = 2 1 (cid:31) c = −3.
2 Replacing c and c in Equation (4.19) by these values, you obtain the unique solution of the given 1 2 initial-value problem in the form y = e3x(2 sin 4x − 3 cos 4x).
/ √ You may write this in an alternate form by first multiplying and dividing by (22) + (−3)2 = 13 to obtain r l y = √13e3x √1 sin 4x − √3 cos 4x 13 13 from this you may express the solution in the alternate form √ y = 13e3x sin(4x + φ), where the angle φ is defined by the equations (cid:31) 3 (cid:31) sin φ = − √ (cid:31) (cid:31) 13 (cid:31)(cid:31) 2 (cid:31) cos φ = √ 13 3.2.6 The Method of Undetermined Coefficients You will be dealing with the (nonhomogeneous) differential equation a0y(n) + a1y(n−1) + · · · an −1yl + an y = b(x) (18) where the coefficients a , a , ..., a are constants but where the nonhomogeneous term b is (in general) a 0 1 n nonconstant function of x.
Recall that the general solution of (18) may be written y = yc + yp where y is the complementary function.
that is the general solution of the corresponding homogeneous c equation (equation (18) with b replaced by 0), and y is a particular integral, that is, any solution of (18) p containing no arbitrary constants.
In last section, you learnt how to find the complementary function, now you will consider methods of determining a particular integral.
You shall first consider the method of undetermined coefficients.
Mathematically speaking, the class of functions b to which this method applies is actually quite restricted; but this mathematically narrow class includes functions of frequent occurrence and considerable importance in various physical applications.
And this method has one distinct advantage - when it does apply, it is relatively simple.
The following are some preliminary definition7s0  3.2 General Theory for Linear Differential Equationswith ConstantCoefficent Definition 3.8 You should call a function UC function if it is either 1.
A function defined by any of the following (a) xn, where n is a positive integer or zero.
(b) eax, where a is a constant /= 0.
(c) sin(bx + c), where b and c are constants, b /= 0.
(d) cos(bx + c), where b and c are constants, b /= 0. or 2.
A function defined as a finite product of two or more functions of these four types.
The method of undetermined coefficients applies when the nonhomogeneous function b in the differ- ential equation is a finite linear combination of UC functions.
Observe that given a UC function f, each successive derivative of f is either itself a constant multiple of a UC function or else a linear combination of UC functions.
Definition 3.9 Consider a UC function f. The set of functions consisting of f itself and all linearly in- dependent UC functions of which the succesive derivatives of f are either constant multiples or linear combinations will be called the UC set of f. Example 3.26 The function f defined for all real x by f (x) = x3 is a UC function.
Computing derivatives of f, you find f l(x) = 3x2, f ll(x) = 6x, f lll = 6, f (n)(x) = 0 for n > 2.
Examples Below are a few illustrative examples which gives you the procedure for finding the particular integral using the method of undetermined coefficients.
Example 3.27 yll − 2yl − 3y = 2ex − 10 sin x.
The corresponding homogeneous equation is yll − 2yl − 3y = 0 and the complementary function is yc = c1e3x + c2e−x The nonhomogeneous term is the linear combination 2ex − 10 sin x of the two UC functions given by ex and sin x.
1.
Form the UC set for each of these two functions.
You find S = {ex} 1 S = {sin x, cos x}.
2 2.
Note that neither of these sets is identical w7i1th nor included in the other; hence both are retained.
3.2 General Theory for Linear Differential Equationswith ConstantCoefficent 3.
Furthermore, by examining the complementary function, you see that none of the functions ex, sin x, cos x in either of these sets is a solution of the corresponding homogeneous equation.
Hence neither set needs to be revised.
4.
Thus the original set S and S remain intact in this problem, and you form the linear combination 1 2 Aex + B sin x + C cos x of the three elements ex, sin x, cos x of S and S , with the undetermined coefficients A, B, C. 1 2 5.
You can determine these unknown coefficients by substituting the linear combination formed in step (4) into the differential equation and demanding that it satisfies the differential equation identically.
That is, you take y = Aex + B sin x + C cos x p is a particular solution.
Then yl = Aex+ B cos x − C sin x p yll = Ae x− B sin x − C cos x p Substitution, gives you [Aex − B sin x − C cos x] − 2[Aex + B cos x − C sin x] − 3[Aex + B sin x + C cos x] = 2ex − 10 sin x or −4Aex + (−4B + 2C ) sin x + (−4C − 2B) cos x = 2ex − 10 sin x. Equating coefficients of like terms, you should obtain the equations (cid:31) −4A = 2 (cid:31) (cid:31) (cid:31) −4B + 2C = −10 (cid:31) (cid:31) (cid:31) −4C − 2B = 0.
From these equations, you find that (cid:31) 1 (cid:31) A = − (cid:31) 2 (cid:31) B = 2 (cid:31) (cid:31) (cid:31) (cid:31) C = −1 and hence you obtain the particular integral 1 y =− ex + 2 sin x − cos x p 2 Thus the general solution of the differential equation under consideration is 1 y = y + y = c e3x + c e−x − ex + 2 sin x −cos x c p 1 2 2 Example 3.28 Initial-Value Problem This section will be closed by applying the results to the solution to the initial-value problem (cid:31) (cid:31) yll − 2yl − 3y = 2ex − 10 sin x, (cid:31) (cid:31) y(0) = 2 (cid:31) (cid:31)(cid:31) yl(0) = 4.
72  3.2 General Theory for Linear Differential Equationswith ConstantCoefficent By theorem 3.1, this problem has a unique solution, defined for all x, −∞ < x < ∞; So you can now proceed to find it.
In example 3.27, you found that the general solution of the differential equation is 1 y = c e3x + c e−x − + 2 sin x − cos x.
1 2 2 From this, you have 1 yl = 3c e3x − c e−x − ex + 2 cos x + sin x.
1 2 2 Applying the initial conditions to the last two equations, respectively, you have (cid:31) (cid:31)(cid:31) 2 = c e0 + c e0 − 1 e0 + 2 sin 0 − cos 0 (cid:31) 1 2 2 (cid:31)(cid:31) 1 (cid:31) 4 = 3c e0 − c e0 − e0 + 2 cos 0 + sin 0 1 2 2 These equations simplify at once to the following: (cid:31) 7 (cid:31) c + c = (cid:31) 1 2 2 (cid:31)(cid:31) 5 (cid:31) 3c − c = 1 2 2 From these two equations you obtain (cid:31) 3 (cid:31) (cid:31) c = 1 2 (cid:31) (cid:31) c = 2.
2 Substituting these values for c and c into the general solution you obtain the unique solution of the given 1 2 initial-value problem in the form 3 1 y = e3x + 2e−x − ex + 2 sin x −cos x.
2 2 3.2.7 Variation Of Paramenters The Method While the process of carrying out the method of undetermined coefficients is quite straightforward (involv- ing only techniques of college algebra and differentiation, the method applies in general to a rather small class of problems.
For example, it does not apply to the apparently simple eqution yll + y = tan x You thus need a method of finding a particular integral which applies in all cases of variable coefficients) in which the complementary function is known.
Such a method is called method of variation of parameters, which you would now consider.
This method shall be developed with the general second order differential equation with variable coef- ficients a (x)yll + a (x)yl + a (x)y = b(x) (19) 0 1 2 Suppose that y and y are linearly independent solutions of the corresponding homogeneous equation 1 2 a0(x)yll + a17(3x)yl + a2(x)y = 0 (20)  3.2 General Theory for Linear Differential Equationswith ConstantCoefficent Then the complementary function of equation (19) is c y + c y , 1 1 2 2 where c and c are arbitray constants.
The procedure in the method of variation of parameters is to replace 1 2 the arbitray constants c and c in the complementary function by respective functions v and v which will 1 2 1 2 be determined so that the resulting function v y + v y (21) 1 1 2 2 will be a particular integral of equation (19) (hence the name, variation of parameters).
conditions that (21) be a solution of (19).
Since you have two functions but only one conditions on them, you are thus free to impose a second condition, provided this second condition does not violate the first one.
You shall see when and how to impose this additional condition as you proceed.
You thus assume a solution of the form (21) and write y = v y + v y , (22) p 1 1 2 2 Differentiating (22) you would have yl = v yl + v yl + vl y + vl y (23) p 1 1 2 2 1 1 2 2 At this point, you should impose the condition; vl y + vly = 0 (24) 1 1 2 2 With this condition imposed, (33) reduces to yl = v yl + v yl.
(25) p 1 1 2 2 Now differentiating (25), you should obtain yll= v yll + v yll + vl yl + vl yl .
(26) p 1 1 2 2 1 1 2 2 Now impose the basic condition that (22) be a solution of equation (19).
Thus you substitute (22), (25), and (26) for y, yl, and yll, respectively, in equation (19) and obtain the identity a [v yll + v yll + vl yl + vl yl ] + a [v yl + v yl ] + a [v y + v y ] = b 0 1 1 2 2 1 1 2 2 1 1 1 2 2 2 1 1 2 2 This can be written as v [a yll + a yl + a y ] + v [a yll + a yl a y ] + a [vl yl + vl yl ] = b (27) 1 0 1 1 1 2 1 2 0 2 1 2 2 2 0 1 1 2 2 Since y and y are solutions of the corresponding homogeneous differential equation (20), the expressions 1 2 in the first two brackets in (27) are identically zero.
This leaves merely b vl y l + vl yl = (28) 1 1 2 2 a 0 This is actually what the basic conditioin demands.
Thus the two imposed conditions require that the functions v and v be chosen such that the system of equations 1 2 (cid:31) y vl + y vl = 0 (cid:31)(cid:31) 1 1 2 2 (29) b (cid:31)(cid:31) yl vl + yl vl = 1 174 2 2 a0 None 3.2 General Theory for Linear Differential Equationswith ConstantCoefficent is satisfied.
The determinant of coefficients of this system is precisely y y W (y , y ) = 1 2 1 2 yl yl 1 2 Since y and y are linearly independent solutions of the corresponding homogeneous differential equations 1 2 (20) you know that W (y , y ) /= 0.
Hence the system (29) has a unique solution.
Actually solving the 1 2 sytem you obtain 0 y 2 b yl vl1 = ya 0 y 2 = −a Wb (yy 2 , y ) 1 2 0 1 2 yl yl 1 2 y 0 1 b yl vl2 = y1 ay 0 = a Wb (yy 1, y ) 1 2 0 1 2 yl yl 1 2 Thus you obtain the functions v and v given by 1 2 x b(t)y (t)dt 2 v1(x) = − a (t)W [y (t), y (t)] 0 1 2 (30) x b(t)y (t)dt 1 v2(x) = a (t)W [y (t), y (t)] 0 1 2 Therefore a particular integral of equation (29) is y = v y + v y , p 1 1 2 2 where v and v are defined by (30) 1 2 Examples Example 3.29 yll + y = tan x (31) The complementary function is y = c sin x + c cos x. c 1 2 Assume y = v sin x + v cos x, (32) p 1 2 where the functions v and v will be determined such that this is a particular integral of the differential 1 2 equation (31).
Then using the formulas above, you obtain 0 cos x tan x − sin x − cos x tan x vl = = = sin x 1 sin x cos x −1 cos x − sin x 75  6 Tutor Marked Assignments(TMAs) sin x 0 cos x tan x − sin x tan x sin2 x cos2 x − 1 − vl = = 1 sin x cos x = − = = cos x sec x. cos x − sin x −1 cos x cos x Integrating you find: v1 = − cos x + c3 (33) v = sin x − ln | sec x + tan x| + c 2 4 Substituting (33) into (32) you have y = [− cos x + c ] sin x + [sin x − ln | sec x + tan x| + c ] cos x p 3 4 = − sin x cos x + c sin x + sin x cos x − ln | sec x + tan x|(cos x) + c cos x 3 4 = c sin x + c cos x − (cos x)[ln | sec x + tan x|].
3 4 Since a particular integral is a solution free of arbitrary constants, you may assign any particular values A and B to c and c , respectively, and the result will be the particular integral 3 4 A sin x + B cos x − (cos x)[ln | sec x + tan x|].
Thus y = y + y becomes: c p y = c sin x + c cos x + A sin x + B cos x − (cos x) ln | sec x + tan x| 1 2 which you may write as y = C sin x + C cos x − cos x − (cos x) ln | sec x + tan x|, 1 2 where C = c + A, C = c + B.
1 1 2 2 Thus you see that you might as well have chosen the constants c and c both equal to 0 in (33).
for 3 4 essentially the same result, y = c sin x + c cos x − (cos x) ln | sec x + tan x|, would have been obtained.
1 2 This is the general solution of the differential equation (31).
The method of variation of parameters extend to higher order linear equations.
The proof of the validity of this method for the general nth-order equation will not be given in this work, you can find it in advanced text of ODE.
4 Conclusion In this unit, you have studied the basic theory of linear differential equations and have used the explicit methods described in this unit to obtain the general and particular solutions of differential equations with constant coefficients.
5 Summary Having gone through this unit, you now know; 1. the basic theory of nth order linear ordinary differential equations.
2. how to obtain the solutions to a given ODEusing the explicit method described in this unit.
76  4 Conclusion 6 Tutor Marked Assignments(TMAs) Exercise 6.1 1.
Theorem 3.1 applies to one of the following problems but not to the other.
Determine to which the problems applies and state precisely the conclusion which can be drawn in this case.
Explain why the theorem does not apply to the remaining problem.
(cid:31) (cid:31) (cid:31) yll + 5yl + 6y = ex (cid:31) yll + 5yl + 6y = ex (cid:31)(cid:31) (cid:31)(cid:31) (a) y(0) = 5 (b) y(0) = 5 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) yl(0) = 7. yl(1) = 7.
2.
Answer orally: What is the solution of the following initial-value problem?
Why?
(cid:31) yll + xyl + x2y = 0 (cid:31) (cid:31) (cid:31) y(1) = 0 (cid:31) (cid:31) (cid:31) yl(1) = 0.
3.
Consider the differential equation yll − 5yl + 6y = 0.
(a) Show that e2x and e3x are linearly independent solutions of this equation on the interval −∞ < x < ∞.
(b) Write the general solution of the given equation.
(c) Find the solution which satisfies the condition y(0) = 2, yl(0) = 3.
Explain why this solution is unique.
4.
Consider the differential equation x2yll + xyl − 4y = 0 (a) Show that x2 and 1 are linearly independent solutions of this equations of this equation on the x2 interval 0 < x < ∞.
(b) Write the general solution of the given equation.
(c) Find the solution which satisfies the conditions y(2) = 3, yl(2) = −1.
Over what interval is this solution defined?
5.
The functions ex and e4x are both solutions of the differential equation yll − 5yl + 4y = 0.
(a) Show that these solutions are linearly independent on the interval −∞ < x < ∞.
(b) What theorem enables you to conclude at once that 2ex − 3e4x is also a solution of the given differential equation?
(c) Show that the solution of part(b) and the solution ex are also linearly independent on −∞ < x < ∞.
77  6 Tutor Marked Assignments(TMAs) 6.
Given that e−x, e3x and e4x are all solutions of ylll − 6yll + 5yl + 12y = 0, show that they are linearly independent on the interval −∞ < x < ∞ and write the general solution.
Exercise 6.2 Find the general solution of each of the differential equations in the following exercises.
1. yll − 5yl + 6y = 0.
2. yll − 2yl − 3y = 0.
3.
4yll − 12yl + 5y = 0.
4.
3yll − 14yl − 5y = 0.
5. ylll − 3yll − yl + 3y = 0 6. ylll − 6yll + 5yl + 12y = 0 7. yll − 8yl + 16y = 0 8.
4yll + 4yl + y = 0 9. yll − 4yl + 13y = 0 10. yll + 6yl + 25y = 0 11. yll + 9y = 0 12.
4yll + y = 0 13. ylll − 5yll + 7yl − 3y = 0 14.
4ylll + 4yll − 7yl + 2y = 0 15. ylll − 6yll + 12yl − 8y = 0 16. ylll + 4yll + 5yl + 6y = 0 17. ylll − yll + yl − y = 0 18. y(iv) + 8yll + 16y = 0 19. y(v) − 2y(iv) + ylll = 0 20. y(iv) − ylll − 3yll + yl + 2y = 0 21. y(iv) − 3ylll − 2yll + 2yl + 12y = 0 22. y(iv) + 6ylll + 15yll + 20yl + 12y = 0 23. y(iv) + y = 0.
24. y(v) = 0 Solve the initial-value problems in the exercises that follow.
78  6 Tutor Marked Assignments(TMAs) (cid:31) (cid:31) yll − yl − 12y = 0 (cid:31) (cid:31) 25. y(0) = 3 (cid:31) (cid:31) (cid:31) yl(0) = 5 (cid:31) (cid:31) 9yll − 6yl + y = 0 (cid:31) (cid:31) 26. y(0) = 3 (cid:31) (cid:31) (cid:31) yl(0) = −1 (cid:31) (cid:31) yll − 4yl + 29y = 0 (cid:31) (cid:31) 27. y(0) = 0 (cid:31) (cid:31) (cid:31) yl(0) = 5 (cid:31) 4yll + 4yl + 37y = 0 (cid:31) (cid:31) (cid:31) 28. y(0) = 2 (cid:31) (cid:31) (cid:31) yl(0) = −4 (cid:31) (cid:31) ylll − 6yll + 11yl − 6y = 0 (cid:31) (cid:31) (cid:31)(cid:31) y(0) = 0 29.
(cid:31) yl(0) = 0 (cid:31) (cid:31) (cid:31) (cid:31) yll(0) = 2.
(cid:31) (cid:31) ylll − 2yll + 4yl − 8y = 0 (cid:31) (cid:31) (cid:31)(cid:31) y(0) = 2 30.
(cid:31) yl(0) = 0 (cid:31) (cid:31) (cid:31) (cid:31) yll(0) = 0.
31.
The roots of the auxiliary equation, corresponding to a certain 10th-order homogeneous linear differ- ential equation with constant coefficients, are 4, 4, 4, 4, 2 + 3i, 2 − 3i, 2 + 3i, 2 − 3i, 2 + 3i, 2 − 3i Write the general solution.
32.
Given that sin x is a solution of y(iv) + 2ylll + 6yll + 2yl + 5y = 0, find the general solution.
Exercise 6.3 79  6 Tutor Marked Assignments(TMAs) Find the general solution of each of the differential equations following 1. yll − 3yl + 2y = 4x2 2. yll − 2yl − 8y = 4x2 − 21e−3x.
3. yll + 2yl + 5y = 6 sin 2x + 7 cos 2x 4. ylll + 2yll − 3yl − 10y = 8e−2x.
5. ylll + yll + 3yl − 5y = 5 sin 2x + 10x2 − 3x + 7.
6. y(iv) − 3ylll + 2yll = 3e−x + 6e2x − 6x 7. y(iv) − 5ylll + 7yll − 5yl + 6y = 5 sin x − 12 sin 2x Solve the initial-value problem in Exercises 18 through 21.
(cid:31) (cid:31) yll − 4yl + 3y = 9x2 + 4.
(cid:31) (cid:31) 8. y(0) = 6 (cid:31) (cid:31)(cid:31) yl(0) = 8.
(cid:31) yll + 4yl + 13y = 5 sin 2x.
(cid:31) (cid:31) (cid:31) 9. y(0) = 1 (cid:31) (cid:31)(cid:31) yl(0) = −2.
(cid:31) yll + y = 3x2 − 4 sin x.
(cid:31) (cid:31) (cid:31) 10. y(0) = 0 (cid:31) (cid:31) (cid:31) yl(0) = 1.
(cid:31) ylll − 4yll + yl + 6y = 3xex + 2ex − sin x.
(cid:31) (cid:31) (cid:31) 33 (cid:31) (cid:31) (cid:31) y(0) = 40 11.
(cid:31) (cid:31) yl(0) = 0 (cid:31) (cid:31) (cid:31) yll(0) = 0 80  MODULE 2 UNIT 4: LINEAR SYSTEM Contents 1 Introduction 81 2 Objectives 82 3 Linear System 82 3.1 Properties of Solution of Homogeneous Linear System 82 3.2 The Adjoint of the System (3) 87 3.3 Linear non-homogeneous System 88 3.3.1 Variation of Parameter Technique 88 3.4 Linear Homogenous Equation with constant Coefficients 91 3.5 Characterization of Fundamental Matrix in terms of exponential functions 100 3.6 Linear Non-homogeneous System 104 3.7 Linear Homogeneous System with Periodic Coefficients 105 4 Conclusion 107 5 Summary 107 6 Tutor Marked Assignments (TMAs) 109 1 Introduction In your previous studies, you know that equation such as where ai; i = 1; 2; :::; n are variable coefficient can be reduced to vector form 81  2 Objectives LINEAR SYSTEM where the unknown functions x ∈ Rn, A is n × n matrix function of t defined on some interval I and F : I → Rn is defined and continuous on I .
While f : I × Rn → Rn is a vector function of two variable t and x defined on Rn+1.
In this unit, you shall study Linear systems of ODE of the form (2).
And you shall see some results concerning the solution of this linear systems.
2 Objectives At the end of this unit, you should be able to (i) identify different forms of systems of ODE.
(ii) understand the nature of solutions of systems of ODE, both homogeneous and nonhomogeneous ODE.
(iii) define and obtain the adjoint of a system.
(iv) characterize fundamental matrices in terms of exponential functions.
3 Linear System 3.1 Properties of Solution of Homogeneous Linear System Definition 3.1 If F (t) = 0, then the system (2) is called a linear homogeneous system otherwise the system (2) is a linear nonhomogeneous system.
The order of (2) is the order of A.
Definition 3.2 A function Φ : I → Rn is a solution of x = f (t, x) (f : G → Rn, where G ⊂ R × Rn, an open subset.)
If for t ∈ I , you have that the pair (t, Φ(t)) ∈ G and Φ(t) is differentiable on I and Φ (t) = f (t, x(t)) Definition 3.3 A function Φ : I → Rn is a solution of IVP x = f (t, x), x(t0) = x0 if t0 ∈ I and Φ satisfies definition 3.2 and x(t0) = x0 It is evident from existence and uniqueness theorem that for any given t0 ∈ I , x0 ∈ Rn with \x0\ < ∞, the system (2) has a unique solution satisfying x(t ) = x .
0 0 Your attention will be drawn first to the homogeneous equation, x˙ = A(t)x (3) the following results are immediate 82  3.1 Properties of Solution of HomogeneousLinear System LINEAR SYSTEM Theorem 3.1 1.
If x = Φ(t) is a solution of (3) satisfying Φ(t0) = 0, t ∈ I , then Φ(t) ≡ 0 on I .
r 2.
If Φ1, Φ2, ..., Φr are solutions of (3) on I .
Then c Φ are also solutions on I .
i i i=1 Proof.
1.
The proof of this follows from the fact that X ≡ 0 is a solution of (3) and the uniqueness property of solution (3).
2.
Note that given Φ1, Φ2, ..., Φr , dΦ1 = AΦ1 , dΦ2 = AΦ2 , · · · , dΦr = AΦr .
dt dt dt Therefore d (c Φi) = Ac Φi, i = 1, 2, 3, ..., r i i dt Let r Φ = c1Φ1 + c2Φ2 + · · · + cr Φr = ciΦi i=1 Thus r r r r Φ˙ = d c Φ = d(c Φi) = Ac Φ = A c Φi = AΦ.
i i i i i i dt dt i=1 i=1 i=1 i=1 This follows from the linearity of (2) Theorem 3.2 The set of all solutions of (3) on I form an n­dimensional vector space over the real field called solution space.
Proof.
That the solution space is a vector follows from property (2) and the fact that X ≡ 0 is a solution of (3) on I .
To prove that the space is n­dimensional, you have to prove the existence of n-linearly independent solutions of (3) on I such that any other solutions of (3) on I can be written as a linear combination of this independent set.
Let ai, (i = 1, 2, ..., n) be a linealy independent set in Rn.
In particular, you can choose ai = (0, 0, ..., 0, 1, 0, ... with 1 at the ith position.
They by the existence theorem, given t0 ∈ I , ai ∈ Rn, there exists n solutions Φi(t), i = 1, 2, ..., n of (3) such that Φi(t) = ai.
These solutions are uniquely defined by t and ai.
Suppose 0 the Φi’s are linearly dependent, then there exist constants c (i = 1, 2, ..., n) not all equal to zero sunc that i r ciΦi(t) = 0, t ∈ I .
i=1 83  3.1 Properties of Solution of HomogeneousLinear System LINEAR SYSTEM In particular, n n ciai = ciΦi(t0) = 0 t0 ∈ I i=1 i=1 which contradicts the assumption that the ai’s are linearly independent.
Now let Φ be any solution such that Φ(t0) = a, a ∈ Rn for some unique constants c1, ...cn, n a = c a i i i=1 n Since the ai’s form a basis in Rn.
Hence the function c Φi is a solution of (3) on I , which assumes the i i=1 value a at t = t and by uniqueness 0 n Φ = ciΦi i=1 Thus every other solution of (3) can be expressed as a unique linear combination of the Φi’s.
Hence the proof of theorem (1.2) is complete.
Definition 3.4 1.
If Φ1, Φ2, ..., Φn are linearly independent solutions of (3) on I , then the set Φ1, Φ2, ..., Φn is called a fundamental set of solutions of (3) on I .
2.
If Φ1, Φ2, ..., Φn are solutions of (3) on I , the matrix with Φ1, Φ2, ..., Φn as a column is called a matrix solution of (3) (cid:31) (cid:31) Φ111 Φ21 2 · · · Φ1nn (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) Φ211 Φ222 · · · Φn2 n (cid:31)(cid:31) (cid:31) (cid:31) X = (cid:31) (cid:31) (cid:31)(cid:31) .
.
.
.
.
.
(cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) Φn11 Φn22 · · · Φnnn and it is easy to verify that X˙ = A(t)X (4) is the matrix differential equation associated with the system (3).
The problem of determining n linearly independent solutions of (3) is the same as finding a particular solution of such that the columns are linearly independent.
3.
If X is a matrix solution such that all its column are linearly indpendent.
Then X is said to be fundamental matrix solution of (3).
Theorem 3.3 A solution matrix X of (3) on I is fundamental if and only if the determinant det X (t) /= 0 for at least one t ∈ I 84  3.1 Properties of Solution of HomogeneousLinear System LINEAR SYSTEM The proof of the above theorem requires the following lemma.
Lemma 3.1 Let X be a solution matrix of (3) on I then W (t) ≡ det X (t) (5) satisfies on I the differential equation W˙ (t) = {tr(A)}W (t) (6) with initial condition.
W (t0) = W0, t0 ∈ I indeed for t ∈ I , t W (t) = W exp trA(s)ds (7) 0 0 where the trace of A n tr(A) = a ii i=1 Proof of Lemma Let x and a be components of X and A respectively.
Since X is a solution matrix, ij ij we have X˙ = AX and hence n x˙ = a x , i, j = 1, 2, ..., n ij ik kj i=1 By definition W=W(t) is differentiable in t. Futhermore, the derivative n W˙ (t) = W (t) i i=1 where the terms is obtained from W by differentiating ith row of W and leaving all other rows.
Indeed n n n a1k xk1 a1k xk2 · · · a1k xkn k=1 k=1 k=1 W˙ = x21 x22 · · · x2n .. .. ... .. xn1 xn2 · · · xnn 85  3.1 Properties of Solution of HomogeneousLinear System LINEAR SYSTEM The determinant remains unchanged if you subtract from the 1st row { a x second row +a x third row 12 13 +... + a x nth row}.
In deed you shall obtain 1n a11x11 a11x12 · · · a11x1n x21 x22 · · · x2n W˙ = .
.
.
.
.
xn1 xn2 · · · xnn By treating W , W , ..., W in similar way, you see that 2 3 n ˙ W(t) = (a11 + a22 + · · · + ann)W (t) which proves (6).
The result (7) follows by W˙ (t) = (tr(A(t)))W (t) t W (t) = W exp trA(s)ds 0 t0 Note: As a conseqence of the lemma, it is clear that if W (t0) /= 0 then W (t) /= 0 for t ∈ I .
This f t is obvious from the fact that exp( trA(s)ds) does not vanish except at a singularity of A(t).
The continuity t 0 ensures that this does not happen.
Also the fact that W (t) /= 0 for all t ∈ I proves that the column of X = X (t) are linearly independent.
Proof of Theorem1.3 Let X be a fundamental matrix of (3) on I , with column vector xj , j = 1, 2, ..., n. Suppose that x is a nontrivial solution of (3) on I .
By theorem (1.1), there exists a unique constant c , i i = 1, 2, ..., n not all zero such that x = cixi i=1 or equivalently x = X C where C = (c , ..., c )T , a column matrix, and X is the matrix with xi, i = 1, ..., n as columns.
At any 1 n point t0 ∈ I , x is a system of n linear equations in n­unknowns c1, ..., cn.
It has a unique solution for any choice of x(t0).
Hence from the theory of linear algebra det(X (t0)) /= 0 for t ∈ I .
Then the columns of X are linearly independent, and so X is a fundamental matrix of (3) on I .
Remark 3.1 A matrix of linearly independent vectors on I may have its determinant equal to zero.
The main point of Theorem 1.2 is that this cannot happen for column vectors which are solutions of (3) (cid:31) (cid:31) t t2 X (t) = (cid:31) (cid:31) 0 0 x˙ = 1 x˙ = 2t 11 12 x˙ = 0 x˙ = 0 21 22 86  3.3 Linear nonhomogeneous System LINEAR SYSTEM Not possible.
Theorem 3.4 If Φ is a fundamental matrix of (3) on I so also is ΦC where C is a constant nonsingular n × n matrix.
Every fundamental matrix of (3) on I is of the form (ΦC ) for some nonsingular constant matrix C. Proof.
By definition, if Φ is a fundamental matrix, then ˙ Φ = A(t)Φ, t ∈ I and d (ΦC ) = Φ˙ C = A(t)ΦC dt Thus ΦC is a solution matrix.
The fact that ΦC is a fundamental matrix follows from the fact det(ΦC ) = (det Φ)(det C ) /= 0 If Φ , Φ , are fundamental matrix on I for (3) then we prove that for some nonsingular constant matrix C, 1 2 Φ = Φ C 2 1 To verify this, set Φ(t) = Φ1−1Φ2 or Φ1Ψ = Φ2 Differentiating, the last equation Φ˙ = Φ˙ Ψ + Φ Ψ˙ 2 1 1 and so AΦ = AΦ˙ Ψ + Φ Ψ˙ or Φ Ψ˙ = 0 2 1 1 1 This implies that Ψ˙ = 0 i.e., Φ = C, where C is a constant.
By definition, C is nonsingular 3.2 The Adoint of the System (3) Let Φ be a fundamental matrix of (3) on I , then by definition Φ−1 exists on I and ΦΦ−1 = I (8) n where In is the unit n × n constant matrix .
Differentiating (8) yields Φ˙ Φ−1 + ΦΦ˙ −1 = 0 so that A(t)ΦΦ−1 + ΦΦ˙ −1 = 0 87  3.2 The Adoint of the System (3) LINEAR SYSTEM Thus Φ˙ −1 = ­Φ−1A(t) Taking the transpose of both sides, then (Φ˙ −1)T = AT (t)(Φ−1)T so that (Φ−1)T is a fundamental matrix of x˙ = ­AT (t)x (9) The equatioin (9) is known as the adjoint of the system (3).
The matrix differential equation X˙ = ­AT (t)X associated with (9) is also the adjoint of the matrix associated with (3).
The relationship is symmetric.
Thus, (3) is called the adjoint of (9) and (9) the adjoint of (3).
Theorem 3.5 If Φ is a fundamental matrix for (3) then Ψ is a fundamental matrix for its adjoint (9) if and only if ΨT Φ = C for some constant nonsingular n × n matrix C. Proof.
Suppose Φ is a fundamental matrix of (3).
Then (Φ−1)T is a fundamental matrix of (9).
Also Ψ is a fundamental matrix of (9) .
By theorem (1.4), (Φ−1)T is a fundamental matrix (Φ−1)T C is also a fundamental matrix.
Therefore Ψ = (Φ−1)T C (10) Taking transpose of both sides of (10) you have Ψ˙ T = Φ−1C and ΨT Φ = C and hence the proof.
3.3 Linear nonhomogeneous System You will refer to the system (2) as a linear inhomogeneous system with A(t), F (t) defined as before.
By the existence and uniqueness theorem given t0 ∈ I , x0 ∈ Rn, with \x0\ < ∞ then there exist a unique solution x(t) of (2) satisfying x (t) = x .
0 0 3.3.1 Variation of Parameter Technique Recall that if Φ(t) is a fundamental matrix solution for (3) then x(t) = Φ(t)C (11) where C is a constant n-vector is a solution of (3).
For a particular solution x(t), with x (t) = x , C is given 0 0 by Φ(t )x .
Then C in (11) is a vector parameter.
Now you have to consider C as a variable in t and seek a 0 0 condition on C=C(t) such that (11) is a solution of (2) on I satisfying some prescribed initial condition.
88  3.3 Linear nonhomogeneous System LINEAR SYSTEM Indeed let x(t) = Φ(t)C (t) (12) be a solution of (2).
Differentiating both sides of (12), you have x˙ (t) = Φ˙ (t)C (t) + Φ(t)C˙ (t) Ax(t) = A(t)Φ(t)C (t) + Φ(t)C˙ (t) (13) From (2), Ax(t) = A(t)Φ(t)C (t) + F (t) (14) since Φ is a fundamental matrix solution and (12) is a solution of (2), C˙ (t) = Φ−1(t)F (t) (15) A particular case of equation (15) satisfying C (t ) = 0 is given by 0 t C (t) = Φ−1(τ )F (τ )dτ.
t0 Thus t x(t) = Φ(τ )Φ−1(τ )F (τ )dτ t0 is a solution of (2).
Now, the solution x(t) of (2) satisfying the initial condition x(t0) = x0 is given by t x(t) = Φ(t)Φ−1(t )x + Φ(τ )Φ−1(τ )F (τ )dτ (16) 0 0 t0 Theorem 3.6 Given the system (2), with A(t) (n × n matrix), F (t) n­vector (functions) defined and con- tinuous on the interval I .
Let Φ = Φ(t) be a fundamental matrix solution of (3) on the interval I, then the function t x(t) = Φ(t) Φ−1(t )x + Φ−1(τ )F (τ )dτ 0 0 t0 is a solution of (2 ) on the interval I , satisfying the initial condition x(t ) = x .
0 0 Proof.
Φ(t) is a fundamental matrix solution of (3), then x(t) = Φ(t)C (t) By straightforward differentiation x˙ (t) = Φ˙ (t)C (t) + Φ(t)C˙ (t) From (13) and (14) Φ(t)C˙ (t) = F (t) yielding C˙ (t) = Φ−1(t)F (t) (17) 89  3.3 Linear nonhomogeneous System LINEAR SYSTEM Integrating (17), you will obtain t C (t) = Φ−1(τ )F (τ )dτ t0 Therefore, t Φ(t)C (t) = Φ(t) Φ−1(τ ) t0 Now the solution of the system (2) satisfying the initial condition x(t ) = x is given by 0 0 t x(t) = Φ(t)Φ−1(t )x + Φ(t) Φ−1(τ )F (τ )dτ 0 0 t0 and t x(t) = Φ(t) Φ−1(t )x + Φ−1(τ )F (τ )dτ 0 0 t0 and this completes the proof of theorem (1.6).
Theorem 3.7 Let A(t), F (t) be defined as in theorem 1.6, Let Φ = Φ(t) be a fundametal matrix solution for the adjoint system (9).
Then the equation t x(t) = (ΦT )−1 ΦT (t )x + ΦT (τ )F (τ )dτ (18) 0 0 t0 is a solution of (2) satisfying x(t ) = x .
0 0 Proof.
Now let x be a solution of (2) and Φ be a fundamental matrix of solution of (18).
Then x(t) = ΦT (t)x(t) (19) Differentiating both sides of (19) you have x˙ (t) = Φ˙ T (t)x(t) + ΦT (t)x˙ (t) From (9), you have that x˙ (t) = ­A(t)ΦT x(t) + ΦT (t)[A(t)x(t) + F (t)]orx˙ (t) = ΦT (t)F (t) Integerating from t = t to t, you have 0 t ΦT (t)x(t) ­ ΦT (t0)x(t0) = ΦT (τ )F (τ )dτ t0 i.e., t ΦT (t)x(t) = ΦT (t )x(t ) + ΦT (τ )F (τ )dτ 0 0 t0 which yields t x(t) = (ΦT )−1 ΦT (t )x + ΦT (τ )F (τ )dτ 0 0 t0 and the proof of theorem (1.7) is complete.
90  3.4 Linear Homogenous Equation with constantCoefficients LINEAR SYSTEM 3.4 Linear Homogenous Equation with constant Coefficients Consider the system x˙ (t) = Ax(t) (20) where A is a constant n × n matrix.
Suppose that x(t) = ceλt is a solution of (20), then x˙ (t) = λceλt = Aceλt That is (A ­ λIn) = 0 Thus x = ceλt is a solution of (20) if and only if λ is an eigenvalue and c is the corresponding eigenvector.
Theorem 3.8 Let λ , λ , ..., λ be distinct eigenvalues of A with corresponding eigenvectors c , c , ..., c , 1 2 n 1 2 n then n x(t) = c eλi t i i=1 is the general solution of (20).
Proof.
Assuming that all the eigenvalues of A are distinct, then there exists a nonsingular matrix T which reduces A to its diagonal form that is T −1AT = D where (cid:31) (cid:31) λ1 0 0 · · · 0 0 (cid:31)(cid:31) 0 λ2 0 · · · 0 0 (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) 0 0 λ3 · · · 0 0 (cid:31) D = (cid:31)(cid:31) .
.
.
.
.
.
.
.
(cid:31)(cid:31) (cid:31) (cid:31) (cid:31) 0 0 0 · · · λn−1 0 (cid:31) 0 0 0 · · · 0 λn Now let y = T −1x y˙ = T −1x˙ = T −1Ax = T −1AT y = Dy That is y˙i = λiyi and so yi = cieλi t where the c ’s are arbitrary constants.
i You can now exhibit n-linearly independent solutions of the vector equation y˙ = Dy They are 91  3.4 Linear Homogenous Equation with constantCoefficients LINEAR SYSTEM (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) eλi t 0 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) 0 (cid:31)(cid:31) (cid:31)(cid:31) eλ2 t (cid:31)(cid:31) (cid:31)(cid:31) 0 (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) (cid:31)(cid:31) , y1 = (cid:31)(cid:31) (cid:31)(cid:31) , · · · yn = (cid:31)(cid:31) (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) .
(cid:31) (cid:31) .
(cid:31) (cid:31) .
(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 0 0 eλn t These vectors are linearly independent since the determinant eλ1 t 0 0 · · · 0 0 0 eλ2 t 0 · · · 0 0 0 0 eλ3 t ··· 0 0 .
.
.
.. = e(λ1 +λ2 +···+λn )t .
.
0 0 0 ··· eλn−1 t 0 0 0 0 ··· 0 eλn t which is nonzero.
Since x = T y, T y , T y , ..., T y form a fundamental solution for (20) and the matrix 1 2 n whose columns are T y , T y , ..., T y is the fundamental matrix.
1 2 n Example 3.1 Find the general solution of the system 0 1 0 x˙ = x, x(0) = 1 2 1 Solution.
The eigenvalues of the matrix 0 1 A = 1 2 is obtained as follows 0 ­ λ 1 = 0 i.e., ­λ(2 ­ λ) ­ 1 = 0 or λ2 ­ 2λ ­ 1 = 0 1 2 ­ λ so that λ1,2 = 2 ±2√ 2 i.e., λ1 = 1 + √ 2 and λ2 = 1 ­ √ 2 2 Now, for λ = 1 + √ 2, 1 (cid:31) √ (cid:31) (cid:31) (cid:31) √ ­1 ­ 2 1 c1 (­1 ­ 2)c1 + c2 = 0 (cid:31) (cid:31) (cid:31) (cid:31) = 0 or √ √ 1 1 ­ c2 c1 + (1 ­ 2)c2 = 0 2 92  3.4 Linear Homogenous Equation with constantCoefficients LINEAR SYSTEM So that (cid:31) (cid:31) (cid:31) a (cid:31) c1 (cid:31) 1 + √ 2 (cid:31) (cid:31) (cid:31) = (cid:31) (cid:31) c2 a √ For λ2 = 1 ­ 2, (cid:31) √ (cid:31) (cid:31) (cid:31) √ ­1 + 2 1 c1 (­1 + 2)c1 + = 0 (cid:31) (cid:31) (cid:31) (cid:31) = 0 or √ √ 1 1 + c2 c1 + (1 + 2)c2 = 0 2 So that (cid:31) (cid:31) (cid:31) (cid:31) b c1 (cid:31) √ (cid:31) (cid:31) (cid:31) = (cid:31)(cid:31) 1 ­ 2 (cid:31)(cid:31) c2 b Therefore, (cid:31) (cid:31) (cid:31) a (cid:31) b y = (cid:31)(cid:31) 1 + √2 (cid:31)(cid:31) e( 1+ √ 2) t, and y = (cid:31)(cid:31) 1 ­ √ 2 (cid:31)(cid:31) e ( 1− √ 2)t 1 2 (cid:31) (cid:31) a b are linearly independent solutions of the system 0 1 0 x˙ = x, x(0) = 1 2 1 The fundamental matrix for the system is Φ = col(y , y ) 1 2 The general solution of the system is x = y1 + y2 (cid:31) (cid:31) a b (cid:31) (cid:31) a b (cid:31) √ + √ (cid:31) 0 √ + √ = 0 (i) x(0) = (cid:31) 1 + 2 1 ­ 2 (cid:31) = (cid:31) (cid:31) or 1 + 2 1 ­ 2 (cid:31) (cid:31) 1 a + b a + b = 1 (ii) From (i) a = b, thus, a = 1 = b so that 2 (cid:31) (cid:31) (cid:31) 1 2 1 √ √ x(t) = (cid:31)(cid:31)(cid:31) 2(1 + (cid:31)2e)( +(cid:31) (cid:31)(cid:31) 1+√2 2))t 2((cid:31)(cid:31)1 ­ (cid:31) (cid:31) (cid:31) 1 1 93  3.4 Linear Homogenous Equation with constantCoefficients LINEAR SYSTEM (cid:31) 2 (cid:31) (cid:31) ( e 1 √ −(cid:31) 2)t (cid:31) 94  3.4 Linear Homogenous Equation with constantCoefficients LINEAR SYSTEM Example 3.2 Solve the differential equation ... x ­ 2x¨ ­ x˙ + 2x = 0 Subject to x(0) = 0, x˙ (0) = 0, x¨(0) = 1 Solution.
The given differential equation is equivalent to the system x˙ = Ax where (cid:31) (cid:31) 0 1 0 (cid:31) (cid:31) (cid:31) (cid:31) A = (cid:31) 0 0 1 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) ­2 1 2 The eigenvalues of A are the roots of ­λ 1 0 0 ­λ 1 = 0 or λ3 ­ 2λ2 ­ λ + 2 = 0 ­2 1 2 ­ λ From which we obtain λ1 = 1, λ2 = ­1 and λ3 = 2 For λ = 1 1 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) ­1 1 0 c1 0 ­c1 + c2 + 0 = 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31)(cid:31) 0 ­1 1 (cid:31)(cid:31)(cid:31) (cid:31)(cid:31)(cid:31) c2 (cid:31)(cid:31)(cid:31) = (cid:31)(cid:31)(cid:31) 0 (cid:31)(cid:31)(cid:31) or 0 ­ c2 + c3 = 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) ­2 1 1 c3 0 ­2c1 + c2 + c3 = 0 from this you obtain c = c = c = a.
Thus, the eigenvector associated to λ = 1 is 1 2 3 1 (cid:31) (cid:31) (cid:31) (cid:31) c a 1 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) c (cid:31)(cid:31) = (cid:31)(cid:31) a (cid:31)(cid:31) (cid:31) 2 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) c a 3 For λ2 = ­1 95  3.4 Linear Homogenous Equation with constantCoefficients LINEAR SYSTEM (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 1 1 0 c 0 c + c + 0 = 0 1 1 2 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) 0 1 1 (cid:31)(cid:31) (cid:31) (cid:31) c (cid:31)(cid:31) = (cid:31)(cid:31) 0 (cid:31)(cid:31) or c + c = 0 (cid:31) (cid:31) (cid:31) 2 (cid:31) (cid:31) (cid:31) 2 3 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) ­2 1 3 c3 0 ­2c1 + c2 + 3c3 = 0 from this you obtain c2 = ­c1 and c3 = c1.
If c1 = b then, the eigenvector associated to λ1 = 1 is (cid:31) (cid:31) (cid:31) (cid:31) c b 1 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) c2 (cid:31)(cid:31) = (cid:31)(cid:31) ­b (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) c b 3 For λ = 2 3 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) ­2 1 0 c1 0 ­2c1 + c2 + 0 = 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31)(cid:31) 0 ­2 1 (cid:31)(cid:31)(cid:31) (cid:31)(cid:31)(cid:31) c2 (cid:31)(cid:31)(cid:31) = (cid:31)(cid:31)(cid:31) 0 (cid:31)(cid:31)(cid:31) or 0 ­ 2c2 + c3 = 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) ­2 1 0 c3 0 ­2c1 + c2 + 0 = 0 from this you obtain c = 2c and c = 4c .
If c = c then, the eigenvector associated to λ = 1 is 2 1 3 1 1 1 (cid:31) (cid:31) (cid:31) (cid:31) c c 1 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) c (cid:31)(cid:31) = (cid:31)(cid:31) 2c (cid:31)(cid:31) (cid:31) 2 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) c 3c 3 are linearly independent.
The general solution of the system (cid:31) (cid:31) (cid:31) (cid:31) 0 1 0 x1 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) x˙ = (cid:31) 0 0 1 (cid:31)(cid:31) x (cid:31) (cid:31) (cid:31) (cid:31) 2 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) ­2 1 2 x3 with x(0) = 0, x˙ (0) = 0, and x¨(0) = 1 is (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) a b c (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) x(t) = (cid:31)(cid:31) a (cid:31)(cid:31)e t + (cid:31)(cid:31) ­b (cid:31)(cid:31)e −t + (cid:31)(cid:31)2 c (cid:31)(cid:31)e2 t (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) a b 4c Using the initial condition, you obtain a + b + c = 0 (i) a ­ b + 2c = 0 (ii) a + b + 4c = 0 (iii) 96  3.4 Linear Homogenous Equation with constantCoefficients LINEAR SYSTEM Solving the above system gives you that 1 1 1 a = ­ , b = , c = 2 6 3 Therefore the solution is (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 1 1 1 ­ 2 6 3 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) x(t) = (cid:31)(cid:31)(cid:31) ­ 21 (cid:31)(cid:31)(cid:31) et + (cid:31)(cid:31)(cid:31) ­ 16 (cid:31)(cid:31)(cid:31) e −t + (cid:31)(cid:31)(cid:31) 23 (cid:31)(cid:31)(cid:31) e2t (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 1 1 4 ­ 2 6 3 Example 3.3 Solve completely the differential equation x¨ + x = 0, x(0) = 0, x˙ (0) = 1 Solution.
The auxiliary equation is λ2 + 1 = 0 or, λ2 = ­1, i.e., λ = ±i Thus, the general solution is x(t) = c sin t + c cos t 1 2 x˙ (t) = c1 cos t ­ c2 sin t Using the initial values, you obtain x(0) = c = 0 and x˙ (0) = c = 1 2 1 Therefore, c = 0 and c = 1.
Thus, the solution to the initial value problem is x(t) = sin t. 1 2 Example 3.4 Solve the system (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 0 1 0 0 x˙ = (cid:31) (cid:31) x + (cid:31) (cid:31) , x(0) = (cid:31) (cid:31) 1 0 sin t 1 Solution.
Consider the homogeneous system (cid:31) (cid:31) 0 1 x˙ = (cid:31) (cid:31) x 1 0 97  3.4 Linear Homogenous Equation with constantCoefficients LINEAR SYSTEM (cid:31) (cid:31) 0 1 The eigenvalues of A = (cid:31) (cid:31) are the roots of 1 0 |A ­ λI | = 0 That is the roots of λ2 ­ 1 = 0 or λ = ±1 the eigenvector for λ = 1 is (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) ­1 1 c1 0 (cid:31) (cid:31) (cid:31) (cid:31) = (cid:31) (cid:31) 1 ­1 c2 0 (cid:31) (cid:31) a This implies that c = c = a and so (cid:31) (cid:31) et is a solution of the system.
1 2 a For λ = ­1, (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 1 1 c 0 1 (cid:31) (cid:31) (cid:31) (cid:31) = (cid:31) (cid:31) 1 1 c2 0 (cid:31) (cid:31) b Gives you that c1 = ­c2 = b.
Thus, (cid:31) (cid:31) e−t is also a solution of the system ­b (cid:31) (cid:31) 0 1 x˙ = (cid:31) (cid:31) x 1 0 Set a = b = 1, then the two solutions are linearly independent.
The fundamental matrix solution Φ = Φ(t) is given by (cid:31) (cid:31) et e−t Φ(t) = (cid:31) (cid:31) et ­e−t and (cid:31) (cid:31) e−t e−t 1 Φ−1(t) = (cid:31) (cid:31) 2 et ­e−t using (16), the desired solution t x(t) = Φ(t)Φ−1(0)x + Φ(t) Φ−1(τ )F (τ )dτ 0 0 (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) (cid:31) 1 et e−t 1 1 0 1 et e−t t eτ e−τ 0 x(t) = (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) (cid:31)+ (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) dτ 2 2 et ­e−t 1 ­1 1 et ­e−t 0 eτ ­eτ sinτ 97  3.4 Linear Homogenous Equation with constantCoefficients LINEAR SYSTEM Example 3.5 Find the general solution for the system (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 0 1 0 a x˙ = (cid:31) (cid:31) x + (cid:31) (cid:31) , x(0) = (cid:31) (cid:31) ­ω2 0 sin t b Solution.
Consider the homogeneous linear differential equation (cid:31) (cid:31) 0 1 x˙ = (cid:31) (cid:31) ­ω2 0 The eigenvectors are (cid:31) (cid:31) (cid:31) (cid:31) 1 sin ωt cos ωt ω (cid:31) (cid:31) and (cid:31) (cid:31) cos ωt ­ω sin ωt They are linearly independent and the fundamental matrix solution is given by (cid:31) (cid:31) cos ωt 1 sin ωt ω Φ(t) = (cid:31) (cid:31) ­ω sin ωt cos ωt The general solution of the system (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 0 1 0 a x˙ = (cid:31) (cid:31) x + (cid:31) (cid:31) , x(0) = (cid:31) (cid:31) ­ω2 0 sin t b is t x(t) = Φ(t)Φ−1(0)x(0) + Φ(t) Φ−1(τ ) sin τ dτ 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) cos ωt 1 sin ωt 1 0 a cos ωt 1 sin ωt ω ω = (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) + (cid:31) (cid:31) ­ω sin ωt cos ωt 0 1 b ­ω sin ωt cos ωt (cid:31) (cid:31) (cid:31) (cid:31) t (cid:31) cos ωτ ω1 sin ωτ (cid:31) (cid:31) 0 (cid:31) dτ 0 ­ω sin ωτ cos ωτ sin τ from (16) Example 3.6 Solve the nonlinear differential equation (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 0 1 0 1 x˙ = (cid:31) 3 (cid:31) x ­2 ­ + (cid:31)1 e− t 2 98  3.4 Linear Homogenous Equation with constantCoefficients LINEAR SYSTEM (cid:31) , x(0) = (cid:31) (cid:31) 0 (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) (cid:31) 1 et e−t 1 1 0 1 et e−t t eτ e−τ 0 x(t) = (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) (cid:31)+ (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) dτ 2 2 et ­e−t 1 ­1 1 et ­e−t 0 eτ ­eτ sinτ 97  3.4 Linear Homogenous Equation with constantCoefficients LINEAR SYSTEM (cid:31) (cid:31) 0 1 The eigenvalues of A = (cid:31) (cid:31) are the roots of 1 0 |A ­ λI | = 0 That is the roots of λ2 ­ 1 = 0 or λ = ±1 the eigenvector for λ = 1 is (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) ­1 1 c1 0 (cid:31) (cid:31) (cid:31) (cid:31) = (cid:31) (cid:31) 1 ­1 c2 0 (cid:31) (cid:31) a This implies that c = c = a and so (cid:31) (cid:31) et is a solution of the system.
1 2 a For λ = ­1, (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 1 1 c 0 1 (cid:31) (cid:31) (cid:31) (cid:31) = (cid:31) (cid:31) 1 1 c2 0 (cid:31) (cid:31) b Gives you that c1 = ­c2 = b.
Thus, (cid:31) (cid:31) e−t is also a solution of the system ­b (cid:31) (cid:31) 0 1 x˙ = (cid:31) (cid:31) x 1 0 Set a = b = 1, then the two solutions are linearly independent.
The fundamental matrix solution Φ = Φ(t) is given by (cid:31) (cid:31) et e−t Φ(t) = (cid:31) (cid:31) et ­e−t and (cid:31) (cid:31) e−t e−t 1 Φ−1(t) = (cid:31) (cid:31) 2 et ­e−t using (16), the desired solution t x(t) = Φ(t)Φ−1(0)x + Φ(t) Φ−1(τ )F (τ )dτ 0 0 98  3.5 Characterization of Fundamental Matrix interms ofexponential functions LINEAR SYSTEM (cid:31) (cid:31) (cid:31) (cid:31) 1 1 ­1 ­1 Φ(0) = (cid:31) (cid:31) and Φ−1(0) = (cid:31) (cid:31) ­1 ­ 1 2 2 From (16), the general solution of the system (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 0 1 0 1 x˙ = (cid:31) (cid:31) x + (cid:31) (cid:31) , x(0) = (cid:31) (cid:31) ­2 ­ e− 1t 0 2 3 is given by t x(t) = Φ(t)Φ−1(0)x + Φ(t) Φ−1(τ )f (τ )dτ 0 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) e−t e−2t ­1 ­1 1 = (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) ­e−t ­2e−2t 1 2 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) e−t e−2t e−τ e−2τ 0 t 1 + (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) ­e−t ­2e−2t 0 e−3τ ­eτ ­2e−2τ e− 21 τ 3.5 Characterization of Fundamental Matrix in terms of exponential functions Let the function etA, where A is a constant n × n matrix be defined by etA = ∞ tnAn (21) n!
n=0 That is interpreting etA as a Taylor series expansion.
Now define the norm of A \A\ by n \A\ = |aij | i,j=1 and the expression I I IIIt nnA!
n III ≤ | nt|!n \A\n ∞ and since the exponential series rn converges for all finite values of r, you conclude from the inequality n!
n=0 1 (cid:31) et e−t (cid:31) (cid:31) 1 IIIII1 n N= (cid:31) 0 t(cid:31)nnA!0 n III(cid:31)II ≤ nN1=0(cid:31) |tn|en!t \A\e n− t (cid:31) t (cid:31) eτ e−τ (cid:31)(cid:31) 0 (cid:31) x(t) = (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) (cid:31)+ (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) dτ That the series2 ( 21) converges for every constant matrix 2A and for all finite values of t. et ­e−t 1 ­1 1 et ­e−t 0 eτ ­eτ sinτ It is also readily verifiable that 97  3.5 Characterization of Fundamental Matrix interms ofexponential functions LINEAR SYSTEM d etA = AetA dt 98 None 3.5 Characterization of Fundamental Matrix interms ofexponential functions LINEAR SYSTEM so that the matrix etA satisfies (20), that is etA is a matrix solution of (20).
Since e0A = I and the determinant of etA = exp(T race of A) you conclude that etA is a fundamental matrix solution for (20).
On the basis of the fact, the following result is stated.
Theorem 3.9 A fundamental matrix solution for (20) is given by Φ(t) = etA |t| < ∞ and the solution x(t) satisfying (20) with x(τ ) = ξ is given by x(t) = e(t−τ )ξ It is of interest to investigate the form of Φ(t) = etA.
For this purpose, you require the following results from linear Algebra.
Proposition 3.1 Every complex n × n matrix A is similar to a matrix of the form (cid:31) (cid:31) J0 0 0 0 · · · 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) 0 J1 0 0 · · · 0 (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) 0 0 J2 0 · · · 0 (cid:31)(cid:31) (cid:31) (cid:31) J = (cid:31) (cid:31) (22) (cid:31)(cid:31) 0 0 0 J3 · · · 0 (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) .. .. .. .. .
.
.
.. (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 0 0 0 0 · · · Jn where J is a diagonal matrix with diagonal elements λ , λ , ..., λ and 0 1 2 q (cid:31) (cid:31) λq+i 1 0 0 · · · 0 0 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) 0 λq+i 1 0 · · · 0 0 0 (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) 0 0 λq+i 1 · · · 0 0 0 (cid:31)(cid:31) (cid:31) (cid:31) J = (cid:31) (cid:31) (23) i (cid:31)(cid:31) .
.
.
.
.
.
.
.
.
.
.
.
(cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) 0 0 0 0 · · · λq+i 1 0 (cid:31)(cid:31) (cid:31) (cid:31) 0 0 0 0 · · · 0 λq+i 1 The λ s, i = 1, 2, ..., q + s are the eigenvalues of A which need not be distince.
If λ is a simple i j eigenvalue, it appears in J and if all the eigenvalues are distinct, then A is similar to the diagonal matrix 0 101  3.5 Characterization of Fundamental Matrix interms ofexponential functions LINEAR SYSTEM J given by (cid:31) (cid:31) λ1 0 0 · · · 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) 0 λ2 0 · · · 0 (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) J = (cid:31)(cid:31) 0 0 λ3 · · · 0 (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) .. .. .. .
.
.
.. (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 0 0 0 · · · λn The J s can be rewritten in the form i Ji = λq+iI ri + Zi where J has r rows and columns and i i (cid:31) (cid:31) 1 0 0 · · · 0 (cid:31) (cid:31) (cid:31) 0 1 0 ··· 0 (cid:31) (cid:31) (cid:31) Z i = (cid:31)(cid:31)(cid:31) 0.. 0.. 1.. ·.·..· 0.. (cid:31)(cid:31)(cid:31) 0 0 0 ··· 1 Another valid form of Ji is λq+i + iI ri + Zi Where r is a non-zero complex number.
Note that Z is nil-potent (Z ri = 0).
Indeed Z 2 has its diagonal of i i i one’s moved one element to the right of what of Z and all other elements zero.
Thus Z r0 −1 is the matrix i i with zero everywhere except for a single 1 in the first end last column.
For 3 × 3 matrix, (cid:31) (cid:31) 0 1 0 Z = (cid:31) 0 0 1 (cid:31) i 0 0 0 (cid:31) (cid:31) 0 0 1 Z2 = (cid:31) 0 0 0 (cid:31) i 0 0 0 (cid:31) (cid:31) 0 0 0 Z3 = (cid:31) 0 0 0 (cid:31) i 0 0 0 Now Let J be the canonical form of A defined by (22).
SupposeP is a non-singular matrix such that P −1AP = J ⇒ P J P −1 = A Then etA = etP J P −1 = P etJ P −1 Proof.
For any matrix M (P M P −1)k = P M k P −1 102  3.5 Characterization of Fundamental Matrix interms ofexponential functions LINEAR SYSTEM Since J has the form (22), then J k is of the form (cid:31) (cid:31) J k 0 0 · · · 0 0 (cid:31) 0 J k 0 · · · 0 (cid:31) 1 (cid:31) (cid:31) J k = (cid:31)(cid:31) 0 0 J 2k · · · 0 (cid:31)(cid:31) (cid:31)(cid:31) .
.
.
.
.. .
(cid:31)(cid:31) 0 0 0 · · · J sk and etJ = ∞ tk J k (24) k!
k=0 (cid:31) (cid:31) ∞ tk J k (cid:31) 0 0 0 · · · 0 (cid:31) (cid:31) k!
(cid:31) (cid:31) k=0 (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) ∞ tkJ k (cid:31)(cid:31) (cid:31)(cid:31)(cid:31) 0 k!1 0 · · · 0 (cid:31)(cid:31)(cid:31) (cid:31) k=0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) = (cid:31) ∞ tk J k (cid:31) (cid:31)(cid:31) 0 0 k!2 · · · 0 (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) k=0 (cid:31) (cid:31) (cid:31) (cid:31)(cid:31)(cid:31) .. .. .. .
.
.
.. (cid:31)(cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) 0 0 0 · · · ∞ t kk Js!
k (cid:31) (cid:31) k=0 (cid:31) (cid:31) etJ0 0 0 · · · 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) 0 etJ1 0 · · · 0 (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) = (cid:31)(cid:31) 0 0 e tJ2 · · · 0 (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) .
.
.
.
.
.
.
.
.
.
(cid:31) (cid:31) .
(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 0 0 0 · · · etJs It is obvious that (cid:31) (cid:31) etλ1 0 0 · · · 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) 0 etλ2 0 · · · 0 (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) etJ0 = (cid:31)(cid:31) 0 0 e tλ3 · · · 0 (cid:31)(cid:31) (25) (cid:31) (cid:31) (cid:31) .
.
.
.
.
.
(cid:31) (cid:31) (cid:31) .
.
(cid:31) (cid:31) 103  3.5 Characterization of Fundamental Matrix interms ofexponential functions LINEAR SYSTEM .
(cid:31) .
.
(cid:31) (cid:31) (cid:31) 0 0 0 · · · etλq and since 104  3.6 Linear Nonhomogeneous System LINEAR SYSTEM Ji = λq+i + Zi etJi = etλq+i etZi (cid:31) (cid:31) 1 t t2 · · · tri −1 (cid:31) 2!
(ri −1)!
(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) 0 1 t · · · ( rtir −i −2)2!
(cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) etJi = etλq+i (cid:31)(cid:31)(cid:31) 0 0 1 · · · ( rtri − i −3 3) !
(cid:31)(cid:31)(cid:31) (26) (cid:31) (cid:31) (cid:31)(cid:31) .. .. .. ... .. (cid:31)(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 0 0 0 · · · 1 Where Ji are ri × ri matrix and n = q + r1 + r2 + · · · + rs.
Thus if the canonical form of A is known, then a fundamental matrix etA of (20) is given explicitly by (24) where etJ can be obtained from (24), (25) and (26).
3.6 Linear Nonhomogeneous System Example (4), (5) and (6) have been are using the method of variation of parameter techniques.
Now, consider it from direct differentiation and integration.
Consider the nonlinear system x˙ = A(t)x + f (t) t ∈ I (27) where as before A(t) is continuous n × n matrix defined on I , and f : I → Rn is continuous function by the basic existence theorem, for any given t0 ∈ I , x0 ∈ Rn \x0\ < ∞ there is a unique solution x(t) of (27) satisfying the initial condition x(t ) = x .
0 0 In the special case x˙ = A(t)x (28) You know that if Φ(t) is a fundamental matrix solution of (28) then the solution x(t) with x(t ) = x is 0 0 given by x(t) = Φ(t)Φ−1(t )x 0 0 You now have a stepping stage for the solution of (28) Theorem 3.10 Let Φ = Φ(t) be a fundamental matrix for the adjoint x˙ = ­AT (t)x (29) of (28) of I , then the function Φ = Φ(t) defined by t Φ(t) = ΦT (t) −1 ΦT (t )x + ΦT (τ )f (τ )dτ (30) 0 0 t0 is a solution of (28) satisfying the initial condition Φ(t ) = x .
0 0 105  3.7 Linear Homogeneous System with Periodic Coefficients LINEAR SYSTEM Proof.
Let Φ = Φ(t) be a fundamental matrix solution for (29) and let x be a solution of (27).
Then ddt ΦT x = Φ˙ T x + ΦT x˙ = Φ˙T x + ΦT {A(t)x + f (t)} But Φ˙ T = ­ΦT A(t).
Hence d ΦT x = ­ΦT A(t)x + ΦT A(t)x + ΦT f (t) = ΦT f (t) dt Integrating between t = t and t, you have 0 t ΦT (t)x(t) ­ ΦT (t0)x(t0) = ΦT (τ )f (τ )dτ t0 so that t ΦT (t)x(t) = ΦT (t0)x(t0) + ΦT (τ )f (τ )dτ t0 Therefore t x(t) = ΦT (t) −1 ΦT (t )x(t ) + ΦT (τ )f (τ )dτ 0 0 t0 and the proof of theorem 1.10 follows.
You can also obtain a representation of the solution of (27) in terms of fundamental matrix of (28).
See theorem (1.6).
Example 3.7 See examples 3.4, 3.5 and 3.6 3.7 Linear Homogeneous System with Periodic Coefficients Consider the system (28) where A(t) as before is a continuous n × n matrix defined on I ⊂ R and A(t + ω) = A(t) f or all t ∈ I .
(31) for some constant ω > 0.
In this case (28) is called a periodic system.
The basic result here is that a fundamental matrix can be expressed as a periodic matrices and a solution matrix for a system with constant coefficients.
Theorem 3.11 If Φ = Φ(t) is a fundamental matrix for (28) on I , then so also is Ψ, where Ψ(t) = Φ(t + ω) t ∈ I , ω > 0 Corresponding to every such Φ, then there exists a periodic nonsingular matrix P, with period ω and a constant R such that Φ(t) = P (t)etR, t ∈ I (32) Proof.
Let Φ = Φ(t) be a fundamental matrix solution for (28) on I .
Then d 106  3.6 Linear Nonhomogeneous System LINEAR SYSTEM (Φ(t)) = A(t)Φ(t) t ∈ I dt 107  4 Conclusion LINEAR SYSTEM And so d Φ(t + ω) = A(t + ω)Φ(t + ω) dt = A(t)Φ(t + ω) Therefore Φ(t + ω) is a solution matrix of (28).
It is fundamental since [det Φ(t + ω)]|t=0 = det Φ(ω) /= 0 Thus there exists a constant nonsingular n × n matrix C such that Φ(t + ω) = Φ(t)C (33) What is more there exists a constant matrix R such that C = eωR (34) From (33) and (34), you have that Φ(t + ω) = Φ(t)eωR (35) Then by (36), P (t + ω) = Φ(t + ω)e−(t+ω)R = Φ(t)eωR · e−(t+ω)R = Φ(t)e−tR = P (t) by (36).
Thus P (t) is periodic with period ω.
Since Φ(t) and e−tR are nonsingular on I , so also is P (t).
You can now examine the following implicatiion of theorem 1.11.
Let Φ(t) be a fundamental matrix solution of (28) such that Φ(0) = I where I is the identity matrix.
Then 1.
Φ(t + ω) = Φ(t)Φ(ω) 2.
Φ(­ω) = Φ−1(ω) 3.
Φ(ρω) = Φρ(ω) for some ρ > 0 an integer.
Clearly, Φ(t + ω) = Φ(t)C where C is a constant n × n nonsingular matrix.
At t = 0, you have that Φ(ω) = C So that Φ(t + ω) = Φ(t)Φ(ω) Now set t = ­ω I = Φ(0) = Φ(­ω)Φ(ω) Thus Φ(­ω) = Φ−1(ω) Set t = ω in Φ(t + ω) = Φ(ω)Φ(ω) = Φ(2ω) = Φ2(ω) By induction, it follows that 106 26  4 Conclusion LINEAR SYSTEM Φ(ρω) = Φρ(ω) for ρ > 0 and integer 4.
If A(t) = A ≡ constant, then A is periodic with arbitrary period, and if Φ(t) is a fundamental matrix solution such that Φ(0) = I , then for arbitrary s, Φ(t + s) = Φ(t)Φ(s) Φ(t ­ s) = Φ(t)Φ(­s) = Φ(t)Φ−1(s) 5.
Observe that the result implies the existence of at least one solution Φ = Φ(t) of (28) such that Φ(t + ω) ­ ρΦ(t) = 0 (36) for all t, where ρ is some convenient constant.
Indeed if Φ = Φ(t) is a solution of (28) then there is a constant n-vector x such that 0 Φ(t) = Φ(t)x 0 where Φ(t) is a fundamental matrix solution of (28).
That is Φ(t) = ρ(t)etRx0 If Φ(t) is to satisfy (37), then a simple calculation will show that ρ, x must satisfy 0 (eωR ­ ρI )x0 = 0 Thus if ρ is an eigenvalue of eωR and x the corresponding eigenvector then Φ(t) satisfying (37).
0 Note, the eigenvalues of eωR are called the characteristic multipliers of the system (28).
To each characteristic multipliers of (28) you can define a characteristic exponent τ by ρ = eτ ω 4 Conclusion In this section, you have studied Linear Systems of ODE.
You saw the properties of solution of Linear systems for both homogeneous and nonhomogeneous systems.
You also had knowledge of the adjoint system of a given linear system of ODE.
5 Summary Having gone throught this unit, you now know that; (i) A linear system of ODE is of the form x˙ = Ax + F (t) = f (t, x) where A, F and f have their usual meaning 107  5 Summary LINEAR SYSTEM (ii) A function Φ : I → Rn is a solution of the system x = f (t, x) If for t ∈ I , you have that the pair (t, Φ(t)) ∈ G and Φ(t) is differentiable on I and satisfy Φ (t) = f (t, x) (iii) the solution space forms an n-dimensional vector space over Rn (iv) The equation x = A(t)x has n-linearly independent solutions.
(v) any solution of y = A(t)y is a linear combination of the n-linearly independent solutions the system.
(vi) A matrix whose columns comprises of the n-linearly independent solutions of y = A(t)y is also a solution of the system and is called the fundamental matrix of solutions.
(vii) If y¯ is any particular solution of the nonhomongeneous equation y = A(t)y + b(t) Then any solution of the nonhomongeneous system can be written in the form y(t) = y¯(t) + Y (t) · C where Y (t) is a fundamental matrix of solutions to the corresponding homogeneous equation y = A(t)y (viii) (method of variation of constants) if Y(t) is a fundamental matrix to y = A(t)y then t y¯(t) = Y (t) Y −1(s)b(t)ds a (with A(t) continuous on [a, b]) is a particular solution to the nonhomogeneous equation y = Ay + b (ix) a general solution of the nonhomogeneous system y = Ay + b is t y(t) = Y (t) C + Y −1(s)b(c)ds a where Y (t) is the fundamental matrix of solutions and C is an n × n nonsingular constant matrix.
(x) The adjoint of the system x = A(t)x is given by x = AT (t)x 108  6 Tutor Marked Assignments(TMAs) LINEAR SYSTEM 6 Tutor Marked Assignments(TMAs) Exercise 6.1 Find a real general solution of the following systems.
(cid:31) (cid:31) y1 = 3y2 1.
(cid:31) y = 12y 2 1 (a) y1 = c1e−3t + c2e3t, y2 = ­2c1e−3t + 2c2e3t (b) y1 = c1e−3t + c2e3t, y2 = 2c1e−3t ­ 2c2e3t (c) y1 = c1e−6t + c2e6t, y2 = ­2c1e−6t + 2c2e6t (d) y1 = c1e−6t + c2e6t, y2 = 2c1e−6t + 2c2e6t (cid:31) (cid:31) y1 = y1 + y2 2.
(cid:31) y = y + y 2 1 2 (a) y1 = c1e−2t + c2, y2 = c1e−2t ­ c2 (b) y1 = c1e2t ­ c2, y2 = c1e2t + c2 (c) y1 = c1e2t + c2, y2 = c1e2t ­ c2 (d) y1 = c1e−2t ­ c2, y2 = c1e−2t + c2 (cid:31) (cid:31) y1 = 4y2 3.
(cid:31) y2 = ­4y1 (a) y1 = A cos 4t + B sin 4t, y2 = B cos 4t ­ A sin 4t where A = c1 + c2, B = i(c1 ­ c2) (b) y1 = A cos 2t + B sin 2t, y2 = B cos 2t ­ A sin 2t where A = c1 + c2, B = i(c1 ­ c2) (c) y1 = A cos 2t + B sin 2t, y2 = ­B cos 2t + A sin 2t where A = c1 + c2, B = i(c1 ­ c2) (d) y1 = A cos 4t + B sin 4t, y2 = ­B cos 4t + A sin 4t where A = c1 + c2, B = i(c1 ­ c2) (cid:31) (cid:31) y1 = ­y1 + y2 + 0.4y3 (cid:31) (cid:31) 4. y 2 = y1 ­ 0.1y2 + 1.4y3 (cid:31) (cid:31) (cid:31) y = 0.4y + 1.4y + 0.2y 3 1 2 3 (a) y1 = 2c1 + c2e−6t, y2 = ­c1 + c3e−6t, y3 = ­c1 ­ 2(c2 + c2)e−6t (b) y1 = 2c1 + c2e6t, y2 = ­c1 + c3e6t, y3 = ­c1 + 2(c2 + c2)e6t (c) y1 = 2c1 + c2e−6t, y2 = ­c1 + c3e−6t, y3 = ­c1 + 2(c2 + c2)e−6t (d) y1 = 2c1 ­ c2e−6t, y2 = ­c1 + c3e6t, y3 = ­c1 + 2(c2 + c2)e−6t 109  6 Tutor Marked Assignments(TMAs) LINEAR SYSTEM (cid:31) (cid:31) y1 = 2y1 + 8y2 ­ 4y3 (cid:31) (cid:31) 5. y 2 = ­4y1 ­ 10y2 + 2y3 (cid:31) (cid:31) (cid:31) y3 = ­4y1 ­ 4y2 ­ 4y3 Solve the following initial value problems.
(cid:31) (cid:31) y1 = y1 + 2y2 (cid:31) (cid:31) (cid:31) 6. y2 = 12 y1 + y2 (cid:31) (cid:31) y (0) = 16, (cid:31)(cid:31) 1 y2(0) = ­2 (cid:31) (cid:31) y1 = 12 y1 ­ 2y2 (cid:31) (cid:31)(cid:31) 7. y2 = ­3 2 y1 + y2 (cid:31) (cid:31) y (0) = 0.4, (cid:31)(cid:31) 1 y (0) = 3.8 2 (cid:31) (cid:31) y1 = 2y1 + 5y2 (cid:31) (cid:31) (cid:31) y = 5y + 12.5y 8.
2 1 2 (cid:31) (cid:31) y (0) = 12, (cid:31)(cid:31) 1 y (0) = 1 2 9.
If Y is a fundamental matrix for y = Ay and T is a nonsingular constant n ×n matrix, find the vector equation for which T ·Y is a fundamental matrix.
Find the vector differential eqution with Fundamental matrix Y (t) as (cid:31) (cid:31) sin t cos t 10.
(cid:31) (cid:31) cos t ­ sin t (cid:31) (cid:31) et tet 11.
(cid:31) (cid:31) et (t + 1)et Find particular solution for the following equations (cid:31) (cid:31) (cid:31) (cid:31) 1 1 1 12. y = (cid:31) (cid:31) y + (cid:31) (cid:31) 0 ­1 0 (cid:31) (cid:31) (cid:31) (cid:31) 1 1 1 13. y = (cid:31) (cid:31) y + (cid:31) (cid:31) 0 ­1 0 110  6 Tutor Marked Assignments(TMAs) LINEAR SYSTEM (cid:31) (cid:31) (cid:31) (cid:31) 1 1 1 14. y = (cid:31) (cid:31) y + (cid:31) (cid:31) 0 ­1 0 Determine a general solution of y = Ay, where (cid:31) (cid:31) 0 ­3 1 (cid:31) (cid:31) (cid:31) (cid:31) 15.
A = (cid:31)(cid:31) ­2 ­1 1 (cid:31)(cid:31) (cid:31) (cid:31) 0 0 2 (cid:31) (cid:31) 1 1 ­1 (cid:31) (cid:31) (cid:31) (cid:31) 16.
A = (cid:31) 1 1 1 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) ­1 1 1 (cid:31) (cid:31) 0 1 0 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) ­1 0 0 0 (cid:31)(cid:31) 17.
A = (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) 0 0 0 ­1 (cid:31)(cid:31) (cid:31) (cid:31) 0 0 1 0 (cid:31) (cid:31) 0 ­4 18.
A = (cid:31) (cid:31) ­4 0 (cid:31) (cid:31) 2 ­1 3 (cid:31) (cid:31) (cid:31) (cid:31) 19.
A = (cid:31)(cid:31) 2 ­1 3 (cid:31)(cid:31) (cid:31) (cid:31) 2 ­1 3 Solve y = Ay, y(0) = y where 0 (cid:31) (cid:31) (cid:31) (cid:31) ­1 4 3 20.
A = (cid:31) (cid:31) , y(0) = (cid:31) (cid:31) 2 3 0 (cid:31) (cid:31) (cid:31) (cid:31) 2 ­1 3 ­4 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 21.
A = (cid:31) 3 1 0 (cid:31) , y(0) = (cid:31) 4 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 2 ­1 3 4 (cid:31) (cid:31) (cid:31) (cid:31) 0 2 1 22.
A = (cid:31) (cid:31) , y(0) = (cid:31) (cid:31) ­2 0 1 111  6 Tutor Marked Assignments(TMAs) LINEAR SYSTEM Find eAt by determining a fundamental matrix for y = Ay (cid:31) (cid:31) 1 2 23.
A = (cid:31) (cid:31) 0 ­1 (cid:31) (cid:31) 1 2 24.
A = (cid:31) (cid:31) 0 ­1 (cid:31) (cid:31) 2 0 0 (cid:31) (cid:31) (cid:31) (cid:31) 25.
A = (cid:31)(cid:31) 0 1 ­8 (cid:31)(cid:31) λ1,2 = ­3 ± i, λ3 = 2 (cid:31) (cid:31) 0 2 ­7 (cid:31) (cid:31) ­8 6 ­3 (cid:31) (cid:31) (cid:31) (cid:31) 26.
A = (cid:31)(cid:31) ­12 10 ­3 (cid:31)(cid:31) , P (λ)(λ + 2)2(λ ­ 4) (cid:31) (cid:31) ­12 ­12 ­ 2 (cid:31) (cid:31) 0 ­1 0 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 1 0 0 0 (cid:31) (cid:31) (cid:31) 27.
A = (cid:31)(cid:31) (cid:31)(cid:31) , P (λ) = (λ2 + 1)2 (cid:31)(cid:31) 1 0 0 ­1 (cid:31)(cid:31) (cid:31) (cid:31) 0 1 1 0 112  UNIT 5: ADJOINT SYSTEMS Contents 1 Introduction 113 2 Objectives 113 3 The Adjoint Equation 114 3.1 Definitions and Examples 114 3.1.1 The Second-Order Case 114 3.1.2 Lagrange Identity 115 3.2 Self Adjointness 120 4 Conclusion 122 5 Summary 122 6 Tutor Marked Assignments (TMAs) 122 1 Introduction In this unit, you shall have a detail of the study you were introduced to in unit 4, which are Adjoint systems.
2 Objectives At the end of this unit, you should be able to (i) Define and give examples of Adjoint Equations.
(ii) Establish some results related to adjoint equations (iv) Define self - adjoint equations and give examples (v) Transform a system to a self-adjoint one.
113  3.1 Definitions and Examples 3 The Adjoint Equation 3.1 Definitions and Examples Definition 3.1 Consider the nth-order linear differential operator dn dn−1 d L = a (x) + a (x) + · · · + a (x) + a (x) n 0 dxn 1 dxn−1 n−1 dx n And the corresponding nth-order linear differential equation L y = 0 n The nth order linear operator L¯ = (−1)n dn [a (x)] + (−1)n−1 dn−1 [a (x)] + · · · − d [a (x)] + a (x) n dxn 0 dxn−1 1 dx n− 1 n is the adjoint operator of the operator L , and the differential equation n L¯ y = 0 n is called the adjoint equation to the equation L y = 0.
That is, the adjoint equation to n dny dn−1y dy a (x) + a (x) + · · · + a (x) + a (x) = 0 (1) 0 dxn 1 dxn−1 n−1 dx n is the equation (−1)n dn [a (x)y] + (−1)n−1 dn−1 [a (x)y] + · · · − d [a (x)y] + a (x)y = 0 (2) dxn 0 dxn−1 1 dx n− 1 n Note: In your knowlege of equation (1) you have assumed that a , a , ..., a , a are all continuous on 0 1 n−1 n an interval a ≤ x ≤ b and that a (x) /= 0 on a ≤ x ≤ b.
In order that the adjoint Equation (2) shall shall 0 possess such continuity properties on a ≤ x ≤ b you must now further assume that the coefficients a in k Equation (1) have continuous (n − k)th derivatives (k = 0, 1, ..., n − 1) on a ≤ x ≤ b.
3.1.1 The Second-Order Case Consider in particular the second-order linear differential operator d2 d L = a (x) + a (x) + a (x) 2 0 dx2 1 dx 2 and the corresponding second-order linear differential equation d2y dy a (x) + a (x) + a (x)y = 0 (3) 0 dx2 1 dx 2 From equation (2) the adjoint equation to equation (3) is d2 d ( − 1)2 [a (x)y] + ( − 1) [a (x)y] + a (x)y = 0 dx2 0 dx 1 2 This reduces to d2y dy a (x) + [2at − a (x)] + [att(x) − at (x) + a (x)y] = 0, (4) 0 dx2 0 1 dx 0 1 2 where the primes denote differentiations with respect to x.
Thus the adjoint equation to the second-order equation (3) is the equation (4).
111145  3 The Adjoint Equation Example 3.1 Consider d2 y dy x2 + 7x + 8y = 0.
(5) dx2 dx Here a (x) = x2, a (x) = 7x, a (x) = 8.
By (4) the adjoint equation to equation (5) is 0 1 2 d2 y dy x2 + [4x − 7x] + [2 − 7 + 8]y = 0 dx2 dx or simply d2 y dy x2 − 3x + 3y = 0.
(6) dx2 dx Of course you could have obtained equation (6) directly from (2) without using the special result given in (4).
3.1.2 Lagrange Identity Theorem 3.1 Langrange Identity.
1.
Let the coefficients ak in dn dn−1 d L = a (x) + a (x) + · · · + a (x) + a (x) n 0 dxn 1 dxn−1 n−1 dx n have continuuous (n-k)th derivatives, (k = 0, 1, 2, ..., n) on the interval a ≤ x ≤ b.
2.
Let u and v be any two functions having nth derivatives on a ≤ x ≤ b.
Then vLn[u] − uL¯n[v] = ddx [P (u, v)] (7) where r 1 )n )k P (u, v) = (−1)j−1u(k−1)(van −k )(j−1) (8) k=1 j=1 Note: You should refer to the form P (u, v) as the bilinear concomitant associated with L .
The notation n u(k−j) denotes the (k − j)th derivative of u with respect to x, and in like manner (van −k )(j−1) denotes the (j − 1)stx derivative of va .
n−k Proof.
By differentiating the expression U (k−1)V − U (k−2)V t + · · · + (−1)n−2U tV (k−2) + (−1)k−1U V (k−1) one obtains the formula d V U (k) = (−1)k V (k)U + [U (k−1)V − U (k−2)V t + · · · + (−1)k−2U tV (k−2) + (−1)k−1U V (k−1)] (9) dx (k = 0, 1, 2, ..., n).
Apply formula (9) with U = u and V = va , va , ..., va , successively, in 0 1 n−1 dnu dn−1u du vL [u] = va + va + · · · + va + va u. n 0 dxn 1 dxn−1 n−1 dx n  3.1 Definitions and Examples You obtain d vL [u] = (−1)n(va )(n)u + [u(n−1)(va ) − u(n−2)(va )t + · · · + (−1)n−1u(va )(n−1)] n 0 0 0 0 dx d +(−1)n−1(va )(n−1)u + [u(n−2)(va ) − u(n−3)(va )t + · · · + (−1)n−2u(va )(n−2)] 1 1 1 1 dx d + · · · + (−1)1(va )tu + [uva ] + va u n n−1 n dx r 1 )n )n d = u (−1)n−k (va )(n−k) + ( − 1)j−1u(n−j)(va )(j−1) k dx 0 k=0 j=1 r)n−1 1 r )1 1 d d = + dx ( − 1 )j−1u(n−1−j)(va 1)(j−1) + · · · + dx (− 1)j−1u(1−j)(va n−1)(j−1) j=1 j=1 But )n (−1)(n−k)(vak )(n−k)=Ln [v] k=0 Thus r 1 )n )k d vLn[u] − uL¯n[v] = dx (−1)j−1u(k−j)(van −k )(j−1) k=1 j=1 and hence r 1 d )n )k vL [u] − uL¯ [v] = (−1) j−1 u(k−j) (va ) (j−1) n n dx n−k k=1 j=1 Corollary 3.1 Green’s formula With the Hypothesis of Theorem 3.1.
Then for any two points x and x of a ≤ x ≤ b, 1 2 x2 {vL [u] − uL¯ [v]}dx = P (u, v)| − P (u, v)| n n x=x2 x=x1 x1 Proof.
Merely integrate the Lagrange Identity (7) from x to x .
1 2 The Second-Order Case.
Consider the Lagrange Identity (7) in the second-order case.
In this case d2 d L = a (x) + a (x) + a (x) 2 0 dx2 1 dx 2 and from (4) you see that the adjoint operator L¯ may be written 2 L¯ = a (x) d2 + [2at (x) − a (x)] d + [att(x) − at (x) + a (x)].
2 0 dx2 0 1 dx 0 1 2 Thus the left member vL [u] − uL¯ [v] of the Lagrange Identity reduces to 2 2 a0vutt + a1vut − a0uvtt −1111265at0 u vt + a1uvt − a0tt uv + a1t uv, (10)  3.1 Definitions and Examples where the primes denote differentiations with respect to x.
Now the right member of the identity is d [P (u, v)], dx where in this case r 1 )2 )k )1 )2 P (u, v) = (−1)j−1u(k−j)(va2 −k )(j−1) = (−1)j−1u(1−j)(va1)(j−1)+ (−1)j−1u(2−j) (va0) (j−1).
k=1 j=1 j=1 j=1 This reduces to P (u, v) = uva1 + ut(va0) − u(va0)t or P (u, v) = a vut + (a − at )vu − a vtu.
(11) 0 1 0 0 Thus the right member of (7) in the second-order case is d [a vut + (a − at )vu − a vtu].
(12) dx 0 1 0 0 You should perform the indicated differentiation in (12) and observe that the result is indeed the expres- sion given by (10).
Theorem 3.2 A necessary and sufficient condition that f be a solution of the nth order linear differential equation L y = 0is that f be a solution of the (n − 1)st-order linear differential equation.
n P [y, g(x)] = c, (13) where P (u, v) is the bilinear concomitant associated with L , the function g is a nontrivial solution of the n adjoint equation L¯ y = 0, and c is an arbitrary constant.
n Proof.
Since g is a solution of L¯ y = 0, L¯ [g(x)] = 0 and the Lagrange Identity (7) with u = y, and n n v = g(x) becomes d g(x)L [y] = {P [y, g(x)]} (14) n dx If f is a solution of L y = 0, then L [f (x)] = 0.
Thus letting y = f (x) in (14), you see that (14) reduces to n n d {P [f (x), g(x)]} = 0. dx Thus P [f (x), g(x)] = c, where c is an arbitrary constant.
Thus if f is a solution of L y = 0, then it also satisfies the equation n P [y, g(x)] = c, which is actually an (n − 1)st order linear differential equation in the dependent variable y. Conversely, suppose f satisfies P [y, g(x)] = c, where c is an arbitrary constant.
Then P [f (x), g(x)] = c d and {P [f (x), g(x)] } = 0.
Then (14) gives g(x)L [f (x)] = 0.
Since g is a nontrivial solution of L¯ y = 0, dx n n you see that f is a solution of L y = 0.
Thus if f satisfies P [y, g(x)] = c, it also satisfies L y = 0. n n The Second Order Case The bilinear concomitant P (u, v) associated with the second order linear operator L has been given ex- 2 plicitly in (11).
Using this, you find that in the second order case dy P [y, g(x)] = a (x)g(x) + {[a (x) − at (x)]g(x) − a (x)gt(x)}y.
0 dx 1181 0  3.1 Definitions and Examples Hence f is a solution of the second-order linear equation d2y dy a (x) + a (x) + a (x)y = 0 (15) 0 dx2 1 dx 2 if and only if it is a solution of the first-order linear equation dy a (x)g(x) + {[a (x) − at (x)]g(x) − a (x)gt(x)}y = c (16) 0 dx 1 0 0 where g is a solution of the adjoint equation to (15) and c is an arbitrary constant.
Example 3.2 Solve d2 y dy x2 + 7x + 8y = 0 (17) dx2 dx by finding a solution of its adjoint equation by inspection.
Solution.
The adjoint equation to the given equation is given by (6).
It is d2 y dy x2 − 3x + 3y = 0. dx2 dx Clearly g such that g(x) = x is a solution of this equation.
In Equation (17) a (x) = x2, a (x) = 7x, 0 1 and a (x) = 8.
Thus in this case Equation (16) becomes 2 dy x2 · x + {[7x − 2x] · x − x2 · 1}y = c dx or simply dy x3 + 4x2y = c. (18) dx substituting this first-order linear equation in the standard form, you have that x4 is an integrating factor.
Thus the equation (18) reduces to d [x4y] = cx dx integrating will give you cx2 x4y = 2 + c2 y = c x−2 + c x−4, 1 2 where c and c are arbitrary constants.
Thus f defined by f (x) = c x−2 + c x−4 is a solution of 1 2 1 2 (17), where c and c are arbitrary constants.
In other words, you have obtained the general solution 1 2 of equation (17) by finding a solution of its adjoint and then solving the related first order equation (18).
Theorem 3.3 Let L¯ be the adjoint operator of L .
Then L is the adjoint operator of L¯ .
n n n n 117 0 3.1 Definitions and Examples Proof.
Let L¯ denote the adjoint operator of L¯ Then n n d uL¯ [v] − vL¯[u] = {P¯(u, v)}, n dx where P¯(u, v) is the bilinear concomitant associated with the operator L¯ .
By hypothesis, n d vL [u] − uL¯ [v] = {P (u, v)}, n n dx where P (u, v) is the bilinear concomitant associated with L .
Thus n d v{L [u] − L¯[u]} = {P (u, v) + P¯(v, u)}.
n dx Now (8) shows that the bilinear concomitant associated with an nth order linear differential operator is a homogeneous linear form in v, vt, ..., v(n−1).
Thus P (u, v) + P¯(v, u) = c v(n−1) + c v(n−2) + · · · + c v (19) 1 2 n n where the coefficients c (i = 1, ..., n) are functions of u, ut, ..., u(n−1), the various coefficients in the opera- i d tors under consideration, and certain derivatives of these various coefficents.
Thus {P (u, v) + P¯(u, v) } dx is the homogeneous linear form c1v(n) + [c1t + c2]v(n−1) + · · · + [ctn −1 + cn]vt + cnt v (20) in v, vt, ..., v(n).
Thus by (19) you see that v{L [u] − L¯ [u]} is equal to the form (21).
n n Thus the coefficients of v(n), v(n−1), ..., vt in (21) must be zero.
From this it follows at once that c = c = 1 2 · · · = c = 0, and hence (20) shows that P (u, v) + P¯(v, u) = 0.
Thus from (19) you see that L¯ [u] = L [u].
n n n Thus the adjoint operator of the adjoint operator L¯ is the original operator L .
n n Thus if L y = 0 is a given nth order homogeneous linear equation and L¯ y = 0 is the adjoint equation n n L¯ y = 0 is the original equation L y = 0. n n Example 3.3 You have already seen in Example 3.1 that the adjoint equation to d2 y dy x2 + 7x + 8y = 0 (21) dx2 dx is d2 y dy x2 − 3x + 3y = 0 (22) dx2 dx In equation (23) a (x) = x2, a (x) = −3x, and a (x) = 3.
Using (4) you find that the adjoint equation to 0 1 2 (23) is d2 y dy x2 + [4x + 3x] + [2 + 3 + 3]y = 0 dx2 dx which is the original equation (22).
120  3.2 Self Adjointness 3.2 Self Adjointness Definition 3.2 An nth order homogeneous linear differential equation L y = 0 is called self adjoint if it is n identical with its adjoint equation L y = 0. n In what follows you should be concerned with self-adjoint equations of the second order.
In this con- nection, you have the following theorem.
Theorem 3.4 Consider the second-order linear differential equation d2y dy a (x) + a (x) + a (x)y = 0, (23) 0 dx2 1 dx 2 where a has a continuous second derivative, a has a continuous first derivative, a is continuous, and 0 1 2 a (x) /= 0 on a ≤ x ≤ b.
A necessary and sufficient condition that equation (24) be self-adjoint is that 0 d [a (x)] = a (x) (24) dx 0 1 on a ≤ x ≤ b.
Proof.
From Equation (4) the adjoint to equation (24) is d2y dy a (x) + [2at (x) − a (x)] + [att(x) − at (x) + a (x)]y = 0.
(25) 0 dx2 0 1 dx 0 1 2 If condition (75) is satisfied, then 2at (x) − a (x) = a x) 0 1 ( and a0tt ( x) − at1(x) + a2(x) = a2(x) These relations show that Equations (24) and (26) are identical; that is, equation (24) is self-adjoint.
Conversely, If Equation (24) and (26) are identical then 2at (x) − a (x) = a x) 0 1 ( and at0t (x) − at1(x) + a2(x) = a2(x) The second of these conditions shows that at (x) = a (x) + c, where c is an arbitrary constant.
From the 0 1 first condition, you see that at (x) = a (x).
Thus c = 0 and you have the condition (25).
0 1 Corollary 3.2 Suppose the second-order equation a (x) d2 y + a (x) dy + a (x)y = 0, (24) 0 dx2 1 dx 2 is self-adjoint.
Then Equation (24) can be written in the form r l d dy a (x) + a (x)y = 0 (26) dx 0 dx 2 119 4 Conclusion Proof.
Since Equation (24) is self-adjoint, condition (25) is satisfied.
Thus equation (24) may be written d2y dy a (x) + a (x) + a (x)y = 0, 0 dx2 1 dx 2 or r l d dy a (x) + a (x)y = 0 dx 0 dx 2 Example 3.4 (Legendre’s Equation) d2y dy (1 − x2) − 2x + n(n + 1)y = 0 dx2 dx d is self-adjoint, for a (x) = 1 − x2, a (x) = −2x and (1 −x2) = −2x.
Written in the form (27), it is 0 1 dx r l d dy (1 − x2) + n(n + 1)y = 0 dx dx Theorem 3.5 The coefficients a , a and a in the differential equation 0 1 2 a (x) d2 y + a (x) dy + a (x)y = 0 (24) 0 dx2 1 dx 2 are continuous on a ≤ x ≤ b, and a (x) /= 0 on a ≤ x ≤ b.
0 Then Equation (24) can be transformed into the equivalent self-adjoint equation r l d dy P (x) + Q(x)y = 0 (27) dx dx on a ≤ x ≤ b, where P (x) = eR aa10 ((xx)) dx, Q(x) = a2(x) e R aa 10 ((xx)) dx (28) a (x) 0 by multiplication throughout by the factor 1 e R aa10 ((xx)) dx.
(29) a (x) 0 Proof.
Multiplying equation (24) through by the factor (30) you obtain e R aa01 ((xx)) dx d2 y + a 1 (x) eR aa10 ((xx)) dx dy + a 2 (x) e R aa10 ((xx)) dxy = 0 dx2 a (x) dx a (x) 0 0 This equation is clearly self-adjoint and may be written as r l d eR aa10 ((xx)) dx dy + a2(x) e R aa10 ((xx)) dxy = 0 dx dx a (x) 0 or r l d dy P (x) + Q(x)y = 0 dx dx where P and Q are given by (29).
121  6 Tutor Marked Assignments(TMAs) Example 3.5 Consider the equation d2 y dy x2 − 2x + 2y = 0 (30) dx2 dx Here a (x) = x2, a (x) = −2x.
Since at (x) = 2x /= −2x = a (x), Equation (31) is not self-adjoint.
You 0 1 0 1 can form the factor (30) for this equation.
You have 1 e R aa10 ((xx)) dx = 1 eR − x 2 2x dx = 1 .
a0(x) x2 x4 1 Multiplying Equation (31) by on any interval a ≤ x ≤ b which does not include x = 0, you obtain x4 1 d2y 2 dy 2 − + y = 0. x2 dx2 x3 dx x4 ( \ d 1 2 Since = − , this equation is self adjoint and may be written in the form x2 x3 dx r l d 1 dy 2 + y = 0 dx x2 dx x4 4 Conclusion In this unit, you studied adjoint equations, you saw some examples, and learnt of self-adjoint equations and how to transform an equation to a self adjoint equation.
5 Summary Having gone through this unit, you can now 1.
Give the meaning of adjoint equations.
2. obtain an adjoint equation of a given Linear ODE 3. identify self adjoint equations 4. transform an equation to an equivalent self adjoint equation.
6 Tutor Marked Assignments(TMAs) Exercise 6.1 1.
Find the adjoint equation to each of the following equations: d2 y dy (a) x2 + 3x + 3y = 0. dx2 dx d2 y dy (b) (2x + 1) + x3 + y = 0.
123  4 Conclusion d3 y d2 y dy (c) x3 + x2 + x + y = 0. dx3 dx2 dx (d) d 4y + x d3y + x2 d 2y+ x3 d y + x3y = 0. dx4 dx3 dx2 dx 2.
Solve d2y dy x2 + (2x3 + 7x) + + 8)y = 0. dx2 (8x2 dx by finding a simple solution of its adjoint equation by inspection.
3.
Transform each of the following equations into an equivalent self-adjoint equation: d2 y dy (a) x2 + x + y = 0 dx2 dx d2 y dy (b) (x4 + x2) + 2x3 + 3y = 0 dx2 dx d2 y dy (c) − tan x + y = 0 dx2 dx (d) f (x) dy + g(x)y = 0 dx2 dx2 dx 122 MODULE 3 UNIT 6: STURM-LIOUVILLE BOUDARY VALUE PROBLEMS Contents 1 Introduction 124 2 Objectives 124 3 Main Content 125 3.1 Sturm-Liouville Problems 125 3.1.1 Definition and Examples 125 3.1.2 Characteristic Values and Characteristic Functions 128 4 Conclusion 131 5 Summary 131 6 Tutor Marked Assignments (TMAs) 132 1 Introduction In this unit, you shall be introduced to a special kind of boundary value problem known as a Sturm-Liouville Problem.
Your study of this type of problem will introduce you to several important concepts including characteristic function, orthogonality, and Fourier series (which are beyond the scope of this book).
These concepts are frequently employed in the applications of differential equations to physics and engineering.
2 Objectives At the end of this unit, you should be able to (i) Define and give examples of Sturm-Liouville problems (ii) Know the meaning of characteristic values and characteristic functions.
3.1 Sturm-Liouville Problems 3 Main Content 3.1 Sturm-Liouville Problems 3.1.1 Definition and Examples The first concern in this unit is a study of the special type of two-point boundary value problem given in the following definition: Definition 3.1 Consider a boundary value problem which consists of 1. a second-order homogeneous linear differential equation of the form r l d dy p(x) + [q(x) + λr(x)]y = 0 (1) dx dx where p, q and r are real functions such that p has continuous derivative, q and r are continuous, and p(x) > 0 and r(x) > 0 for all x on a real interval a ≤ x ≤ b; and λ is a parameter independent of x; and 2. two supplementary conditions A1y(a) + A2yt(a) = 0, (2) B y(b) + B yt(b) = 0 1 2 where A , A , B and B are real constants such that A and A are not both zero and B and B are 1 2 1 2 1 2 1 2 not both zero.
This type of boundary-value problem is called a Sturm-Liouville Problem (or Sturm-Liouville System).
Two important special cases are those in which the supplementary conditions (2) are either of the form yt(a) = 0, y(b) = 0 (3) or of the form yt(a) = 0, yt(b) = 0.
(4) Example 3.1 The boundary-value problem d2y + λy = 0 (5) dx2 y(0) = 0, y(π) = 0 (6) is a Sturm-Liouville problem.
The differential equation (5) may be written r l d dy 1 · + [0 + λ · 1]y = 0 dx dx 124 and hence is of the form (1), where p(x) = 1, q(x) = 0, and r(x) = 1.
The supplementary conditions (6) are of the special form (3) of (2).
3 Main Content Example 3.2 The boundary-value problem r l d dy x + [12x2 + λx3]y = 0 (7) dx dx 3y(1) + 4yt(1) = 0, (8) 5y(2) − 3yt(2) = 0 is a Sturm-Liouville Problem.
The differential equation (7) is of the form of (1), where p(x) = x, q(x) = 2x2, and r(x) = x3.
The conditions (8) are of the form (2), where a = 1, b = 2, A = 3, A = 4, B = 5, 1 2 1 and B = −3.
2 You are now due to be introduced to what is involved in solving a Sturm-Liouville Problem.
You must find a function f which satisfies both the differential equation (1) and the two supplementary conditions (2).
Clearly one solution of any problem of this type is the trivial solution φ such that φ(x) = 0 for all values of x.
Equally clear is the fact that this trivial solutiion is not very useful.
You should therefore focus you attention on the search for nontrivial solutions of the problem.
That is, you should attempt to find functions, not identically zero, which satisfies both the differential equation(1) and the two conditions (2).
You shall see that the existence of the nontrivial solutions depends upon the value of the parameter λ in the differential equation (1).
To illustrate this, you have to return to the Sturm-Liouville Problem of Example (1) and attempt to find nontrivial solutions Example 3.3 Find nontrivial solutions of the Sturm-Liouville Problem d2y + λy = 0, (5) dx2 y(0) = 0, y(π) = 0.
(6) Solution.
You would need to consider three cases according as λ = 0, λ < 0 and λ > 0.
In each case you should first find the general solution of the differential equation (5).
You shall then attempt to determine the two arbitrary constants in this solution so that the supplementary conditions (6) will also be satisfied.
Case I: (λ = 0).
In this case the differential equation (5) reduced at once to d2y = 0 dx2 and so the general solution is y = c + c x.
(9) 1 2 You can now apply conditions (6) to the solution (9).
Applying the first condition y(0) = 0, you obtain c1 = 0.
Applying the second condition y(π) = 0, you find that c1 + c2π = 0.
Hence, since c = 0, you must have also that c = 0.
Thus in order for the solution (9) to satisfy the conditions 1 2 (6), you must have c = c = 0.
But then the solution (9) becomes the solution y such that y(x) = 0 1 2 for all values of x.
Thus if the parameter λ = 0, the only solution of the given problem is the trivial solution.
127 3.1 Sturm-Liouville Problems Case II: (λ < 0).
The auxiliary equation of the differential equation (5) is m2 + λ = 0 and the roots √ √ ± −λ.
Since in this case λ < 0, these roots are real and unequal.
Denoting −λ by α, you can see that for λ < 0 the general solution of (5) is of the form y = c eαx + c e−αx (10) 1 2 Applying the conditions (6) to the solution (10) starting with the first, gives you c + c = 0 (11) 1 2 Applying the second condition y(π) = 0, you find that c eαπ + c e−απ = 0 (12) 1 2 You must thus determine c and c such that the system consisting of (11) and (12) is satisfied.
Thus 1 2 in order for the solution (10) to satisfy the conditions (6), the constants c and c must satisfy the 1 2 system (11) and (12).
Obviously c = c = 0 is a solution of this system; but these values of c and c 1 2 1 2 would only give the trivial solution of this given problem.
You must therefore seek nonzero values of c and c which satisfy (11) and (12).
By some theorems of ODE, this system has nonzero solutions 1 2 only if the determinant of the coefficient is zero.
Therefore you must have 1 1 = 0. eαπ e−απ But this implies that eαπ = e−απ and hence that α.
Thus in order for a nontrivial function of the form √ (10) to satisfy the conditions (6) you must have α = 0.
Since α = −λ, you must have λ = 0.
But λ < 0 in this case.
Thus there are no nontrivial solutions of the given problem in the case λ < 0.
Case √ III: (λ > 0).
Since λ > 0, here, the roots ± −λ of the auxiliary equation of (5) are the √ conjugate complex numbers ± λi.
Thus in this case the general solution of (5) is of the form √ √ y = c sin λx + c cos λx.
(13) 1 2 Applyining now the conditions (6) to this general solution, begining from the first condition y(0)=0, you obtain c sin 0 + c cos 0 = 0 1 2 and hence c .
Applying the second condition y(π) = 0, you would find that 2 √ √ c sin λπ + c cos λπ = 0 1 2 Since c = 0, this reduces at once to 2 √ c sin λπ = 0 (14) 1 You must therefore satisfy (14).
At first glance it appears that you can do this in either of two ways: √ you can set c = 0 or you can set sin λπ = 0.
However, if you set c = 0, then (since c = 0 also) 1 1 2 the solution (13) reduces immediately to the unwanted trivial solution.
Thus to obtain a nontrivial solution you cannot set c = 0 but rather you must set 1 √ sin λπ = 0 (15) If k > 0, then sin kπ = 0 only if k is a positive integer n = 1, 2, 3, ....
Thus in order that the differential equation (5) have a nontrivial solution of the form (13) satisfying the conditions (6), you must have λ = n2, where n = 1, 2, 3, ... (16) 126  3.1 Sturm-Liouville Problems In other words, the parameter λ in (5) must be a member of the infinit sequence 1, 4, 9, 16, ..., n2, ... You can now summarize you result as follows.
If λ < 0 the Sturm-Liouville problem consisting of (5) and (6) does not have a nontrivial solution; if λ > 0, a nontrivial solution can exist only if λ is one of the values given by (16).
You now note that if λ is one of the values (16), then the problem does have nontrivial solutions.
Indeed, from (13) you see that nontrivial solutions corresponding to λ = n2(n = 1, 2, 3, ...) are given by y = c sin nx(n = 1, 2, 3, ...), (17) n where c (n = 1, 2, 3, ...) is an arbitrary nonzero constant.
That is, the functions defined by c sin x, n 1 c sin 2x, c sin 3x, ..., where c , c , c , ... are arbitrary nonzero constants, are non trivial solutions of 2 3 1 2 3 the given problem.
3.1.2 Characteristic Values and Characteristic Functions Example 12.3 shows that the existence of nontrivial solution of a Sturm-Liouville Problem does indeed depend upon the value of the parameter λ in the differential equation of the problem.
Those values of the parameter for which nontrivial solutions do exist, as well as the corresponding nontrivial solutions themselves, are singled out by the following definition.
Definition 3.2 Consider the Sturm-Liouville Problem consisting of the differential equation (1) and the supplementary conditions (2).
The values of the parameter λ in (1) for which there exist nontrivial solutions, of the problem are called the Characteristic values of the problem.
The corresponding nontrivial solutions themselves are called the characteristic functions of the problem.
Example 3.4 Consider again the Sturm-Liouville Problem d2y + λy = 0, (5) dx2 y(0) = 0, y(π) = 0.
(6) In Example 12.3 you found that the values of λ in (5) for which there exist nontrivial solutions of this problem are the values λ = n2, where n = 1, 2, 3, ... (16) These then are the characteristics values of the problem under consideration.
The characteristic function of the problem at the corresponding nontrivial solutions y = c sin nx (n = 1, 2, 3, ...) (17) n where c (n = 1, 2, 3, ...) is an arbitrary nonzero constant.
n Example 3.5 Find the characteristic values and the characteristic functions of the Sturm-Liouville Problem r l d dy λ x + y = 0, (18) dx dx x yt(1) = 0, yt(e2π ) = 0 (19) where it is assumed that the parameter λ in (18) i1s2n8onnegative.
4  3.1 Sturm-Liouville Problems Solution.
Consider separately the cases λ = 0 and λ > 0.
If λ = 0, the differential equation (18) reduces to r l d dy x = 0 dx dx The general soltion of this differential equation is y = C ln |x| + C , 0 where C and C are arbitrary constants.
If you apply the conditions (19) to this general solution, you 0 will find that both of them require that C = 0 but neither of them imposes andy arbitrary constant.
These are nontrivial solutions for all choices of C /= 0.
Thus λ = 0 is a characteristic value and 0 the corresponding characteristic functions are given by y = C , where C is an arbitrary nonzero 0 0 constant.
If λ > 0, you see that for x /= 0 this equation is equivalent to the Cauchy-Euler Equation d2 y dy x2 + x + λy = 0.
(20) dx2 dx Letting x = et, then equation (20) transforms into d2y + λy = 0.
(21) dx2 Since λ > 0, the general solution of (21) is of the form √ √ y = c sin λt + c cos λt 1 2 Thus for λ > 0 and x > 0 the general solution of (18) may be written √ √ y = c sin( λ ln x) + c cos( λx).
(22) 1 2 Differentiating (22) and Applying the supplementary conditions (19) gives you that √ √ dy c λ √ c λ √ = 1 cos( λx) − 2 sin( λ ln x) (23) dx x x for x > 0.
Applying the first conditiioin yt(0) = 0 of (19) to (23), you would have √ √ √ √ c λ cos( λ ln 1) − c λ sin( λ ln 1) = 0 1 2 √ or simply c λ = 0.
Thus you must have 1 c = 0.
1 Applying the second condition yt(e2π ) = 0 of (19) to (23), you obtain √ √ √ √ c λe−2π cos( λ ln e2π ) − c λe−2π sin( λ ln e2 π ) = 0.
1 2 Since c = 0 by (24), and ln e2π = 2π, this reduces at once to 1 √ √ c λe−2π sin(2π λ) = 0.
2 √ Since c = 0, thechoice c = 0 would lead to the trivial solution.
Thus you must have sin(2π λ) = 0 1 √ 2 and hence 2π λ = nπ, where n = 1, 2, 3, ....
Thus in order to satisfy the second condition (19) nontrivially you must have n2 λ = (n = 1, 2, 3, ...) (24) 129  3.1 Sturm-Liouville Problems Corresponding to these values of λ you obtain for x > 0 the nontrivial solutions n ln x y = C cos , (n = 1, 2, 3, ...) (25) n 2 where C (n = 1, 2, 3, ...) are arbitrary nonzero constants.
n Thus the values 1 9 25 n2 λ = 0, , 1, , 4, , ..., , ..., 4 4 4 4 given by (25) for n ≥ 0, are the characteristic values of the given problem.
The functions ln x 3 ln x C , C cos , C cos(ln x), C cos , ..., 0 1 2 2 3 2 given by (26) for n ≥ 0, where C , C , C , C , ... are arbitrary nonzero constants, are the correspond- 0 1 2 3 ing characteristic functions.
For each of the Sturm-Liouville Problems of Examples (3.3) and (3.5), you must have found an infi- nite number of characteristic values.
You could observe that in each of these problems the infinite set of characteristic values thus found can be arranged in a monotonic increasing sequence λ < λ < λ < · · · 1 2 3 such that λ → +∞ as n → ∞.
For example, the characteristic values of the problem in example (3.3) can n be arranged in the monotonic increasing sequence 1 < 4 < 9 < 16 < · · · (26) such that λ → +∞ as n → +∞.
You also note that in each problem there is a one-parameter of character- n istic functions corresponding to the same characteristic value are merely nonzero constant multiples of each other.
For example, in the problem of example 3.3, the one-parameter family of characteristic functions corresponding to the characteristic value n2 is c sin nx, where c /= 0 is the parameter.
n n You might now inquire whether or not all Sturm-Liouville Problems of the type under consideration possess characteristic values and characteristic functions having the properties noted in the preceding para- graph.
You can answer in the affirmative by stating the following important theorem.
Theorem 3.1 Consider the Sturm-Liouville Problem consisting of (i) the differential equation r l d dy p(x) + [q(x) + λr(x)]y = 0, (27) dx dx where p, q and r are real functions such that p has a continuous derivative, q and r are continuous and p(x) > 0 and r(x) > 0 for all x on the real interval a ≤ x ≤ b; and λ is a parameter independent of x; and (ii) the conditions A1y(a) + A2yt(a) = 0 (28) B y(b) + B yt(b) = 0 1 2 where A1, A2, B1 and B2 are real constants such that A1 and A2 are not both zero and B1 and B2 are not both zero.
130 4  6 Tutor Marked Assignments(TMAs) Then (i) There exists an infinite number of characteristic values λ can be arranged in a monotonic increasing n sequence λ < λ < λ < · · · 1 2 3 such that λ → +∞ as n → +∞.
n (ii) correspoinding to each characteristic value λ there exists a one-parameter family of characteristic n functions φ .
Each of these characteristic functions is defined on a ≤ x ≤ b, and any two character- n istic functions corresponding to the same characteristic value are nonzero constant multiples of each other.
(iii) Each characteristic function φ corresponding to the characteristic value λ (n = 1, 2, 3, ...) has n n exactly (n − 1) zeros in the open interval a < x < b.
Example 3.6 Consider again the Sturm-Liouville Problem of Examples 3.3 and 3.4 d2y + λy = 0, (29) dx2 y(0) = 0, y(π) = 0.
(30) You have already noted the validity of conclusions (i) and (ii) of theorem 3.1 for this problem.
The infinite number of characteristic values λ = n2(n = 1, 2, 3, ...) can be arranged in the unbounded monotonic n increasing sequence indicated by (27); and the characteristic functions c sin nx(c /= 0), corresponding to n n λ = n2 possess the properties stated.
n Conclusion (iii) is illustrated by showing that each function c sin nx corresponding to λ = n2 has exactly n n (n − 1) zeros in the open interval 0 < x < π.
You know that sin nx = 0 if and only if nx = kπ, where k is an integer.
Thus the zeros of c sin nx are given by n kπ x = , (n = 0, ±1, ±2, ...) (31) n The zeros (28) which lie in the open interval 0 ≤ x ≤ π are precisely those for which k = 1, 2, 3, ..., n − 1.
Thus, just as conclusion (iii) asserts, each characteristic functions c sin nx has precisely (n − 1) zeros in n the open interval 0 < x < π.
4 Conclusion In this unit, you have studied the two point Sturm-Liouville problem.
You saw some examples, and learnt how to find the solutions to these problems by obtaining the Characteristic values and the Characteristic functions.
5 Summary Having gone through this unit, you now know (i) what is meant by a two point Sturm-Liouville boundary value problem.
(ii) the meaning of a characteristic value and the corresponding characteristic function of a Sturm-  4 Conclusion 6 Tutor Marked Assignments(TMAs) Exercise 6.1 Find the characteristic values and characteristic functions of each of the following Sturm-Liouville Prob- lems.
(cid:31) d2y (cid:31) + λy = 0 (cid:31)(cid:31) dx2 (cid:31) 1. y(0) = 0, (cid:31) (cid:31) (cid:31) π (cid:31) y = 0.
2 (cid:31) d2y (cid:31) + λy = 0 (cid:31)(cid:31) dx2 2. y(0) = 0, (cid:31) (cid:31) (cid:31) (cid:31) yt (π) = 0.
(cid:31) d2y (cid:31) + λy = 0 (cid:31)(cid:31) dx2 3. y(0) = 0, (cid:31) (cid:31) (cid:31) (cid:31) y (L) = 0, where L > 0 (cid:31) d2y (cid:31) + λy = 0 (cid:31)(cid:31) dx2 4. yt(0) = 0, (cid:31) (cid:31) (cid:31) (cid:31) yt (L) = 0, where L > 0.
(cid:31) d2y (cid:31) + λy = 0 (cid:31)(cid:31) dx2 5. y(0) = 0, (cid:31) (cid:31) (cid:31) (cid:31) y(π) − yt(π) = 0.
(cid:31) d2y (cid:31) + λy = 0 (cid:31)(cid:31) dx2 6. y(0) − yt(0) = 0, (cid:31) (cid:31) (cid:31) (cid:31) y(π) − yt(π) = 0.
(cid:31) r l d dy λ (cid:31) x + y = 0 (cid:31) (cid:31) dx dx x (cid:31) 7. y(1) = 0, (cid:31) (cid:31)(cid:31)(cid:31)Li ouville problem.
131 y(eπ ) = 0.
132  6 Tutor Marked Assignments(TMAs) (cid:31) r l d dy λ (cid:31) x + y = 0 (cid:31) (cid:31) dx dx x (cid:31) 8. y(1) = 0, (cid:31) (cid:31) (cid:31) (cid:31) yt(eπ ) = 0.
(cid:31) r l d dy λ (cid:31) (x2 + 1) + y = 0 2 (cid:31) (cid:31) dx dx x + 1 (cid:31) 9. y(0) = 0, (cid:31) (cid:31) (cid:31) (cid:31) y(1) = 0.
[Hint.
Let x = tan t.] (cid:31) r l d 1 dy (cid:31) + +λ(3x2 + 1)y = 0 (cid:31) (cid:31) dx 3x2 + 1 dx (cid:31) 10. y(0) = 0, (cid:31) (cid:31) (cid:31) (cid:31) y(π) = 0.
[Hint.
Let t = x3 + x] 133 UNIT 7: NONLINEAR EQUATIONS Contents 1 Introduction 134 2 Objectives 135 3 Main Content 135 3.1 Phase Plane, Paths, and Critical Points 135 3.1.1 Basic Concepts and Definitions 135 3.1.2 Types of Critical Points 139 3.1.3 Stability.
139 3.2 Critical Points and Paths of Linear Systems 139 3.2.1 Basic Theorems 139 3.2.2 Examples and Applications 141 3.3 Critical Points and Paths of Nonlinear Systems 141 3.3.1 Basic Theorems on Nonlinear Systems 141 4 Conclusion 145 5 Summary 145 6 Tutor Marked Assignments (TMAs) 145 1 Introduction The mathematical formulation of numerous physical problems results in differential equations where are actually nonlinear.
In many cases it is possible to replace such a non-linear equation by a related linear equation which approximates the actual nonlinear equations closely enough to give useful results.
However, such a “linearization” is not always feasible; and when it is not, the original nonlinear equation itself must be considered.
While the general theory and methods of linear equations are highly developed, very little of a general character is known about nonlinear equations.
The study of nonlinear equations is generally confined to a variety of rather special cases, and one must resort to various methods of approximation.
In this unit, you shall be introduced briefly to certain of these methods.
134  2 Objectives 2 Objectives At the end of this unit, you should be able to; (i) define phase plane, paths and critical points.
(ii) describe types of critical points (iii) define and describe stability of a critical point.
(iv) determine the critical points of linear system.
(v) describe the nature of the critical point (0, 0) (vi) describe the stability of the critical point (0, 0) (vii) linearize a nonlinear differential equation and describe the nature and stability of the critical point (0, 0) 3 Main Content 3.1 Phase Plane, Paths, and Critical Points 3.1.1 Basic Concepts and Definitions For simplicity, you should be concerned with second-order nonlinear differential equations of the form x¨ = F (x, x˙ ) (1) where x=x(t).
As a specific example of such equation you have the important van der Pol equation x¨ + µ(x2 − 1)x˙ + x = 0, (2) where µ is a positive constant.
For the time being, you could observe that you can put (2) in form (1), where F (x, x˙ ) = −µ(x2 − 1)x˙ − x Suppose that the differential equation (1) describes a certain dynamical system having on degree of freedom.
The state of this system at time t is determined by the values of x (position) and x˙ (velocity).
The plane of the varibles x and x˙ is called a phase plane.
If you let y = x˙ , you can replace the second-order equation (1) by the equivalent system (cid:31) (cid:31) x˙ = y (3) (cid:31) y˙ = F (x, y) You can determine information about the equation (1) from a study of the system (1).
In particular you should be interested in the configuration formed by the curves which the solutions of (3) define.
You should regard t as a parameter so that these curves will appear in the xy plane.
Since y = x˙ = dx/dt, this xy plane is simply the x, dx/dt- phase plane mentioned in the preceeding paragraph.
135 3.1 Phase Plane, Paths, and CriticalPoints More generally, you should consider the system of the form (cid:31) (cid:31) x˙ = P (x, y) (4) (cid:31) y˙ = Q(x, y) where P and Q have continuous first partial derivatives for all (x, y).
Such a system, in which the inde- pendent varible t appears only in the differentials dt of the left members and not explicitly in the functions P and Q on the right, is called an autonomous system.
You shall now proceed to study the configurations formed in the xy-phase plane by the curves which are defined by the solutions of (4).
From the existence theorem, it follows that given any number t and any pair (x , y ) of real numbers, 0 0 0 there exists a unique solution (cid:31) (cid:31) x = f (t) (5) (cid:31) y = g(t) of the system (5) such that (cid:31) (cid:31) f (t0) = x0 (cid:31) g(t0) = y0 If f and g are not both constant functions, then (5) defines a curve in the xy plane which you shall call a path of the system (4).
If the ordered pair of functions defined by (5) is a solution of (4) and t is any real number, then it is 1 easy to see that the ordered pair of functions defined by (cid:31) (cid:31) x = f (t − t ) 1 (6) (cid:31) y = g(t − t ) 1 is also a solution of (4).
Assuming that f and g in (5) are not both constant functions and that t j= 0, the 1 solutions defined by (5) and (6) are two different solutions are simply different parametrizations of the same path.
You can observe that the terms solution and path are not synonymous.
On the one hand, a solution of (4) is an ordered pair of functions (f, g) such that x = f (t), y = g(t) simultaneously satisfy the two equations of the system (4) identically; on the other hand, a path of (4) is a curve in the xy-phase plane, which may be defined parametrically by more than one solution of (4).
Through any point of the xy-phase plane there passes at most one path of (4).
Let C be a path of (4) and consider the totality of different solutions of (4) which define this path C parametrically.
For each of these defining solutions, C is traced out in the same direction as the parameter t increases.
Thus with each path C there is associated a definite direction, the direction of increase of the parameter t in the various possible parametric representations of C by the corresponding solutions of the system.
In your figures, you shall use arrows to indicate this direction associated with a path.
Eliminating t between the two equations of the system (4), you obtain the equation dy Q(x, y) = (7) dx P (x, y) This equation gives the slope of the tangent to the path of (4) passing through the point (x, y), provided the functions P and Q are not both zero at this point.
The general solution of (7) thus provides the one- parameter family of paths of (4).
However, the description (7) does not indicate the directions associated with these paths.
At a point (x , y ) at which both P and Q are zero, the slope of the tangent to the path, as defined by 0 0 (7), is indeterminate.
Such points are singled out1i3n6the following definition.
3.1 Phase Plane, Paths, and CriticalPoints Definition 3.1 Given the autonomous system (cid:31) (cid:31) x˙ = P (x, y) (4) (cid:31) y˙ = Q(x, y) a point (x , y ) at which both 0 0 P (x , y ) = 0 and Q(x , y ) = 0 0 0 0 0 is called a critical point of (4).
Example 3.1 Consider the linear autonomous system (cid:31) (cid:31) x˙ = y (8) (cid:31) y˙ = −x Solving this, using the methods developed in unit 4, you would find that the general solution of the system may be written (cid:31) (cid:31) x = c sin t − c cos t 1 2 (cid:31) y = c cos t + c sin t 1 2 where c and c are arbitrary constants.
The solution satisfying the conditions x(0) = 0, y(0) = 1 is readily 1 2 found to be (cid:31) (cid:31) x = sin t (9) (cid:31) y = cos t This solution defines a path C in the xy plane.
The solution satisfying the conditions x(0) = −1, y(0) = 0 1 is (cid:31) (cid:31) x = sin(t − π/2) (10) (cid:31) y = cos(t − π/2) The solution (10) is different from the solution (9), but (10) also defines the same path C .
That is, the 1 ordered pairs of functions defined by (9) and (10) are two different solutions of (8) which are different parametrizations of the same path C .
Eliminating t from either (9) or (10) you obtain the equation x2 +y2 = 1 1 of the path C in the xy phase plane.
Thus the path C is the circle with center at (0, 0) and radius 1.
From 1 1 either (9) or (10) you see that the direction associated with C is the clockwise direction.
1 Eliminating t between the equations of the system (8) you obtain the differential equation dy x = − (11) dx y which gives the slope of the tangent to the path of (8) passing through the point (x, y), provided (x, y) j= (0, 0).
The general solution x2 + y2 = c2 of equation (11) gives the one-parameter family of paths in the xy phase plane.
Several of these are shown in figure 1.
The path C referred to above is of course that for which c = 1 1 137  3.1 Phase Plane, Paths, and CriticalPoints y C 1 0 1 2 3 x Figure 1: Looking back at the system (8), you see that P (x, y) = y and Q(x, y) = −x.
Therefore the only critical point of the system is the origin (0, 0).
Given any real number t , the solution x = f (t), y = g(t) such that 0 f (t ) = g(t ) = 0 is simply 0 0 (cid:31) (cid:31) x = 0 (cid:31) y = 0 for all t. You can also interpret the autonomous system (4) as defining a velocity vector field V, where V (x, y) = [P (x, y), Q(x, y)] The x component of this velocity vector at a point (x, y) is given by P (x, y), and the y component there is given by Q(x, y).
This velocity vector of a representative point R describing a path of (4) defined paramet- rically by a solution x = f (t), y = g(t).
At a critical point both components of this vector velocity are zero, and hence at a critical point the point R is at rest.
In particular, you can consider the special case (3) which arises from a dynamical system described by dx dy dy d 2x the differential equation (1).
At a critical point of (3) both and are zero.
Since = , you thus dt dt dt dt2 see that at such a point the velocity and acceleration of the dynamical system described by (1) are both zero.
Thus the critical points of (3) are equilibrium points of the dynamical system described by (1).
The following are basic concept dealing with critical points and paths.
Definition 3.2 A critical point (x , y ) of the system (4) is called isolated if there exists a circle 0 0 (x − x0)2 + (y − y0)2 = r2 about the point (x , y ) such that (x , y ) is the only critical point of (4) within this circle.
0 0 0 0 3.1 Phase Plane, Paths, and CriticalPoints In what follows, assume that every critical po1in38t is isolated.
139 3.2 Critical Points and Paths of Linear Systems Definition 3.3 Let C be a path of the system (4), and let x = f (t), y = g(t) be a solution of (4) which represents C parametrically.
Let (x , y ) be a critical point of (4).
You shall say that the path C approaches 0 0 the critical point (x , y ) as t → +∞ if 0 0 lim f (t) = x , lim g(t) = y , (12) 0 0 t→+∞ t→+∞ Definition 3.4 Let C be a path of the system (4) which approaches the critical point (x , y ) as t → +∞, 0 0 and let x = f (t), y = g(t) be a solution of (4) which represents C parametrically.
You will say that C enters the critical point (x , y ) as t → +∞ if 0 0 lim g(t) − y0 (13) t→+∞ f (t) − x0 exists or if the quotient in (13) becomes either positively or negatively infinite as t → +∞.
3.1.2 Types of Critical Points 1.
Center: This is a critical point that is surrounded by infinite family of closed paths which is not approached by any of the paths as t → +∞ or t → −∞.
2.
Saddle point 3.
A critical point is called spiral point if such a point is approached in a spiral-like manner by an infinite family of paths as t → +∞ (or as t → −∞).
4.
A critical point is called a node if such a point is not only approached but also entered by an infinite family of paths as t → +∞ (or as t → −∞).
3.1.3 Stability Definition 3.5 Let (x .y ) be a critical point of the system (4); let C be a path of (4); and let x = f (t), 0 0 y = g(t) be a solution of (4) represent C parametrically.
Let D(t) = [f (t) − x ]2 + [g(t) − y ]2 (14) 0 0 denote the distance between (x , y ) and the point R : [f (t), g(t)] on C. The critical point (x , y ) is called 0 0 0 0 stable if for every E > 0, there exists a number δ > 0 such that the following is true: Every path C for which D(t ) < δ f or some value t (15) 0 0 is defined for all t ≥ t and is such that 0 D(t) < E f or t ≤ t < ∞.
(16) 0 3.2 Critical Points and Paths of Linear Systems 3.2.1 Basic Theorems Although the major interest in this unit is to classify the critical point of nonlinear systems.
But you shall see that under appropriate circumstance you can replace a given nonlinear system by a related linear system and then employ this linear system to determine the nature of the critical point of the given system.
Thus in this section, you shall first investigate the critical1p3o9ints of a linear autonomous system.
3.2 Critical Points and Paths of Linear Systems Consider the linear system (cid:31) (cid:31) x˙ = ax + by (17) (cid:31) y˙ = cx + dy.
where a, b, c and d (in the right member of the second equation) are real constants.
The origin (0, 0) is clearly a critical point of (15).
Assume that a b j= 0, (18) c d and hence (0, 0) is the only critical point of (15).
Note that the solutions of (15) are sought and found of the form (cid:31) (cid:31) x = Aeλ t (19) (cid:31) y = Beλt and if (17) would be a solution of (15), then λ must satisfy the quadratic equation λ2 − (a + d)λ + (ad − bc) = 0 (20) called the characteristic equation of (15).
Note that by condition (16), zero cannot be a root of the equation (18) in the problem under discussion.
Let λ and λ be the roots of the characteristic equation (18).
You 1 2 need to prove that the nature of critical point (0, 0) of the system (15) depends upon the nature of the roots λ and λ .
We shall consider five cases according as 1 2 1. λ , and λ are real, unequal, and of the same sign 1 2 2. λ , and λ are real, unequal, and of opposite signs 1 2 3. λ , and λ are real and equal 1 2 4. λ , and λ are conjugate, complex and pure imaginary.
1 2 5. λ , and λ are pure imaginary.
1 2 Theorem 3.1 If the roots λ and λ of the characteristic equation are 1 2 1. real, unequal and of the same sign, then the critical point (0, 0) of the linear system is a node.
2. are real, unequal and of opposite sign then the critical point (0, 0) of the linear system is a saddle point 3. real and equal then the critical point (0, 0) of the linear system (15) is a node 4. conjugate complex with real part not zero (that is not pure imaginary) then the critical point (0, 0) of the linear system (15) is a spiral point.
5. pure imaginary, then the critical point (0, 0) of the linear system (15) is a center Theorem 3.2 The critical point (0, 0) of the linear system (cid:31) (cid:31) x˙ = ax + by a b , where j= 0, (cid:31) y˙ = cx + dy c d is stable if and only if both roots of the characteristic equation have negative or zero real parts.
140  3.3 Critical Points and Paths of Nonlinear Systems 3.2.2 Examples and Applications Example 3.2 Determine the nature of the critical point (0, 0) of the system (cid:31) (cid:31) x˙ = 2x − 7y (21) (cid:31) y˙ = 3x − 8y and determine whether or not the point is stable.
Solution.
The system (19) is of the form (15) where a = 2, b = −7, c = 3 and d = −8.
The characteristic equation is λ2 + 6λ + 5 = 0.
Hence the roots of the characteristic equation are λ = −5 and λ = −1.
Since the roots are negative, 1 2 the critical point (0, 0) of (19) is a node.
Since the roots are negative, the point is stable.
Example 3.3 Determine the nature of the critical point (0, 0) of the system (cid:31) (cid:31) x˙ = 2x + 4y (22) (cid:31) y˙ = −2x + 6y and determine whether or not the point is stable.
Solution.
Here a = 2, b = 4, c = −2 and d = 6.
The characteristic equation is λ2 − 8λ + 20 = 0 and its roots are 4 ± 2i.
Since these roots are conjugate complex but not pure imaginary, conclude that the critical point (0, 0) of (20) is a spiral point.
Since the real part of the roots is positive, the point is stable.
3.3 Critical Points and Paths of Nonlinear Systems 3.3.1 Basic Theorems on Nonlinear Systems Consider the nonlinear real autonomous system (cid:31) (cid:31) x˙ = P (x, y) (23) (cid:31) y˙ = Q(x, y) Assume that the system (21) has an isolated critical point which you shall choose to be the origin (0, 0).
Assume further that the function P and Q in the right members of (21) are such that P (x, y) and Q(x, y) can be written in the form (cid:31) (cid:31) P (x, y) = ax + by + P1(x, y) (24) (cid:31) Q(x, y) = cx + dy + Q (x, y) 1 where (i) a, b, c and d are real constants, 141  3.3 Critical Points and Paths of Nonlinear Systems a b and j= 0, c d and (ii) P and Q have continuous first partial derivatives for all (x, y), and are such that 1 1 P (x, y) Q (x, y) lim 1 = lim 1 = 0 (25) (x,y)→(0,0) x2 + y2 (x,y)→(0,0) x2 + y2 Thus the linear system under consideration may be written in the form (cid:31) (cid:31) x˙ = ax + by + P (x, y) 1 (26) (cid:31) y˙ = cx + dy + Q (x, y) 1 where a, b, c, d, P and Q satisfy the requirements above.
1 1 If P (x, y) and Q(x, y) in (21) can be expanded in power series about (0, 0), the system (21) takes the form (cid:31) (cid:31)(cid:31)(cid:31) x˙ = ∂∂xP x + ∂∂yP y + a12x2 + a22xy + a21y2 + · · · (0,0) (0,0) (27) (cid:31) ∂Q ∂Q (cid:31) y˙ = x + y + b x2 + b xy + b y2 + · · · (cid:31) ∂x ∂y 12 22 21 (0,0) (0,0) This system is of the form (24), where P (x, y) and Q (x, y) are the terms of higher degree in the right 1 1 ∂(P, Q) members of the equations.
The requirments above will be met, provided the Jacobian j= 0.
∂(x, y) (0,0) Observe that the constant terms are missing in the expansion in the right members of (25), since P (0, 0) = Q(0, 0) = 0.
Example 3.4 The system (cid:31) (cid:31) x˙ = x + 2y + x 2 (cid:31) y˙ = −3x − 4y + 2y2 is of the form (24) and satisfies the requirments (i) and (ii) above.
Here a = 1, b = 2, c = −3 and d = −4, and a b = 2 j= 0 c d Further P (x, y) = x2, Q (x, y) = 2y2, and hence 1 1 P (x, y) x2 lim 1 = lim = 0 (x,y)→(0,0) x2 + y2 (x,y)→(0,0) x2 + y2 and Q (x, y) 2y2 lim 1 = lim = 0 (x,y)→(0,0) x2 + y2 (x,y)→(0,0) x2 + y2 By the requirement of (ii) the nonlinear terms P (x, y) and Q (x, y) in (24) tend to zero more rapidly 1 1 than the linear terms ax + by and cx + dy.
Hence one would suspect that the behaviour of the paths of the system (24) near (0, 0) would be similar to that of the paths of the related linear system (cid:31) (cid:31) x˙ = ax + by (28) (cid:31) y˙14=2 cx + dy None 3.3 Critical Points and Paths of Nonlinear Systems obtained from (24) by neglecting the nonlinear terms.
In other words, it would seem that the nature of the critical point (0, 0) of the nonlinear system (24) should be similar to that of the linear system (15).
In general this is actually the case.
It is now time to state without proof the main theorem regarding this relation.
Theorem 3.3 Consider the nonlinear system (cid:31) (cid:31) x˙ = ax + by + P (x, y) 1 (29) (cid:31) y˙ = cx + dy + Q (x, y) 1 where a, b, c, d, P and Q satisfy the requirements (i) and (ii) above.
Consider the linear system 1 1 (cid:31) (cid:31) x˙ = ax + by (30) (cid:31) y˙ = cx + dy obtained from (27) by neglecting the nonlinear terms P (x, y) and Q (x, y).
Both systems have an isolated 1 1 critical point at (0, 0).
Let λ and λ be the roots of the characteristic equation 1 2 λ2 − (a + d)λ + (ad − bc) = 0 (31) of the linear system (28).
Then (a) The critical point (0, 0) of the nonlinear system (28) in the following cases (i) If λ and λ are real, unequal and of the same sign, then not only is (0, 0) a node of (28) but also 1 2 (0, 0) is a node of (27).
(ii) If λ and λ are real, unequal, and of opposite sign, then not only is (0, 0) a saddle point of (28), but 1 2 also (0, 0) is a saddle point of (27).
(iii) If λ and λ are real and equal and the system (28) is not such that a = d j= 0, b = c = 0.
Then not 1 2 only is (0, 0) a node of (28), but also (0, 0) is a node of (27).
(iv) If λ and λ are conjugate complex with real part not zero, then not only is (0, 0) a spiral point of 1 2 (28), but also (0, 0) is a spiral point of (27).
(b) The critical point (0, 0) of the nonlinear system (27) is not necessarily of the type as that of the linear system (28) in the following cases: (v) If λ and λ are real and equal and the system (28) is such that a = d j= 0, b = c = 0, then although 1 2 (0, 0) is a node of (28), the point (0, 0) may be either a node, a spiral point of (28).
(vi) If λ and λ are pure imaginary, then although (0, 0) is a center of (28), the point may be either a 1 2 center or a spiral point of (27).
Theorem 3.3 deals with the type of the critical point (0, 0) of the nonlinear system (27).
Concerning the stability of this point, you have without proof the following theorem of Lyapunov.
More on this is discussed in unit 8.
Theorem 3.4 With Hypothesis as exactly as in theorem 3.3, 143  3.3 Critical Points and Paths of Nonlinear Systems (a) If the roots λ and λ of the characteristic equation (29) of the linear system (28) both have negative 1 2 real parts, then not only is (0, 0) a stable critical point of (28) but also (0, 0) is a stable critical point of (27).
(b) If at least one of the roots λ and λ of (29) has a positive real part, then not only is (0, 0) an unstable 1 2 critical point of (28), but also an unstable critical point of (27).
Example 3.5 Consider the nonlinear system (cid:31) (cid:31) x˙ = x + 4y − x2 (32) (cid:31) y˙ = 6x − y + 2xy .
This is of the form (27), where P (x, y) = −x2 and Q (x, y) = 2xy.
You see at once that the hypotheses 1 1 of Theorems 13.7 and 13.8 are satisfied.
Hence to investigate the critical point (0,0) of (30), consider the linear system (cid:31) (cid:31) x˙ = x + 4y (33) (cid:31) y˙ = 6x − y of the form (28).
The characteristic equation (29) of this system is λ2 − 25 = 0.
Hence the roots are λ = 5, λ = −5.
Since the roots, are real, unequal, and of opposite sign, you see from 1 2 conclusion (ii) of theorem 3.3, that the critical point (0, 0) of the nonlinear system (31) is a saddle point.
From the conclusion (b) of theorem 3.4, you further conclude that the point is unstable.
Eliminating dt from the equation (30), you obtain the differential equation dy 6x − y + 2xy = (34) dx x + 4y − x2 which gives the slope of the paths in the xy-phase plane defined by the solutions of (30).
The first order equation (32) is exact.
Its general solutionis readily found to be x2y + 3x2 − xy − 2y2 + c = 0 (35) where c is an arbitrary constant.
Equation (33) is the equation of the family of paths in the xy-phase plane.
Example 3.6 Consider the nonlinear system (cid:31) (cid:31) dx = sin x − 4y dt (36) (cid:31) dy = sin 2x − 5y dt Using the expansion x3 x5 sin x = x − + −··· 3!
5!
You write this system in the form (cid:31) (cid:31) x˙ = x − 4y − x3 + x5 + · · · 6 120 (37) (cid:31) y˙ = 2x −154y4− 4x 3 + 4x5 − · · · 3 15  6 Tutor Marked Assignments(TMAs) The hypothesis of theorems 3.3 and 3.4 are satisfied.
Thus to investigate the critical point (0,0) of (27) or (28), you consider the system (cid:31) (cid:31) x˙ = x − 4y (38) (cid:31) y˙ = 2x − 5y The characteristic equation of this system is λ2 + 4λ + 3 = 0.
Thus the roots are λ = −3, λ = −1.
Since the roots are real, unequal, and of the same sign, you see 1 2 from conclusion (i) of theorem 3.3 that the critical point (0, 0) of the nonlinear system (34) is a node.
From conclusion (a) of theorem 3.4, you can conclude that this node is stable.
Example 3.7 Consider the two nonlinear systems (cid:31) (cid:31) x˙ = −y − x2 (39) (cid:31) y˙ = x and (cid:31) (cid:31) x˙ = −y − x 3 (40) (cid:31) y˙ = x The point (0, 0) is a critical point for each of these systems.
The hypotheses of Theorem 3.3 are satisfied in each case, and in each case the corresponding linear system to be investigated is (cid:31) (cid:31) x˙ = −y (41) (cid:31) y˙ = x The characteristic equation of the system (39) is λ2 + 1 = 0 with the pure imaginary roots ±i.
Thus the critical point (0, 0) of the linear system (39) is a center.
How- ever, Theorem 3.3 does not give us definite information, concerning the nature of this point for either of the nonlinear systems (37) and (38).
Conclusion (vi) of theorem 3.3 tells you that in each case (0, 0) is either a center or a spiral point; but this is all that this theorem tells us concerning the two systems under consideration.
4 Conclusion In this unit, you studied nonlinear systems.
In which you learnt how to determine the critical points of a system of differential equations and discuss the nature and stability of a critical point especially (0,0) You also learnt how to linearize a non linear system.
5 Summary Having gone through this unit, you are now able; 145  4 Conclusion (i) define phase plane, paths and critical points.
(ii) describe types of critical points (iii) define and describe stability of a critical point.
(iv) determine the critical points of linear system.
(v) describe the nature of the critical point (0, 0) (vi) describe the stability of the critical point (0, 0) (vii) linearize a nonlinear differential equation and describe the nature and stability of the critical point (0, 0) 6 Tutor Marked Assignments(TMAs) Exercise 6.1 Determine the nature of the critical point (0, 0) of each of the linear autonomous systems in the following Also determine whether or not the critical point is stable.
(cid:31) (cid:31) x˙ = x + 3y 1.
(cid:31) y˙ = 3x + y (cid:31) (cid:31) x˙ = 3x + 4y 2.
(cid:31) y˙ = 3x + 2y (cid:31) (cid:31) x˙ = 2x −4y 3.
(cid:31) y˙ = 2x − 2y (cid:31) (cid:31) x˙ = x −y 4.
(cid:31) y˙ = x + 5y Determine the type and stability of the critical point (0, 0) of each of the nonlinear autonomous systems (cid:31) (cid:31) x˙ = x + x2 −3xy 5.
(cid:31) y˙ = −2x + y + 3y2 (cid:31) (cid:31) x˙ = x + y −x2y 6.
(cid:31) y˙ = 3x − y + 2xy3 (cid:31) (cid:31) x˙ = (y + 1)2 −cos x 7.
(cid:31) y˙ = sin(x + y) 146  6 Tutor Marked Assignments(TMAs) 8.
Consider the autonomous system (cid:31) (cid:31) x˙ = ye x (cid:31) y˙ = ex − 1 (a) What type of critical point is (0, 0)?
(b) Obtain the differential equation of the paths and find its general solution.
147  UNIT 8: THEOREMS AND SOLUTIONS OF LYAPUNOV EQUATION Contents 1 Introduction 148 2 Objectives 148 3 Stability 149 3.1 Stability in the sense of Lyapunov 149 3.2 Quasilinear System 154 3.3 Lyapunov Second Method 155 4 Conclusion 159 5 Summary 160 6 Tutor Marked Assignments (TMAs) 160 1 Introduction In this unit, you shall be introduced to stability theory.
This will aid you to determine the stability of a system of ordinary differential equation.
2 Objectives At the end of this section, you should be able to (i) say whether a system of an ODE is stable or not.
(ii) determine whether a critical point is stable or not.
(iii) use Lyapunov’s theory to determine the stability of a critical point.
148  3 Stability 3 Stability The term stability is an expression that almost tells its own story.
Suppose a device of some sort operates under general conditions, and these conditions are slightly changed or modified.
The question now is, “Does this change or modification have little or considerable effect on the device?
In your thought, if the first instance is stable, then the second is unstable.
How does this apply to physical systems in particular?
The system will depend upon certain number of physical parameters x , x , ..., x which define position and also velocity.
These will 1 2 n be represented in some space Rn by a vector point x.
The state of the system at time t will be x = x(t).
As will be produce a trajectory g, in Rn space.
The question again is, how do trajectories g which start near g behave with respect to g?
Do they as time goes on remain near g which is stability or do they shift away from g which is instability.
Suppose at time t, the state of a physical system is described by x = x (t) i = 1, 2, ..., n i i and suppose the conditions of motion of the system require variable to satisfy x˙ = x (x , x , x , ..., x ) (1) i i 1 2 3 n Suppose x = η (t) is some particular state of the system i.e., x = η (t) is a solution of (1).
i i i i To study the properties of solutions of (1) in the neighbourhood of η (t), you make i yi = xi ­ ηi where y = 0 or x = η is the unperturbed motion or trajectory and x (t) describes another i i i i solution or state of the system.
The new variable y (t), now satisfies an equation of the form i dyi = y (y , y , ..., y , t) (2) dt i 1 2 n where yi(y1, y2, ..., yn, t) = xi(y1 + η1, ..., yn ­ ηn, t) ­ xi(η1, η2, ..., ηn, t).
(3) Here the curve {ηi(t)} is denoted by y = 0 i is called the null-solution (or trivial solution) as can be seen from (2) and (3).
Thus the stability of the solution ηi(t) of (1) is reduced to that of the trivial solution of yi ≡ 0 of (2).
Given that equation x˙ = f (t, x), df (t, 0) = 0 (4) in which f : I × D → Rn is assumed continuous and satisfy conditions for uniqueness and continuous dependence of solutions on initial data.
Then the following definitions hold.
3.1 Stability in the sense of Lyapunov Definition 3.1 The trivial solution x(t) = 0 of (4) is said to be stable (in the sense of Lyapunov) if E > 0 is given and t ∈ I , there exists, for any y(t) a solution of (4), a positive number 149  3.1 Stability in the sense of Lyapunov δ = δ(t0, E) such that y(t0) < δ implies that y(t) < E or y(t0) ­ x(t0) < δ implies that y(t) ­ x(t) < E for t > t0.
If δ can be chosen independent of t , then the x(t) is said to be uniformly stable.
0 Definition 3.2 The solution x(t) is said to be assymptotically stable if it is stable and for any given δ > 0 and a solution y(t) of (4), lim x(t) ­ y(t) = 0 for x(t0) ­ y(t0) < δ t→∞ Note that the definition of stability given are local in nature in the sence that you are con- cerned with solutions where the initial values are sufficiently close.
Example 3.1 Show that the differential equation x¨ + x = 0 is stable in the sense of Lyapunov but not assymptotically stable.
Solution.
The scalar equation x¨ + x = 0 is equivalent to the system (cid:31) (cid:31) x˙ = y 0 1 or x = (cid:31) (cid:31) y˙ = ­x ­1 0 with solution as x = A cos t + B sin t and y = ­A sin t + B cos t (cid:31) (cid:31) (cid:31) (cid:31) x x 1 Define the a norm on X = (cid:31) (cid:31) ≡ (cid:31) (cid:31) by y x 2 X = |x1| + |x2| X (0) = |A| + |B| X (t) = |A cos t + B sin t| + | ­ A sin t + B cos t| ≤ 2(|A| + |B|) < E Choose δ = E .
2 Then from the definition, the trivial solutions (cid:31) (cid:31) (cid:31) (cid:31) x 0 (cid:31) (cid:31) = (cid:31) (cid:31) y 0 is stable in the sense of Lyapunov.
However, the trivial solution is NOT assymptotically stable, why?
150  3.1 Stability in the sense of Lyapunov Example 3.2 Show that the differential equation x¨ + 3x˙ + 2x = 0 is both stable and assymptotically stable in the sense of Lyapunov.
Solution.
The scalar equation x¨ + 3x˙ + 2x = 0 is equivalent to the system (cid:31) (cid:31) (cid:31) (cid:31) x˙ 1 = x2 0 1 x1 or X = (cid:31) (cid:31) X with X = (cid:31) (cid:31) x˙ 2 = ­3x2 ­ ­2 ­ x2 2x1 3 The auxiliary equation is λ2 + 3λ + 2 = 0 i.e., λ1 = ­1, and λ2 = ­2 The general solution is given by X = c1e−t + c2e−2t and X˙ = ­c1e−t ­ 2c2e−2t X (0) = |x(0)| + |x˙ (0)| ≤ 2c1 + 3c2 X (t) ≤ 2|c1|e−t + 3|c2|e−2t ≤ (2|c1| + 3|c2|)e−t E Since e−t ≤ 1.
Choose δ = and conclude that the trivial solution is stable.
2|c1| + 3|c2| lim X (t) ≤ lim {2|c1| + 3|c2|}e−t → 0 as t → 0 t→∞ t→∞ Therefore, lim X (t) = 0.
Thus, the trivial solution of the system t→∞ (cid:31) (cid:31) 0 1 X˙ = (cid:31) (cid:31) X ­2 ­3 is assymptotically stable in the sense of Lyapunov.
Example 3.3 Consider the homogeneous system x˙ = Ax where A is a constant n × n matrix all of whose eigenvalues have negative real parts.
Then you 151  3.1 Stability in the sense of Lyapunov can conclude both stability and assymptotic stability.
152  3.1 Stability in the sense of Lyapunov Proof.
Suppose all the roots of a are distinct, recall that T y , i = 1, 2, ..., n are the n i linearly independent solution, where (cid:31) (cid:31) 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) .
(cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) yi = (cid:31)(cid:31) eλi t (cid:31)(cid:31) i = 1, 2, ..., n (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 0 (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) (cid:31)(cid:31) .
(cid:31)(cid:31) (cid:31) .
(cid:31) (cid:31) (cid:31) 0 (cid:31) (cid:31) eλ1 t (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) 0 (cid:31) T y1 = (cid:31)(cid:31) (cid:31)(cid:31) .
Any solution x(t) of the system is of the form (cid:31) (cid:31) (cid:31) (cid:31) (cid:31) .
(cid:31) 0 x(t) = (T y1, T y2, ..., T yn)xn x(t) ≤ Ae−µt x0 where µ is the smallest of αi < 0λi = αi + jβiα1 < α2 < · · · < αj < 0 you can conclude both stability and assymptotic stability.
Suppose the roots are not necessarily distinct.
Then the general solution is given by )k )mj x(t) = ti−1eλj tcij m1 + m2 + · · · + mk = n (5) j=1 i=1 Fix j = 1, Then the expression (5) becomes x(t) = c11eλ1 t + c21teλ1 t + c31t2eλ1 t + · · · + cm 1tm1 −1eλ1 t 1 e(αj +µ)t ti−1eλj tci,j ≤ mij |ti−1| eµt · eβ j t αj + µ < 0, µ > 0 ≤ mij |ti− 1|e−(αeµj +t µ)t ≤ M mij e−µt → 0 as t → ∞ 153  3.1 Stability in the sense of Lyapunov Therefore assymptotically stable.
Note that given the system x˙ = Ax A is a constant n × n matrix all of whose eigenvalues have negative real parts then there exists α > 0, β > 0 such that eAt ≤ βe−αt, t > 0 (6) (i) If all the roots of A are distinct then each column of the fundamental matrix solution of Φ is of the form eλk tP k k = 1, 2, ..., n where the P k ’s are some constants n­vectors, Clearly, you can write λ = µ + α , u < 0 k k k k Assume that uk < ­α for all k. Then Φ(t) ≤ n max |P k |e−αt, t > 0, k, j = 1, 2, ..., n j If λ is a repeated root of A, then the corresponding column of Φ involve terms of the i form Φr (t) = etλi )n ti−1 P i (7) (i ­ 1)!
i=1 where Pi’s are constant n­vectors.
Since et−r eαtλts = t r e (µs +αi )t µs < ­αs < 0 and µ + α < 0, it follows that s s tr e(µs +α)t → 0 as t → ∞ Thus tr e(µs +α)t ≤ Ms, Ms > 0 is a constant.
Combining with (7) it follows readily that there exist constants M > 0 and α > 0 such that Φ(t) ≤ M e−αt Remark 3.1 x˙ = A(t)x with A(t + ω) = A(t), the solution Φ(t) = P (t)etR If all the roots of R have negative real parts then Φ(t) ≤ M e−αt t ≥ 0, α > 0, M > 0 154  3.2 Quasilinear System 3.2 Quasilinear System Theorem 3.1 Given the differential equation x˙ = Ax + f (t, x) x(0) = x (8) 0 where A is a constant n × n matrix all whose eigenvalues have negative real parts, f is a continuous function of x and t. Suppose that f (t, x) ≤ K x (9) for t and x.
Then the solution of the system (8) are assymptotically stable provided K is small enough Proof.
Any solution of (8) can be written in the form t x(t) = eAtx + eA(t−τ )f (τ, x(τ ))dτ 0 0 t x(t) ≤ eAt x0 + eA(t−τ ) f (τ, x(τ )) dτ 0 Clearly there exists α > 0, β > 0 such that eAt ≤ βe−αt, t ≥ 0 and so t x(t) < β x0 e−αt + βK eατ x(τ ) dτ 0 Thus x(t)eαt/1 ≤ 1 (10) β x + tβkeατ x(t) dτ 0 0 Multiplying bothsides by βk βk x(t)eαt ≤ βk β x + t βkeατ x(τ ) dτ 0 0 Integrating between 0 and t you obtain t t log β x0 + βkeατ x(τ ) dτ ≤ βkt 0 0 β x 0 + 0t βkeατ x(τ ) dτ ≤ eβkt β x0 Thus t x(t) eαt ≤ β x0 + βkeατ x(τ ) dτ ≤ β x0 eβkt 0 and so x(t) ≤ β x0 e−(α−βk)t Fix k > 0 such that α ­ kβ > 0, then 155  3.3 Lyapunov Second Method e−(α−kβ)t ≤ 1 for all t Therefore x(t) ≤ β x0 < E provided x0 < δ = E β The solutions x(t) ≤ β x0 e−(α−βk)t are assymptotically stable since lim x(t) ≤ lim β x0 e−(α−β)t = 0 t→∞ t→∞ 3.3 Lyapunov Second Method The examples you have considered so far pressume a knowledge of solutios before you can conclude stability.
There are only very few equations whose solutions can be determined in closed form (i.e., in terms of elementary functions).
An alternative method initiated by a Russian Mathematician A.M. Lyapunov is a generaliza- tion based on the well known observatioin that near the equilibrium point of a physical system, the total energy of a given system is either constant or decreasing.
Therefore idea here is intro- duction of some functions now known as Lyapunov functions, which generalize the total energy in a system.
Consider the differential equation x˙ = f (x, t), f (0) = 0 (11) where f : Rn → Rn is continuous and the solutions are unique and very continuously with the initial data.
Let V : Rn → R be defined and continuous together with the first partial derivatives ∂V ∂xi (i = 1, 2, ..., n) on some open let Ω ⊂ Rn Ω = {x : x ∈ Rn, x < h} The following are some definitions that would be of help you as you proceed in the understand- ing of this topic.
Definitions 1.
A function V : Ω → R is said to be positive definite (negative definite) if V (0) = 0 and V assume positive (negative) values on Ω.
2.
A function V : Ω → RΩ ⊂ R is said to be positive(negative) semi-definite if V (0) = 0 and V (x) ≥ 0 (V (x) ≤ 0) on Ω.
If the functions assume arbitrary values then it is said to be indefinite.
156  3.3 Lyapunov Second Method Example 3.4 (a) V = x2 + y2 is positive definite.
(b) (x + y)2 + z2 is positive semi-definite.
(c) V = x2 + y2 ­ z2 is indefinite.
3.
The derivatives (Euler’s) of V along solution paths of (11) is given by d ∂V ∂V V˙ = V (x(t)) = x˙ = f (x ) dt ∂x i ∂x i i 1 Note: On investigation of stability or instability Lyapunov pioneered the work which appeared in France 1907.
The definitions (1), (2) and (3) are very essential in this study.
These will be tied up ultimately in the context of systems.
Stability or Instability can be assumed directly using the following theorems accondingly.
Theorem 3.2 Given the differential equation (4) that is x˙ = f (t, x), f (t, 0) = 0 Suppose there exists a C 1 function V : Rn → R which is positive definite and is such that the time derivative of V along the solution paths of (4), that is, F · gradV is negative semi-definite.
Then the trivial solution x ≡ 0 is stablen in the sense of Lyapunov.
Theorem 3.3 Lyapunov Given the system (4).
Suppose that there exists a C 1 function V : R2 → R, with the following properties; (i) V is positive definite.
(ii) The time derivative U (x , x ) of V (x , x ) along the solution paths of (4) is negative 1 2 1 2 definite.
(iii) Then the trivial solution x = 0 of (4) is assymptotically stable.
Theorem 3.4 Given the sytem (4).
Suppose that there exists a C 1 function V : R2 → R, with the following properties (i) V is positive definite.
(ii) The time derivatives U (x , x ) of V (x , x ) along the solution paths of (4) is positive 1 2 1 2 definite.
Then the trivial solution of (4) is unstable in the sense of Lyapunov.
Theorem 3.5 (Cêtaev) On Instability Consider the system (11) i.e., x˙ = f (x); f (0) = 0 which f is sufficiently smooth in the domain G (in Rn) containing the origin.
Let D ⊂ G be a domain in Rn with the boundary of D which lies inside G passing through the origin.
Suppose there exists a C 1 function V : Rn → R such that 157  3.3 Lyapunov Second Method (i) V (x) = 0 on that part of the boundary D lying inside G and V (x) > 0 elsewhere.
(ii) The time derivative elsewhere of V along the solution paths of (11) that is f · gradV > 0 in D. Then the trivial solution x ≡ 0 of (11) is unstable The following are some applications of these theorems to some specific cases.
Example 3.5 Consider the section equation x¨ + x = 0 or rather the equivalent 2-system x˙ 1 = x2, x˙ 2 = ­x1 (12) with the function V defined by 1 V (x , x ) = (x2 + x2) 1 2 2 1 2 Show that the system (12) is stable in the sense of Lyapunov Solution.
Clearly V given by 1 V (x , x ) = (x2 + x2) 1 2 2 1 2 is positive definite.
Along the solution paths of (12) V˙ (x1, x2) = x1x˙ 1 + x2x˙ 2 = x1x2 ­ x1x2 = 0 Thus V˙ (x , x ) is negative semi-definite.
Hence V is a suitable function to which theorem 1 2 1.2 can be applied to give that the trivial solution x ≡ 0 is stable in the sense of Lyapunov.
Example 3.6 Consider the system (cid:31) x˙ 1 = ­x31 ­ 2x1x22 (cid:31) (13) (cid:31) x˙ 2 = x12 x2 ­ x23 with the function V (x , x ) defined by 1 2 V (x , x ) = x2 + x2x2 + x4 1 2 1 1 2 2 prove that the system (13) is assymptotically stable Solution.
158  3.3 Lyapunov Second Method Note that V (x , x ) is positive definite since 1 2 V (x1, x2) = x21 + x21 x 22 + x42 = x21( 1 + x22) + x42 ≥ 0 Along the solution paths of (13) V (x , x ) = 2x x˙ + 2x x2x˙ 2x x2x˙ + 4x3x˙ 1 2 1 1 1 2 1 2 1 2 2 2 = ­2x1(x13 + 2x1x22 ) ­ 2x1x22 (x13 + 2x1x22 ) +2x21x 2(x21x 2 ­ x22 ) + 4x23 (x12 x2 ­ x23 ) = ­2x4 ­ 4x2x2 ­ 2x2x4 ­ 4x6 1 1 2 1 2 2 V˙ (x1, x2) = ­2x12 (x12 + 2x22 + x24 ) ­ 4x26 This is negative definite.
Thus by theorem 1.3, the system (13) is assymptotically stable in the sense of Lyapunov.
Example 3.7 Consider the 2-system x˙ 1 = x2, x˙ 2 = ­ax2 ­ bx1 (14) a, b are constants, with the function V (x , x ) defined by V (x , x ) = ax2 + bx2.
Discuss the 1 2 1 2 2 1 conditions for (i) assymptotic stability (ii) instability on the system (14) Solution.
Our V (x , x ) defined by 1 2 V (x , x ) = ax2 + bx2 1 2 2 1 is positive semidefinite if a ≥ 0, b ≥ 0.
Along the solution paths of (14) V˙ (x , x ) = x˙ ∂V + x˙ ∂V 1 2 1∂x1 2 ∂x2 = x˙ 2(2bx1) + (­ax2 ­ bx1)2x2 + 2bx1x2 ­ 2a2x2 ­ 2bx1x2 = ­2ax22 Note: Our V is positive definite if a > 0, b > 0, also that V˙ , considered as a function x1 and x satisfies the following 2 (i) V˙ is negative definite if a > 0 (ii) V˙ is positive definite if a < 0 and conclusions follows accordingly That is 159  4 Conclusion (i) Assymptotically stable if V˙ is negative definite.
(ii) Instability if V˙ is positive definite Example 3.8 Given the scalar equation x¨ + ax˙ + h(x) = 0 (15) where a > 0 is a constant and the function h : R2 → R is such that solutions exist and are unique and very continuously with initial data.
By considering with initial data.
By considering an appropriate equivalent system and considering the function 2V (x, y) = (y + ax)2 + y2 + 4H (x) x where H (x) = h(s)ds.
Determine the conditions on h which ensure (i) stability (ii) as- 0 symptotic stability of the trivial solution of scalar equation (15) Solution.
1.
The scalar equation (15) is equivalent to the system (cid:31) x˙ = y (cid:31) (16) (cid:31) y˙ = ­ay ­ h(x) Along the solution paths of (16) V˙ = (y + ax)y˙ + a(y + ax)x˙ + yy˙ + 2h(x)x˙ ­(y + ax)(ay + h(x)) + ay2 + a2xy ­ ay2 ­ yh(x) + 2h(x)y = ­ay2 ­ yh(x) ­ a2xy ­ ah(x)x + ay2 + ax2y ­ ay2 ­ yh(x) + 2h(x)y = ­(ay2 + ah(x)x) = ­a(y2 + h(x)x) If xh(x) < 0 for all x I= 0 when you conclude stability b if xh(x) > 0 for all x I= 0 then you conclude assymptotic stability.
4 Conclusion Lyapunov and other theroems listed earlier depend heavily on the construction of suitable Lya- punov functions.
There is no fixed standard technique for constructing such Lyapunov functions for a given ordinary differentiatial equation.
This remains the main problems in the application of the theorems.
If a suitable function V can be found then stability or instability follows and if not, you cannot proceed.
160  5 Summary 5 Summary Having gone through this unit, you are now able to; (i) determine the stability of the trivial solution and a critical point of a system of ODE.
(ii) use the Lyapunov’s theorem to determine the stability of a solution of a linear system.
6 Tutor Marked Assignments(TMAs) Exercise 6.1 1.
Given the function V defined by 1 V (x, y) = y2 + G(x) 2 x where G(x) = g(s)ds Determine the conditions on g which ensure stability of the 0 trivial solution of x¨ + g(x) = 0, g(0) = 0 Note: Any relevant theorems used must be stated.
2.
By considering the function 1 V = (x2 + y2) 2 Prove that the trivial solution of the system x˙ = ­x ­ x3 ­ x sin y y˙ = ­y ­ y3 3 is assymptotically stable in the sense of Lyapunov.
3.
The scalar equation ... x + f (x˙ )x¨ax˙ + bx = 0 a > 0, b > 0 are constants, f is a continuous function such that solutions exist and are uniquely determined by the initial conditions.
Furthermore the function b f (y) ≥ C ≥ a where C is a constant by considering the function V defined by 1 1 y V = (az2) + (b2x2 + a2y2) + byz + abxy + b uf (u)du 2 2 0 Prove that the scalar equation ... x + f (x˙ )x¨ + ax˙ + bx = 0 is stable and assymptotically stable in the sense of Lyapunov.
160  6 Tutor Marked Assignments (TMAs) 4.
Consider the scalar equation x¨ ­ x3 = 0 and V (x1, x2) defined by V (x1, x2) = x1x2 Show that the scalar equation is unstable in the sense of Lyapunov.
Any relevant theorem used must be clearly stated 5.
Consider the 2-system x˙ 1 = x2 + x21x2, x˙ 2 = x1 + 10x24 and by using V (x , x ) defined by 1 2 V (x1, x2) = x1x2 Show that the trivial solution x = 0 is unstable.
6.
(a) State and prove a theorem due Lyapunov used in establishing stability of a trivial solution x = 0 of the scalar equation x˙ = f (x), f (0) = 0 (b) Hence or otherwise show that the system x˙ 1 = x2, x˙ 2 = ­x2 ­ x1 ­ 21x3 and the function V (x , x ) is positive definite.
3 1 2 (c) Show that the zero solution x = 0 is assymptotically stable in the sense of Lyapunov.
7.
By considering the system x˙ 1 = x2 + 2x2, x˙ 2 = 3x1 + x2 and the function V4(x1, x2) = x1x2 (a) Show that the zero solution x ≡ 0 is unstable in the sense of Lyapunov (b) Any theorem used in the above must be stated (No Proof).
8.
By considering the function V : R2 → R defined by V (x , x ) = x2 + 9x2 1 2 2 1 Show that the zero solution x ≡ 0 of the trivial solution of the system x˙ 1 = x2, x˙ 2 = ­9x1 is stable in the sense of Lyapunov 9.
Given that the function V : R2 → R defined by V (x1, x2) = x1x2.
Prove that the trivial solution, x = 0 of the system x˙ 1 = x2, x˙ 2 = x31 is unstable 161
