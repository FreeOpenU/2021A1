CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY NATIONAL OPEN UNIVERSITY OF NIGERIA SCHOOL OF SCIENCE AND TECHNOLOGY COURSE CODE: CIT 463 COURSE TITLE: INTODUCTION TO MULTIMEDIA TECHNOLOGY 1 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY CIT 463 COURSE GUIDE INTODUCTION TO MULTIMEDIA TECHNOLOGY Course Writer: Edeama O. Onwuchekwa National Open University of Nigeria Lagos Programme Leader Prof. Kehinde Obidairo National Open University of Nigeria Lagos Course Coordinator Vivian Nwaocha National Open University of Nigeria Lagos Content Editor Dr. Francis Bakpo University of Nigeria, Nsukka NATIONAL OPEN UNIVERSITY OF NIGERIA 2 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY National Open University of Nigeria Headquarters 14/16 Ahmadu Bello Way Victoria Island Lagos Abuja Office No.
5 Dar es Salaam Street Off Aminu Kano Crescent Wuse II, Abuja Nigeria E-mail: centralinfo@nou.edu.ng URL: www.nou.edu.ng Published by National Open University of Nigeria Printed ISBN All Rights Reserved CONTENTS PAGE Introduction……………………………………………….….. … What you will Learn in this Course……………….……… 3 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Course Aims…………………………………………………….
Course Objectives……………………………………………..
Working through this Course…………………………….…… Course Materials……………………………………….……... Study Units …………………………………………………....
Assignment File………………………………………………… Presentation Schedules………………………………………… Assessment…………………………………………………….
Tutor Marked Assignment…………………………………….
Final Examination and Grading………………………………..
Course Marking Scheme……………………………………….
Course Overview…………………………………………….... How to Get the Most from this Course……………………… Facilitators/Tutors and Tutorials……………………….…….
Summary…………………………………………………… ….
Introduction The course guide provides you with the various topics on the introductory course in Multimedia Technology.
In this course, we will study the basics of the multimedia system and of the different elements of the multimedia system.
The theories of Authoring systems, its tools and development areas have also been discussed in this course.
This course also considers the concept of Video 4 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Conferencing and the protocols in Multimedia such as the real time transfer protocol, session control protocol etc.
It goes beyond the traditional access network processes to discuss technological developments such as Cable Television, Digital Subscriber lines, digital television etc.
The overall aims of this course are to introduce you to the history and components of the Multimedia Technology.
The fundamentals of Digital audio, video, images and colours are equally discussed.
There are five modules in this course; each module consists of at least 4 units of topics that you are expected to complete in 2 hours.
The five modules and their units are listed below.
What You will Learn in this Course The overall aims and objectives of this course are to provide guidance on what you should be achieving in the course of your studies.
Each unit also has its own unit objectives which state specifically what you should achieve in the corresponding unit.
To evaluate your progress continuously, you are expected to refer to the overall course aims and objectives as well as the corresponding unit objectives upon the completion of each.
Course Aims The overall aims and objectives of this course will help you to: 1.
Develop your knowledge and understanding of the underlying concepts and theories of the Multimedia System.
2.
To outline and critically analyze the different elements of the Multimedia System.
3.
Develop your competence in understanding the concept and developing applications of Multimedia Technology.
4.
Provide the necessary details on how multimedia data are represented, stored, compressed and used; Course Objectives It is pertinent to note that each unit has precise objectives.
Students should learn them carefully before proceeding to subsequent units.
Therefore, it may be useful to refer to these objectives in the course of your study of the unit to assess your progress.
You should always look at the unit objectives after completing a unit.
In this way, you can be sure that you have done what is 5 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY required of you by the end of the unit.
However, below are overall objectives of this course.
On successful completion of this course, you should be able to: • Discuss the history of Multimedia • Give a concise definition of Multimedia • Identify the desired features of the Multimedia System • Explain the term “Multimedia Hardware ” • Outline the types of Multimedia Hardware.
• Explain what the Software is • State the significance of a software in Multimedia System • Explain the concept of Digital Audio • Identify the difference between a digital and analogue audio system • Explain the principles of Video compression • Identify ways to create digital images • Explain the Basics of Color • Discover the benefits and challenges of using Colors • Define the term Authoring System • Outline and state the features of an Asynchronous Transfer Mode(ATM) • Describe the Routing process • Explain the concept of Video Conferencing • Describe the Internet Telephony Service and the Computer Telephony Integration • Discuss the concept and features of a Digital Subscriber Lines Working through this Course We designed this course in a systematic way, so you need to work through it from Module one, Unit 1 through to Module five, Unit four.
This will enable you appreciate the course better.
Course Materials For this course, you will require the following materials: 1) The course guide : 2) Study units which are twenty-one (21) in number 3) Textbooks recommended at the end of the units and 4) The presentation schedule 6 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Study Unit There are twenty-one study units in this course broken into five modules.
They are as follows: MODULE 1 INTRODUCTION TO MULTIMEDIA Unit 1 Overview of Multimedia Unit 2 Multimedia Hardware Unit 3 Multimedia Software Unit 4 Server Unit 5 Networks MODULE 2 ELEMENTS OF MULTIMEDIA SYSTEM Unit 1 Digital Audio Unit 2 Digital Images Unit 3 Video Unit 4 Color MODULE 3 MULTIMEDIA SYSTEMS TECHNOLOGY Unit 1 Multimedia Compression Unit 2 Authoring System Unit 3 Communication Networks Unit 4 ATM MODULE 4 MULTIMEDIA APPLICATION DEVELOPMENT Unit 1Multicast Unit 2 Routing Unit 3 Protocols Unit 4 Video Conference MODULE 5 ACCESS NETWORKS Unit 1Internet Telephony Unit 2 Computer Telephony Integration Unit 3 Digital Subscriber Line Unit 4 Digital Television and Cable Television Each unit contains some exercises on the topics covered and you will be required to attempt the exercises.
These will enable you evaluate your progress as well as reinforce what you have learnt so far.
The exercises, together with the tutor-marked assignments will help you in achieving the stated learning objectives of the individual units and the course.
Assignment File 7 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY The assignment file will be given to you in due course.
In this file, you will find all the details of the work you must submit to your tutor for marking.
The marks you obtain for these assignments will count towards the final mark for the course.
Altogether, there are 21 tutor marked assignments for this course.
Presentation Schedule The presentation schedule included in this course guide provides you with important dates for completion of each tutor marked assignment.
You should therefore endeavor to meet the deadlines.
Assessment The course, Introduction to Multimedia Technology entails attending a two- hour final examination which contributes 50% to your final grading.
The final examination covers materials from all parts of the course with a style similar to the Tutor-marked assignments.
The examination is aimed at testing your ability to apply the knowledge you have learned throughout the course, rather than your ability to memorize the materials.
In preparing for the examination, it is essential that you receive the activities and Tutor-marked assignments you have completed in each unit.
The other 50% will account for all the TMAs at the end of each unit.
Tutor-Marked Assignment In this course, you will be required to study twenty-one (21) units, and complete Tutor-marked Assignments, provided at the end of each unit.
The assignments carry 10% marks each, the best four of your assignments will constitute 40% of your final mark.
At the end of the course, you will be required to write a final examination, which counts for 60% of your final mark.
You may wish to consult other related materials apart from your course material to complete your Tutor-marked Assignments.
Ensure that your assignments reaches your tutor on or before the stipulated deadline .If for any reason you are unable to complete your assignment in time, contact your tutor before the date due to discuss the possibility of an extension.
Note that extensions will not be 8 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY granted after the due date for submission unless under exceptional circumstances.
Final Examination and Grading The final examination for CIT 463 will last for a period of 4 hours and have a value 60% of the total course grade.
The examination will consist of questions which reflect the self assessment exercise and tutor marked assignments that you have previously encountered.
Furthermore, all areas of the course will be examined.
It would be better to use the time between finishing the last unit and sitting for the examination, to revise the entire course.
You might find it useful to review your TMAs and comment on them before the examination.
The final examination covers information from all parts of the course.
Course marking Scheme The following table includes the course marking scheme Table 1 Course Marking Scheme ASSESSMENT MARKS Assignments 1-21 21Assignments: 40% of the best 4 Total=10%X 4 = 40 Final Examination 60% of the overall course marks Total 100% of Course Marks Course Overview This table presents the units, the number of weeks required to complete each unit as well as the necessary assignments.
Table 2: Course Organizer 9 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Unit Title of Work Weeks Assessment (End of Activit Unit) y Course Guide Week 1 Module 1 INTRODUCTION TO MULTIMEDIA Unit 1 Overview of Week 1 Assignment 1 Multimedia Unit 2 Multimedia Week 2 Assignment 2 Hardware Unit 3 Multimedia Software Week 2 Assignment 2 Unit 4 Server Week 3 Assignment 3 Unit 5 Network Week 4 Assignment 4 ELEMENTS OF MULTIMEDIA SYSTEM Module 2 Unit 1 Digital Audio Week 4 Assignment 4 Unit 2 Digital Images Week 4 Assignment 5 Unit 3 Video Week 5 Assignment 6 Unit 4 Color Week 5 Assignment 7 Module 3 MULTIMEDIA SYSTEMS TECHNOLOGY Unit 1 Multimedia Week 6 Assignment 8 Compression Unit 2 Authoring System Week 6 Assignment 9 Unit 3 Communication Week 7 Assignment 10 Network Unit 4 ATM Week 7 Assignment 10 MULTIMEDIA APPLICATION Module 4 DEVELOPMENT Unit 1 Multicast Week 8 Assignment 11 Unit 2 Routers Week 9 Assignment 12 Unit 3 Protocols Week Assignment 13 10 Unit 4 Video Conference Module 5 MULTIMEDIA ACCESS SYSTEMS Unit 1 Internet Telephony Week Assignment 14 11 Unit 2 Computer Week Assignment 15 Telephony 12 10 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Integration Unit 3 Digital Subscriber Week Assignment16 Line 13 Unit 4 Digital Television/ Week Assignment 17 Cable Television 14 How to Get the Most from this Course In order for you to learn various concepts in this course, it is essential to practice.
Independent activities and case activities which are based on a particular scenario are presented in the units.
The activities include open questions to promote discussion on the relevant topics, questions with standard answers and program demonstrations on the concepts.
You may try to delve into each unit adopting the following steps: 1.
Read the study unit 2.
Read the textbook, printed or online references 3.
Perform the activities 4.
Participate in group discussions 5.
Complete the tutor-marked assignments 6.
Participate in online discussions There are also optional readings in the units.
You may wish to read these to extend your knowledge beyond the required materials.
They will not be assessed.
Facilitators/Tutors and Tutorials About 13 hours of tutorials will be provided in support of this course.
You will be notified of the dates, time and location for these tutorials, together with the name and phone number of your tutor as soon as you are allotted a tutorial group.
Your tutor will mark and comment on your assignments, keep a close watch on your progress and on any difficulties you might encounter and provide assistance to you during the course.
You must mail your TMAs to your tutor well before the due date (at least two working days are required).
They will be marked by your tutor and returned to you as soon as possible.
11 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Do not hesitate to contact your tutor by phone, or e-mail if you need help.
The following might be circumstances in which you would find help necessary.
You can also contact your tutor if: i.
You do not understand any part of the study units or the assigned readings ii.
You have difficulty with the TMAs iii.
You have a question or problem with your tutor’s comments on an assignment or with the grading of an assignment.
You should try your best to attend tutorials, since it is the only opportunity to have an interaction with your tutor and to ask questions which are answered instantly.
You can raise any problem encountered in the course of your study.
To gain maximum benefit from the course tutorials, you are advised to prepare a list of questions before attending the tutorial.
You will learn a lot from participating in discussions actively.
Summary The course, Introduction to Multimedia Technology is intended to develop your understanding of the basics of the Multimedia System, thus enabling you understand the Multimedia processes.
This course also provides you with an understanding of the developing applications of the Multimedia System.
We hope that you will find the course enlightening, interesting and useful.
In the longer term, we hope you will get acquainted with the National Open University of Nigeria and we wish you every success in your future.
12 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY CIT 463 INRODUCTION TO MUTIMEDIA TECHNOLOGY Course Writer: Edeama O. Onwuchekwa National Open University of Nigeria Lagos Programme Leader Prof. Kehinde Obidairo National Open University of Nigeria Lagos Course Coordinator Vivian Nwaocha National Open University of Nigeria Lagos Content Editor Dr. Francis Bakpo University of Nigeria, Nsukka 13 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY NATIONAL OPEN UNIVERSITY OF NIGERIA National Open University of Nigeria Headquarters 14/16 Ahmadu Bello Way Victoria Island Lagos Abuja Annex Abuja e-mail: centralinfo@nou.edu.ng URL: www.nou.edu.ng National Open University of Nigeria First Printed ISBN: All Rights Reserved Printed by …………….. For National Open University of Nigeria 14 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY TABLE OF CONTENTS MODULE 1 INTRODUCTION TO MULTIMEDIA Unit 1 Overview of Multimedia............................................................................. Unit 2 Multimedia Hardware................................................................................. Unit 3 Multimedia Software................................................................................. Unit 4 Server.............................................................................................................. Unit 5 Network........................................................................................................ MODULE 2 ELEMENTS OF MULTIMEDIA Unit 1 Digital Audio.............................................................................................. Unit 2 Digital Images............................................................................................ Unit 3 Video.......................................................................................................... Unit 4 Colour........................................................................................................ MODULE 3 MULTIMEDIA SYSTEM TECHNOLOGY Unit 1 Multimedia Compression................................................................................... Unit 2 Authoring System........................................................................................... Unit 3 Multimedia Communications.................................................................................... Unit 4 ATM.................................................................................................................... MODULE 4 MULTIMEDIA APPLICATION DEVELOPMENT Unit 1Multicast.................................................................................................... Unit 2 Routing...................................................................................................... Unit 3 Protocol.................................................................................................... Unit 4 Video Conference....................................................................................... MODULE 5 MULTIMEDIA ACCESS SYSTEMS Unit 1 Internet Telephony..................................................................................... Unit 2 Computer Telephony Integration............................................................... Unit 3 Digital Subscriber Line.................................................................................. Unit 4 Digital Television........................................................................................ 15 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY MODULE 1 INTRODUCTION TO MULTIMEDIA Unit 1 Overview of Multimedia Unit 2 Multimedia Hardware Unit 3 Multimedia Software Unit 4 Server Unit 5 Network UNIT 1 OVERVIEW OF MULTIMEDIA TECHNOLOGY CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 History of Multimedia 3.2 Definition of Multimedia 3.3 Desirable Features of a Multimedia System 3.4 Multimedia Applications 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION The term "multimedia" describes a new application-oriented technology that is based on the multisensory nature of humans and the evolving ability of computers to convey diverse types of information.
Fundamental to this technology is the ability to manipulate digital forms of audio and video information in the realm of the computer.
Multimedia requires integrating storage, communication and presentation mechanisms for diverse data types in a single technology.
This unit will introduce you to the multimedia basics.
It will also provide an overview of the essential aspects of multimedia.
Thus, it is recommended that you go through the entire module systematically to gain some insight of the course.
16 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 2.0 OBJECTIVES At the end of this unit, you should be able to: • Give a concise definition of multimedia • Discuss the history of multimedia technology • Identify the desired features of a multimedia System.
3.0 MAIN CONTENT 3.1 HISTORY OF MUTLMEDIA The term "multimedia" was first coined by Bob Goldstein to promote the July 1966 opening of his "LightWorks at L'Oursin" show at Southampton, Long Island.
In the late 1970s the term was used to describe presentations consisting of multi-projector slide shows timed to an audio track.
However, by the 1990s 'multimedia' took on its current meaning.
In the 1998 fourth edition of McGraw-Hill’s Multimedia: Making It Work, Tay Vaughan declared, “Multimedia is any combination of text, graphic art, sound, animation, and video that is delivered by computer or other electronic means.
When you allow the user – the viewer of the project – to control what and when these elements are delivered, it is interactive multimedia.
Some computers which were marketed in the 1990s were called "multimedia" computers because they incorporated a CD-ROM drive, which allowed for the delivery of several hundred megabytes of video, picture, and audio data.
3.2 DEFINTION OF MULTIMEDIA Several authors have defined multimedia in different ways.
Essentially, it can be described as the integration of sound, animation, and digitized video with more traditional types of data such as text.
It is also seen as an application-oriented technology that is used in a variety of ways, for example, to enhance presentations, and is based on the increasing capability of computers to store, transmit, and present many types of information.
A general definition is: Multimedia is the field concerned with the computer-controlled integration of text, graphics, drawings, still and moving images (Video), animation, audio, 17 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY and any other media where every type of information can be represented, stored, transmitted and processed digitally.
For the purpose of this course, we will consider some definition from the CEMCA & COL (2003) and some others.
According to Fenrich (1997) “Multimedia” is the existing combination of computer hardware and software that allows you to integrate video, animation, audio, graphics, and test resources to develop effective presentations on an affordable desktop computer” Phillips, (1997) also states that “Multimedia is characterized by the presence of text, pictures, sound, animation and video; some or all of which are organized into some coherent program” From all we have seen, Multimedia is an inter-disciplinary subject because it involves a variety of different theories and skills: these include computer technology, hardware and software; arts and design, literature, presentation skills; application domain knowledge.
It is a woven combination of text, graphic art, sound, animation, video and other kinds of elements.
3.3 DESIRABLE FEATURES FOR A MULTIMEDIA SYSTEM The word multimedia in a computer environment implies that many media are under computer control.
Thus a multimedia computer is a system capable of processing multimedia data and applications.
A multimedia computer should support more than one of the following media types: text, images, video, audio and animation.
However, that means that a computer which manipulates only text and images would qualify as a multimedia computer.
A Multimedia System is characterized by its capability to process, store, generate, manipulate and render multimedia information.
The following features are desirable for a multimedia System: Very High Processing Power: This is a requirement for dealing with large data processing and real time delivery of media.
- Multimedia Capable File System: This feature is essential for delivering real-time media - - e.g.
Video/Audio Streaming.
Special Hardware/Software needed e.g.
RAID technology.
- Data Representations/File formats that support multimedia: Data representations/file formats should be easy to handle yet allow for compression/decompression in real-time.
- Efficient and High I/O: 18 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Input and output to the file subsystem needs to be efficient and fast.
It is necessary to allow for real-time recording as well as playback of data.
e.g.
Direct to Disk recording systems.
- Special Operating System: A special operating system is required to provide access to file system and process data efficiently and quickly.
Consequently, the multimedia system needs to support direct transfers to disk, real-time scheduling, fast interrupt processing, I/O streaming etc.
- Storage and Memory: Large storage units (of the order of 50-100 Gb or more) and large memory (50 -100 Mb or more) are needed.
Large Caches are also required and frequently those of Level 2 and 3 hierarchy for efficient management.
- Network Support: Client-server systems commonly known as distributed systems.
- Software Tools: User friendly tools are needed to handle media, design and develop applications, deliver media.
3.4 MULTIMEDIA APPLICATIONS In recent times, multimedia applications use a collection of multiple media sources e.g.
text, graphics, images, sound/audio, animation and/or video.
Some examples of multimedia applications are: business presentations, online newspapers, distance education, and interactive gaming, advertisements, art, entertainment, engineering, medicine, mathematics, business, scientific research and spatial temporal applications.
Other examples of Multimedia Applications include: • World Wide Web (WWW) • Hypermedia courseware • Video-on-demand • Interactive TV • Computer Games • Virtual reality • Digital video editing and production systems • Multimedia Database systems • Video conferencing and Teleconferencing • Groupware • Home shopping 19 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY • Games · Virtual reality · Digital video editing and production systems · Multimedia Database systems SELF ASSESSMENT EXERCISE Mention the essential features for a Multimedia system __________________________________________________________ __________________________________________________________ __________________________________________________________ __________________________________________________________ 4.0 CONCLUSION In this unit, we highlighted the history of the Multimedia Technology.
We learnt that Multimedia is the field concerned with the computer-controlled integration of text, graphics, drawings, still and moving images (Video), animation, audio, and any other media where every type of information can be represented, stored, transmitted and processed digitally.
We equally considered the essential features of the multimedia and the different multimedia applications such as World Wide Web (WWW),Hypermedia courseware, Video-on-demand, Interactive TV, Computer Games, Virtual reality etc 5.0 SUMMARY This unit provided an overview of the history of multimedia, the definitions of multimedia, its features and applications.
Now, let us attempt the questions below.
6.0 TUTOR MARKED ASSIGNMENT 1) Give a concise definition of multimedia?
2) What is a multimedia application?
3) State at least 3 examples of a Multimedia Application?
7.0 REFERENCES/FURTHER READINGS Buford.J.F.K (1994).
Multimedia Systems, ACM Press, (ISBN 0-201-53258-1).
Chellis, James et.al (1997) MSCE: Networking Essentials Study Guide Sybex Network Press, San Francisco 20 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Usha V. R, Director (2003).
Commonwealth Educational Media Centre for Asia (CEMCA), New Delhi.
Fluckiger.
(1994).
Understanding Networked Multimedia, Prentice Hall.
Boyle.
(1998).Design for Multimedia Learning, Prentice Hall, (ISBN 0-13-242155-8) Agnew, P.W.
and Kellerman, A.S. (1996).
Distributed Multimedia: Technologies, Applications, and Opportunities in the Digital Information Industry (1st Edition) Addison Wesley.
Sloane, McGraw Hill.
(2002).
Multimedia Communication, (ISBN 0-077092228) Vaughan, Tay, 1998, Multimedia: Making It Work (first edition) Osborne/McGraw-Hill, Berkeley.
Shuman, J. G. (2002).
Multimedia Elements.
Multimedia in Action.
Vikas Publishing House Pvt Ltd. Maurer H, (1996).
Hyperwave: The Next Generation Web Solution, Addison Wesley, (ISBn 0-201-40346).
Watkinson, (2004).
The Art of Digital Audio, -Heinmann.
Synthesizer Basics, GPI Publications.
Murray James D. Van Ryper,W (1996).
Encyclopaedia of Graphics File Formats, Second Edition, O'Reilly & Associates.
21 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY UNIT 2 MULTIMEDIA HARDWARE CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Hardware 3.1.1 Compact Disc 3.1.2 DVD 3.1.3 USB 3.1.4 DirectX 3.1.5 Active Movie 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION A multimedia system is not different from any other type of computer system except for its ability to process multimedia data.
Thus, it should have features that can process audio, video, graphics and animation.
In this Unit and the following, we will be considering the components (Hardware and Software) required for a multimedia system 2.0 OBJECTIVES At the end of this unit, you should be able to: • Explain the term “Multimedia Hardware” • Outline the different types of Multimedia Hardware • Describe the difference between the types of multimedia systems 3.0 MAIN CONTENT 3.1 HARDWARE 22 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Hardware is a general term for the physical artefacts of a technology.
It may also mean the physical components or items of a computer system that you can see or touch.
The major forms of multimedia Hardware are discussed below: 3.1.1 CD STORAGE A compact disc, or CD, is a thin wafer of clear polycarbonate plastic and metal measuring 4.75 inches (120mm) in diameter, with a small hole, or hub, in its centre.
The metal layer is usually pure aluminium, sputtered onto the polycarbonate surface in a thickness measureable in molecules.
As the disc spins in the CD player, the metal reflects light from a tiny infrared laser into a light-sensitive receiver diode.
These reflections are transformed onto an electrical signal and then further converted to meaningful bits and bytes for use in digital equipment.
CDs (compact discs) are used to store data for use in a variety of devices, including computers and CD players.
The main or standard type of CD is called a CD-ROM; ROM means read-only memory.
It can be played back or read by just any CD player as well as most computers that have CD drives.
One is the CD-R, which is the typical choice for an individual who only wants to add data files or music to a CD once.
An individual uses a CD burner, which is a component of many modern computer systems, to record to these discs.
Some recordable CDs are classified as CD+R.
This type of disc allows consumers to record music or data to it, but provides nearly twice the amount of space that is available with a CD- R. A CD-RW also has a place among the recordable CDs.
This one is a bit different, because it allows consumers to erase it and record over it again.
Otherwise, it can be used in the same manner as CD-Rs and CD+Rs.
Diagram of different types of Compact Disc.
23 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 3.1.2 DVD DVD, which stands for Digital Video Disc, Digital Versatile Disc, is the next generation of optical disc storage technology.
This disc has become a major new medium for a whole host of multimedia system: It's essentially a bigger, faster CD that can hold video as well as audio and computer data.
DVD aims to encompass home entertainment, computers, and business information with a single digital format, eventually replacing audio CD, videotape, laserdisc, CD-ROM, and perhaps even video game cartridges.
DVD has widespread support from all major electronics companies and all major computer hardware companies.
It's important to understand the difference between DVD-Video and DVD-ROM.
DVD- Video (often simply called DVD) holds video programs and is played in a DVD player hooked up to a TV.
DVD/ROM holds computer data and is read by a DVD-ROM drive hooked up to a computer.
The difference is similar to that between Audio CD and CD-ROM.
DVD-ROM also includes future variations that are recordable one time (DVD-R) or many times (DVD-RAM).
Most new computers with DVD-ROM drives will also be able to play DVD-Videos.
3.1.3 UNIVERSAL SERIAL BUS (USB) USB has effectively replaced a variety of interfaces such as serial and parallel ports.
It can connect computer peripherals such as mice, keyboards, digital cameras, printers, personal media players, flash drives, Network Adapters, and external hard drives.
For many of those devices, USB has become the standard connection method.
USB was designed for personal computers, but it has become commonplace on other devices such as smart phones, PDAs and video game consoles, and as a power cord.
USB devices are linked in series through hubs.
There always exists one hub known as the root hub, which is built into the host controller.
So-called sharing hubs, which allow multiple computers to access the same peripheral device(s), also exist and work by switching access between PCs, either automatically or manually.
Sharing hubs are popular in small-office environments.
A physical USB device may consist of several logical sub-devices that are referred to as device functions.
A single device may provide several functions, for example, a webcam (video device function) with a built-in microphone (audio device function).
Such a device is called a compound device in which each logical device is assigned a distinctive address by 24 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY the host and all logical devices are connected to a built-in hub to which the physical USB wire is connected.
Diagram of Universal Serial Bus 3.1.4 MICROSOFT DIRECTX Microsoft DirectX is a collection of application programming interfaces (APIs) for handling tasks related to multimedia, especially game programming and video, on Microsoft platforms.
Originally, the names of these APIs all began with Direct, such as Direct3D, DirectDraw, DirectMusic, DirectPlay, DirectSound, and so forth.
The name DirectX was coined as shorthand term for all of these APIs (the X standing in for the particular API names) and soon became the name of the collection.
Direct3D (the 3D graphics API within DirectX) is widely used in the development of video games for Microsoft Windows, Microsoft Xbox, and Microsoft Xbox 360.
Direct3D is also used by other software applications for visualization and graphics tasks such as CAD/CAM engineering.
As Direct3D is the most widely publicized component of DirectX, it is common to see the names "DirectX" and "Direct3D" used interchangeably.
The components of DirectX are • DirectDraw: for drawing 2D Graphics (raster graphics).
• Direct3D (D3D): for drawing 3D graphics.
• DXGI: for enumerating adapters and monitors and managing swap chains for Direct3D 10 and up.
25 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY • Direct2D for 2D Graphics • Direct Write for Fonts • Direct Compute for GPU Computing • DirectInput: for interfacing with input devices including keyboards, mice, joysticks, or other game controllers.
• DirectPlay: for communication over a local-area or wide-area network.
• DirectSound: for the playback and recording of waveform sounds.
o DirectSound3D (DS3D): for the playback of 3D sounds.
• DirectMusic: for playback of soundtracks authored in DirectMusic Producer.
• DirectX Media: comprising DirectAnimation for 2D/3D web animation, DirectShow for multimedia playback and streaming media, DirectX Transform for web interactivity, and Direct3D Retained Mode for higher level 3D graphics.
DirectShow contains DirectX plugins for audio signal processing and DirectX Video Acceleration for accelerated video playback.
• DirectX Diagnostics (DxDiag): a tool for diagnosing and generating reports on components related to DirectX, such as audio, video, and input drivers.
• DirectX Media Objects: support for streaming objects such as encoders, decoders, and effects.
3.1.5 ACTIVE MOVIE Active Movie is a streaming media technology now known as DirectShow, developed by Microsoft to replace Video for Windows.
ActiveMovie allows users to view media streams, whether distributed via the Internet, an Intranet or CD-ROMs.
When ActiveMovie was installed, an option was added to the Start Menu to launch the ActiveMovie Control.
This allowed users to play multimedia files and thus was a rudimentary media player.
In March 1997, Microsoft announced that ActiveMovie was going to become part of the DirectX set of technologies, and by July it was being referred to as DirectShow.
SELF ASSESSMENT EXERCISE Identify four types of multimedia hardware systems __________________________________________________________ __________________________________________________________ 26 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY __________________________________________________________ __________________________________________________________ 4.0 CONCLUSION From our studies in this unit, we have seen that there are different types of multimedia hardware systems.
It is equally pertinent to note that the hardware system cannot function effectively without the software component of multimedia systems.
5.0 SUMMARY A multimedia system is not different from any other type of computer system except for its ability to process multimedia data.
Thus, it should have features that can process audio, video, graphics and animation.
In this unit, we looked at the fundamental types of multimedia hardware systems such as CDs, DVD, USBs, Microsoft DirectX and the Active Movie.
We hope you found the unit enlightening.
To assess your comprehension, attempt the questions below.
6.0 TUTOR MARKED ASSIGNMENT 1).
List the types of multimedia systems?
2).
Explain the difference between the types of multimedia hardware systems you have studied?
7.0 REFERENCES/FURTHER READINGS Buford.
J.F.K, (1994).
Multimedia Systems, ACM Press, 1994 (ISBN 0-201-53258-1).
Fluckiger.
(1994).
Understanding Networked Multimedia, Prentice Hall.
Boyle.
(1998).Design for Multimedia Learning, Prentice Hall, (ISBN 0-13-242155-8) Chellis, James et.al (1997) MSCE: Networking Essentials Study Guide Sybex Network Press, San Francisco Agnew P.W.
and Kellerman.
A.S. (1996).
Distributed Multimedia: Technologies, Applications, and Opportunities in theDigital Information Industry (1st Edition) Addison Wesley.
27 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Sloane,.
(2002).
Multimedia Communication, McGraw Hill (ISBN 0-077092228) Vaughan, Tay, 1998, Multimedia: Making It Work (first edition) Osborne/McGraw-Hill, Berkeley.
Shuman, J. G. (2002).
Multimedia Elements.
Multimedia in Action.
Vikas Publishing House Pvt Ltd. Murray J.D.
and Van Ryper, W (1996).
Encyclopaedia of Graphics File Formats, Second Edition, O'Reilly & Associates.
UNIT 3 MULTIMEDIA SOFTWARE CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 System Software.
3.2 Classes of Software 3.2.1 System Software 3.2.2 Programming Software 3.2.3 Application Software 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION Computer software, or just software, is a collection of computer programs and related data that provide the instructions telling a computer what to do and how to do it.
Software is, in a way invisible, and therefore not recognized as important in an electronic imaging system.
Software is just as important as hardware, however, because the hardware will not function 28 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY without it.
The "brains" of the system, software includes the instructions, procedures, and system supervisor in an electronic form.
2.0 OBJECTIVES By the end of this unit, you should be able to: • ·Explain what software is • State the significance of software in the multimedia system • List the functions of a Software 3.0 MAIN CONTENT 3.1 SOFTWARE Software refers to one or more computer programs and data held in the storage of the computer for some purposes.
In other words software is a set of programs, procedures, algorithms and its documentation.
Program software performs the function of the program it implements, either by directly providing instructions to the computer hardware or by serving as input to another piece of software.
The term was coined to contrast the old term hardware (meaning physical devices).
Software performs the following functions: • Interfaces between the operator, peripheral components, and the control computer's processor • Regulates the flow of information among the components and the central processing unit • Translates commands from the operator into specific hardware instructions • Allocates hardware resources for specific tasks • Indexes and cross-references • Produces workflow scripts for routing, document flow, and processing • Provides administration, statistics, and reports 3.2 CLASSES OF SOFTWARES Practical computer systems divide software systems into three major classes system software, programming software and application software, although the distinction is arbitrary, and often blurred.
3.2.1 SYSTEM SOFTWARE 29 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY System software provides the basic functions for computer usage and helps run the computer hardware and system.
It includes a combination of the following: • Device drivers • Operating systems • Servers • Utilities • Window systems System software is responsible for managing a variety of independent hardware components, so that they can work together harmoniously.
Its purpose is to unburden the application software programmer from the often complex details of the particular computer being used, including such accessories as communications devices, printers, device readers, displays and keyboards, and also to partition the computer's resources such as memory and processor time in a safe and stable manner.
3.2.2 PROGRAMMING SOFTWARE Programming software usually provides tools to assist a programmer in writing computer programs, and software using different programming languages in a more convenient way.
The tools include: • Compilers • Debuggers • Interpreters • Linkers • Text editors An Integrated development environment (IDE) is a single application that attempts to manage all these functions.
3.3.3 APPLICATION SOFTWARE Application software is developed to aid in any task that benefits from computation.
It is a broad category, and encompasses software of many kinds, including the internet browser being used to display this page.
This category includes: 30 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY • Business software • Databases • Decision making software • Educational software • Image editing • Industrial automation • Mathematical software • Medical software • Molecular modelling software • Quantum chemistry and solid state physics software • Simulation software • Spreadsheets • Telecommunications (i.e., the Internet and everything that flows on it) • Video games • Word processing SELF ASSESSMENT EXERCISE What is the significance of software in a multimedia computer system?
4.0 CONCLUSION Software is in a way invisible, and therefore not recognized as important in an electronic imaging system.
Software is just as important as hardware, however, because the hardware will not function without it.
The "brains" of the system, software includes the instructions, procedures, and system supervisor in an electronic form.
5.0 SUMMARY In this unit, we considered the Software system.
We equally looked at some functions of multimedia software .We also discovered that computer systems divide software systems into three major classes system software, programming software and application software.
6.0 TUTOR MARKED ASSIGNMENT 1).
Explain the term “software” 2).
Describe the different feature of the different classes of Software.
31 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 3).
Discuss the functions of system software 7.0 REFERENCES/FURTHER READINGS Comer, Douglas E.; Stevens, David L. (1993).
Vol III: Client-Server Programming and Applications.
Internetworking with TCP/IP.
Department of Computer Sciences, Purdue University, West Lafayette, IN 47907.
Don M. (1995) Indexing, Compression.ARMA Records Management Quarterly.
Volume: 29.
Issue: 1.
32 Chellis, James et.al (1997) MSCE: Networking Essentials Study Guide Sybex Network Press, San Francisco Buford.
J.F.K, (1994).
Multimedia Systems, ACM Press, Gary, B.S et.al (2007) Discovery Computers 2007:A gateway to Information.
Thomson, Australia Fluckiger.
(1994).
Understanding Networked Multimedia, Prentice Hall.
Agnew, P.W.
and Kellerman, A.S. (1996).
Distributed Multimedia: Technologies, Applications, and Opportunities in the Digital Information Industry (1st Edition) Addison Wesley.
Murray, J.D and Van Ryper.W(1996), Encyclopedia of Graphics File Formats, Second Edition O'Reilly & Associates.
(ISBN: 1-56592-161-5) Parsons, J and Dan O (2004) Computer Concepts 7TH edition.
Thomson Learning Inc. Australia.
Vaughan, Tay ( 1993), Multimedia: Making It Work (first edition, Osborne/ McGraw-Hill, Berkeley, pg.
3.
32 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Shuman, J. G. (2002).
Multimedia Elements.
Multimedia In Action.
Vikas Publishing House Pvt Ltd. UNIT 4 SERVER COMPUTER 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Server 3.2 Specialised Server 3.2.1 Application Server 3.2.2 Fax Server 3.2.3 File and Print Server 3.2.4 Mail Server 3.2.5 Web Server 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION In this unit, we shall focus on the definition of a computer server.
We will equally consider the different types of the specialised server.
2.0 OBJECTIVES At the end of this unit, you should be able to: • Identify what a Server is • List and explain the different types of specialised Server.
• Differentiate between the different types of servers listed below.
3.0 MAIN CONTENT 3.1 SERVER A Server is a computer, or series of computers, that link other computers or electronic devices together.
They often provide essential services across a network, either to private users inside a large organization or to public users via the internet.
For example, when you 33 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY enter a query in a search engine, the query is sent from your computer over the internet to the servers that store all the relevant web pages.
The results are sent back by the server to your computer.
In computing, the term server is used to refer to one of the following: • A computer program running as a service, to serve the needs or requests of other programs (referred to in this context as "clients") which may or may not be running on the same computer.
• A physical computer dedicated to running one or more such services, to serve the needs of programs running on other computers on the same network.
• A software/hardware system (i.e.
a software service running on a dedicated computer) such as a database server, file server, mail server, or print server.
Many servers have dedicated functionality such as web servers, print servers, and database servers.
While nearly any personal computer is capable of acting as a network server, a dedicated server will contain features making it more suitable for production environments.
These features may include a faster CPU, increased high-performance RAM, and typically more than one large hard drive.
More obvious distinctions include marked redundancy in power supplies, network connections, and even the servers themselves.
3.2 SPECIALIZED SERVERS Within the broad classification of machines that functions as network servers, it’s possible to assign a variety of specialty roles, depending on the services that such servers provide.
On large networks, in particular, servers with specialized roles to play will often be deployed.
Specialized server types typically include application servers, communication servers, domain controllers/directory servers, fax server, file and print servers, mail servers, and Web servers.
3.2.1 APPLICATION SERVERS Application servers supply the server side of client/server applications, and often the data that goes along with them, to network clients.
A database server, for instance, not only supplies the query processing and data analysis facilities; it also acts as the repository for the huge amount of data that often reside within a database.
34 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Application servers differ from basic file and print servers in that they provide processing services as well as handling requests for file or print services, where the client does its own file handling and print processing.
Clients generally must run specialized client side applications (or plug-ins to other applications) to enable them to communicate with an application server.
For such applications, the client-side typically formulates request and ships them off to the application server, which handles all the background processing of the request and then delivers the result back to the client-side part.
The client-side then formats and displays those results to the user.
3.2.2 FAX SERVERS Fax servers manages fax traffic for a network, receiving incoming faxes via telephone and distributing them to their recipients over the network and collecting outgoing faxes across the network before sending them via telephone.
Such servers typically use one or more fax modem interfaces (often referred to more simply as fax modem) to perform these tasks.
3.2.3 FILE AND PRINT SERVERS File and print servers is the mainstay of the server world in that they provide basic networked file storage and retrieval services, and access to networked printers – functions that define the fundamental uses of most business networks.
Such servers let users run applications locally but keep their data files on the server (and print these file when they want hardcopy output).
3.3.4 MAIL SERVERS Mail servers handle e-mail messages on behalf of network users, which may involve simply acting as a clearinghouse for a local exchange of message.
But mail servers also commonly provide “store-and-forward” services, where incoming e-mail messages are held at the server while waiting for users to access them.
Likewise outgoing messages can be stored on the server until a connection to an appropriate external mail server is established, so that they can be forwarded to their intended destinations.
3.2.5 WEB SERVERS As companies increasingly turn to software using the TCP/IP protocol (the one used on the Internet) to distribute information, no one service has gained popularity as quickly as the World Wide Web (www).
Many organizations intranets (in-house TCP/IP-based networks) 35 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY are taking great advantage of IIS (internet Information Server) for their organisational services.
Windows remains Microsoft’s primary operating system software offering designed to handle this broad range of needs.
SELF ASSESSMENT EXERCISE What do you understand by a computer Server?
4.0 CONCLUSION In this unit you have learnt about the server and its features.
You have also learnt that there are different specialised servers that are used for institutional purposes.
5.0 SUMMARY A Server is a computer, or series of computers, that link other computers or electronic devices together.
They often provide essential services across a network, either to private users inside a large organization or to public users via the internet.
6.0 TUTOR MARKED ASSIGNMENT 1).Distinguish between the file and print server and a fax server?
2).Explain what you understand by the term server 3) List and explain the different types of specialised servers.
7.0 REFERENCES/FURTHER READINGS Chellis, James et.al (1997) MSCE: Networking Essentials Study Guide Sybex Network Press, San Francisco Ifeachor, E. C., and Jervis, B. W,( 2002) Digital Signal Processing: A Practical Approach (Harlow, England: Pearson Education Limited) Rabiner, L.R., and Gold, B., (1975): Theory and Application of Digital Signal Processing (Englewood Cliffs, New Jersey: Prentice-Hall, Inc.) 36 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Watkinson, John, (1994): The Art of Digital Audio (Oxford: Focal Press) Bosi, Marina, and Goldberg, Richard E., (2003) Introduction to Digital Audio Coding and Standards .Springer E. Larsen and R.M.
Aarts (2004), Audio Bandwidth extension.
Application of Psychoacoustics, Signal Processing and Loudspeaker Design.
J. Wiley.
Larsen E., Aarts R.M.
(March 2002).
"Reproducing low-pitched signals through small loudspeakers" (PDF).
J.
Audio Eng.
Soc.
50 (3): 147–164.
http://www.extra.research.philips.com/hera/people/aarts/papers/aar02n4.pdf.
Oohashi T., Kawai N, et.al (2006).
"The Role of Biological System other than auditory air-conduction in the emergence of the hypersonic effect".
Brain Research 1073: 339–347.
doi:10.1016/j.brainres.2005.12.096.
PMID 16458271 UNIT 5 NETWORK 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Networking 3.2 Types of Networking 3.2.1 MAN (Metropolitan Area Network) 3.2.2 WAN (Wide Area Network) 3.2.3 LAN (Local Area Network) 3.3Network Topologies 3.3.1 Bus Topology 3.3.2 Star Topology 3.3.3 Ring Topology 3.3.4 Tree Topology 3.3.5 Mesh Topology 3.4 Network Architecture 3.4.1 Client Server Architecture 3.4.2 Peer-Peer Architecture 37 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION Networking involves connecting computes to create a for the purpose of sharing information and resources.
Even though the concept is basic, a great deal of technology is required to one computer to connect and communicate with another.
In this unit, you learn about the fundamental concepts that drive all networks and understand why networking is so important in an organisation.
2.0 OBJECTIVES • Give a concise definition a network • List and discuss the different topology of network • Describe the characteristics of the different network topologies • Differentiate between the client server and peer-to peer styles of network 3.0 MAIN CONTENT 3.1 NETWORK In its simplest form, a network is a cluster of computers, with one computer acting as a server to provide network services such as file transfer, email and document printing to the client computers of that network.
Using gateways and routers, a local area network (LAN) can be connected to other LANs to form a wide area network (WAN).
These LANs and WANs can also be connected to the internet through a server that provides both the necessary software for the internet and the physical data connection (usually a high –bandwidth telephone line.)
Individual computers not permanently part of a network (a home computer or a laptop) can dial up to one of these internet servers and , with proper identification and onboard client software, contain an IP address on the internet.
Computers connected over a network can make that information exchange easier and faster.
The information moves directly from computer to computer rather than through a human intermediary.
38 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 3.1 TYPES OF NETWORK Computer Networks are mostly classified on the basis of the geographical area that the network covers, the topology used, the transmission media used and the computing model used.
Based on the geographical area covered the networks may be LAN, MAN, WAN.
3.1.1 METROPOLITAN AREA NETWORK (MAN) Diagram of a Metropolitan Area Network Connection Metropolitan Area Network is a Computer network designed for a town or city.
In terms of geographic area MAN’s are larger than local-area networks (LANs), but smaller than wide- area networks (WANs).
MAN’s are usually characterised by very high-speed connections using fibre optical cable or other digital media.
It is designed for organisations who need a high – speed connectivity normally to the internet and have end point spread over a city or a part of the city.
Characteristics of a MAN are: • Confined to a larger area than a LAN and can range from 10km to a few 100km in length.
• Slower than a LAN but faster than a WAN.
• Operates at a speed of 1.5 to 150 Mbps.
39 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY • Expensive equipment.
• Moderate error rates.
3.1.2 WIDE AREA NETWORK (WAN) Diagram of a Wide Area Network Connection Wide Area Network is a computer network that spans a relatively large geographical area.
Typically, a WAN consists of two or more local-area networks (LANs).
It provides a long distance transmission of data, image, audio and video information over large geographic areas that may comprise a country, a continent or even the whole world.
Computers connected to a wide-area network are often connected through public networks, such as the telephone system.
They can also be connected through leased lines or satellites.
Characteristics of a WAN are: • A WAN can range from 100krn to 1000krn and the speed between cities can vary forml.5 Mbps to 2.4 Gbps.
• WAN supports large number of computers and multiple host machines.
• Various segments of network are interconnected using sophisticated support devices like routers and gateways.
• Usually the speed is much slower than LAN speed.
40 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY • Highest possible error rate compared to LAN & MAN.
3.1.3 LOCAL AREA NETWORK (LAN) Diagram of a Local Area Network Connection A local Area network is usually privately owned and links the devices in a single office, building or campus.
Depending o the needs of an organisation, and the type of technology used, a Local area network can be as simple as two PC or it can extend throughout a company and include audio and video peripherals.
LANS are designed to allow resources to be shared between personal computers or workstations.
The resources to be shared can include hardware (e.g printer), software (e.g an application program) or data.
A common example of a LAN, found in many business environment s, links a work group of task- related computers example engineering workstations or accounting PCs.
One of the computers may be given a large capacity disk drive and may become a server to clients.
A local area network (LAN) is a number of computers connected to each other by cable in a single location , While local area network are perfect for sharing resources within a building or campus, they cannot be used to connect distant sites.
3.3 NETWORK TOPOLOGY 41 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Topology refers to the shape of a network, or the network’s layout.
How different nodes in a network are connected to each other and how they communicate with each other is determined by the network’s topology.
Topologies are either physical or logical.
Some of the most common network topologies are: • Bus topology • Star topology • Ring topology • Tree topology • Mesh topology 3.2.1 BUS TOPOLOGY Diagram of a Bus Topology In Bus topology, all devices are connected to a central cable, called the bus or backbone.
The bus topology connects workstations using a single cable.
Each workstation is connected to the next workstation in a point-to- point fashion.
Nodes are connected to the bus cable by drop lines and taps.
A drop line is a connection running between the device and the main cable.
A tap is a connector that either splices into the main cable or punctures the sheathing of a cable to create a contact with the metallic core.
In this type of topology, if one workstation goes faulty all workstations may be affected as all workstations share the same cable for the sending and receiving of information.
The cabling cost of bus systems is the least of all the different topologies.
Each end of the cable is terminated using a special terminator.
42 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY The common implementation of this topology is Ethernet.
Here, message transmitted by one workstation is heard by all the other workstations.
Advantages of Bus Topology • Installation is easy and cheap when compared to other topologies • Connections are simple and this topology is easy to use.
• Less cabling is required.
Disadvantages of Bus Topology • Used only in comparatively small networks.
• As all computers share the same bus, the performance of the network deteriorates when we increase the number of computers beyond a certain limit.
• ·Difficulty in reconnection and fault isolation.
• A single fault in the cable stops all transmission.
3.2.2 STAR TOPOLOGY Diagram of a Star Topology Star topology uses a central hub through which, all components are connected.
In a Star topology, the central hub is the host computer, and at the end of each connection is a terminal.
Nodes communicate across the network by passing data through the hub.
A star network uses a significant amount of cable as each terminal is wired back to the central hub, even if two terminals are side by side but several hundred meters away from the host.
The central hub makes all routing decisions, and all other workstations can be simple.
43 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY An advantage of the star topology is that failure, in one of the terminals does not affect any other terminal; however, failure of the central hub affects all terminals.
This type of topology is frequently used to connect terminals to a large time-sharing host computer.
Advantages of Star Topology • Installation and configuration of network is easy.
• Less expensive when compared to mesh topology.
• Faults in the network can be easily traced.
• Expansion and modification of star network is easy.
• Single computer failure does not affect the network.
• Supports multiple cable types like shielded twisted pair cable, unshielded twisted pair cable, ordinary telephone cable etc.
Disadvantages of Star Topology • Failure in the central hub brings the entire network to a halt.
• More cabling is required in comparison to tree or bus topology because each node is connected to the central hub.
3.2.3 RING TOPOLOGY Diagram of a Ring Topology In Ring Topology all devices are connected to one another in the shape of a closed loop, so that each device is connected directly to two other devices, one on either side of it, i.e., the ring topology connects workstations in a closed loop, Each terminal is connected to two other terminals (the next and the previous), with the last terminal being connected to the first.
Data 44 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY is transmitted around the ring in one direction only; each station passing on the data to the next station till it reaches its destination.
Information travels around the ring from one workstation to the next.
Each packet of data sent on the ring is prefixed by the address of the station to which it is being sent.
When a packet of data arrives, the workstation checks to see if the packet address is the same as its own, if it is, it grabs the data in the packet.
If the packet does not belong to it, it sends the packet to the next workstation in the ring.
Faulty workstations can be isolated from the ring.
When the workstation is powered on, it connects itself to the ring.
When power is off, it disconnects itself from the ring and allows the information to bypass the workstation.
The common implementation of this topology is token ring.
A break in the ring causes the entire network to fail.
Individual workstations can be isolated from the ring.
Advantages of Ring Topology • Easy to install and modify the network.
• Fault isolation is simplified.
• Unlike Bus topology, there is no signal loss in Ring topology because the tokens are data packets that are re-generated at each node.
Disadvantages of Ring Topology • Adding or removing computers disrupts the entire network.
• A break in the ring can stop the transmission in the entire network.
• Finding fault is difficult.
• Expensive when compared to other topologies.
3.2.4 TREE TOPOLOGY 45 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Diagram of a Tree Topology Tree topology is a LAN topology in which only one route exists between any two nodes on the network.
The pattern of connection resembles a tree in which all branches spring from one root.
Tree topology is a hybrid topology, it is similar to the star topology but the nodes are connected to the secondary hub, which in turn is connected to the central hub.
In this topology groups of star-configured networks are connected to a linear bus backbone.
Advantages of Tree Topology • Installation and configuration of network is easy.
• Less expensive when compared to mesh topology.
• Faults in the network can be detected traced.
• The addition of the secondary hub allows more devices to be attached to the central hub.
• Supports multiple cable types like shielded twisted pair cable, unshielded twisted pair cable, ordinary telephone cable etc.
Disadvantages of Tree Topology • Failure in the central hub brings the entire network to a halt.
• More cabling is required when compared to bus topology because each node is connected to the central hub.
3.2.5 MESH TOPOLOGY 46 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Diagram of A Mesh Topology Devices are connected with many redundant interconnections between network nodes.
In a well-connected topology, every node has a connection to every other node in the network.
The cable requirements are high, but there are redundant paths built in.
Failure in one of the computers does not cause the network to break down, as they have alternative paths to other computers.
Mesh topologies are used in critical connection of host computers (typically telephone exchanges).
Alternate paths allow each computer to balance the load to other computer systems in the network by using more than one of the connection paths available.
A fully connected mesh network therefore has n (n-1)/2 physical channels to link n devices.
To accommodate these, every device on the network must have (n-l) input/output ports.
Advantages of Mesh Topology • Use of dedicated links eliminates traffic problems.
• Failure in one of the computers does not affect the entire network.
• Point-to-point link makes fault isolation easy.
• It is robust.
• Privacy between computers is maintained as messages travel along dedicated path.
Disadvantages of Mesh Topology • The amount of cabling required is high.
47 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY • A large number of I/O (input/output) ports are required.
3.4 NETWORK ARCHITECTURE Depending on the architecture used Networks can be classified as Client/Server or Peer-to- Peer Networks.
Sever-based networks are the most typical in most organizations and represent the primary focus of the discussion here.
It is essential to understand both types, especially as they compare and contrast with one another.
3.4.1 CLIENT/SERVER ARCHITECTURE Client/Server Architecture is one in which the client (personal computer or workstation) is the requesting machine and the server is the supplying machine, both of which are connected via a local area network (LAN) or wide area network (WAN).
Since the early 1990s, client/server has been the buzzword for building applications on LANs in contrast to centralised minis and mainframes with dedicated terminals.
A client/server network is called Centralised or Server based network.
The client contains the user interface and may perform some or all of the application processing.
Servers can be high-speed microcomputers, minicomputers or even mainframes.
A database server maintains the databases and processes requests from the client to extract data from or update the database.
An application server provides additional business processing for the clients.
The term client/server is sometimes used to contrast a peer-to-peer network, in which any client can also act as a server.
In that case, a client/server entails having a dedicated server.
However, client/server architecture means more than dedicated servers.
Simply downloading files from or sharing programs and databases on a server is not true client/server either.
True client/server implies that the application was originally designed to run on a network and that the network infrastructure provides the same quality of service as traditional mini and mainframe information systems.
The network operating system (NOS) together with the database management system (DBMS) and transaction monitor (TP monitor) are responsible for integrity and security of these types of networks.
Some of these products have gone through many client/server versions by now and have finally reached industrial strength.
48 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 3.4.2 PEER-TO-PEER ARCHITECTURE A type of network in which each workstation has equal capabilities and responsibilities is called peer-to-peer network.
Here each workstation acts as both a client and a server.
There is no central repository for information and there is no central server to maintain.
Data and resources are distributed throughout the network, and each user is responsible for sharing data and resources connected to their system.
This differs from client/server architectures, in which some computers are dedicated to serving the others.
Peer-to-peer networks are generally simpler and less expensive, but they usually do not offer the same performance under heavy loads.
A peer-to-peer network is also known as a Distributed network.
SELF ASSESSMENT EXERCISE Identify the differences between the client Server and Peer-to-Peer network Architecture 6.0 CONCLUSION In this unit you have learnt about networking and the different types of networks.
You have also learnt that the primary motivation for networking arises from a need for individuals and programs to share data quickly and efficiently.
How different nodes in a network are connected to each other and how they communicate with each other is determined by the network’s topology.
Topologies are either physical or logical.
Some of the most common network topologies are: Bus topology, Star topology, Ring topology, Tree topology and the Mesh topology 5.0 SUMMARY The most elementary of all networks consists of two computers, each connected to the other using some kind of cable to permit information exchange.
No matter how many computers may be interlinked, or what kinds of connections may be in use, all networking derives from this basic description.
In fact, when computers communicate, they frequently do so in pairs, with one machine sending information and the other receiving the information.
Even though this may seem elementary, the introduction of computer networks represents significant step up from what any single computer can do alone.
6.0 TUTOR MARKED ASSIGNMENT 49 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 1).Distinguish between the different types of network 2) Describe the two types of network Architecture.
2).State three advantages and disadvantages of the WAN, LAN &MAN Networks 7.0 REFERENCES/FURTHER READINGS Fluckiger.
(1994).
Understanding Networked Multimedia, Prentice Hall.
Boyle.
(1998).Design for Multimedia Learning, Prentice Hall, (ISBN 0-13-242155-8) Behouz, F.A (2007) Data Communucations and Networks.
Mc Graw Hill.
Boston.
Chellis, James et.al (1997) MSCE: Networking Essentials Study Guide Sybex Network Press, San Francisco David , J.
(1998) Networking Essentials: Examination Prep.
Certification Insider Press.
Cambridge.
Agnew P.W.
and Kellerman.
A.S. (1996).
Distributed Multimedia: Technologies, Applications, and Opportunities in theDigital Information Industry (1st Edition) Addison Wesley.
Sloane, (2002).
Multimedia Communication, McGraw Hill (ISBN 0-077092228) Vaughan, Tay, 1998, Multimedia: Making It Work (first edition) Osborne/McGraw-Hill, Berkeley.
Shuman, J. G. (2002).
Multimedia Elements.
Multimedia in Action.
Vikas Publishing House Pvt Ltd. MODULE 2 ELEMENTS OF MULTIMEDIA 50 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Unit 1 Digital Audio Unit 2 Video Unit 3 Image Unit 4 Colour UNIT 1 DIGITAL AUDIO CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Digital Audio 3.1.1 Psychoacoustics 3.1.1.1Psychoacoustic Model 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION In this unit, we shall treat the concepts of digital audio distinctly to facilitate a deeper understanding of the different elements of the Multimedia system.
2.0 OBJECTIVES At the end of this unit, you should be able to: • Explain the concept of digital Audio • Identify the differences between a digital audio and an analogue audio.
3.0 MAIN CONTENT 3.1 DIGITAL AUDIO Digital audio is the result of sound reproduction, using pulse-code modulation and digital signals.
This includes analogue-to-digital conversion (ADC), digital-to-analogue conversion (DAC), storage, and transmission.
In effect, the system commonly referred to as digital is in fact a discrete-time, discrete-level while analogue is a continuously varying electrical analogue.
51 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Digital audio has emerged because of its usefulness in the recording, manipulation, mass- production, and distribution of sound.
Modern distribution of music across the Internet via on-line stores depends on digital recording and digital compression algorithms.
Distribution of audio as data files rather than as physical objects has significantly reduced the cost of distribution.
While modern systems can be quite subtle in their methods, the primary usefulness of a digital system is the ability to store, retrieve and transmit signals without any loss of quality.
The digital audio signal may be stored or transmitted.
Digital audio storage can be on a CD, a digital audio player, a hard drive, USB flash drive, Compact Flash, or any other digital data storage device.
Audio data compression techniques — such as MP3, Advanced Audio Coding— are commonly employed to reduce the file size.
Digital audio can be streamed to other devices.
The digital audio chain begins when an analogue audio signal is first sampled, and then (for pulse-code modulation, the usual form of digital audio) it is converted into binary signals— ‘on/off’ pulses—which are stored as binary electronic, magnetic, or optical signals, rather than as continuous time, continuous level electronic or electromechanical signals.
This signal may then be further encoded to allow correction of any errors that might occur in the storage or transmission of the signal; however this encoding is for error correction, and is not strictly part of the digital audio process.
The last step is for digital audio to be converted back to an analogue signal with a DAC.
Like ADCs, DACs run at a specific sampling rate and bit resolution but through the processes of oversampling, up sampling, and down sampling, this sampling rate may not be the same as the initial sampling rate.
3.1.1 PSYCHOACOUSTICS Psychoacoustics is the scientific study of sound perception.
More specifically, it is the branch of science studying the psychological and physiological responses associated with sound (including speech and music).
52 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Hearing is not a purely mechanical phenomenon of wave propagation, but is also a sensory and perceptual event; in other words, when a person hears something, it arrives the ear as a mechanical sound wave travelling through the air, but within the ear it is transformed into neural action potentials.
These nerve pulses then travel to the brain where they are perceived.
Hence, in many problems in acoustics, such as for audio processing, it is advantageous to take into account not just the mechanics of the environment, but also the fact that both the ear and the brain are involved in a person’s listening experience.
Audio compression techniques, such as MP3, make use of this fact.
In addition, the ear has a nonlinear response to sounds of different loudness levels.
Telephone networks and audio noise reduction systems make use of this fact by nonlinearly compressing data samples before transmission, and then expanding them for playback.
Another effect of the ear's nonlinear response is that sounds that are close in frequency produce phantom beat notes, or inter modulation distortion products.
3.1.1.1 PSYCHOACOUSTIC MODEL The psychoacoustic model provides for high quality lossy signal compression by describing which parts of a given digital audio signal can be removed (or aggressively compressed) safely — that is, without significant losses in the (consciously) perceived quality of the sound.
Psychoacoustics is based heavily on human anatomy, especially the ear's limitations in perceiving sound as outlined previously.
To summarize, these limitations are: • High frequency limit • Absolute threshold of hearing • Temporal masking • Simultaneous masking Given that the ear will not be at peak perceptive capacity when dealing with these limitations, a compression algorithm can assign a lower priority to sounds outside the range of human hearing.
By carefully shifting bits away from the unimportant components and toward the important ones, the algorithm ensures that the sounds a listener is most likely to perceive are of the highest quality SELF ASSESSMENT EXERCISE 53 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY What do you understand by Psychoacoustics?
7.0 CONCLUSION In this unit you have learnt about the digital audio and its features.
You have also learnt that Psychoacoustics is the branch of science studying the psychological and physiological responses associated with sound (including speech and music).
Psychoacoustics is based heavily on human anatomy, especially the ear's limitations in perceiving sound .
Some of its limitations are High frequency limit, absolute threshold of hearing, temporal masking and simultaneous masking 5.0 SUMMARY Digital audio is the result of sound reproduction, using pulse-code modulation and digital signals.
What you have learned in this unit concerns the features of the digital audio and sheds light on psychoacoustics.
The units that follow shall give more information on other elements of multimedia.
6.0 TUTOR MARKED ASSIGNMENT 1).Distinguish between the digital audio and analogue audio 2).Explain what you understand by “Psychoacoustics” 7.0 REFERENCES/FURTHER READINGS Chellis, James et.al (1997) MSCE: Networking Essentials Study Guide Sybex Network Press, San Francisco Ifeachor, E. C., and Jervis, B. W.,( 2002) Digital Signal Processing: A Practical Approach (Harlow, England: Pearson Education Limited) Rabiner, L.R., and Gold, B., (1975): Theory and Application of Digital Signal Processing (Englewood Cliffs, New Jersey: Prentice-Hall, Inc.) Watkinson, John, (1994): The Art of Digital Audio (Oxford: Focal Press) Bosi, Marina, and Goldberg, Richard E., (2003)Introduction to Digital Audio Coding and Standards (Springer 54 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY E. Larsen and R.M.
Aarts (2004), Audio Bandwidth extension.
Application of Psychoacoustics, Signal Processing and Loudspeaker Design., J. Wiley.
Larsen E., Aarts R.M.
(March 2002).
"Reproducing low-pitched signals through small loudspeakers" (PDF).
J.
Audio Eng.
Soc.
50 (3): 147–164.
http://www.extra.research.philips.com/hera/people/aarts/papers/aar02n4.pdf.
Oohashi T., Kawai N, et.al (2006).
"The Role of Biological System other than auditory air-conduction in the emergence of the hypersonic effect".
Brain Research 1073: 339–347.
doi:10.1016/j.brainres.2005.12.096.
PMID 16458271 UNIT 2 VIDEO CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Video 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION A still image is a spatial distribution of intensity that is constant with respect to time.
Video, on the other hand, is a spatial intensity pattern that changes with time.
Another common term for video is image sequence, since video can be represented by a time sequence of still images.
Video has traditionally been captured, stored and transmitted in analog form.
The term analog video signal refers to a one-dimensional (1-D) electrical signal of time that is obtained by sampling the video intensity pattern in the vertical and temporal coordinates and converting intensity to electrical representation.
The unit will equally analyse the principles and application of video.
2.0 OBJECTIVES At the end of this unit, you should be able to: • Describe the features of a Video 55 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY • Explain the need of a Video in the Multimedia System 3.0 MAIN CONTENT 3.1 VIDEO A still image is a spatial distribution of intensity that is constant with respect to time.
Video, on the other hand, is a spatial intensity pattern that changes with time.
Another common term for video is image sequence, since video can be represented by a time sequence of still images.
Video is simply a sequence of digitized picture.
Video can also be referred to as moving picture.
The terms “frame” and “pictures” are also used interchangeably in relation to video.
The term video ("video" meaning "I see", from the Latin verb "videre") commonly refers to several storage formats for moving pictures: digital video formats, including Blu-ray Disc, DVD, QuickTime, and MPEG-4; and analogue videotapes, including VHS and Betamax.
Video can be recorded and transmitted in various physical media: in magnetic tape when recorded as PAL or NTSC electric signals by video cameras, or in MPEG-4 or DV digital media when recorded by digital cameras.
Quality of video essentially depends on the capturing method and storage used.
Digital television (DTV) is a relatively recent format with higher quality than earlier television formats and has become a standard for television video.
The size of a video image is measured in pixels for digital video, or horizontal scan lines and vertical lines of resolution for analogue video.
In the digital domain (e.g.
DVD) standard- definition television (SDTV) is specified as 720/704/640×480i60 for NTSC and 768/720×576i50 for PAL or SECAM resolution.
However in the analogue domain, the number of visible scan lines remains constant (486 NTSC/576 PAL) while the horizontal measurement varies with the quality of the signal: approximately 320 pixels per scan line for VCR quality, 400 pixels for TV broadcasts, and 720 pixels for DVD sources.
Aspect ratio is preserved because of non-square "pixels".
New high-definition televisions (HDTV) are capable of resolutions up to 1920×1080p60, i.e.
1920 pixels per scan line by 1080 scan lines, progressive, at 60 frames per second.
56 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Video resolution for 3D-video is measured in voxels (volume picture element, representing a value in three dimensional spaces).
For example 512×512×512 voxels resolution, now used for simple 3D-video, can be displayed even on some PDAs.
Pixels on computer monitors are usually square, but pixels used in digital video often have non-square aspect ratios, such as those used in the PAL and NTSC variants of the CCIR 601 digital video standard, and the corresponding anamorphic widescreen formats.
Therefore, an NTSC DV image which is 720 pixels by 480 pixels is displayed with the aspect ratio of 4:3 (which is the traditional television standard) if the pixels are thin and displayed with the aspect ratio of 16:9 (which is the anamorphic widescreen format) if the pixels are fat.
SELF ASSESSMENT EXERCISE Explain the principles of Video __________________________________________________________ __________________________________________________________ __________________________________________________________ 4.0 CONCLUSION We have introduced to you that a Video is simply sequence of digitized picture.
5.0 SUMMARY In summary, this unit looked at the basic information about the video as an element of a multimedia system.
You can now attempt the questions below.
6.0 TUTOR MARKED ASSIGNMENT 1).
State 2 reasons for video in the Multimedia System 2).
Explain the features of a Video 7.0 REFERENCES/FURTHER READINGS Buford.
J.F.K, (1994).
Multimedia Systems, ACM Press, (ISBN 0-201-53258-1).
Fluckiger.
(1994).
Understanding Networked Multimedia, Prentice Hall.
57 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Chellis, James et.al (1997) MSCE: Networking Essentials Study Guide Sybex Network Press, San Francisco Boyle.
(1998).Design for Multimedia Learning, Prentice Hall, (ISBN 0-13-242155-8) Agnew, P.W.
and.
Kellerman, A.S (1996).
Distributed Multimedia: Technologies, Applications, and Opportunities in theDigital Information Industry (1st Edition) Addison Wesley.
Sloane, (2002).
Multimedia Communication, McGraw Hill.
(ISBN 0-077092228) Murray J.D.
and Van Ryper, W (1996).
Encyclopaedia of Graphics File Formats, Second Edition, O'Reilly & Associates.
Vaughan, Tay, (1998), Multimedia: Making It Work (first edition) Osborne/McGraw-Hill, Berkeley, pg.
3.
Shuman, J. G. (2002).
Multimedia Elements.
Multimedia in Action.
Vikas Publishing House Pvt Ltd. H. Maurer, Addison Wesley, (1996).
Hyperwave: The Next Generation Web Solution, (ISBn 0-201-40346).
Kientzle, T.(1997).
A programmer's Guide to Sound, Addison Wesley, (ISBN 0-201-41972-6) Watkinson, (2004).
The Art of Digital Audio, -Heinmann.
Synthesizer Basics, GPI Publications.
Brook and Wynne, Hodder and Stoughton (2001).Signal Processing: Principles and Applications.
58 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY UNIT 3 IMAGE CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Images 3.1.1 Digital Image Creation 3.1.2 Digital Image Processing 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION Now that you’ve been introduced to two elements of the multimedia system, we will now consider Images as another element of the multimedia systems.
2.0 OBJECTIVES At the end of this unit, you should be able to: • Describe what a digital Image is?
• Identify the ways to create digital Images • State the difference between an image and a digital Image • List the ways to process the Digital Image.
3.0 MAIN CONTENT 3.1 IMAGES An image is a spatial representation of an object, a two-dimensional or three-dimensional scene or another image.
Often the images reflect the intensity of lights.
Most photographs are called continuous-tone images because the method used to develop the photograph creates the illusion of perfect continuous tone throughout the image.
Images stored and processed by computers, displayed on computer screens, are called digital 59 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Images, though they often look like continuous-tone.
This is because they are represented by a matrix of numeric values each representing a quantised intensity values.
The smallest element on a digital image is known as a pixel — a picture element.
The word pixel is based on a contraction of pix ("pictures") and el (for "element"); thus a ‘pixel’ refers to the smallest addressable screen element; it is the smallest unit of picture that can be controlled.
Each pixel has its own address.
The address of a pixel corresponds to its coordinates.
Pixels are normally arranged in a two-dimensional grid, and are often represented using dots or squares.
Each pixel is a sample of an original image; more samples typically provide more accurate representations of the original.
The intensity of each pixel is variable.
A digital image consists of many picture elements (pixels).
The number of pixels that compose a monitors’ image determines the quality of the image (resolution).
Higher resolution always yields better quality.
A bit-map representation stores the graphic/image data in the same manner that the computer monitor contents are stored in video memory.
3.1.1 DIGITAL IMAGE CREATION There are many ways to create or get digital images.
Some of the most common ways are: • Make an image from scratch with a paint program.
A good program will allow you to choose the depth, resolution and size.
• Grab an image of a screen.
The depth, resolution and size are determined by the screen.
Capture an image from a digital camera or a camcorder.
The depth, resolution and size are determined by the camera or the camcorder.
The popular depth is 24-bit.
The commonly used resolution is 320 _ 240, 640 _ 480 and 800 _ 600.
• Scan a photograph or a print using a scanner.
You can select from a range of different depths and resolution.
The choice should be determined by the type of original and the final output form.
• Convert from existing digital media— e.g., photo CD.
The attribute is determined by the original image.
• Synthesize an image from numerical data.
3.1.2 DIGITAL IMAGE PROCESSING 60 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Digital Image Processing is very large area but it contains the following sub-areas: • Image analysis is concerned with techniques for extracting descriptions from images that are necessary for higher-level scene analysis methods.
• Image recognition is concerned with the techniques for recovering information about objects in the image.
A sub-area is character recognition.
• Image enhancement is concerned with the technique to improve the image and to correct some defects, such as, colour and tonal adjustment, transformations, e.g., scale, rotate, Special effects, e.g., texture, stylize, blur, and sharpen etc SELF ASSESSMENT EXERCISE Explain some of the ways to create a Digital Image __________________________________________________________ __________________________________________________________ __________________________________________________________ 4.0 CONCLUSION In this unit you have learnt that Images stored and processed by computers, displayed on computer screens, are called digital Images.
You should also have learnt about the different ways to create and process digital images.
5.0 SUMMARY We highlighted the difference between an image and a digital image, the ways to create digital images and the different areas in processing.
6.0 TUTOR MARKED ASSIGNMENT 1).List and explain the different areas of digital image processing 2).List at least 4 ways to create a digital image 3).
Identify the key feature of a digital image.
7.0 REFERENCES/FURTHER READINGS Gonzalez, Rafael, C; Woods, Richard E (2008).
Digital Image Processing, 3rd Edition.
Pearson Prentice Hall.
pp.
577.
ISBN 013168728.
61 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Jähne, Bernd (1993).
Spatio-temporal image processing, Theory and Scientific Applications.
Springer Verlag.
pp.
208.
ISBN 3540574182 UNIT 4 COLOUR CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Basics of Colour 3.2 Colour Representation 3.3 Benefits and Challenges of using colour 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION In this unit we will be learning about the basics of colour.
We would also bring to light the benefits and challenges of using colour as well as the guidelines for using colours.
Hope you will be able to grasp the key points.
2.0 OBJECTIVES What you would study in this unit, would enable you to: • Explain the basics of Colours • Discover the science of Colours • Discuss the benefits and challenges of using Colour 3.1 BASICS OF COLOR Colour is a vital component of multimedia.
Colour management is both a subjective and a technical exercise, because: • Colour is a physical property of light • Colour perception is a human physiological activity.
62 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY • Choosing a right colour or colour combination involves many trials and aesthetic judgement.
• Colour is the frequency/wave-length of a light wave within the narrow band of the electromagnetic spectrum (380 – 760nm) to which the human eye responds.
Colour is the visual perceptual property corresponding in humans to the categories called red, green, blue and others.
Colour derives from the spectrum of light (distribution of light energy versus wavelength) interacting in the eye with the spectral sensitivities of the light receptors.
Colour categories and physical specifications of colour are also associated with objects, materials, light sources, etc., based on their physical properties such as light absorption, reflection, or emission spectra.
By defining a colour space, colours can be identified numerically by their coordinates.
Because perception of colour stems from the varying sensitivity of different types of cone cells in the retina to different parts of the spectrum, colours may be defined and quantified by the degree to which they stimulate these cells.
These physical or physiological quantifications of colour, however, do not fully explain the psychophysical perception of colour appearance.
The science of colour is sometimes called chromatics.
It includes the perception of colour by the human eye and brain, the origin of colour in materials, colour theory in art, and the physics of electromagnetic radiation in the visible range (that is, what we commonly refer to simply as light).
Colour space can be used as a model to identify colours numerically; for example, a colour can be specified by their unique RGB and HSV values.
3.2 BENEFITS AND CHALLENGES OF USING COLOUR Benefits: Colour is important for effective display and hardware design because it makes the screen layout attractive; may reduce user’s interpretation errors; emphasize logical organisation of the information; and is very efficient at drawing the user's attention to a given part of the screen.
Challenges: However, Colour is difficult to use correctly.
The environment affects human colour perception e.g.
lighting conditions may change the colours seen to less effective ones in display terms.
Annoying after-images may be produced if a block of saturated colour is on 63 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY display for a period of time.
In addition, colour 'blindness' may significantly alter the appearance of a display for those affected by it, e.g.
approximately 6% of men have difficulty distinguishing between shades of red and green.
4.0 CONCLUSION In this unit, we discovered that Colour is a vital component of multimedia.
Management of colour is both a subjective and technical exercise.
Colour is a frequency of a light wave within the narrow band of the electromagnetic spectrum to which the human eye responds.
Colour is important for effective display and hardware design because it makes the screen layout attractive; may reduce user’s interpretation errors; emphasize logical organisation of the information; and is very efficient at drawing the user's attention to a given part of the screen.
5.0 SUMMARY This unit highlighted the rudiments of colour in multimedia.
The benefits and challenges of using colour as well as the guidelines for using colour were equally presented.
We hope you enjoyed your studies.
6.0 TUTOR MARKED ASSIGNMENT 1) ·Give a concise explanation on the basics of Colour 2).Explain the concept of “Chromatics” 3).Describe the benefits of using colour 4).
State the challenges of using colour.
SELF ASSESSMENT EXERCISE Explain the term Chromatics?
__________________________________________________________ __________________________________________________________ __________________________________________________________ __________________________________________ 64 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 7.0 REFERENCES/FURTHER READINGS Buford.
J.F.K, (1994).
Multimedia Systems, ACM Press, (ISBN 0-201-53258-1).
Fluckiger.
(1994).
Understanding Networked Multimedia, Prentice Hall.
Boyle.
(1998).Design for Multimedia Learning, Prentice Hall, (ISBN 0-13-242155-8) Agnew, P.W.
and.
Kellerman, A.S (1996).
Distributed Multimedia: Technologies, Applications, and Opportunities in theDigital Information Industry (1st Edition) Addison Wesley.
Sloane, (2002).
Multimedia Communication, McGraw Hill.
(ISBN 0-077092228) Murray J.D.
and Van Ryper, W (1996).
Encyclopaedia of Graphics File Formats, Second Edition, O'Reilly & Associates.
Vaughan, Tay, (1998), Multimedia: Making It Work (first edition) Osborne/McGraw-Hill, Berkeley, pg.
3.
Shuman, J. G (2002).
Multimedia Elements.
Multimedia in Action.
Vikas Publishing House Pvt Ltd. Watkinson, (2004).
The Art of Digital Audio, -Heinmann.
Synthesizer Basics, GPI Publications.
Brook and Wynne, Hodder and Stoughton (2001).Signal Processing: Principles and Applications.
65 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY MODULE 3 MULTIMEDIA SYSTEMS TECHNOLOGY Unit 1Multimedia Compression Unit 2 Authoring System Unit 2 Multimedia Communications Unit 3 ATM UNIT 1 MULTIMEDIA COMPRESSION CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Multimedia Compression 3.2 Categories of Multimedia Compression 3.2.1 Lossy Compression 3.2.2 Lossless Compression 3.3 Lossy versus Lossless Compression 3.4 Principles of Video Compression 3.5 Application of Multimedia Compression 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION Multimedia compression is a broad term that refers to the compression of any type of multimedia (i.e.
combination of media and content forms), most notably graphics, audio, and video.
In this unit, we shall treat the concepts of Multimedia Compression.
We shall consider the different categories of compression and the similarities between them.
2.0 OBJECTIVES At the end of this unit, you should be able to: • Describe the concept of Multimedia Compression • Explain the differences in the different categories of Multimedia Compression • Discuss the principle of video compression 66 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 3.0 MAIN CONTENT 3.1 MULTIMEDIA COMPRESSION Multimedia compression is a broad term that refers to the compression of any type of multimedia (i.e.
combination of media and content forms), most notably graphics, audio, and video.
Multimedia actually derives from data sampled by a device such as a camera or a microphone.
Such data contains large amounts of random noise, thus, traditional lossless compression algorithms tend to do a poor job compressing multimedia.
Multimedia compression algorithms, traditionally known as codecs, work in a lossy fashion and the entire process is known as transform coding.
The term Transform coding is a technique for compressing signals such as audio signals (1- D) or images (2-D).
In transform coding, a frequency transform or other basic transformation is applied before entropy coding.
The inverse transformation is applied after decoding.
This has a considerable benefit since it produces coefficients that have a statistically significant distribution which can be modelled and compressed more easily.
3.2 CATEGORIES OF MULTIMEDIA COMPRESSION Multimedia compression can be broadly classified as Lossless and Lossy compression.
3.2.1 LOSSY COMPRESSION In information technology, "lossy" compression is a data encoding method which discards some of the data, in order to achieve its goal, with the result that decompressing the data yields content that is different from the original, though similar enough to be useful in some way.
Lossy compression is most commonly used to compress multimedia data (audio, video, still images), especially in applications such as streaming media and internet telephony.
Lossy compression formats suffer from generation loss: repeatedly compressing and decompressing the file will cause it to progressively lose quality.
Information theoretical foundations for lossy data compression are provided by rate distortion theory.
There are two basic lossy compression schemes: 67 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY • In lossy transform codecs, samples of picture or sound are taken, chopped into small segments, transformed into a new basis space, and quantized.
The resulting quantized values are then entropy coded.
• In lossy predictive codecs, previous and/or subsequent decoded data is used to predict the current sound sample or image frame.
The error between the predicted data and the real data, together with any extra information needed to reproduce the prediction, is then quantized and coded.
In some systems, the two techniques are combined, with transform codecs being used to compress the error signals generated by the predictive stage.
3.2.2 LOSSLESS COMPRESSION Lossless compression is a compression technique that does not lose any data in the compression process.
This compression "packs data" into a smaller file size by using a kind of internal shorthand to signify redundant data.
If an original file is 1.5MB, lossless compression can reduce it to about half that size, depending on the type of file being compressed.
This makes lossless compression convenient for transferring files across the Internet, as smaller files transfer faster.
Lossless compression is also handy for storing files as they take up less room.
The zip convention, used in programs like WinZip, uses lossless compression.
For this reason zip software is popular for compressing program and data files.
That's because when these files are decompressed, all bytes must be present to ensure their integrity.
If bytes are missing from a program, it won't run.
If bytes are missing from a data file, it will be incomplete and garbled.
GIF image files also use lossless compression.
Lossless compression has advantages and disadvantages.
The advantage is that the compressed file will decompress to an exact duplicate of the original file, mirroring its quality.
The disadvantage is that the compression ratio is not all that high, precisely because no data is lost are missing from a program, it won't run.
If bytes are missing from a data file, it will be incomplete and garbled.
GIF image files also use lossless compression.
3.3 LOSSY VERSUS LOSSLESS COMPRESSION Lossless and lossy compressions have become part of our every day vocabulary largely due to the popularity of MP3 music files.
A standard sound file in WAV format, converted to an 68 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY MP3 file will lose much data as MP3 employs a lossy, high-compression algorithm that tosses much of the data out.
This makes the resulting file much smaller so that several dozen MP3 files can fit, for example, on a single compact disk, verses a handful of WAV files.
However the sound quality of the MP3 file will be slightly lower than the original WAV.
The advantage of lossy methods over lossless methods is that in some cases a lossy method can produce a much smaller compressed file than any lossless method, while still meeting the requirements of the application.
Lossy methods are most often used for compressing sound, images or videos.
This is because these types of data are intended for human interpretation where the mind can easily "fill in the blanks" or see past very minor errors or inconsistencies – ideally lossy compression is transparent (imperceptible), which can be verified via an ABX test.
3.4 PRINCIPLES OF VIDEO COMPRESSION A diagram of a video compression The principle of still image compression is very similar to that of video compression.
In principle, one way to compress video source is to apply any of the common algorithms such 69 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY as JPEG algorithm independently to each frame that makes up a video.
This approach is also known as moving JPEG or MPEG.
For now typical compression ratios of about 29:1 obtained with JPEG are not large enough to produce the compression ratio needed for multimedia applications.
In practice, in addition to the spatial redundancy present in each frame considerable redundancy is often present between a set of frame since only a small portion of each frame is involved with any motion that is taking place.
For an example, consider the movement of a person’s lip or eye in a video telephony application.
3.5 APPLICATION OF MULTIMEDIA COMPRESSION Video (and audio) need to be compressed in practice for the following reasons: 1.
Uncompressed video (and audio) data are huge.
In HDTV, the bit rate easily exceeds 1 Gbps and this poses a big problem for storage and network communications.
As can be seen, restriction in data rate means that the original signal must be compressed.
It is really impressive to note that the intent is to deliver very high quality video to the end user, with as few visible artefacts as possible.
2.
Lossy methods have to be employed since the compression ratio of lossless methods is not high enough for image and video compression, especially when distribution of pixel values is relatively flat.
The following compression types are commonly used in Video compression: · Spatial Redundancy Removal - Intraframe coding (JPEG) · Spatial and Temporal Redundancy Removal - Intraframe and Interframe coding (H.261, MPEG).
4.0 CONCLUSION Multimedia compression can be broadly classified as Lossless and Lossy compression.
In information technology, "lossy" compression is a data encoding method which discards some of the data, in order to achieve its goal, with the result that decompressing the data yields content that is different from the original, though similar enough to be useful in some way while Lossless compression is a compression technique that does not lose any data in the compression process.
SELF ASSESSMENT EXERCISE Discuss the advantage of a lossy method over the lossless method of compression.
70 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 5.0 SUMMARY In this unit you have learnt about Multimedia Compression and its features.
You have also learnt that there different applications of multimedia compression.
6.0 TUTOR MARKED ASSIGNMENT 1) What are the comparative features between the two categories of Multimedia Compression?
2) Explain the application of multimedia Compression.
3) What do you understand by the principle of Video Compression?
7.0 REFERENCES/FURTHER READINGS B. Furht, S. W. Smoliar, H-J, (1996) “Video and Image Processing in Multimedia Systems”, Kluwer Academic Pub, Chellis, James et.al (1997) MSCE: Networking Essentials Study Guide Sybex Network Press, San Francisco Ifeachor, E. C., and Jervis, B. W.,( 2002) Digital Signal Processing: A Practical Approach (Harlow, England: Pearson Education Limited) Rabiner, L.R., and Gold, B., (1975): Theory and Application of Digital Signal Processing (Englewood Cliffs, New Jersey: Prentice-Hall, Inc.) Watkinson, John, (1994): The Art of Digital Audio (Oxford: Focal Press) Bosi, Marina, and Goldberg, Richard E., (2003)Introduction to Digital Audio Coding and Standards (Springer E. Larsen and R.M.
Aarts (2004), Audio Bandwidth extension.
Application of Psychoacoustics, Signal Processing and Loudspeaker Design., J. Wiley.
Larsen E., Aarts R.M.
(March 2002).
"Reproducing low-pitched signals through small loudspeakers" (PDF).
J.
Audio Eng.
Soc.
50 (3): 147–164.
http://www.extra.research.philips.com/hera/people/aarts/papers/aar02n4.pdf.
71 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Oohashi T., Kawai N, et.al (2006).
"The Role of Biological System other than auditory air-conduction in the emergence of the hypersonic effect".
Brain Research 1073: 339–347.
doi:10.1016/j.brainres.2005.12.096.
PMID 16458271 UNIT 2 AUTHORING SYSTEM CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Authoring Systems 3.1.1Icon Based Authoring tool 3.1.2Card and Page Based Authoring tool 3.1.3 Author ware (Macintosh/Windows) 3.1.4 Time based Authoring tool 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION In this module, we will focus on the different media Systems technology.
We will equally consider the authoring system and the different authoring tools.
2.0 OBJECTIVES What you will study in this unit, would enable you: • Define the term Authoring System • List the Authoring Tools • Identify the key role of the authoring system in the multimedia technology.
3.0 MAIN CONTENT 3.1 AUTHORING SYSTEM An Authoring System refers to a program which has pre-programmed elements for the development of interactive multimedia software titles.
It generally takes about 1/8th of the time to develop an interactive multimedia project, in an authoring system as opposed to programming it in compiled codes.
72 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Authoring systems vary widely in orientation, capabilities, and learning curve.
There is no such thing as a completely point-and-click automated authoring system; some knowledge of heuristic thinking and algorithm design is necessary.
Whether you realize it or not, authoring is actually just a speeded-up form of programming; you don't need to know the intricacies of a programming language, or worse, an API, but you do need to understand how programs work.
Authoring can be described as creating highly interactive applications in which the information can flow in both directions i.e., from application to user and from user to application.
Multimedia authoring tools has helped in creating higher-quality audio and video applications with very little expertise.
Multimedia authoring tools can be evaluated by performing certain tests, which include the creation of non-interactive multimedia, computer-based training (CBT) applications, catalog creation and even authoring for the World Wide Web.
The advantage of using object-oriented programming has been inculcated in the authoring products for example Everest Authoring System offers object instancing, while Media Verse and Oracle Media Objects allows one to add new methods and events to existing objects.
In order to create effective multimedia, one need tools that can handle a wide range of authoring tasks, including interactive title development, CBT, interactive catalogs /kiosks and web authoring.
Authoring software provides an integrated environment for binding together the content and functions of your project.
Authoring systems typically include the ability to create, edit, and import specific types of data; assemble raw data into a playback sequence or cue sheet; and provide a structured method or language for responding to user input.
With multi-media authoring software, you can make.
(cid:1) Video productions (cid:1) Animations (cid:1) Games (cid:1) Demo disks and interactive guided tours (cid:1) Presentations (cid:1) Interactive kiosk applications (cid:1) Interactive training 73 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY (cid:1) Simulations, prototypes, and technical visualizations.
Multimedia authoring tools provide the important framework you need for organizing and editing the elements of your multimedia project, including graphics, sounds, animations, and video clips.
Authoring tools are used for designing inter activity and user interface, for presenting your project on screen, and for assembling multimedia elements into a single, cohesive project.
Here are some authoring tools: 3.1.1 ICON –BASED AUTHORING TOOL Icon Author is an authoring tool which requires the use of an icon-based flowchart for building an application.
It maintains a strict separation between an application's structure and the actual content and still ships with a number of ancillary programs that helps to edit and manage content.
Icon-based Authoring tools are event-driven tools that provide a visual programming approach to organizing and presenting multimedia.
First you build a structure or flow-chart of events, tasks, and decisions, by dragging appropriate icons from a library.
These icons can include menu choices, graphics images, sounds, and computations.
The flowchart graphically depicts the project’s logic.
When the structure is built, you can add your content: text, graphics, animation, sounds, and video movies.
Then, to refine your project, you edit your logical structure by rearranging and fine-tuning the icons and their properties.
This component is called Smart Object Editor.
The role of Smart Object editor has become central to the creation of Icon Author applications.
Smart Object Editor assembles individual object such as imported pictures, sound files, video clips, animations, database links, text push buttons, tables and list boxes into coherent pages layouts.
The appearance and behaviour of these objects can be controlled by changing the properties associated with each one.
3.1.2 CARD-AND PAGE-BASED AUTHORING TOOLS Card-and page-based authoring tools` provide a simple and easily understood metaphor for organizing multimedia elements.
Because graphic images typically form the backbone of a project, both as navigation menus and as content, many developers first arrange their images 74 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY into logical sequences or grouping similar to the chapters and pages of a book, or cards in a card catalog.
Navigation routines become, then, simply directives to go to a page or card that contains appropriate images and text, and associated sounds, animations, and video clips.
Page-based authoring systems contain media objects: the objects are the buttons, text fields, graphic objects, backgrounds, pages or cards, and even the project itself.
The characteristics of objects are defined by properties (highlighted, bold, red, hidden, active, locked, and so forth).
Each object may contain programming script, usually a property of that object, that is activated when an event (such as a mouse click) related to that object occurs.
Events cause messages to pass along the hierarchy of objects in your project; for example, a mouse-click message can be sent from a button to the background, to the page, and then to the project itself.
As the message travels, it looks for handlers in the script of each object; if it finds a matching handler, the authoring system then executes the task specified by that handler.
Most page-based authoring systems provide a facility for linking objects to pages or cards (by automatically programming branching go-to statements for navigating by mouse clicks), but learning to write your own scripts and understanding the message-passing nature of these authoring tools is essential to making them perform well.
3.1.3 AUTHORWARE (Macintosh/Windows) With Authorware from Macromedia, nontechnical multimedia authors can build sophisticated applications without scripting.
Authorware is useful as a design tool for story boarding; because it lets you change sequences, add options, and restructure interactions by simply dragging and dropping icons.
You can print out your navigation map or flowchart, an annotated project index with or without associated icons, design and presentation windows, and a cross-reference table of variables.
Developers who use both Macintoshes and PCs can work with almost identical interfaces, authoring functions, media-editing capabilities, and data management on both platforms.
Authorware offers more than 200 system variables and functions for capturing, manipulating, and displaying data, and for controlling the operation of your project.
Variables include interaction, decision, time, video, graphics, general, file, and user; functions include math, string time jump, video, graphics, general, file, and user.
You can post variables and 75 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY functions into calculation windows, option slots, or presentation windows, and you can control the format of variables embedded in selected display text.
3.1.4 TIME-BASED AUTHORING TOOLS Time-based systems are popular multimedia authoring tools.
Each uses its own distinctive approach and user interface for managing events over time.
Many use a visual timeline for sequencing the events of a multimedia presentation, often displaying layers of various media elements or events alongside the scale in increments as precise as one second.
Others arrange long sequences of graphic frames and add the time component by adjusting each frame’s duration of play.
SELF ASSESSMENT EXERCISE Discuss the uses of Multimedia Authoring tools?
__________________________________________________________ __________________________________________________________ __________________________________________________________ __________________________________________ 4.0 CONCLUSION An Authoring System refers to a program which has pre-programmed elements for the development of interactive multimedia software titles.
Multimedia authoring tools provide the important framework you need for organizing and editing the elements of your multimedia project, including graphics, sounds, animations, and video clips.
Authoring tools are used for designing inter activity and user interface, for presenting your project on screen, and for assembling multimedia elements into a single, cohesive project.
5.0 SUMMARY This unit provided an overview of the authoring system; we also considered the types of authoring tools and their unique features.
Hope you have found this unit enlightening.
6.0 TUTOR MARKED ASSIGNMENT 1).
Describe the concept of Authoring System?
2).Identify 4 main types of an Authoring tool?
3).Explain the differences between these tools?
76 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 7.0 REFERENCES/FURTHER READINGS Boyle.
(1998).Design for Multimedia Learning, Prentice Hall, (ISBN 0-13-242155-8) Agnew, P.W.
and Kellerman, A.S. (1996).
Distributed Multimedia: Technologies, Applications, and Opportunities in the Digital Information Industry (1st Edition) Addison Wesley.
Sloane, (2002).
Multimedia Communication, McGraw Hill.
(ISBN 0-077092228) J. Vince, (1995).Virtual Reality Systems, Addison Wesley, (ISBN 0-201-87687-6) Vaughan, Tay, 1998, Multimedia: Making It Work (fourth edition), Osborne/ McGraw-Hill, Berkeley.
Shuman, J. G. (2002).
Multimedia Elements.
Multimedia In Action.
Vikas Publishing House Pvt Ltd. Watkinson, (2004).
The Art of Digital Audio, -Heinmann.
Synthesizer Basics, GPI Publications.
UNIT 3 MULTIMEDIA COMMUNICATIONS CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Qos (Quality of Service) 3.1.1 Integrated Services (InterServ) 77 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 3.1.2 Differentiated Services (DiffServ) 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION Within a communications network, multimedia applications require interactive or distribution services.
Interactive services are divided into conversational, messaging and retrieval services.
This unit presents the concept of Quality of Service and explains the types of services available within the quality of service.
2.0 OBJECTIVES What you would study in this unit, would make it possible for you to: • Give a concise definition of a QoS • State the advantages of a Differentiated Services • Identify the features of an Integrated Services 3.0 MAIN CONTENT 3.1 QoS In the field of computer networking and other packet-switched telecommunication networks, the traffic engineering term quality of service (QoS) refers to resource reservation control mechanisms rather than the achieved service quality.
Quality of service is the ability to provide different priority to different applications, users, or data flows, or to guarantee a certain level of performance to a data flow.
For example, a required bit rate, delay, jitter, packet dropping probability and/or bit error rate may be guaranteed.
Quality of service guarantees are important if the network capacity is insufficient, especially for real-time streaming multimedia applications such as voice over IP, online games and IP-TV, since these often require fixed bit rate and are delay sensitive, and in networks where the capacity is a limited resource, for example in cellular data communication.
3.1.1 INTEGRATED SERVICES 78 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY In computer networking, IntServ or integrated services is an architecture that specifies the elements to guarantee quality of service (QoS) on networks.
IntServ can for example be used to allow video and sound to reach the receiver without interruption.
IntServ specifies a fine- grained QoS system, which is often contrasted with DiffServ's coarse-grained control system.The idea of IntServ is that every router in the system implements IntServ, and every application that requires some kind of guarantees has to make an individual reservation.
The IntServ architecture model (RFC 1633, June 1994) was motivated by the needs of real- time applications such as remote video, multimedia conferencing, visualization, and virtual reality.
It provides a way to deliver the end-to-end Quality of Service (QoS) that real-time applications require by explicitly managing network resources to provide QoS to specific user packet streams (flows).
It uses "resource reservation" and "admission control" mechanisms as key building blocks to establish and maintain QoS.
IntServ uses Resource Reservation Protocol (RSVP) to explicitly signal the QoS needs of an application's traffic along the devices in the end-to-end path through the network.
If every network device along the path can reserve the necessary bandwidth, the originating application can begin transmitting.
3.1.2 DIFFERENTIATED SERVICES The second and currently accepted approach is “DiffServ” or differentiated services.
In the DiffServ model, packets are marked according to the type of service they need.
Routers supporting DiffServ use multiple queues for packets awaiting transmission from bandwidth constrained (e.g., wide area) interfaces.
Router vendors provide different capabilities for configuring this behavior, to include the number of queues supported, the relative priorities of queues, and bandwidth reserved for each queue.
Differentiated Services or DiffServ is a computer networking architecture that specifies a simple, scalable and coarse-grained mechanism for classifying, managing network traffic and providing Quality of Service (QoS) guarantees on modern IP networks.
DiffServ , for example, can be used to provide low-latency to critical network traffic such as voice or video while providing simple best-effort traffic guarantees to non-critical services such as web traffic or file transfers.
79 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY DiffServ operates on the principle of traffic classification, where each data packet is placed into a limited number of traffic classes, rather than differentiating network traffic based on the requirements of an individual flow.
Each router on the network is configured to differentiate traffic based on its class.
Each traffic class can be managed differently, ensuring preferential treatment for higher-priority traffic on the network.
One advantage of DiffServ is that all the policing and classifying is done at the boundaries between DiffServ clouds.
This means that in the core of the Internet, routers can get on with doing the job of routing, and not care about the complexities of collecting payment or enforcing agreements.
That is, DiffServ requires no advance setup, no reservation, and no time-consuming end-to-end negotiation for each flow, as with integrated services.
This leads DiffServ services to be relatively easy to implement.
SELF ASSESSMENT EXERCISE What are the difference between the Integrated and Differentiated Services?
__________________________________________________________ __________________________________________________________ __________________________________________________________ 4.0 CONCLUSION Quality of service is the ability to provide different priority to different applications, users, or data flows, or to guarantee a certain level of performance to a data flow.
It is important to note that IntServ specifies a fine-grained QoS system, which is often contrasted with DiffServ's coarse-grained control system.
5.0 SUMMARY This unit provided an overview of the Quality of Service in Multimedia technology.
It highlighted the two types of services available which are the IntServ and the DiffServ.
We hope you found this unit enlightening.
6.0 TUTOR MARKED ASSIGNMENT 1).Give a concise definition of Quality of Service (Qos) 2).
List at least 4 features each of the Integrated Service and the differentiated Service.
3).What is the relevance of QoS in Multimedia Technology 80 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 7.0 REFERENCES/FURTHER READINGS Xipeng Xiao (2008,) Technical, Commercial and Regulatory Challenges of QoS: An Internet Service Model Perspective.
Morgan Kaufmann, ISBN 0-12-373693-5 John Evans, Clarence Filsfils (2007),Deploying IP and MPLS QoS for Multiservice Networks: Theory and Practice .Morgan Kaufmann, ISBN 0-12-370549-5 Lelli, F. Maron, G. Orlando, S. Client Side Estimation of a Remote Service Execution.
15th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems, 2007.
MASCOTS '07.
Mario Marchese (2007) QoS Over Heterogeneous Networks Wiley, ISBN 978-0-470-017524) Kalevi Kilkki (1999) Differentiated Services for the Internet", Macmillan Technical Publishing, Indianapolis, IN, USA.
UNIT 4 ATM CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 ATM (Asynchronous Transfer Mode) 3.2 How ATM works 3.3 Types of ATM Network 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION 81 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY In the previous unit we examined the quality of Service and the types of services associated with it.
Here, we will be looking at ATM, the Asynchronous transfer Mode in Multimedia Technology.
Do make the most of your studies.
2.0 OBJECTIVES At the end of this unit, you should be able to: • Identify what an ATM is • State the typical features of the Asynchronous transfer Mode 3.0 MAIN CONTENT 3.1 ATM (Asynchronous transfer Mode) ATM is a new networking technology that is being used increasingly in network backbones and wide area networks.
ATM is an attempt to meet the requirements of three different types of network traffic: (cid:1) Audio (voice telephone over short and long distances) (cid:1) Video (cable television) (cid:1) Data (computer communications in LAN and WAN environments) ATM is a high-speed network that uses fiber-optic cables or category 5 copper cables.
It is a point-to-point switches network, meaning that central devices called switches are directly connected to end stations and to each other.
ATM is widely used as a backbone technology in carrier networks and large enterprises, but never became popular as a local network (LAN) topology.
ATM is highly scalable and supports transmission speeds of 1.5, 25, 100, 155, 622, 2488 and 9953 Mbps.
ATM is also running as slow as 9.6 Kbps between ships at sea.
An ATM switch can be added into the middle of a switch fabric to enhance total capacity, and the new switch is automatically updated using ATM’s PNNI routing protocol.
3.2 HOW ATM WORKS Rather than transmitting frames, which can be variably sized, ATM communicates with cells.
A cell is exactly 53 octets long.
An octet is exactly 8 bits of data.
Octets are more precisely defined than bytes, which are usually but not always 8 bits.
Rather than specifying the source and destination addresses of the stations communicating, an ATM cell indicates the path the data will flow through.
Small cells all of the same sizes are 82 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY used to minimize latency and to make it easy for devices to process a cell, so intermediate devices (called switches) can maintain a very high data rate.
The small constant cell size also allows ATM equipment to transmit video, audio and computer data over the same network, and assures that no single type of data hogs the line.
3.3 TYPES OF ATM NETWORK ATM is a circuit-based network, in that a virtual circuit is set up between two devices to communicate over the network.
There are two types of circuits in an ATM network: (cid:1) Permanent Virtual Circuit (PVC): A circuit that is set up once in the switches to allow communication between two devices (cid:1) Switched Virtual Circuit (SVC): A circuit that is temporarily set up just for the duration of a communication two devices.
ATM is a descendant of packet-switching.
Its high-speed advantage comes from transmitting uniform data packets that are subdivided into data frames, and each frame is enclosed within an addressable 53-byte cell and routed by hardware switching.
The switching achieves very high-speed data transmission rate, between 155 and 622 Mbps (theoretically, up to 1.2 gigabits per second).
ATM offers fast, real-time, demand-responsive switching for efficient use of network resources using broadband and baseband LANs or WANs.
Asynchronous Transfer Mode (ATM) seeks to provide: (cid:1) A single network interface to communication channels for each media type - audio, video, image and text.
(cid:1) Adaptability of an application's bandwidth requirements.
(cid:1) Flexibility for handling different data types.
(cid:1) A common signalling structure.
The ATM (Asynchronous transfer Mode) provides the following levels of service: • Constant Bit Rate (CBR) guarantees bandwidth for real time voice and video.
• Real time variable Bit Rate (RT-VBR) supports interactive multimedia that requires minimal delays.
• Non-real time variable bit rate (NRT- VBR) is used for busy transaction traffic.
• Available Bit Rate (ABR) adjusts bandwidth according to congestion levels for LAN traffic.
• Unspecified Bit Rate (UBR) provides the best effort for noncritical data such as file transfers.
83 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY SELF ASSESSMENT EXERCISE State one limitation and delimitation of the Asynchronous Transfer Mode (ATM) __________________________________________________________ 4.0 CONCLUSION In conclusion, ATM is replacing frame relay as the digital network over which public telephone systems operate worldwide.
It was, however, designed with service for computers in mind and is being used with much success as a high-speed back-bone.
ATM will eventually provide direct connection between private networks and public telephone networks for very high-speed access to the Internet.
5.0 SUMMARY We considered the Asynchronous Transfer mode.
There are two types of circuits in an ATM network namely Permanent Virtual Circuit and the Switched Virtual Circuit.
To test your knowledge, attempt the exercise below.
6.0 TUTOR MARKED ASSIGNMENT 1).Explain what you understand by the term Asynchronous Transfer Mode (ATM) 2).List at least 3 Functions of the Asynchronous Transfer Mode (ATM) 7.0 REFERENCES/FURTHER READINGS Agnew, P.W.
and Kellerman, A.S. (1996).
Distributed Multimedia: Technologies, Applications, and Opportunities in the Digital Information Industry (1st Edition) Addison Wesley.
Boyle.
(1998).Design for Multimedia Learning, Prentice Hall, (ISBN 0-13-242155-8) Buford, J.F.K, (1994).
Multimedia Systems, ACM Press, 1994 (ISBN 0-201-53258-1).
Chellis, James et.al (1997) MSCE: Networking Essentials Study Guide Sybex Network Press, San Francisco.
84 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Fluckiger.
(1994).
Understanding Networked Multimedia, Prentice Hall Sloane, (2002).
Multimedia Communication, McGraw Hill.
(ISBN 0-077092228) J. Vince, (1995).Virtual Reality Systems, Addison Wesley, (ISBN 0-201-87687-6) Vaughan, Tay, 1998, Multimedia: Making It Work (fourth edition), Osborne/ McGraw-Hill, Berkeley.
Shuman, J. G. (2002).
Multimedia Elements.
Multimedia In Action.
Vikas Publishing House Pvt Ltd. Watkinson, (2004).
The Art of Digital Audio, -Heinmann.
Synthesizer Basics, GPI Publications.
MODULE 4 MULTIMEDIA APPLICATION DEVELOPMENT Unit 1 Multicast Unit 2 Routing Unit 3 Protocols Unit 4 Video Conference UNIT1 MULTICAST CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Multicast 3.1.1 Multicast Applications 3.2 M bone 4.0 Conclusion 5.0 Summary 85 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION In this unit, we will learn the basics about Multicast process in the transfer of Information and then go on to study about some other Multimedia protocols in the Multimedia System.
2.0 OBJECTIVES What you would study in this unit, would enable you: • Explain what a Multicast is • Understand the Mbone Concept.
• Identify the major characteristics of an Mbone 3.0 MAIN CONTENT 3.1 MULTICAST In computer networking, multicast is the delivery of a message or information to a group of destination computers simultaneously in a single transmission from source and creating copies automatically in other network elements, such as routers.
Multicast is most commonly implemented in IP multicast, which is often employed in Internet Protocol (IP) applications of streaming media and Internet television.
In IP multicast the implementation of the multicast concept occurs at the IP routing level, where routers create optimal distribution paths for datagram sent to a multicast destination address.
In multicast communication, there is one source and a group of destinations.
The relationship is one-to-may.
In this type of communication, the source address is a unicast address, but the destination address is a group address, which defines one or more destinations.
The group address identifies the members of the group.
A multicast packet starts from the source S1 and goes to all destinations that belong to group G1.
In multicasting, when a router receives a packet, it may forward it through several of its interfaces.
At the Data Link Layer, multicast describes one-to-many distribution such as Ethernet multicast addressing, Asynchronous Transfer Mode (ATM) point-to-multipoint virtual circuits (P2MP) or Infini band multicast.
86 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 3.1.1 MULTICAST APPLICATION Multicasting has many applications today such as access to distributed databases, information dissemination, teleconferencing and distance learning Access to Distributed Databases Most of the large databases today are distributed.
That is, the information is stored in more than one location, usually at the time of production.
The user who needs to have access to the database does not need to know the location of the information.
The user’s request is multicast to all the database locations, and the location that has the information responds Information Dissemination Businesses often need to send information to their customers.
If the nature of information is the same for everyone, the information can be multicast.
For example, a software update can be sent to all purchasers of a particular software package.
Dissemination of News In a similar manner, news can be easily disseminated through multicasting.
One single message can be sent to those interested in a particular topic.
For example, the statistics of the championship of a college tournament can be sent to the sports editor s of many newspapers.
Teleconferencing Teleconferencing involves multicasting.
The individuals attending a teleconference all need to receive the same information at the same time.
Temporary or permanent groups can be formed for this purpose.
Distance Learning One growing area in the use of multicasting is distance learning.
Lessons taught by one single professor can be received by a specific group of students.
This is especially convenient for those students who find it difficult to attend classes on campus.
87 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 3.2 MBONE Mbone (short for "multicast backbone") is a virtual network invented by Van Jacobson.
The purpose of “Mbone” is to minimize the amount of data required for multipoint audio/video- conferencing.
Since most Internet routers have IP multicast disabled due to concerns of bandwidth tracking and billing, the Mbone evolved to connect multicast-capable networks over the existing Internet infrastructure.
The commercialization of multicast routers is difficult because there are no efficient access control capabilities to the multicast trees (multicast routers and their protocols), and because Internet service providers have difficulty computing charges for multicast traffic.
Some of its major characteristics are Topology: combination of mesh and star networks IP addresses: 224.2.0.0; routing schemes: DVMRP, MOSPF Session registration: IGMP Mbone uses a network of Mrouters that can support IP multicast, and enables access to real- time interactive multimedia on the Internet.
SELF ASSESSMENT EXERCISE Give a concise description of the term ‘Multicast’ __________________________________________________________ __________________________________________________________ __________________________________________________________ 4.0 CONCLUSION In this unit, we learnt that multicast is the delivery of a message or information to a group of destination computers simultaneously in a single transmission from source and creating copies automatically in other network elements.
5.0 SUMMARY In multicast communication, there is one source and a group of destinations.
The relationship is one-to-may.
In this type of communication, the source address is a unicast address, but the 88 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY destination address is a group address, which defines one or more destinations.
The group address identifies the members of the group.
6.0 TUTOR MARKED ASSIGNMENT 1).Describe the basic characteristics of an Mbone?
2) What is multicasting?
3) List and describe the different aspects of multicasting REFERENCES/FURTHER READINGS Ash, Gerald (1997).
Dynamic Routing in Telecommunication Networks.
McGraw-Hill.
ISBN 0070064148.
Doyle, Jeff and Carroll, Jennifer (2005).
Routing TCP/IP, Volume I, Second Ed.. Cisco Press.
ISBN 1587052024.Ciscopress ISBN 1-58705-202-4 Doyle, Jeff and Carroll, Jennifer (2001).
Routing TCP/IP, Volume II,.
Cisco Press.
ISBN 1578700892.Ciscopress ISBN 1-57870-089-2 Huitema, Christian (2000).
Routing in the Internet, Second Ed.. Prentice-Hall.
ISBN 0321227352.
Kurose, James E. and Ross, Keith W. (2004).
Computer Networking, Third Ed.. Benjamin/Cummings.
ISBN 0321227352.
Medhi, Deepankar and Ramasamy, Karthikeyan (2007).
Network Routing: Algorithms, Protocols, and Architectures.
Morgan Kaufmann.
ISBN 0120885883.
89 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY UNIT 2 ROUTING CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Routing 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION 2.0 OBJECTIVES At the end of this unit, you should be able to: • Give a concise explanation of what a Router is • Identify the desired features of a Router • Discuss the relationship between the Router and Internet 3.0 MAIN CONTENT 3.1 ROUTING OR ROUTEING Routing or routeing is the process of selecting paths in a network along which to send network traffic.
Routing is performed for many kinds of networks, including the telephone network (Circuit switching) , electronic data networks (such as the Internet), and transportation networks.
In packet switching networks, routing directs packet forwarding, the transit of logically addressed packets from their source toward their ultimate destination through intermediate nodes, typically hardware devices called routers, bridges, gateways, firewalls, or switches.
Routing, in a more narrow sense, is often contrasted with bridging in its assumption that network addresses are structured and that similar addresses imply proximity within the network.
Because structured addresses allow a single routing table entry to represent the route to a group of devices, structured addressing (routing, in the narrow sense) outperforms unstructured addressing (bridging) in large networks, and has become the dominant form of addressing on the Internet, though bridging is still widely used within localized environments.
90 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Routing is a key feature of the Internet because it enables messages to pass from one computer to another and eventually reach the target machine.
Each intermediary computer performs routing by passing along the message to the next computer.
Part of this process involves analyzing a routing table to determine the best path.
Routers are more advanced devices used to connect separate networks to form an internetwork.
An internetwork is created when two or more independent networks are connected yet continue to function separately.
A network grows and become a more integral part of an organization.
It is a common request to supply multiple paths through a network to provide fault tolerance.
A bridge cannot handle multiple paths for data and can in fact, create a situation in which the packet can travel in an endless loop.
Routers can be used like bridges to connect multiple network segments and filter traffic, also, unlike bridges, routers can be used to form complex networks.
As shown in Figure below, routers can connect complex networks with multiple paths between network segments.
Each network segment, also called a sub network (or subnet), is assigned a network address.
Each node on a subnet is assigned an address as well.
Using a combination of the network and node address, the router can route a packet from the source to a destination address somewhere else on the network.
Network Network Network 6 6 5 Network Network 4 8 Router F Router G Router E Network Router C Network 9 7 Router D 91 Router I Router A Router B CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Network 1 Network 2 Figure Routers can connect networks with many different paths between the networks.
To successfully route a packet through the internetwork, a router must determine the packet’s path.
When the router receives a packet, it analyzes the packet’s destination network address and looks up that address in its routing table.
The router then repackages the data and sends it to the next router in the path.
Because routers operate at a higher layer of the OSI model than bridges do, router can easily send information over different network architectures.
For example, a packet received from a token ring network can be sent over an Ethernet network.
The router removes the token ring frame, examines the packet to determine the network address repackages the data into Ethernet frames and sends the data out onto the Ethernet network.
Dynamic routers are easier to maintain and provide better route selection than static routers, but the routing table updates and discovery generate additional network traffic.
This is especially true with distance-vector protocols such as RIP, which sends its entire routing table across the network every 30 seconds.
SELF ASSESSMENT EXERCISE Mention the essential features of a Router __________________________________________________________ __________________________________________________________ __________________________________________________________ __________________________________________________________ 4.0 CONCLUSION In this unit, we highlighted the process of Routing.
We learnt the relationship level between the Router and the Internet.
92 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 5.0 SUMMARY Routing is often confused with bridging, which performs a similar function.
The principal difference between the two is that bridging occurs at a lower level and is therefore more of a hardware function whereas routing occurs at a higher level where the software component is more important.
And because routing occurs at a higher level, it can perform more complex analysis to determine the optimal path for the packet.
This unit provided an overview of the concept of routing.
6.0 TUTOR MARKED ASSIGNMENT 1) Give a concise definition of Router?
2) Differentiate between Routing and Bridging 3) Describe the basic functions of a Router 7.0 REFERENCES/FURTHER READINGS Buford.J.F.K (1994).
Multimedia Systems, ACM Press, (ISBN 0-201-53258-1).
Chellis, James et.al (1997) MSCE: Networking Essentials Study Guide Sybex Network Press, San Francisco Usha V. R, Director (2003).
Commonwealth Educational Media Centre for Asia (CEMCA), New Delhi.
Fluckiger.
(1994).
Understanding Networked Multimedia, Prentice Hall.
Boyle.
(1998).Design for Multimedia Learning, Prentice Hall, (ISBN 0-13-242155-8) Agnew, P.W.
and Kellerman, A.S. (1996).
Distributed Multimedia: Technologies, Applications, and Opportunities in the Digital Information Industry (1st Edition) Addison Wesley.
Sloane, McGraw Hill.
(2002).
Multimedia Communication, (ISBN 0-077092228) 93 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Vaughan, Tay, 1998, Multimedia: Making It Work (first edition) Osborne/McGraw-Hill, Berkeley.
Maurer H, (1996).
Hyperwave: The Next Generation Web Solution, Addison Wesley, (ISBn 0-201-40346).
Watkinson, (2004).
The Art of Digital Audio, -Heinmann.
Synthesizer Basics, GPI Publications.
UNIT 3 PROTOCOLS CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Protocols 3.1.1 Session Control Protocol 3.1.2 Real Time Transfer Protocol 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION In this unit, we shall define what a protocol and its different elements.
This will facilitate a deeper understanding of the different multimedia applications.
2.0 OBJECTIVES At the end of this unit, you should be able to: • Give a concise definition of a Protocol • Identify the features of the elements of a protocol.
• Differentiate between a Session control protocol and a real time transfer protocol 94 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 3.0 MAIN CONTENT 3.1 PROTOCOL In computer networks, communication occurs between entities in different systems.
An entity is anything capable of sending or receiving information.
However two entities cannot simply send bit streams to each other and expect to be understood.
For communication to occur, the entities must agree on a protocol.
A protocol is a set of rules that govern data communications.
A protocol defines what is communicated, and when it is communicated.
The key elements of a protocol are syntax, semantics and timing.
Syntax: The term syntax refers to the structure or format of the data, meaning the order in which they are presented.
For example, a simple protocol might expect the first 8 bits to be the address of the receiver, and the rest of the stream to be the message itself.
Semantics: The word Semantics refers to the meaning of each section of bits.
How is a particular pattern to be interpreted, and what action is to be taken based on that interpretation?
For example does an address identify the route to be taken or the final destination of the message?
Timing: The term timing refers to two characteristics: when data should be sent and how fast they can be sent.
For example, if the sender produces data at 100Mbps but the receiver can process data at only1Mbps, the transmission will overload the receiver and some data will be lost.
Some examples of major protocols are explained below.
3.1.1 SESSION CONTROL PROTOCOL Session Control Protocol (SCP) is a simple protocol which lets a server and client has multiple conversations over a single TCP connection.
The protocol is designed to be simple to implement, and is modelled after TCP.
(Transport Control Protocol) SCP's main service is dialogue control.
This service allows either end of the connection to establish a virtual session over a single transport connection.
SCP also allows a sender to indicate message boundaries, and allows a receiver to reject an incoming session.
SCP allows 95 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY data to be sent with the session establishment; the recipient does not confirm successful connection establishment, but may reject unsuccessful attempts.
This simplifies the design of the protocol, and removes the latency required for a confirmed operation.
Session Control Protocol has a fixed overhead of 8 bytes per segment.
This overhead is half the size of an IPNG address, and is only incurred once per segment, instead of once per packet.
In its design, the session control protocol should be simple enough to implement for a single application.
3.1.2 REAL-TIME TRANSFER PROTOCOL (RTP) Real-time Transfer Protocol (RTP) is the Internet-standard protocol for the transport of real-time data, including audio and video.
It can be used for media-on-demand as well as interactive services such as Internet telephony.
RTP consists of a data and a control part.
The latter is called RTCP.
The data part of RTP is a thin protocol providing support for applications with real-time properties such as continuous media (e.g., audio and video), including timing reconstruction, loss detection, security and content identification.
RTCP provides support for real-time conferencing of groups of any size within an Internet.
This support includes source identification and support for gateways like audio and video bridges as well as multicast-to-unicast translators.
It also offers quality-of-service feedback from receivers to the multicast group as well as support for the synchronization of different media streams.
SELF ASSESSMENT EXERCISE State the basic features of a Session Control protocol and a real time transfer protocol?
4.0 CONCLUSION In this unit, we considered some of the transfer protocols in the multimedia System.
Some of them are Session Control Protocol, real time transfer protocol etc.
We equally studies about the key elements of a protocol.
5.0 SUMMARY 96 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY A protocol is a set of rules that govern data communications.
A protocol defines what is communicated, and when it is communicated.
The key elements of a protocol are syntax, semantics and timing.
6.0 TUTOR MARKED ASSIGNMENT 1).Explain what you understand by the Term Protocol 2) List and explain the major elements of a Protocol.
7.0 REFERENCES/FURTHER READINGS Chellis, James et.al (1997) MSCE: Networking Essentials Study Guide Sybex Network Press, San Francisco Ifeachor, E. C., and Jervis, B. W.,( 2002) Digital Signal Processing: A Practical Approach (Harlow, England: Pearson Education Limited) Rabiner, L.R., and Gold, B., (1975): Theory and Application of Digital Signal Processing (Englewood Cliffs, New Jersey: Prentice-Hall, Inc.) Larsen E., Aarts R.M.
(March 2002).
"Reproducing low-pitched signals through small loudspeakers" (PDF).
J.
Audio Eng.
Soc.
50 (3): 147–164.
http://www.extra.research.philips.com/hera/people/aarts/papers/aar02n4.pdf.
UNIT 4 VIDEO CONFERENCE CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1VideoConference 3.1.1 Dedicated System 3.1.2 Desktop System 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 97 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 1.0 INTRODUCTION In this unit, you'll gain knowledge of the concept of Video conferencing.
You would also learn about the different types of video conferencing system.
2.0 OBJECTIVES What you would study in this unit would equip you to do the following: • What is Video Conferencing • In your own words explain the concept of Video Conferencing • Identify the types of Video Conferencing Systems 3.0 MAIN CONTENT 3.1 Video Conference A videoconference or video conference (also known as a video teleconference) is a set of interactive telecommunication technologies that allows two or more locations to interact via two-way video and audio transmissions simultaneously.
It has also been called 'visual collaboration' and is a type of groupware.
Videoconferencing differs from videophone calls in that it's designed to serve a conference rather than individuals.
The core technology used in a videoconferencing system is digital compression of audio and video streams in real time.
The hardware or software that performs compression is called a codec (coder/decoder).The components required for a videoconferencing system includes: • Video input : video camera or webcam • Video output: computer monitor , television or projector • Audio input: microphones, CD/DVD player, cassette player, or any other source of PreAmp audio outlet.
• Audio output: usually loudspeakers associated with the display device or telephone • Data transfer: analog or digital telephone network, LAN or Internet.
3.1.1 DEDICATED SYSTEMS There are basically two types of videoconferencing systems: Dedicated and Deskstop systems which are examined below.
Dedicated systems have all required components packaged into a single piece of equipment, usually a console with a high quality remote controlled video camera.
These cameras can be 98 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY controlled at a distance to pan left and right, tilt up and down, and zoom.
They became known as PTZ cameras.
The console contains all electrical interfaces, the control computer, and the software or hardware-based codec.
Omni-directional microphones are connected to the console, as well as a TV monitor with loudspeakers and/or a video projector.
There are several types of dedicated videoconferencing devices: Large group videoconferencings are non-portable, large, more expensive devices used for large rooms and auditoriums.
Small group videoconferencings are non-portable or portable, smaller, less expensive devices used for small meeting rooms.
Individual videoconferencing are usually portable devices, meant for single users, have fixed cameras, microphones and loudspeakers integrated into the console.
3.1.2 DESKTOP SYSTEMS Desktop systems are add-ons (hardware boards, usually) to normal PCs, transforming them into videoconferencing devices.
A range of different cameras and microphones can be used with the board, which contains the necessary codec and transmission interfaces.
Most of the desktops systems work with the H.323 standard.
Videoconferences carried out via dispersed PCs are also known as e-meetings.
SELF ASSESSMENT EXERCISE What are the components required for a video Conferencing System?
__________________________________________________________ __________________________________________________________ __________________________________________________________ 4.0 CONCLUSION To wrap up, we discovered that Videoconferencing uses telecommunications of audio and video to bring people at different sites together for meetings, conferences etc.
5.0 SUMMARY In this unit, we covered the concept of Video Conferencing and its types.
W e also discovered that the core technology used in a videoconferencing system is digital compression of audio and video streams in real time.
The hardware or software that performs 99 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY compression is called a codec (coder/decoder).The components required for a videoconferencing system includes video output, video input, audio output, audio input etc.
6.0 TUTOR MARKED ASSIGNMENTS 1).Explain the features of the dedicated and the desktop systems of Video Conferencing?
2) What are components required for a video conferencing system 3) Describe the Term “Video Conferencing” 7.0 REFERENCES / FURTHER READINGS Wolfe, Mark.
(2007) “Broadband videoconferencing as Knowledge Management tool,” Journal of Knowledge Management 11, no.
2 Ferran, Carlos and Watts, Stephanie.
(2008) “Videoconferencing in the field: A heuristic processing model,” Management Science 54, no.
9 Tokson, Matthew J.
(2007) Virtual Confrontation: Is Videoconference Testimony by a Witness Constitutional?
University of Chicago Law Review, , Vol.
74, No.
4.
Amy B. Woszczynski et.al( 2008), Handbook of Distance Learning for Real-Time and Asynchronous Information Technology Education, Idea Group Inc (IGI), 2008, pg.
17, ISBN 1-59904-964-3, ISBN 978-1-59904-964-9.
Jackman, Elizabeth (2010) New Video Conferencing System Streamlines Fire fighter Training, ---Peoria Times, Peoria, AZ, February 100 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY MODULE 5 MULTIMEDIA ACCESS SYSTEMS Unit 1 Internet Telephony Unit 2 Computer Telephony Integration Unit 3 Digital Subscriber Line Unit 4 Digital/ Cable Television UNIT 1 INTERNET TELEPHONY CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Internet Telephony 3.2.1 Super nodes in Internet Telephony 3.2.2 VoIP vs Internet telephony 3.2.3 Advantages & Disadvantages of Internet Telephony 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION Internet Telephony refers to communications services—voice, fax, SMS, and/or voice- messaging applications—that are transported via the Internet, rather than the public switched telephone network (PSTN).
In this unit, we shall consider deeply the concept of Internet Telephony as this will give a deeper understanding of the relationship between VoIP and the Internet Telephony.
2.0 OBJECTIVES At the end of this unit, you should be able to: • Describe Internet Telephony Service • Identify the steps involved in processing a VoIP call.
• List the advantages and Disadvantages of Internet Telephony 101 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 3.0 MAIN CONTENT 3.1 INTERNET TELEPHONY Internet Telephony refers to communications services—voice, fax, SMS, and/or voice- messaging applications—that are transported via the Internet, rather than the public switched telephone network (PSTN).
The steps involved in originating a VoIP telephone call are signalling and media channel setup, digitization of the analog voice signal, encoding, packet- ting , and transmission as Internet Protocol (IP) packets over a packet-switched network.
On the receiving side, similar steps (usually in the reverse order) such as reception of the IP packets, decoding of the packets and digital-to-analog conversion reproduce the original voice stream.
Internet telephony makes use of the Internet instead of traditional telephone lines for the purposes of conversation.
In Internet telephony, voice is transported via the Internet instead of the Public Switched Telephone Network or PSTN.
The basic operation of internet telephony system commences when a person talks into a microphone.
The microphone is in turn connected to a sound card installed in the computer, which accepts an analogue waveform and converts it into a digital data stream.
Internet telephony software operating on the computer takes the digitized voice data stream, which normally represents a 64-Kbps PCM or 32- Kbps ADPCM- encoded voice and compresses the standard encoding data stream into a lower data rate based on the use of a proprietary or standardized voice compression technique.
There are two primary transport protocols used for an internet telephony session.
Transmission control Protocol (TCP) is used to transport addressing or directory information while User datagram protocol (UDP) is used for the actual transfer of voiced-digitized packets.
3.2.1 SUPERNODES IN INTERNET TELEPHONY A super node assists other users to communicate or use Skype software efficiently.
One computer helps other computers anonymously, and securely facilitates communication between other Skype users who cannot establish a direct connection due to firewall 102 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY constraints.
Super node communication forwards requests and does other operations on behalf of ordinary nodes.
Users are unaware of the super node’s assistance.
3.2.2 VoIP vs INTERNET TELEPHONY Internet telephony refers to communication using the Internet.
VoIP refers to making phone calls over an enterprise network.
In VoIP, users place calls using IP phones.
VoIP is a full duplex (two-way) system where both parties can talk at the same time.
A conventional telephone system is full-duplex.
In Internet telephony, only one person can speak at a time.
3.2.3 ADVANTAGES AND DISADVANTAGES OF INTERNET TELEPHONY Internet telephony is an advantage to both developers and clients because the Internet telephony service provider (ITSP) can use a single infrastructure for both Internet access and Internet telephony.
It also results in better bandwidth utilisation.
Calls between two users using the same software are free.
Users have the benefits of receiving voice mail messages when they are busy or offline, ease of use, and cheap international calls.
Skype, the most popular Internet telephony application at this point, is freeware, ad-free and has no spyware.
Some disadvantages exist.
Users need to have a PC and a broadband connection to use this facility.
To conduct a free conversation both the users need similar software.
Callers cannot keep live track of call cost, and the software experiences bad call reception when using other programs at the same time.
SELF ASSESSMENT EXERCISE What do you understand by the term Internet Telephony?
8.0 CONCLUSION In this unit you have learnt about the concept of Internet Telephony and its features.
You have also learnt that about the relationship between VoIP and the Internet Telephony.
5.0 SUMMARY Internet Telephony refers to communications services—voice, fax, SMS, and/or voice- messaging applications—that are transported via the Internet, rather than the public switched 103 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY telephone network (PSTN).
VoIP is a full duplex (two-way) system where both parties can talk at the same time.
A conventional telephone system is full-duplex.
In Internet telephony, only one person can speak at a time.
6.0 TUTOR MARKED ASSIGNMENT 1).Distinguish between the VoIP and the Internet Telephony 2).Explain the Advantages and disadvantages of the Internet Telephony.
3) Explain the concept of Super nodes in Internet Telephony.
4).What is the significance of a Super node in Internet Telephony?
7.0 REFERENCES/FURTHER READINGS Behouz, F.A (2007) Data Communucations and Networks.
Mc Graw Hill.
Boston.
Gill ,Held (2007) Voice and Data Internetworking.
Mc Graw Hill, New York Parsons, J and Dan O (2004) Computer Concepts 7TH edition.
Thomson Learning Inc. Australia.
Ifeachor, Emmanuel C., and Jervis, Barrie W., 2002: Digital Signal Processing: A Practical Approach (Harlow, England: Pearson Education Limited) Rabiner, Lawrence R., and Gold, Bernard, 1975: Theory and Application of Digital Signal Processing (Englewood Cliffs, New Jersey: Prentice-Hall, Inc.) Larsen E., Aarts R.M.
(March 2002).
"Reproducing low-pitched signals through small loudspeakers" (PDF).
J.
Audio Eng.
Soc.
50 (3): 147–164.
http://www.extra.research.philips.com/hera/people/aarts/papers/aar02n4.pdf.
UNIT 2 COMPUTER TELEPHONY INTEGRATION CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Computer Telephony Integration 3.1.1 First party call control 104 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 3.1.2 Third party call control 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION In this unit we will consider the technology known as the Computer Telephony Integration.
The unit will equally analyse the origins, functions and forms of Computer Telephony Integration.
2.0 OBJECTIVES At the end of this unit, you should be able to: • Give a concise description of the forms of Computer Telephony Integration?
• Explain the need for a computer Telephony Integration • Explain the First-party call control form of CTI 3.0MAIN CONTENT 3.1 COMPUTER TELEPHONY INTEGRATION Computer telephony integration, also called computer–telephone integration or CTI, is technology that allows interactions on a telephone and a computer to be integrated or co- ordinated.
As contact channels have expanded from voice to include email, web, and fax, the definition of CTI has expanded to include the integration of all customer contact channels (voice, email, web, fax, etc.)
with computer systems.
The origins of CTI can be found in simple screen population (or "screen pop") technology.
This allows data collected from the telephone systems to be used as input data to query databases with customer information and populate that data instantaneously in the customer service representative screen.
The net effect is the agent already has the required screen on his/her terminal before speaking with the customer.
These are some of the Functions of the CTI: • Call information display (caller's number (ANI), number dialled (DNIS), and Screen population on answer, with or without using calling line data 105 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY • Automatic dialling and computer controlled dialling (fast dial, preview, and predictive dial.)
• Phone control.
(answer, hang up, hold, conference, etc.)
• Coordinated phone and data transfers between two parties (i.e.
pass on the Screen pop with the call) • Call centre phone control.
(logging on; after-call work notification) • Advanced functions such as call routing, reporting functions, automation of desktop activities, and multi-channel blending of phone, e-mail, and web requests • Agent state control (for example, after-call work for a set duration, then automatic change to the ready state) There are two forms of CTI.
They are the First-party call control and Third-party call control.
3.1.1 FIRST PARTY CALL CONTROL First party call control operates as if there is a direct connection between the user's computer and the phone set.
An example of this would be a modem card in a desktop computer, or a phone plugged directly into the computer.
Typically, only the computer associated with the phone can control it, by sending commands directly to the phone.
The computer can control all the functions of the phone, normally at the computer user's direction.
First party call control is the easiest to implement but is not suited to large scale applications such as call centres 3.1.2 THIRD-PARTY CALL CONTROL Third-party call control is more difficult to implement and often requires a dedicated telephony server to interface between the telephone network and the computer network.
Third party call control works by sending commands from a user's computer to a telephony server, which in turn controls the phone centrally.
Specifically, the user's computer has no direct connection to the phone set, which is actually controlled by an external device.
Information about a phone call can be displayed on the corresponding computer workstation's screen while instructions to control the phone can be sent from the computer to the telephone network.
Any computer in the network has the potential to control any phone in the telephone system.
The phone does not need to be attached directly to the user's computer, although it may physically be integrated into the computer (such as a VoIP soft phone), requiring only a 106 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY microphone and headset in the circuit, without even a keypad, to connect to the telephone network.
SELF ASSESSMENT EXERCISE Explain the principles of Computer Telephony Integration __________________________________________________________ __________________________________________________________ __________________________________________________________ 4.0 CONCLUSION We have introduced to you that CTI is technology that allows interactions on a telephone and a computer to be integrated or co-ordinated.
We discovered that there are two forms of the CTI and they are the First-party call control and Third-party call control 5.0 SUMMARY In summary, this unit looked at the basic information about Computer Telephony Integration.
We also considered the different forms of Computer Telephony Integration.
You can now attempt the questions below.
5.0 TUTOR MARKED ASSIGNMENT 1) Explain what a Computer Telephony Integration is 1).
Give a concise description of the functions of the CTI 2).
Explain the differences between the First-party call control and Third-party call control 7.0 REFERENCES/FURTHER READINGS Boyle.
(1998).Design for Multimedia Learning, Prentice Hall, (ISBN 0-13-242155-8) P.W.
Agnew and A.S. Kellerman.
(1996).
Distributed Multimedia: Technologies, Applications, and Opportunities in theDigital Information Industry (1st Edition) Addison Wesley.
107 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY Sloane, McGraw Hill.
(2002).
Multimedia Communication, (ISBN 0-077092228) Vaughan, Tay, 1998, Multimedia: Making It Work (first edition) Osborne/McGraw-Hill, Berkeley.
Shuman,J.
G.(2002).
Multimedia Elements.
Multimedia in Action.
Vikas Publishing House Pvt Ltd. H. Maurer, Addison Wesley, (1996).
Hyperwave: The Next Generation Web Solution, (ISBn 0-201-40346).
T. Kientzle, Addison Wesley, 1997.
A programmer's Guide to Sound, (ISBN 0-201-41972-6) Watkinson, (2004).
The Art of Digital Audio, -Heinmann.
Synthesizer Basics, GPI Publications.
James D. Murray and William van Ryper, (1996).
Encyclopaedia of Graphics File Formats, Second Edition, O'Reilly & Associates.
UNIT 3 DIGITAL SUBSCRIBER LINE CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Digital Subscriber Line 3.2 Types of Digital Subscriber Line 3.2.1Asymmetric Digital Subscriber Line (ADSL) 3.2.2 High Bit Rate Digital Subscriber Line (HDSL) 3.3.3 Symmetric Digital Subscriber Line (SDSL) 3.3.4Very High Bit Rate Digital Subscriber Line (VDSL) 3.5 Summary of Digital Subscriber Technologies 4.0 Conclusion 108 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION After traditional modems reached their peak data rate, telephone companies developed another technology, DSL (Digital Subscriber Line), to provide higher speed access to the internet.
Digital Subscriber line technology is one of the most promising for supporting high speed digital communication over the existing local loops.
There are several other types of the Digital Subscriber Line; some of them will be discussed below.
2.0 OBJECTIVES At the end of this unit, you should be able to: • Describe what Digital Subscriber Line is • Discuss the features of the Digital Subscriber Technology • Compare the differences between the different types of Technologies.
3.0 MAIN CONTENT 3.1 DIGITAL SUBSCRIBER LINE Digital Subscriber Line (DSL) is a family of technologies that provides digital data transmission over the wires of a local telephone network.
It is a high-speed Internet service that competes with cable Internet to provide online access to local customers.
DSL operates over standard copper telephone lines like dial-up service, but is many times faster than dial- up.
In addition to being a faster than dial-up, DSL does not tie up the phone line.
Coexisting with telephone service in this way allows users to surf the Net and use the phone at the same time.
DSL service requires a DSL modem, which connects to the telephone wall jack and computer.
The device acts as a modulator, translating the computer’s digital signals into voltage sent across the telephone lines to a central hub known as a Digital Subscriber Line Access Multiplier (DSLA M, or dee-slam).
In lay terms the DSLAM acts as a switchboard for local DSL clients, routing requests and responses between each client’s computer address and the Internet.
Voice calls and DSL can coexist on copper lines because each service utilizes its own frequency band.
109 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY The DSL “service lane” is split for a two-way traffic, or downstream and upstream signals.
When you click on a link, you are requesting something from the Internet, initiating upstream traffic.
The returned webpage arrives as downstream traffic.
Since requests only require small bits of data, the upstream lane can be fairly narrow (low bandwidth), but the downstream lane must be much wider (high bandwidth) to send WebPages, multimedia, graphics, files and programs.
Thus, standard DSL is called Asynchronous DSL or ADSL, because the download speed is much faster than the upload speed.
3.2.1 ASYMMETRIC DIGITAL SUBSCRIBER LINE (ADSL) The first technology in the set is asymmetric DSL (ADSL).
ADSL, like a 56K modem, provides higher speed (bit rate) in the downstream direction (from the Internet to the resident) than in the upstream direction (from the resident to the Internet).
That is the reason it is called asymmetric.
Unlike the asymmetry in 56K modems, the designers of ADSL specifically divided the available bandwidth of the local loop unevenly for the residential customer.
The service is not suitable for business customers who need a large bandwidth in both directions.
3.2.2 HIGH BIT RATE DIGITAL SUBSCRIBER LINE (HDSL) The high-bit-rate digital subscriber line (HDSL) was designed as an alternative to the T-1 line (1.544 Mbps).
The T-1 line uses alternate mark inversion (AMI) encoding, which is very susceptible to high frequencies.
This limits the length of a T-1 line to 3200 ft (1 km).
For longer distances, a repeater is necessary, which means increased costs.
HDSL uses 2B1Q encoding, which is less susceptible to attenuation.
A data rate of 1.544 Mbps (sometime up to 2 Mbps) can be achieve without repeaters up to a distance of 12,000 ft (3.86 km).
HDSL uses two twisted pairs (one pair for each direction) to achieve full-duplex transmission.
3.2.3 SYMMETRIC DIGITAL SUBSCRIBER LINE (SDSL) The symmetric digital subscriber line (SDSL) is a one twisted-pair version of HDSL.
It provides full-duplex symmetric communication supporting up to 768 kbps in each direction.
SDSL, which provides symmetric communication, can be considered an alternative to ADSL.
ADSL provides asymmetric communication, with a downstream bit rate that is much higher than the upstream bit rate.
Although this feature meets the needs of most residential 110 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY subscribers, it is not suitable for businesses that send and receive data in large volumes in both directions.
3.2.4 VERY HIGH BIT RATE DIGITAL SUBSCRIBER LINE (VDSL) The very high-bit-rate digital subscriber line (VDSL), an alternative approach that is similar to ADSL, uses coaxial, fibre-optic, or twisted-pair cable for short distances.
T he modulation technique is DMT.
It provides a range of bit rates (25 to 55 Mbps) for upstream communication at distances of 3000 to 10,000 ft. the downstream rate is normally 3.2 Mbps.
The figure below shows the summary of DSL technologies.
Note that the data rate and distances are approximations and can vary from one implementation to another.
3.5 SUMMARY OF DSL TECHNOLOGIES Technology Downstream Upstream Distance (ft) Twisted Line Code Rate Rate Pairs ADSL 1.5-6.1 Mbps 16-640 kbps 12,000 1 DMT ADSL Lite 1.5 Mbps 500 kbps 18,000 1 DMT HDSL 1.5-2.0 Mbps 1.5-2.0 Mbps 12,000 2 2B1Q SDSL 768 kbps 768 kbps 12,000 1 2B1Q VDSL 25-55 Mbps 3.2 Mbps 3000-10,000 1 DMT SELF ASSESSMENT EXERCISE What do you understand by a DSLAM __________________________________________________________ __________________________________________________________ __________________________________________________________ 4.0 CONCLUSION Digital subscriber line is a high speed, digital, always on the internet access technology that runs over standard phone lines.
It is one of the fastest internet connections that is affordable to individuals.
A Digital Subscriber Line (DSL) connection can simultaneously carry voice 111 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY and data, if permitted by the DSL provider.
The digital data and analogue voice signals travel over the DSL line to the local switching station.
5.0 SUMMARY In summary, this unit looked at the basic information about the Digital Subscriber Line.
We also considered the different forms of DSL.
Please attempt the questions below.
6.0 TUTOR MARKED ASSIGNMENT 1).
State 2 reasons for a Digital Subscriber Modem.
2).
Explain the differences between the different types of Digital Subscriber Lines 3) What a digital Subscriber line 7.0 REFERENCES/FURTHER READINGS Behouz, F.A (2007) Data Communucations and Networks.
Mc Graw Hill.
Boston.
J.F.K, Buford.
(1994).
Multimedia Systems, ACM Press, (ISBN 0-201-53258-1).
Fluckiger.
(1994).
Understanding Networked Multimedia, Prentice Hall.
Chellis, James et.al (1997) MSCE: Networking Essentials Study Guide Sybex Network Press, San Francisco Boyle.
(1998).Design for Multimedia Learning, Prentice Hall, (ISBN 0-13-242155-8) Agnew P.W.
and Kellerman.
A.S. (1996).
Distributed Multimedia: Technologies, Applications, and Opportunities in the Digital Information Industry (1st Edition) Addison Wesley.
Vaughan, Tay, (1998) Multimedia: Making It Work (first edition) Osborne/McGraw-Hill, Berkeley, pg.
3.
J. G. Shuman, (2002).
Multimedia Elements.
Multimedia in Action.
Vikas Publishing House Pvt Ltd. 112 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY T. Kientzle,(1997).
A programmer's Guide to Sound, Addison Wesley,(ISBN 0-201-41972-6) James D. M and William,V R, (1996).
Encyclopaedia of Graphics File Formats, Second Edition, O'Reilly & Associates.
UNIT 4 DIGITAL TELEVISION /CABLE TELEVISION CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Digital Television 3.2 Cable Television 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION In this unit, we will study the features and attributes of the Cable Television and the Digital Television.
2.0 OBJECTIVES What you would study in this unit, would enable you to: • Explain the basic features of a Digital Television • Discover the advantages of the Digital Television over the Analogue Television • Discuss the major features of a Cable Television 3.1 DIGITAL TELEVISION Digital television (DTV) is the transmission of audio and video by digital signals, in contrast to the analogue signals used by analogue TV.
Many countries are replacing over-the-air 113 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY broadcast analogue television with digital television to allow other uses of the radio spectrum formerly used for analogue TV broadcast.
Digital television supports many different picture formats defined by the combination of size, aspect ratio (width to height ratio) and interlacing.
With digital terrestrial television broadcasting, the range of formats can be broadly divided into two categories: HDTV and SDTV.
These terms by themselves are not very precise, and many subtle intermediate cases exist.
DTV has several advantages over analogue TV, the most significant being that digital channels take up less bandwidth, and the bandwidth needs are continuously variable, at a corresponding reduction in image quality depending on the level of compression as well as the resolution of the transmitted image.
This means that digital broadcasters can provide more digital channels in the same space, provide high-definition television service, or provide other non-television services such as multimedia or interactivity.
DTV also permits special services such as multiplexing (more than one program on the same channel), electronic program guides and additional languages (spoken or subtitled).
Digital signals react differently to interference than analogue signals.
For example, common problems with analogue television include ghosting of images, noise from weak signals, and many other potential problems which degrade the quality of the image and sound, although the program material may still be watchable.
With digital television, the audio and video must be synchronized digitally, so reception of the digital signal must be very nearly complete; otherwise, neither audio nor video will be usable.
3.2 CABLE TELEVISION Cable television is a system of providing television to consumers via radio frequency signals transmitted to televisions through coaxial cables or Digital light pulses though fixed optical fibres located on the subscriber's property.
It is much like the over-the-air method used in traditional television broadcasting (via radio waves) in which a television antenna is required.
FM radio programming, high-speed Internet, telephony, and similar non-television services may also be provided.
The major difference is the change of radio frequency signals used and optical connections to the subscriber property.
114 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY The abbreviation CATV is often used to mean "Cable TV".
It originally stood for Community Antenna Television, from cable television's origins in 1948: in areas where over-the-air reception was limited by distance from transmitters or mountainous terrain, large "community antennas" were constructed, and cable was run from them to individual homes.
The origins of cable broadcasting are even older as radio programming was distributed by cable in some European cities as far back as 1924.It is most commonplace in North America, Europe, Australia and East Asia, though it is present in many other countries, mainly in South America and the Middle East.
Coaxial cables are capable of bi-directional carriage of signals as well as the transmission of large amounts of data.
Cable television signals use only a portion of the bandwidth available over coaxial lines.
This leaves plenty of space available for other digital services such as cable internet, cable telephony and wireless services, using both unlicensed and licensed spectrum.
Broadband Internet is achieved over coaxial cable by using cable modems to convert the network data into a type of digital signal that can be transferred over coaxial cable.
Many large cable systems have upgraded or are upgrading their equipment to allow for bi- directional signals, thus allowing for greater upload speed and always-on convenience, though these upgrades are expensive.
4.0 CONCLUSION In conclusion, we looked into the features of the Cable Television as a system of providing television to consumers via radio frequency signals transmitted to televisions through coaxial cables or Digital light pulses though fixed optical fibres located on the subscriber's property while the Digital Television is the transmission of audio and video by digital signals.
5.0 SUMMARY In summary, we learnt about the different access networks to Information.
Some of these examples are the Cable Television and the digital Television.
Hope you grasped these key points?
You can now attempt the questions below.
6.0 TUTOR MARKED ASSIGNMENT 1).List the common features of a digital Television 2).Give 3 Advantages of a Digital Television over an analogue Television 115 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY 3).Explain what a Cable Television is SELF ASSESSMENT EXERCISE What are the differences between a Digital and an Analogue Television?
_________________________________________________________ __________________________________________________________ __________________________________________________________ __________________________________________ 7.0 REFERENCES/FURTHER READINGS Agnew ,P.W & Kellerman A.S.. (1996).
Distributed Multimedia: Technologies, Applications, and Opportunities in the Digital Information Industry (1st Edition) Addison Wesley.
Behouz, F.A (2007) Data Communucations and Networks.
Mc Graw Hill.
Boston.
Boyle.
(1998).Design for Multimedia Learning, Prentice Hall, (ISBN 0-13-242155-8) Parsons, J and Dan O (2004) Computer Concepts 7TH edition.
Thomson Learning Inc. Australia.
Vaughan, Tay, 1998, Multimedia: Making It Work (first edition) Osborne/McGraw-Hill, Berkeley.
Shuman,J.
G.(2002).
Multimedia Elements.
Multimedia in Action.
Vikas Publishing House Pvt Ltd. Watkinson, (2004).
The Art of Digital Audio, -Heinmann.
Synthesizer Basics, GPI Publications.
Brook and Wynne, Hodder and Stoughton (2001).Signal Processing: Principles and Applications.
116 CIT 463 INTRODUCTION TO MULTIMEDIA TECHNOLOGY James D. M and William V R, (1996).
Encyclopaedia of Graphics File Formats, Second Edition, O'Reilly & Associates.
117
