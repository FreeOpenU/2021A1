 NATIONAL OPEN UNIVERSITY OF NIGERIA SCHOOL OF SCIENCE AND TECHNOLOGY COURSE CODE: MTH 213 COURSE TITLE: NUMERICAL ANALYSIS 1 Course Code MTH 213 Course Title NUMERICAL ANALYSIS 1 Course Developer Dr. Ajibola S. O.
National Open University of Nigeria Lagos Content Editor Dr. ABIOLA.
Bankole National Open University of Nigeria Lagos Course Coordinator Dr. Ajibola S. O.
National Open University of Nigeria Lagos Programme Leader Dr. ABIOLA.Bankole National Open University of Nigeria Lagos NATIONAL OPEN UNIVERSITY OF NIGERIA ii COURSE GUIDE MTH213 National Open University of Nigeria Headquarters 14/16 Ahmadu Bello Way Victoria Island Lagos Abuja Office 5, Dar Es Salaam Street Off Aminu Kano Crescent Wuse II, Abuja Nigeria.
e-mail: centralinfo@nou.edu.ng URL: www.nou.edu.ng National Open University of Nigeria 2006 First Printed 2008 ISBN: All Rights Reserved Printed by: For National Open University of Nigeria iiiCONTENT PAGE Module 1 Interpolation………………………………… 1 Unit 1 Interpolation (Lagrange’s Form)…………….. 1 Unit 2 Newton’s Form of the Interpolating Polynomial 15 Unit 3 Interpolation at Equally Spaced Points……… 31 Module 2 Solution of Linear Algebraic Equations…… 55 Unit 1 Direct Method………………………………… 55 Unit 2 Inverse of A Square Matrix…………………… 91 Unit 3 Iterative Methods……………………………… 112 Unit 4 Eigen-Values and Eigen-Vectors……………… 135 Module 3 Solution of Non-Linear Equations in one Varibale ………………………………….
159 Unit 1 Review of Calculus…………………………… 159 Unit 2 Iteration Methods for Locating Root………….
189 Unit 3 Chord Methods for Finding Root……………... 208 Unit 4 Approximate Root of Polynomial Equation…... 235 iv COURSE GUIDE MTH213 COURSE GUIDE MTH 213 NUMERICAL ANALYSIS 1 Course Developer Dr. Ajibola S. O.
National Open University of Nigeria Lagos Content Editor Dr. ABIOLA.
Bankole National Open University of Nigeria Lagos Course Coordinator Dr. Ajibola S. O.
National Open University of Nigeria Lagos Programme Leader Dr. ABIOLA.
Bankole National Open University of Nigeria Lagos NATIONAL OPEN UNIVERSITY OF NIGERIA vNational Open University of Nigeria Headquarters 14/16 Ahmadu Bello Way Victoria Island Lagos Abuja Office 5, Dar Es Salaam Street Off Aminu Kano Crescent Wuse II, Abuja Nigeria.
e-mail: centralinfo@nou.edu.ng URL: www.nou.edu.ng National Open University of Nigeria 2008 First Printed 2008 ISBN: All Rights Reserved Printed by …………….. For National Open University of Nigeria vi COURSE GUIDE MTH213 CONTENTS PAGE Introduction…………………………………………….
1 The Course ...…………………………………………... 1 Course Aims & Objectives ..…………………………… 2 Working through the course…………………………… 2 Course materials……………………………………….. 2 Study Units…………………………………………….. 3 Textbooks………………….…………………………... 4 Assessment……………………………………………... 5 Tutor-Marked Assignments…………………………….
5 End of Course Examination…………………………….
5 Summary……………………………………………….
5 viiNoneMTH 213 MODULE 3 Introduction MTH 213: Discussion of Lagrange’s form for; The technique of determining an approximate value of f(x) for a non-tabular value of x which lies in the internal [a, b] is called interpolation.
The process of determining the value of f(x) for a value of x lying outside the interval [a, b] is called extrapolation.
The Lagrange’s form of the interpolating polynomial derived above has same draw backs compared to Newton’s form of interpolating polynomial.
Before deriving Newton’s general form of interpolating polynomial.
We introduce the concept of divided difference and the tabular representation of divided differences.
Numerical solution of systems of linear algebraic equations play a prominent role in boundary value problems, for ordinary and partial differential equations, statistical influence, optimization theory, least square fittings of data etc.
Numerical methods for solving linear algebraic system may be divided into two types, direct and iterative.
To understand the numerical methods for solving linear system of equations, it is necessary to have some knowledge of the properties of matrices.
The prerequisite to the course shall be linear Algebra courses.
The Course As a 3-credit unit course, 11 study units grouped into 3 modules of 3 units in module 1, 4 units in module 2 and 4 units in module 3.
This course guide gives a brief summary of the total contents contained in the course material.
The fundamental theorem of algebra and its useful calories, inverse interpolation and errors.
Newton’s form of the interpolating polynomial features divided differences and interpolating polynomial error types.
Likewise interpolating at equally spaced points, here we talked about differences.
For equally spaced nodes, we shall deal with three types of differences, namely forward, backward and central and discuss their representation in the form of a table.
Also discussed her are some direct and iterative methods for finding the solution of system of linear algebraic equations.
Lastly, we discussed three fundamental theorems, namely; intermediate value theorem, Rolle’s theorem and Lagrange’s mean value theorem.
All these theorems give properties of continues functions defined on a 159MTH 213 NUMERICAL ANALYSIS 1 closed interval [a, b].
Although the theorems are not proved but their utility was illustrated with examples.
Course Aim & Objectives On the completion of this course, you are expected to: •••• find the Lagrange’s form of interpolating polynomial •••• complete the approximate value of f at a non-tabular point.
•••• Complete the error omitted in interpolation, if the function is known at a non-tabular point of interest.
•••• Find an upper bound in the magnitude of the error.
•••• Write forward, backward and central differences in terms of function values from a table of either difference and locate a difference of given order at given point.
•••• Obtain the interpolating polynomial of f(x) for a given data by applying any one of the interpolating formulae.
•••• Obtain the solution of systems of linear algebraic equations by using the direct methods such as Cramer’s rule, Gauss elimination method Lu decomposition method.
Working through the Course This course involves that you would be required to spend lot of time to read.
The content of this material is very dense and require you spending great time to study it.
This accounts for the great effort put into its development in the attempt to make it very readable and comprehensible.
Nevertheless, the effort required of you is still tremendous.
I would advice that you avail yourself the opportunity of attending the tutorial sessions where you would have the opportunity of comparing knowledge with your peers.
The Course Material You will be provided with the following materials: Course Guide Study Units In addition, the course comes with a list of recommended textbooks, which through are not compulsory for you to acquire or indeed read, are necessary as supplements to the course material.
160 MTH 213 MODULE 3 Study Units The following are the study units contained in this course.
The units are arranged into 3 identifiable but readable modules.
Module 1 Unit 1 Interpolation (Lagrange’s Form) This unit takes one through the definition of interpolation, inverse interpolation and error.
Unit 2 Newton’s Form of the Interpolating Polynomial This unit is sub-divided into divided difference Newton’s General Form of interpolating polynomial, and the error of the interpolating polynomial.
Divided difference and derivative of the functions and further results on interpolations error.
Unit 3 Interpolation at Equally Spaced Points This unit takes about the three types of differences i.e.
forward, backward and central differences.
Difference formulae which encompasses: Newton’s Forward–Difference formula and Newton’s Backward-Difference formula.
Module 2 Solution of Linear Algebraic Equations.
Unit 1 Direct Method This unit entails the preliminaries, Cramer’s rule, direct methods for special matrices.
Gauss elimination methods and LU decomposition method.
Unit 2 Inverse of A Square Matrix This unit is sub-divided into method of adjoints, the Gauss-Jordan reduction method and LU decomposition method.
Unit 3 Iterative Methods This unit consists of the general iterative methods.
The Jaccobi’s iteration methods and the Gauss-Seidel iteration method.
161MTH 213 NUMERICAL ANALYSIS 1 Unit 4 Eigen-Values and Eigen-Vectors.
This unit focused on the Eigen value problem.
The power method and the inverse power method.
Module 3 Unit 1 Review of Calculus Here, the three fundamental theorems, Taylor's theorem, error (round off and truncation errors) are discussed.
Unit 2 Iteration Methods for Locating Root.
This unit discussed: The initial approximation to a root (tabulation and graphical methods).
Bisection method and fixed point iteration method.
Unit 3 Chord Methods for Finding Root This entails Repuler-Falsi method, Newton – Raphson method and convergence criterion.
Unit 4 Approximate Root of Polynomial Equation.
It can be sub-divided into some results on roots of polynomial equation.
Birge-Vieta method and Graeffe’s Root squaring method.
Textbooks More recent editions of these books are recommended for further reading.
Engineering Mathematics P. D. S. Verma.
Generalized functions in mathematical physics by V. S. Viadimirov.
Mathematical methods for science students by G. Stephenson.
Generalized functions by R. F. Hoskins.
Engineering mathematics by K. A. Strond.
Engineering Mathematics by Kreyszic.
162 MTH 213 MODULE 3 Assessment There are two components of assessment for this course.
The Tutor Marked Assignment (TMAS) and the end of the course examination.
Tutor Marked Assignments (TMAs) The (TMAS) is the continuous assessment component of your course.
It accounts for 30% of the total score.
You will be given 4 (TMAS) to answer.
Three of these must be answered before you are allowed to sit for the end of course examination.
The (TMAS) would be given to you by your facilitator and returned after you have done the assignment.
End Of Course Examination This examination concludes the assessment for the course.
It constitutes 70% of the whole course.
You will be informed of the time for the examination.
It may or may not coincide with the university semester examination.
Summary In summary, we have seen how to desire the Lagrange’s form of interpolating polynomial for a given data.
It has been shown that the interpolating polynomial for a given data is unique.
We have derived the general error formula and its use has been illustrated to judge the accuracy of our calculations.
For a system of ‘n’ equations Ax = b in ‘n’ unknown, where A is a non- singular matrix, the methods of finding the solution vector x may be broadly classified into two types.
i) Direct methods and ii) Iteration methods.
For larger systems, direct methods becomes more efficient if the coefficient matrix A is in one of the forms D (diagonal), L (lower triangular) or U (upper triangular).
We further discussed the following methods for finding approximate roots of polynomial questions: (Birge-Vieta and Graeffe’s root squaring methods).
163MTH 213 NUMERICAL ANALYSIS 1 MODULE 1 INTERPOLATION Unit 1 Interpolation (Lagrange’s Form) Unit 2 Newton’s Form of the Interpolating Polynomial Unit 3 Interpolation at Equally Spaced Points UNIT 1 INTERPOLATION (LAGRANGE’S FORM) CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Lagrange’s Form 3.2 Inverse Interpolation 3.3 General Error Term 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION Let f be a real-valued function defined on the interval [a, b] and we denote f(x ) by f .
suppose that the values of the function f(x) are given k k to be f , f , f , …, f when x = x , x , x , …, x respectively where x < x 0 1 2 n 0 1 2 n 0 1 < x … < x lying in the interval [a, b].
The function f(x) may not be 2 n known to us.
The technique of determining an approximate value of f(x) for a non-tabular value of x which lies in the interval [a, b] is called interpolation.
The process of determining the value of f(x) for a value of x lying outside the interval [a, b] is called extrapolation.
In this unit, we derive a polynomial P(x) of degree n which agrees with the values of f(x) at the given (n + 1) distinct points, called nodes or abscissas.
In other words, we can find a polynomial P(x) such that P(x) = f, j = 0, 1, j j 2, …, n. such a polynomial P(x) is called the interpolating polynomial of f(x).
In section 3.1 we prove the existence of an interpolating polynomial by actually constructing one such polynomial having the desired property.
The uniqueness is proved by invoking the corollary of the fundamental theorem of Algebra.
In section 3.2 we derive general expression for error in approximating the function by the interpolating polynomial at a point and this allows us to calculate a bound on the error over an interval.
In proving this we make use of the general Rolle’s theorem.
164 MTH 213 MODULE 3 2.0 OBJECTIVES After reading this unit, you should be able to: •••• find the Lagrange’s form of interpolating polynomial interpolating f(x) at n + 1 distinct nodal points •••• compute the approximate value of f at a non-tabular point •••• compute the value of x (approximately) given a number y such that f(x) = (y) (inverse interpolation) •••• compute the error committed in interpolation, if the function is known, at a non-tabular point interest •••• find an upper bound in the magnitude of the error.
3.0 MAIN CONTENT 3.1 Lagrange’s Form Let us recall the fundamental theorem of algebra and its useful corollaries.
Theorem 1 If P(x) is a polynomial of degree n ‡ 1, that is P(x) = a xn + a xn-1 + … n n-1 + a x + a , …, a real or complex numbers and a „ 0, then P(x) has at 1 0 n n least one zero, that is, there exists a real or complex number x such that p(x )= 0.
Lemma 1 If z , z , …, z are distinct zeros of the polynomial P(x), then 1 2 k P(x) = (x – z ) (x – z ) … (x – z )R(x) 1 2 k for some polynomial R(x).
Corollary If P (x) and Q (x) are the two polynomials of degree £ k which agree at k k the k + 1 distinct points z , z , z , …, z then P (x) = Q (x) identically.
0 1 2 k k k You have come across Rolle’s Theorem in the perquisite course.
But we need a generalized version of this theorem .
(General Error Term).
This is stated below.
165MTH 213 NUMERICAL ANALYSIS 1 Theorem 2 (Generalised Rolle’s Theorem).
Let f be a real-valued function defined on [a, b] which is n times differentiable on ]a, b[.
If f vanishes at the n + 1 distinct points x , …, x in [a, b], then a number c in ]a, b[ exists such 0 n that f(n) (c) = 0.
We now show the existence of an interpolating polynomial and also show that it is unique.
The form of the interpolating polynomial that we are going to discuss in this section is called the Lagrange’s form of the interpolating polynomial.
We start with a relevant theorem.
Theorem 3: Let x , x , … x be n + 1 distinct points on the real line and let f(x) be a 0 1 n real-valued function defined on some interval I = [a, b] containing these points.
Then, there exists exactly one polynomial P (x) of degree n, n which interpolates f(x) at x , … x , that is, P (x) = f(x), i = 0, 1, 2, …, 0 n n j j n. Proof: First we discuss the uniqueness of the interpolating polynomial, and then exhibit one explicit construction of an interpolating polynomial (Lagrange’s Form).
Let P (x) and Q (x) be two distinct interpolating polynomials of degree n n n, which interpolate f(x) at (n + 1) distinct points x , x , … x .
Let h(x) = 0 1 n P (x) - Q (x).
Note that h(x) is also a polynomial of degree £ n. Also n n h(x) = P (x) - Q (x) = f(x) - f(x) = 0, i = 0, 1, 2, …, n. j n j n j j j That is, h(x) has (n + 1) distinct zeros.
But h(x) is of degree £ n and from the Corollary to Lemma 1, we have h(x) º 0.
That is P (x) Q (x).
n n This proves the uniqueness of the polynomial.
Since the data is given at the points (x , f ), (x , f ), …, (x , f ) let the 0 0 1 1 n n required polynomial be written as n P (x) = L (x)f + L (x)f + … + L (x)f = ∑ L(x)f (1) n j 0 0 1 1 n n i i i=0 Setting x = x in (1), we get j n P (x) = ∑ L(x)f (2) n j i j i i=0 166 MTH 213 MODULE 3 Since this polynomial fits the data exactly, we must have L(x) = 1 j j and L(x) = 0, i „ j j j or L(x) =¶ (3) j j ij The polynomial L(x) which are of degrees £ n are called the i Lagrange fundamental polynomials.
It is easily verified that these polynomial are given by (x - x )(x - x )...(x - x )(x - x )...(x - x ) L(x) = 0 1 i-1 i+1 n j (x - x )(x - x )...(x - x )(x - x )...( x - x ) i 0 i 1 i i-1 i i+1 i n (cid:213) n (cid:213) n = (x – x) / (x – x) (4) j i j i=0 i=0 i=j i=j Substituting of (4) in (1) gives the required Lagrange form of the interpolating polynomial.
Remark The Lagrange form (Eqn.
(1)) of interpolating polynomial makes it easy to show the existence of an interpolating polynomial.
But its evaluation at a point x involves a lot computation.
i A more serious drawback of the Lagrange form arises in practice due to the following: One calculates a linear polynomial P (x), a 1 quadratic polynomial P (x) e.t.c., by increasing the number of 2 interpolation points, until a satisfactory approximation to f(x) has been found.
In such a situation Lagrange form does not take any advantage of the availability of P (x) in calculating P (x).
Later k-1 k on, we shall see how in this respect, Newton form, discussed in the next unit, is more useful.
Let us consider some example to construct this form of interpolation polynomials.
Example 1 167MTH 213 NUMERICAL ANALYSIS 1 If f(1) = -3, f(3) = 9, f(4) = 30 and f(6) = 132, find the Lagrange’s interpolation polynomial of f(x).
Solution We have x = 1, x = 3, x = 4, x = 6 and f = -3, f = 9, f = 30, 0 1 2 3 0 1 2 f = 132.
3 The Lagrange’s interpolating polynomial P(x) is given by P(x) = L (x)f + L (x)f + L (x)f + L (x)f (5) 0 0 1 1 2 2 3 3 where (x - x )(x - x )(x - x ) L (x) = 1 2 3 0 (x - x )(x - x )(x - x ) 0 1 0 2 0 3 (x - 3)(x - 4)(x - 6) = (1- 3)(1- 4)(1- 6) 1 = (x3 – 13x2 + 54x – 72) 30 (x - x )(x - x )(x - x ) L (x) = 0 2 3 1 (x - x )(x - x )(x - x ) 1 0 1 2 1 3 (x - 1)(x - 4)(x - 6) = (3- 1)(3- 4)(3- 6) 1 = (x3 – 11x2 + 34x – 24) 6 (x - x )(x - x )(x - x ) L (x) = 0 1 3 2 (x - x )(x - x )(x - x ) 2 0 2 1 2 3 (x - 1)(x - 4)(x - 6) = (4 - 1)(4 - 3)(4 - 6) 1 = (x3 – 10x2 + 27x – 18) 6 (x - x )(x - x )(x - x ) L (x) = 0 1 2 3 (x - x )(x - x )(x - x ) 3 0 3 1 3 2 168 MTH 213 MODULE 3 (x - 1)(x - 3)(x - 4) = (6- 1)(6- 3)(6- 4) 1 = (x3 – 8x2 + 19x – 12) 30 Substituting L(x) and fj = 0, 1, 2, 3 in Eqn.
(5), we get j j 1 1 P(x) = - [x3 – 13x2 + 54x – 72] (-3) + [x3 – 11x2 + 34x – 24] (9) 30 6 1 1 - [x3 – 10x2 + 27x – 18] (30) + [ x3 – 8x2 + 19x – 12] (132) 6 30 1 2 = [ x3 – 13x2 + 54x – 72] + [x3 – 11x2 + 34x – 24] 10 3 22 -5 [x3 – 10x2 + 27x – 18] + [ x3 – 8x2 = 19x – 12] 5 which gives on simplification P(x) = x3 – 3x2 = 5x – 6 which is the Lagrange’s interpolating polynomial of f(x).
Example 2 Using Lagrange’s interpolation formula, find the value of f when x = 1.4 from the following table.
x 1.2 1.7 1.8 2.0 f 3.3201 5.4739 6.0496 7.3891 Solution the Lagrange’s interpolating formula with 4 points is (x - x )(x - x )(x - x ) (x - x )(x - x )(x - x ) P(x)= 1 2 3 f + 0 2 3 f + 0 1 (x - x )(x - x )(x - x ) (x - x )(x - x )(x - x ) 0 1 0 2 0 3 1 0 1 2 1 3 (x - x )(x - x )(x - x ) (x - x )(x - x )(x - x ) 0 1 3 f + 0 1 2 f (6) 2 3 (x - x )(x - x )(x - x ) (x - x )(x - x )(x - x ) 2 0 2 1 2 3 3 0 3 1 3 2 Substituting x = 1.2, x = 1.7, x = 1.8, x = 2.0 and 0 1 2 3 f = 3.3201, f = 5.4739, f = 6.0496, f = 7.3891 0 1 2 3 169MTH 213 NUMERICAL ANALYSIS 1 in (6), we get (x - 1.7)(x - 1.8)(x - 2.0) P(x) = * 3.3201 + (1.2- 1.7)(1.2- 1.8)(1.2- 2.0) (x - 1.2)(x - 1.8)(x - 2.0) * 5.4739 + (1.7 - 1.2)(1.7 - 1.8)(1.7 - 2.0) (x - 1.2)(x - 1.7)(x - 2.0) * 6.0496 + (1.8 - 1.2)(1.8 - 1.7)(1.8 - 2.0) (x - 1.2)(x - 1.7)(x - 1.8) * 7.3891 (7) (2.0- 1.2)(2.0- 1.7)(2.0- 1.8) Putting x = 1.4 on both sides of (7), we get (1.4 - 1.7)(1.4 - 1.8)(1.4 - 2.0) f (1.4) = P (1.4) = * 3.3201 + (- 0.5)(- 0.6)(- 0.8) (1.4 - 1.2)(1.4 - 1.8)(1.4 - 2.0) * 5.4739 + (0.5)(- 0.1)(0.3) (1.4 - 1.2)(1.4 - 1.7)(1.4 - 2.0) * 6.0496 + (0.6)(0.1)(- 0.2) (1.4 - 1.2)(1.4 - 1.7)(1.4 - 1.8) * 7.3891 (0.8)(0.3)(0.2) (- 0.3)(- 0.4)(- 0.6) = * 3.3201 + (- 0.5)(- 0.6)(- 0.8) (0.2)(- 0.4)(- 0.6) * 5.4739 + (0.5)(- 0.1)(- 0.3) (0.2)(- 0.3)(- 0.6) * 6.0496 + (0.6)(0.1)(- 0.2) (0.2)(- 0.3)(- 0.4) * 7.3891 (0.8)(0.3)(0.2) = 0.99603 + 17.51648 – 18.1488 + 3.69455 170 MTH 213 MODULE 3 = 4.05826 Therefore f(x) = 4.05826.
3.2 Inverse Interpolation In inverse interpolation for a table of values of x and y = f(x), one is given a number y and wishes to find the point x so that f(x) = y, where f(x) is the tabulated function.
This problem can always be solved if f(x) is (continuous/and) strictly increasing or decreasing (that is, the inverse of f exists).
This is done by considering the table of values x, i f(x), i = 0, 1, …, n to be a table of values y g(y), i = 0, 1, 2, …, n for i i i the inverse function g(y) = fn-1(y) = x by taking y = f(x), g(y) = x, i = i i i i 0, 1, 2, …, n. Then we can interpolate for the unknown value g(y) in this table.
( ) P (y) = ∑n x (cid:213) n (y-yj ) n i y -y i=0 i=0 i j i=j and x = P (y).
This process is called inverse interpolation.
n Let us consider some examples.
Example 3 From the following table, find the Lagrange’s interpolating polynomial which agrees with the values of x at the given values of y.
Hence find the value of x when y = 2. x 1 19 49 101 y 1 3 4 5 Solution Let x = g(y).
the Lagrange’s interpolating polynomial P(y) of g(y) is given by (y - 3)(y - 4)(y - 5) (y - 1)(y - 4)(y - 5) P(y) = * 1 + * 19 (1- 3)(1- 4)(1- 5) (3- 1)(3- 4)(3- 5) (y - 1)(y - 3)(y - 5) (y - 1)(y - 3)(y - 4) + * 49 + * 101 (4 - 1)(4 - 3)(4 - 5) (5- 1)(5- 3)(5- 4) 171MTH 213 NUMERICAL ANALYSIS 1 1 19 = - [y3 – 12y2 + 47y – 60] + [y3 – 10y2 + 29y – 20] 24 4 49 101 - [y3 – 9y2 + 23y – 15] + [y3 – 8y2 + 19y – 12] 3 8 which, on simplification, gives P(y) = y3 – y2 + 1.
The Lagrange’s interpolating polynomial of x is given by P(y).
There fore, x = P(y) = y3 – y2 + 1 Therefore, when y = 2, x = P(2) = 5.
Example 4 Find the value of x when y = 3 from the following table of values.
x 4 7 10 12 y -1 1 2 4 Solution The Lagrange’s interpolation polynomial of x is given by (y - 1)(y - 2)(y - 4) (y + 1)(y - 2)(y - 4) P(y) = (4) + (7) (- 2)(- 3)(- 5) 2(1)(- 3) (y + 1)(y - 1)(y - 4) (y + 1)(y - 1)(y - 2) + (10) + (12) (3)(1)(- 2) (5) (3) (2) (2) (1) (- 1) (4) (1) (- 1) Therefore P(3) = (4) + (7) - (2) (3) (5) (2) (3) (4) (2) (- 1) (4) (2) (1) + (10) + (12) - (3) (2) (5)(3) (2) 4 14 40 48 = - + + 15 3 3 15 182 = = 12.1333 15 172 MTH 213 MODULE 3 Hence, x(3) = P(3) = 12.
1333.
Now we are going to find the error committed in approximating the value of the function by P (x).
n 3.3 General Error Term Let E (x) = f(x) – P (x) be the error involved in approximating the n n function f(x) by an interpolating polynomial.
We derive an expression for E (x) in the following theorem.
This result helps us in estimating a n useful bound on the error as explained in an example.
Theorem 4 Let x , x , …, x be distinct numbers in the interval [a, b] and f has 0 1 n (continuous) derivatives upto order (n + 1) in the open interval ]a, b[.
if P (x) is the interpolating polynomial of degree £ n, which interpolates n f(x) at the points x , …, x , then for each x ˛ [a, b], a number x (x) in ]a, 0 n b[ exists such that f (n+1)(x (x))( )( ) ( ) En(x) = f(x) – Pn(x) = (n+1)!
x- x0 x- x1 ....... x- xn (8) Proof If x „ x for any k = 0, 1, 2, …, n, define the function g for t in [a, b] by k ( ) (cid:213) n t- x g(t) = f(t) – P (t) – [f(x) – P (x)] ( j ).
n n x- x j=0 j since f(t) has continuous derivatives up to order (n + 1) and P(t) ha derivatives of all orders, g(t) has continuous derivatives up to (n + 1) order.
Now, for k = 0, 1, 2, …, n, we have ( ) (cid:213) n x - x g(x ) = f(x ) = P (x ) – [f(x) - P (x)] (k j) .
k k n k n x- x j=0 j = 0 – [f(x) - P (x)].0 = 0 n ( ) (cid:213) n x- x Furthermore, g(x) = f(x) - P (x) - [f(x) - P (x)] ( j).
n n x- x j=0 j = f(x) - P (x) - [f(x) - P (x)].
1 = 0 n n 173MTH 213 NUMERICAL ANALYSIS 1 Thus g has continuous derivatives up to order (n + 1) and g vanishes at the (n + 2) distinct points x, x , …, x .
By the generalized Rolle’s 0 n Theorem (Theorem 2) there exists x (x) in ]a, b[ for which g(n+1) x (x) = 0.
Differentiating g(t), (n + 1) times (with respect to t) and evaluating atx (x) i, we get [f(x)- P (x)] 0 = g(n+1) x (x) = f(n+1) x (x) – (n + 1)!
n (cid:213) n ( ) x- x i i=0 Simplifying we get (error at x = x) (cid:213) n ( ) f (n+1)V (x) En(x) = f(x) – Pn(x) = x - xi (n+1)!
(9) i=0 The error formula (Eqn.
(9)) derived above, is an important theoretical results because Lagrange interpolating polynomials are extensively used in deriving important formulae for numerical differentiation and numerical integration.
( ) It is to be noted that x =x x depends on the ;point x at which the error estimate is required.
This dependence need not even be continuous.
This error formula is of limited utility since f(n+1)(x) is not known (when we are given a set of data at specific nodes) and the point x is hardly known.
But the formula can be used to obtain a bound on the error of interpolating polynomial.
Let us see how, by an example.
Example 5 The following table gives the values of f(x) = ex.
If we fit an interpolating polynomial of degree four to the data, find the magnitude of the maximum possible error in the computed value of f(x) when x = 1.25. x 1.2 1.3 1.4 1.5 1.6 y 3.3201 3.6692 4.0552 4.4817 4.9530 Solution From Eqn.
(9), the magnitude of the error associated with the 4th degree polynomial approximation is given by ( )( )( )( )( ) f (5)(x ) |E (x)|= x- x x- x x- x x- x x- x 4 0 1 2 3 4 5!
174 MTH 213 MODULE 3 ( )( )( )( )( ) f (5)(x ) = x- 1.2 x- 1.3 x- 1.4 x- 1.5 x- 1.6 (10) 5!
Since f(x) = cx, f(5)(x) = ex.
When x lies in the interval [1.2, 1.6], Max |f(5)(x)| = e1.6 = 4.9530 (11) Substituting (11) in (10), and putting x = 1.25, the upper bound on the magnitude of the error 4.9530 = |(0.05 (-0.05) (-0.15) (-0.25) (-0.35)| * 120 = 0.00000135.
4.0 CONCLUSION Let us take a brief look at what you have studied in this unit as the concluding path of this unit to the summary.
5.0 SUMMARY In this unit, we have seen how to derive the Lagrange’s form of interpolating polynomial for a given data.
It has been shown that he interpolating polynomial for a given data is unique.
Moreover the Lagrange form of interpolating polynomial can be determined for equally spaced or unequally spaced nodes.
We have also seen how the Lagrange’s interpolation formula can be applied with y as the independent variable and x as the dependent variable so that the value of x corresponding to a given value of y can be calculated approximately when some conditions are satisfied.
Finally, we have derived the general error formula and its use has been illustrated to judge the accuracy of our calculation.
The mathematical formulae derived in this unit are listed below for your easy reference.
1) Lagrange’s Form P (x) = ∑n f(x )L (x) n i i i=0 where     (cid:213) n ( ) (cid:213) n ( ) L(x) = x- x / x - x i  j   i j   jj„=0i   jj„=i0  175MTH 213 NUMERICAL ANALYSIS 1 2) Inverse Interpolation  ( ) P (y) = ∑n x (cid:213) n (y- yj ) n i y - y  i=0 jj„=i0 i j  3) Interpolation Error (cid:213) n ( ) f (n+1)V (x) En(x) = f(x) – Pn(x) = x - xi (n+1)!
i=0 6.0 TUTOR-MARKED ASSIGNMENT 1) Show that n i) ∑ L (x) = 1 i i=0 n ii) ∑ L (x) xk = xk, k £ n i i i=0 where L(x) are Lagrange fundamental polynomials i (cid:213) n ( ) 2) Let w(x) = x- x .
Show that the interpolating polynomial of k k=0 degree £ n with the nodes x , x , …, x can be written as 0 1 n n f(x ) P (x) = w(x) ∑ k n (x - x )w'(x ) i=0 k k 3) Find the Lagrange’s interpolation polynomial of f(x) from the following data.
Hence obtain f(2).
x 0 1 4 5 f(x) 8 11 68 123 4) Find the value of y when x = 6 from the following table: x 1 2 7 8 y 4 5 5 4 176 MTH 213 MODULE 3 5) Using the Lagrange’s interpolation formula, find the value of y when x = 10. x 5 6 9 11 y 12 13 14 16 6) For the data of Example 5 with last one omitted, i.e., considering only first four nodes, if we fit a polynomial of degree 3, find an estimate of the magnitude of the error in the computed value of f(x) when x = 1.25.
Also find an upper bound in the magnitude of the error.
7) Find the value of x when y = 4 from the table given below: x 8 16 20 72 y -1 1 3 5 8) Using Lagrange’s interpolation formula, find the value of f(4) from the following data: x 8 16 20 72 y -1 1 3 5 7.0 REFERENCES/FURTHER READINGS Engineering Mathematics P.D.S.
Verma.
Generalized Functions in Mathematical Physics by V.S.
Viadimirov.
Fundamentals of the Finite Element Method.
Hartley Grandin, Fr.
177MTH 213 NUMERICAL ANALYSIS 1 UNIT 2 NEWTON FORM OF THE INTERPOLATING POLYNOMIAL CONTENTS 1.0 Introduction.
2.0 Objectives.
3.0 Main Content.
3.1 Divided Differences.
3.2 Newton’s General Form of Interpolating Polynomial.
3.3 The Error of the Interpolating Polynomial.
3.4 Divided Difference and Derivative of the Function.
3.5 Further Results on Interpolation Error.
4.0 Conclusion.
5.0 Summary.
6.0 Tutor Marked Assignment.
7.0 References/Further Readings.
1.0 INTRODUCTION The Lagrange’s form of the interpolating polynomial derived in Unit 1 has some drawbacks compared to Newton form of interpolating polynomial that we are going to consider now.
In practice, one is often not sure as to how many interpolation points to use.
One often calculates P (x), P (x), … increasing the number of 1 2 interpolation points, and hence the degrees of the interpolating polynomials till one gets a satisfactory approximation P (x), no k advantage is taken of the fact that one has already constructed P (x), k-1 whereas in Newton form it is not so.
Before deriving Newton’s general form of interpolating polynomial, we introduce the concept of divided difference and the tabular representation of divided differences.
Also the error of the interpolating polynomial in this case is derived in terms of divided differences.
Using the two different expressions for the error term we get a relationship between nth order divided difference and nth order derivative.
2.0 OBJECTIVES After studying this unit, you should be able to: •••• obtain a divided difference in terms of function values •••• form a table of divided differences and find divided differences with a given set of arguments from the table 178 MTH 213 MODULE 3 •••• show that divided difference is independent of the order of its arguments •••• obtain the Newton’s divided differences interpolating polynomial for a given data •••• find an estimate of f(x) for a given non-tabular value of x from a table of values of x and y [f(x)] •••• relate the kth order derivative of f(x) with the kth order divided difference from the expression for the error term.
3.0 MAIN CONTENTS 3.1 Divided Differences Suppose that we have determined a polynomial P (x) of degree £ k – k-1 1 which interpolates f(x) at the points x , x , …x .
In order to make use 0 1 k-1 of P (x) in calculating P (x) we consider the following problem: What k-1 k function g(x) should be added to P (x) to get P (x)?
Let g(x) = P (x).
- k-1 k k P (x).
Now, g(x0 is a polynomial of degree £ k and g(x) = P (x) - P k-1 i k i k- (x) = f(x) - f(x) = 0 for i = 0, 1, …, k – 1.
1 i i i Suppose that P (x) is the Lagrange polynomial of degree at most n that n agrees with the function f at the distinct numbers x , x , …x .
P (x) can 0 1 n n have the following representation, called Newton form.
P (x) = A + A (x – x ) + A (x – x ) (x – x ) + … n 0 1 1 0 1 1 0 1 + A (x – x )…(x – x ) (1) n 0 n-1 for appropriate constant A , A , …, A .
0 1 n Evaluating P (x) (Eqn.
(1)) at x we get A = P (x ).
Similarly when n 0 0 n 0 f(x) - f(x ) P (x) is evaluated at x , we get A = 1 .
Let us introduce the n 1 1 x - x 1 0 notation for divided differences and define it at this stage: The zeroeth divided difference of the function f, with respect to x, is denoted by f[x] i i and is simply the evaluation of f at x, that is, f[x] = f(x).
the first i i i divided difference of f with respect to x and x is denoted by f[x, x ] i i+1 i i+1 and defined as f[x ]- f[x ] f[x, x ] = i+1 i i i+1 x - x i+1 i The remaining divided differences of higher orders are defined inductively as follows.
The kth divided differences relative to x, x , i i+1 …, x is defined as i+k 179MTH 213 NUMERICAL ANALYSIS 1 f[x ...,x ]- f[x ,...,x ] f[x, x , …, x ] = i+1 i+k i i+k-1 .
i i+1 i+k x - x i+k i where the (k – 1)st divided differences f[x, ….., x ] have been i i+k determined.
This shows that kth divided difference is the divided differences of (k – 1)st divided differences justifying the name.
The divided difference f[x, x , …., x ] is invariant under all permutations of i 2 k the arguments x, x , …., x .
To show this we proceed giving another i 2 k expression for the divided difference.
For any integer k between 0 and n. let Q (x) be the sum of the first k + 1 k terms in form (1), i.e.
Q (x) = A + A (x – x ) + … + A (x – x )…( x – x ).. k 0 1 0 k 0 k-1 Since each of the remaining terms in Eqn.
(1) has the factor (x – x ) (x – 0 x )… (x – x ), Eqn.
(1) can be rewritten as 1 k P (x) = Q (x) + (x – x )… (x – x ) R(x) for some polynomial R(x).
as the n k 0 k term (x – x ) (x – x )… (x – x ) R(x) vanishes at each of the points x , 0 1 k 0 … x , we have f(x) = P (x) = Q (x), i = 0, 1, 2, …, k. Since Q (x) is a k i n i k i k polynomial of degree £ k, by uniqueness of interpolating polynomial Q (x) = P (x).
k k This shows that P (x) can be constructed step by step with the addition n of the next term in Eqn.
(1), as one construct the sequence P (x), P (x) 0 1 … with P (x) obtained from P (x) in the form k k-1 P (x) = P (x) + A (x – x )… (x – x ) (2) k k-1 k 0 k-1 That is, g(x) is a polynomial of degree £ k having (at least) the k distinct zeros x , …, x .
0 k-1 \ P (x) - P (x) = g(x) = A (x – x )…(x – x ), for some constant A .
k k-1 k 0 k-1 k this constant A is called the kth divided difference of f(x) at the points k x , …, x for reasons discussed below and is denoted by f[x , x , …, x ].
0 k 0 1 k this coefficient depends only on the values of f(x) at the point x , …, x .
0 k thus Eqn.
(2) can be written as P (x) =P (x) + f[x , …, x ] (x – x )… (x – x ), k k-1 0 k 0 k-1 since (x – x ) (x – x )… (x – x ) = xk + a polynomial of degree < k, 0 1 k-1 we can rewrite P (x) s P (x) = f[x , …, x ] xk + a polynomial of k k 0 k degree < k (4) (as P (x) is a polynomial of degree < k).
k-1 180 MTH 213 MODULE 3 But considering the Lagrange form of interpolating polynomial we have ( ) P (x) = ∑k f(x )(cid:213) k (x- xj ) k i x - x i=0 j=0 i j j„ i     ( ) k  f x k  = ∑ i xk + a polynomial of degree < k. k ( ) i=0 C x - x   i j  ij„=j0  Therefore, on comparison with Eqn.
(4) we have k f(x ) f[x , …, x ] = ∑ i (5) 0 k (x - x )...(x - x )...(x - x )..(x - x ).
i=0 i 0 1 i- 1 1 i+1 i k This shows that f[y , …, y ] = f[x , …, x ] 0 k 0 k if y , …, y is a reordering of the sequence x , …, x .
We have defined 0 k 0 k the zeroeth divided difference of f(x) at x by f[x ] = f(x ) which is 0 0 0 consistent with Eqn.
(5).
For k = 1, we have from Eqn.
(5) f(x ) f(x ) f(x ) - f(x ) f[x ]- f[x ] f[x , x ] = 0 + 1 + 0 1 = 1 0 0 k x - x x - x x - x x - x 0 1 1 0 0 1 1 0 This shows that the first divided difference is really a divided difference of divided differences.
We show below in Theorem 1 that for k > 2 f[x ,....,x ]- f[x ....,x ] f[x , …, x ] = 1 k 0 k-1 (6) 0 k x - x k 0 This shows that the kth divided difference is the divided difference of (k – 1)st divided differences justifying the name.
If M = (x , …, x ) and N 0 n denotes any n – 1 elements of M and the remaining two elements are denoted by a and b, then (f [x ,.., x = 0 n 181MTH 213 NUMERICAL ANALYSIS 1 [(n - 1st divided difference onN and a - (n - 1)st divided difference onN and b] (7) a - b Theorem 1: f[x ,....,x ]- f[x ,x ....,x ] f [x ,.., x] = 1 j 0 1 j-1 (8) 0 j x - x j 0 Proof: Let P (x) be the polynomial of degree £ i – 1 which i-1 interpolates f(x) at x , …, x and let Q (x) be the polynomial of degree 0 i-1 j-1 £ j – 1 which interpolates f(x) at the points x , …, x.
Let us define P(x) 1 j as x - x x - x P(x) = 0 Q (x) + j P (x).
x - x j-1 x - x j-1 j 0 j 0 This is a polynomial of degree £ j, and P(x) = f(x) for i = 0, 1, …, j. i i By uniqueness of the interpolating polynomial we have P(x) = P(x).
j Therefore x - x x - x P(x) 0 Q (x) + j P (x).
j x - x j-1 x - x j-1 j 0 j 0 Equating the coefficient of xj from both sides of Eqn.
(8), we obtain (leading) coefficient of leadingcoefficient of Q (x) xj in P(x) = j-1 j x - x j 0 leadingcoefficient of P (x) j-1 - x - x j 0 f[x ,....,x ]- f[x ,....,x ] That is f [x , ..., x] = 1 j 0 j-1 .
0 j x - x j 0 We now illustrate this theorem with the help of a few examples but before that we give the table of divided differences of various orders.
Table of divided differences Suppose we denote, for convenience, a first order divided difference of f(x) with any two arguments by f[.,.
], a second order divided difference with any three arguments by f[.,.,.]
and so on.
Then the table of divided difference can be written as follows 182 MTH 213 MODULE 3 Table 1 x f[.]
f[.,.]
f[.,.,.]
f[.,.,.,.]
f[.,.,.,.,.]
x f 0 0 f[x ,x ] 0 1 x f f[x ,x x ] 1 1 0 1 2 f[x ,x ] f[x ,x x x ] 1 2 0 1 2 3 x f f[x ,x x ] f[x ,x x x x ] 2 2 1 2 3 0 1 2 3 4 f[x ,x ] f[x x x x ] 2 3 1 2 3 4 x f f[x x x ] 3 3 2 3 4 f[x ,x ] 3 4 x f 4 4 Example 1: If f(x) = x3, find the value of f[a, b, c].
f(b)- f(a) b3 - a3 Solution: f[a, b] = = b - a b - a = b2 + ba + a2 = a2 + ab + b2 Similarly, f[a, b] = c2 + cb + b2 = b2 + bc + c2 f[b,c]- f[a,b] f[a, b, c] = c- a (b2 + bc + c2)- (a2 + ab + b2) = c- a (c2 - a2) + b(c- a) = c- a (c- a)(c + a + b) = (c- a) = a + b + c f[a, b, c] = a + b + c. 1 Example 2: If f(x) = , show that x 1 f[a, b, c, d] = - abcd 183MTH 213 NUMERICAL ANALYSIS 1 1 1 - a - b 1 b a Solution: f[a, b] = = = - b - a ab(b - a) ab Similarly, 1 1 f[b, c] = - , f[c, d] = - bc cd 1 1 1 1 + - bc ab ab bc f[a, b, c] = = c- a c- a c- a   1 abc =  = c- a abc     Similarly, 1 f[b, c, d] = bcd c- a   1 abc however f[a, b, c, d] =   = c- a abc   a- d    abcd =   d - a   1 = - abcd Consequently, 1 f[a, b, c, d] = - abcd In next section we shall make use of the divided difference to derive Newton’s general form of interpolating polynomial.
184 MTH 213 MODULE 3 3.2 Newton’s General Form of Interpolating Polynomial In section 3.1 we have shown how P (x) can be constructed step by step n as one construct the sequence P (x), P (x), P (x), ..., with P (x) obtained 0 1 2 k from P (x) with the addition of the next term in Eqn.
(3), that is, k-1 P (x) = P (x) + (x – x ) (x – x )...(x – x ) f[x , ..., x ] k k-1 0 1 k-1 0 k Using this Eqn.
(1) ca be rewritten as P (x) = f[x ] + (x – x ) f[x ,x ] + (x – x ) (x – x ) f[x ,x ,x ] +...+ (x – x ) n 0 0 0 1 0 1 0 1 2 0 (x – x )... (x – x ) f[x ,x ,....,x ].
(9) 1 n-1 0 1 n This can be written compactly as follows: P (x) = ∑n f[x ,...,x ](cid:213) j- 1(x- x ) (10) n 0 i j i=0 j=0 This is the Newton’s form of interpolating polynomial.
Example 3: From the following table of values, find the Newton’s form of interpolating polynomial approximating (x).
x -1 0 3 6 7 f(x) 3 -6 39 822 1611 Solution: We notice that the values of x are not equally spaced.
We are required to find a polynomial which approximates f(x).
We form the table of divided differences of f(x).
Table 2 x f[.]
f[.,.]
f[.,.,.]
f[.,.,.,.]
f[.,.,.,.,.]
-1 3 9 0 - 6 6 15 5 3 39 41 1 261 13 6 822 132 789 7 1611 185MTH 213 NUMERICAL ANALYSIS 1 Since the divided difference up to order 4 are available, the Newton’s interpolating polynomial P (x) is given by 4 P (x) = f(x ) + (x – x ) f[x ,x ] + (x – x ) (x – x ) f[x ,x ,x ] + 4 0 0 0 1 0 1 0 1 2 (x – x ) (x – x ) (x – x ) f[x ,x ,x ,x ] + 0 1 2 0 1 2 3 (x – x ) (x – x ) (x – x ) (x – x ) f[x ,x ,x ,x ,x ] (11) 0 1 2 3 0 1 2 3 4 where x = -1, x = 0, x = 3, x = 6 and x = 7.
0 1 2 3 4 The divided differences f(x ), f[x ,x ], f[x ,x ,x ], f[x ,x ,x ,x ] and 0 0 1 0 1 2 0 1 2 3 f[x ,x ,x ,x ,x ] are those which lie along the diagonal at f(x ) as shown 0 1 2 3 4 0 by the dotted line.
Substituting the values of x and the values of the i divided differences in Eqn.
(11), we get P (x) = 3 + (x + 1) (-9) + (x + 1) x (6) + (x + 1) x (x – 3) (5) + 4 (x + 1) x (x – 3 ) (x – 6) (1) which on simplification gives P (x) = x4 – 3x3 + 5x2 – 6 4 Therefore, f(x) =P (x) = x4 - 3x3 + 5x2 – 6 4 We now consider an example to show how Newton’s interpolating polynomial can be used to obtain the approximate value of the function f(x) at any non-tabular point.
Example 4: Find the approximate values of f(x) at x = 2 and x = 5 in Example 3.
Solution: Since f(x) = P (x), from Example 3, we get 4 f(2) = P (2) = 16 – 24 + 20 – 6 = 6 4 and f(5) = P(5) = 625 – 375 + 125 – 6 = 369 Note 1: When the values of f(x) for given values of x are required to be found, it is not necessary to find the interpolating polynomial P (x) in its 4 simplified form given above.
We can obtain the required values by substituting the values of x in Eqn.
(11) itself.
Thus, P (2) = 3 + (3) (-9) + (3) (2) (6) + (3) (2) (-1) (5) + (3) (2) (-1) (-4) 1 4 186 MTH 213 MODULE 3 Therefore, P (2) = 3 – 27 + 36 – 30 + 24 = 6.
4 Similarly, P (5) = 3 + (6) (-9) + (6) (5) (6) + (6) (5) (2) (5) + (6) (5) (2) (-1) (1) 4 = 3 – 54 + 180 + 300 – 60 = 369.
Then f(2) = P (2) = 6 4 And f(5) = P(5) = 369.
Example 5: Obtain the divided differences interpolation polynomial and the Lagrange’s interpolating polynomial of f(x) from the following data and show that they are same.
x 0 2 3 4 f(x) -4 6 26 64 Solution: (a) Divided differences interpolation polynomial: Table 3 x f[x] f[.,.]
f[.,.,.]
f[.,.,.,.]
0 -4 5 2 6 5 20 1 3 26 9 38 4 64 P(x) = -4 + x(5) + x(x – 2) (5) + x(x – 2) (x – 3) (1) = x3 + x – 4 \ P(x) = x3 + x – 4 b) Lagrange’s interpolation polynomial: (x - 2)(x - 3)(x - 4) x(x - 3)(x - 4) P(x) = (- 4) + (6) (- 2)(- 3)(- 4) (2)(- 1)(- 2) 187MTH 213 NUMERICAL ANALYSIS 1 x(x - 2)(x - 4) x(x - 2)(x - 3) + (26) + (64) (3)(1)(- 1) (4)(2)(1) 1 3 = (x3 – 9x2 + 26x – 24) + (x3 – 7x2 + 12x) 6 2 26 - (x3 – 6x2 + 8x) + 8(x3 – 5x2 + 6x).
3 On simplifying, we get P(x) = x3 + x – 4.
Thus, we find that both polynomials are same.
In Unit 1 we have derived the general error term i.e.
error committed in approximating f(x) by P (x).
In next section we derive another n expression for the error term in term of divided difference.
3.3 The Error of the Interpolating Polynomial Let P (x) be the Newton form of interpolating polynomial of degree £ n n which interpolates f(x) at x ...., x .
0 n The interpolating error E (x) of P (x) is given by n n E (x) = f(x) – P (x) (12) n n Let x be any point different from x , ..., x .
If P (x) is the Newton form 0 n n of interpolating polynomial which interpolates f(x) at x , ...., x and x, 0 n then P (x) = f(x).
Then by (10) we have n+1 (cid:213) n ( ) P (x) = P (x) + f[x , ..., x , x] x- x n+1 n 0 n j j=0 Putting x = x in the above, we have (cid:213) n ( ) f(x) = P (x) = P (x) + f[x , ..., x , x] x - x n+1 n 0 n j j=0 (cid:213) n ( ) i.e.
E (x) = f(x) - P (x) = f[x , ..., x , x] x - x (13) n n 0 n j j=0 This shows that the error is like the next term in the Newton form.
188 MTH 213 MODULE 3 3.4 Divided Difference and Derivative of the Function Comparing Eqn.
(13) with the error formula derived in Unit 1 Eqn.
(9), we can establish a relationship between divided difference and the derivatives of the function f(n+1)[x(x)] (cid:213) n ( ) E (x) = x- x n (n + 1)!
j j=0 (cid:213) n ( ) = f[x , x , ..., x , x] x- x 0 1 n j j=0 f (n+1)V Comparing, we have f[x , x , ..., x ] = 0 1 n+1 (n+1)!
(considering x = x ) n+1 Further it can be shown that x Î ]min x, max x[.
i i We state these results in the following theorem.
Theorem 2: Let f(x) be a real-valued function, defined on [a, b] and n times differentiable in ]a, b[.
If x , ......, x are n + 1 distinct points in [a, b], 0 n then there exists V ˛ ]a, b[ such that f (n+1)V f[x , ...., x ] = 0 n n!
Corollary 1: If f(x) = xn, then n!
f[x , ...., x ] = = 1.
0 n n!
Corollary 2: If f(x) = xk, k < n, then f[x , ...., x ] = 0 0 k since nth derivative of xk, k < n, is zero.
189MTH 213 NUMERICAL ANALYSIS 1 For example, consider the first divided difference f(x ) - f(x ) f[x ,x ] = 1 0 0 1 x - x 1 0 by Mean Value Theorem f(x ) = f(x ) + (x – x ) f’(V ), x < V < x, 1 0 1 0 0 substituting, we get f[x ,x ] = f’(V ), x < V < x .
0 1 0 1 Example 6: n!
If f(x) = a xn + a xn-1 + ... + a , then find f[x , x , ...., x ] = a * + 0 = n n-1 0 0 1 n n n!
a .
n Let us consider another example.
Example 7: If f(x) = 2x3 + 3x2 – x + 1, find f[1, -1, 2, 3], f[a, b, c, d], f[4, 6, 7, 8].
Solution: Since f(x) is a cubic polynomial, the 3rd order divided differences of f(x) with any set of argument are constant and equal to 2, the coefficient of x3 in f(x).
Thus, it follows that f[1, -1, 2, 3], f[a, b, c, d], and f[4, 6, 7, 8] are each equal to 2.
In the next section, we are going to discuss about bounds on the interpolation error.
3.5 Further Results on Interpolation Error We have derived error formula (cid:213) n ( ) f (n+1)V(x) En(x) = f(x) – Pn(x) = x - xi (n+1)!
.’ i=0 190 MTH 213 MODULE 3 We assume that f(x) is (n + 1) times continuously differentiable in the ( ) interval of interest [a, b] = I that contains x , ..., x and x. since V x is 0 n ( ) max known we may replace f(n+1)( V x ) by x Î I f(n+1)(x) .
If we denote (x - x ) (x – x )...(x – x ) by (cid:1) (x) then we have 0 1 n n max f(n+1)(t) x Î I max y (t) E (x) = |f(x) – P (x)| £ n (14) n n (n + 1)!
x Î I Consider now the case when the nodes are equally spaced, that is (m x = j x + jh), j = 0,.....,N, and h is the spacing between consecutive nodes.
0 For the case n = 1 we have linear interpolation.
If x Î [x , x], then we i-1 i approximate f(x) by P (x) which interpolates at 1 1 max f"(t) max y (t) x , and x.
From Eqn.
(14) we have |E (x)| £ 1 i-1 i n 2 t Î I t Î I where (cid:1) (x) = (x – x ) (x - – x).
1 i-1 i Now, dy 1 = x –x - –= 0 dx gives x = (x - x)/2.
i-1 i Hence, the maximum value of (x – x ) (x - – x)| occurs at i-1 i x = x* = (x - x)/2.
i-1 i The maximum value is given by (x - x )2 h2 |(cid:1) (x*)| = i i-1 = .
1 4 4 Thus, we have for linear interpolation, for nay x ˛ I (x - x )2 1 max f"(x) |E (x)| = |f(x) – P (x)| £ i i-1 1 1 4 2 x Î I h2 = M. (15) 8 where |f”(x)| £ M on I.
For the case n = 2, it can be shown that for any x ˛ [x , x ].
i-1 i+1 191MTH 213 NUMERICAL ANALYSIS 1 h2M |E (x)| £ where |f’”(x)| £ M on I.
(16) 2 9 3 192 MTH 213 MODULE 3 Example 8: Determine the spacing h in table of equally spaced values of the function of f(x) = x between 1 and 2, so that interpolation with a first degree polynomial in this table will yield seven place accuracy.
Solution: Here 1 f"(x) = - x-3/2 4 1 max f"(x) = 4.
1 £ x £ 2 h2 and |E (x)| £ .
1 32 For seven place accuracy, h is to be chosen such that h2 < 5.10-8.
32 or h2 < (160)10-8 that is h < .0013.
4.0 CONCLUSION This unit shall be concluded by giving a summary of what we have covered in it.
5.0 SUMMARY In this unit we have derived a form of interpolating polynomial called Newton’s general form, which has some advantage over the Lagrange’s form discussed in Unit 1.
This form is useful in deriving some other interpolating formulas.
We have introduced the concept of divided differences and discussed some of its important properties before deriving Newton’s general form.
The error term has also been derived and utilizing the error term we have established a relationship between the divided difference and the derivative of the function f(x) for which the interpolating polynomial has been obtained.
The main formula derived are listed below: f[x ,....,x ]- f[x ,....,x ] 1) f[x ,....,x] = 1 j 0 j-1 0 j x - x j 0 193MTH 213 NUMERICAL ANALYSIS 1 2) P (x) = ∑n f[x ,...,x ](cid:213) j- 1(x- x ) n 0 i j i=0 j=0 (cid:213) n ( ) 3) E (x) = f[x ,...,x ,x] x- x n 0 n j j=0 f (n)(x ) 4) f[x ,....,x ] = , x ˛ ]min x, max[ 0 n i i n!
6.0 TUTOR-MARKED ASSIGNMENT 1) Find the Lagrange’s interpolating polynomial of f(x) from the table of values given below and show that it is the same as the Newton’s divided differences interpolating polynomial.
x 0 1 4 5 f(x) 8 11 68 123 2) Form the table of values given below, obtain the value of y when x = 1.5 using a) divided differences interpolation formula.
b) Lagrange’s interpolation formula.
x 0 1 2 4 5 f(x) 5 14 41 98 122 3) Using Newton’s divided difference interpolation formula, find the values of f(8) and f(15) from the following table.
x 4 5 7 10 11 13 f(x) 48 100 294 900 1210 2028 4) If f(x) = 2x3 – 3x2 + 7x + 1, what is the value of f[1, 2, 3, 4]?
5) If f(x) = 3x2 – 2x + 5, find f[1, 2], f[2, 3] and f[1, 2, 3].
6) If f(x) takes the values -21, 15, 12 and 3 respectively when x assumes the values -1, 1, 2 and 3, find the polynomial which approximates f(x).
7) Find the polynomial which approximate f(x), tabulated below 194 MTH 213 MODULE 3 x -4 -1 0 2 5 f(x) 1245 33 5 9 1335 Also find an approximate value of f(x) at x = 1 and x = -2.
8) From the following table, find the value of y when x = 102 x 93.0 96.2 100.0 104.2 108.7 y 11.38 12.80 14.70 17.07 19.91 7.0 REFERENCES/FURTHER READINGS.
Engineering Mathematics P.D.S.
Verma.
Generalized Functions in Mathematical Physics by V.S.
Viadimirov.
Fundamentals of the Finite Element Method.
Hartley Grandin, Fr.
195MTH 213 NUMERICAL ANALYSIS 1 UNIT 3 INTERPOLATION AT EQUALLY SPACED POINTS CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Differences 3.1.1 Forward Differences 3.1.2 Backward Differences 3.1.3 Central Differences 3.2 Difference Formulas 3.2.1 Newton’s Forward-Difference Formula 3.2.2 Newton’s Backward-Formula 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION Suppose that y is a function of x.
The exact functional relation y = f(x) between x and y may or may not be known.
But, the values of y at (n + 1) equally spaced of x are supposed to be known, i.e., (x, y); i = 0, i i ..., n are known where x – x = h (fixed), i = 1, 2, ..., n. Suppose that i i-1 we are required to determine an approximate value of f(x) or its derivative f’(x) for some values of x in the interval of interest.
The methods for solving such problems are based on the concept of finite differences.
We have introduced the concept of forward, backward and central differences and discussed their interrelationship in the previous unit We have already introduced two important forms of the interpolating polynomial in Units 1 and 2.
These forms simply when the nodes are equidistant.
For the case of equidistant nodes, we have derived the Newton’s forward, backward difference forms and Stirling’s central difference form of interpolating, each suitable for use under a specific situation.
We have derived these methods in the previous unit and also given the corresponding error term.
196 MTH 213 MODULE 3 2.0 OBJECTIVES After reading this unit, you should be able to: •••• write a forward difference in terms of function values from a table of forward differences and locate a difference of given order at a given point •••• write a backward difference in terms of function values from a table of backward differences and identify differences of various orders at any given point from the table •••• expand a central difference in terms of function values and form a table of central differences •••• establish relations between V, (cid:209) , d and divided difference •••• obtain the interpolating polynomial of f(x) for a given data by applying any one of the interpolating formulas •••• compute f(x) approximately when x lies near the beginning of the table and estimate the error •••• compute f(x) approximately when x lies near the end of the table and estimate the error •••• estimate the value of f(x) when x lies near the middle of the table and estimate the error.
3.0 MAIN CONTENTS 3.1 Differences Suppose that we are given a table of values (x, y), i = 0, 1, 2, ..., N i i where y = f(x) = f. i i j Let the nodal points be equidistant.
That is x = a + ih, i = 0, ...., N, with N = (b – a)/h (1) i For simplicity we introduce a linear change of variables x - x s = s(x) = 0 , so that x = x(s) = x + sh (2) 0 h and introduce the notation f(x) = f(x + sh) = f (3) 0 s The linear change of variables in Eqn.
(2) transforms polynomials of degree n in x into polynomials of degree n is s. we have already introduced the divided-difference table to calculate a polynomial of 197MTH 213 NUMERICAL ANALYSIS 1 degree £ n which interpolates f(x) at x , x , ..., x .
For equally spaced 0 1 n nodes, we shall deal with three types of differences, namely, forward, backward and central and discuss their representation in the form of a table.
We shall also derive the relationship of these differences with divided differences and their interrelationship.
3.1.1 Forward Differences We denote the forward differences of f(x) if ith order at x = x + sh by 0 D i f and define it as follows: s {f i = 0 D i f = s s V(Vi-1f ) =Vi-1f - Vi-1f,i > 0. s s+1 s Where Vdenotes forward difference operator.
When s = k, that is, x = x , we have k for i = 1 D f = f - f k k+1 k for i = 2 D 2f = f - f k k+1 k = f - f – [f - f ] k+2 k+1 k+1 k = f - f + f k+2 k+1 k Similarly D 3f = f - 3f + 3f - f k k+3 k+2 k+1 k We recall the binomial theorem n s (a + b)s = ∑ ajbr- j (4) j j=0 where s is a real non-negative integer.
We give below in Lemma 1 the relationship between the forward and divided differences.
This relation will be utilized to derive the Newton’s forward difference formula which interpolates f(x) at x + ih, i = 0, 1, k ...., n. Lemma 1: For all i ‡ 0 1 f[x , ..., k ] = D if (5) k k+1 i!hi k 198 MTH 213 MODULE 3 Proof: We prove the result by induction.
For i = 0, both sides of relation (5) are same by convention, that is, f[x ] = f(x ) = f = D 0 f .
k k k k Assuming that relation (5) holds for i = n ‡ 0, we have for i = n + 1 f[x ,.....,x ]- f[x ,.....,x ] f[x , x , ..., k ] = k+1 k+n+1 k k+n k k+1 k+n+1 x - x k+n+1 k [ ] [ ] D n f /n!hn - D n f /n!hn = k+1 k ( ) x + k +n+1h- x - kh 0 0 D n f - D n f D n+1f = k+1 k = k ( ) ( ) n+1!hn+1 n+1!hn+1 This shows that relation (5) holds for i = n + 1 also.
Hence (5) is proved.
We now give a result which immediately follows from this theorem in the following corollary.
Corollary: If P (x) is a polynomial of degree n with leading coefficient a , and x is n n 0 an arbitrary point, then D nP (x ) = a n!
hn n 0 n and D n+1P (x ) = 0, i.e., all higher differences are zero.
n 0 Proof: Taking k = 0 in relation (5) we have 1 f[x , ..., x] = D if .
(6) 0 i 1!hi 0 Let us recall that f (1)(x ) f[x , ..., x] = (7) 0 i 1!
where f(x) is a real-valued function defined on [a, b] and i times differentiable in ]a, b[ and x ˛ ]a, b[.
Taking i = n and f(x) = P (x) in Eqns.
(6) and (7), we get n 199MTH 213 NUMERICAL ANALYSIS 1 P (n)(x) D i nP (x ) = n!h nP [x , ..., x ] = n!hn n n 0 n 0 n n!
= hnn!a .
n Since D i n+1P (x ) = D i nP (x ) - D i nP (x ) n 0 n 1 n 0 = hnn!a - hnn!a = 0. n n This completes the proof The shift operator E is defined as Ef = f (8) i i+1 In general Ef(x) = f(x + h).
We have Esf = f i i+s For example, E3f = f , E1/2f = f and E-1/2f = f i i+3 i i+1/2 i i-1/2 Now, D i f = f - Ef – f = (E – 1)f i i+1 i i i Hence the shift and forward difference operations are related by D = E – 1 or E = 1 + D Operating s times, we get D s = (e – 1)s = ∑n sEj(- 1)r- 1 (9)  j j=0 Making use of relation (8) in Eqn.
(9), we get D s fi = ∑n (- 1)r- 1sjfj+1 j=0 We now give in Table 1, the forward differences of various orders using 5 values.
200 MTH 213 MODULE 3 Table 1: Forward Difference Table x f(x) D 1f D 2 f D 3 f D 4 f x f 0 0 D f 0 x f D 2f 1 1 0 D f D 3f 1 0 x f D 2f D 4f 2 2 1 0 D f D 3f 2 1 x f D 2f 3 3 2 x f D f 4 4 3 Note that the forward difference D kf lie on a straight line sloping 0 downward to the right.
3.1.2 Backward Differences Let f be a real-valued function of x. let the values of f(x) at n + 1 equally spaced points x , x , ....., x be f , f , ...., f respectively.
0 1 n 0 1 n The backward differences of f(x) of ith order at x = x + kh are denoted k 0 by (cid:209) if .
They are defined as follows: k {f , 1 = 0 (cid:209) if = k (10) k (cid:4270)i-1((cid:4270)f ) =(cid:4270)i-1[f - f ],i ³ 1 k k k-1 where (cid:209) denotes backward difference operator.
Using (10), we have for i = 1; (cid:209) f = f – f k k k-1 i = 2; (cid:209) 2f = (cid:209) ( f – f ) k k k-1 = (cid:209) f – f k k-1 = f – 2f + f k k-1 k-2 i = 3; (cid:209) 3f = (cid:209) 2[f – f ] = (cid:209) 2f - (cid:209) 2f = (cid:209) [f ] - (cid:209) [f ] k k k-1 k k-1 k k-1 = (cid:209) [f - f ] - (cid:209) [f - f ] k k-1 k-1 k-2 = (cid:209) f – (cid:209) f - (cid:209) f + f k k-1 k-1 k-2 = f – f – 2[f + f ] + f - f k k-1 k-1 k-2 k-2 k-3 = f – 3f + 3f - f k k-2 k-2 k-3 201MTH 213 NUMERICAL ANALYSIS 1 By induction we can prove the following lemma which connects the divided difference with the backward difference.
Lemma 2: The following relation holds 1 f[x , ..., x ] = (cid:209) kf(x ) (11) n-k n k!hk n The relation between the backward difference operator (cid:209) and the shift operator E is given by (cid:209) = 1 E-1 or E = (i - (cid:209) )-1 Since (cid:209) f = f – f = f – E-1f = [1 – E]f .
k k k-1 k k k Operating s times, we get (cid:209) sfk = [1 – E]sfk = ∑jn=0ms E- m(- 1)mfk =∑n ms (- 1)m fk- m (12) j=0 We can extend the binomial coefficient notation to include negative numbers, by letting ( )( ) ( ) s - s - s- 1 - s- 2.... - s- i+1 s(s + 1)....(s + i- 1)   = =(-1)i i i!
i!
The backward differences of various orders with 5 nodes are given in Table 2.
Table 2: Backward Difference Table x f(x) (cid:209) f (cid:209) 2f (cid:209) 3f (cid:209) 4f x f 0 0 (cid:209) f 1 x f (cid:209) 2f 1 1 2 (cid:209) f (cid:209) 3f 2 3 x f (cid:209) 2f (cid:209) 4f 2 2 3 4 (cid:209) f (cid:209) 3f 3 4 x f (cid:209) 2f 3 3 4 (cid:209) f 4 x f 4 4 Let us consider the following example: 202 MTH 213 MODULE 3 Example 1: Evaluate the differences (a) (cid:209) 3[a x2 + a x + a ] 2 1 0 (b) (cid:209) 3[a x3 + a x2 + a x + a ].
3 2 3 0 Solution: (a) (cid:209) 3[a x2 + a x + a ] = 0 2 1 0 (b) (cid:209) 3[a x3 + a x2 + a x + a ].
3 2 3 0 = a (cid:209) 3(x3) + (cid:209) 3[a x2 + a x + a ] 3 2 1 0 = a .3 !
h2 3 Note that the backward differences (cid:209) kf lie on a straight line sloping 4 upward to the right.
Also note that Vf = (cid:209) f = f – f .
k k+1 k+1 k Try to show that V4f = (cid:209) 4f .
0 4 Let us now discuss about the central differences.
3.1.3 Central Differences The first order central difference of f at x , denoted by df , is defined as k k df = f(x + h/2) – f(x – h/2) = f – f .
k+1/2 k-1/2 Operating with d, we obtain the higher order central differences as dsf = f when s = 0. k k The second order central difference is given by d2f = d[f – f ] = d[f ] - d[f ] k k+1/2 k-1/2 k+1/2 k-1/2 = f – f – f + f k+1 k k k-1 = f – 2f + f k+1 k k-1 Similarly, d3f = f - 3f + 3f - f k k+3/2 k+1/2 k-1/2 k-3/2 and d4f = f - 4f + 6f - 4f + f .
k k+2 k+1 k k-1 k-2 203MTH 213 NUMERICAL ANALYSIS 1 Notice that the even order differences at a tabular value x are expressed k in terms of tabular values of f and odd order differences at a tabular value x are expressed in terms of non-tabular value of f. also note that k the coefficients of dsf are the same as those of the binomial expansion k of (1 – x)s, s = 1, 2, 3, .... .
Since df f – f = (E1/2 – E-1/2)f k k+1/2 k-1/2 k We have the operation relation d = E1/2 – E-1/2 (14) The central differences at a non-tabular point x can be calculated in a k+1/2 similar way.
For example, df = f - f k+1/2 k+1 k d2f = f - 2f + f k+1/2 k+3/2 k+1/2 k-1/2 d3f = f - 3f + 3f - f (15) k+1/2 k+2 k+1 k k-1 d4f = f - 4f + 6f - 4f + f k+1/2 k+3/2 k+3/2 k+1/2 k-1/2 k-3/2 Relation (15) can be obtained easily by using the relation (14) We have dsf = [E1/2 – E-1/2]sf k k = ∑n sE- i/2E(n- i)/2(- 1)if i=0i   k =∑i=n0is(- 1)ifk+(n/2)- 1 (16) The following formulas can also be established: 1 f[x , ...., x ] = d2mf (17) 0 2m (2m)!h2m m 1 f[x , ...., x ] = d2m+1f (18) 0 2m+1 (2m + 1)!h2m+1 m+1/2 1 f[x , ...,x , ...., x ] = d2mf (19) -m 0 m (2m)!h2m 0 204 MTH 213 MODULE 3 1 f[x , ...,x , ...., x ] = d2m+1f (20) -m 0 m+1 (2m + 1)!h2m+1 1/2 1 f[x , ...,x , ...., x ] = d2m+1f (21) -(m+1) 0 m (2m + 1)!h2m+1 -1/2 We now give below the central difference table with 5 nodes.
Table 3: Central Difference Table x f df d2f d3f d4f x f -2 -2 df -3/2 x f d2f -1 -1 -1 df d3f -1/2 -1/2 x f d2f d4f 0 0 0 0 df d3f 1/2 1/2 x f d2f 1 1 1 df 3/2 x f 2 2 Note that the difference d2mf lie on a horizontal line shown by the dotted 0 lines.
Table 4: Central Difference Table x f df d2f d3f d4f x f 0 0 df 1/2 x f d2f 1 1 1 df d3f 3/2 3/2 x f d2f d4f 2 2 2 2 df d3f 5/2 5/2 x f d2f 3 3 3 df 7/2 x f 4 4 Note that the difference d2mf lie on a horizontal line.
2 We now define the mean operator mas follows 1 mf = [f + f ] k k+1/2 k-1/2 2 1 = [E1/2 + E-1/2]f .
k 2 205MTH 213 NUMERICAL ANALYSIS 1 Hence 1 m = [E1/2 + E-1/2] 2 Relation Between the Operators V, (cid:209) , d and m We have expressed V, (cid:209) , d and m in terms of the operator E as follows V = E – 1 (cid:209) = 1 – E-1 d = E1/2 – E-1/2 1 m = [E1/2 + E-1/2] 2 V = E(1 = E-1) = E(cid:209) = E1/2(E1/2 – E-1/2) E1/2d d Also E1/2 = m + 2 d E-1/2 = m - 2 Example 2: (a) Express V3f as a backward difference.
1 (b) Express V3f as a central difference.
1 (c) Express d2f as a forward difference.
2 Solution: (a) D 3f = (E(cid:209) )3f = E3(cid:209) 3f = (cid:209) 3E3f = (cid:209) 3f (D = E(cid:209) ) 1 1 1 1 4 (b) D 3f = [E1/2¶ ]3f = E3/2¶ 3f = ¶ 3E3/2f = ¶ 3f ((cid:209) =E1/2¶ ) 1 1 1 1 5/2 (c) ¶ 2f = [E-1/2¶ ]2f = E-1D 2f =D 2E-1f =D 2f (¶ =E-1/2D ) 2 2 2 2 1 206 MTH 213 MODULE 3 Example 3: Prove that ¶ 2 (a) m2 = 1 + 4 1 (b) md = (D + (cid:209) ) 2 ¶ 2 (c) 1+ m2d2 = 1 + 2 Solution: 1 (a) We have m= [E1/2 + E-1/2] 2 (E1/2 + E-1/2)2 (E1/2 - E-1/2)2 + 4 m2 = = 4 4 (E1/2 - E-1/2)2 = 1 + 4 ¶ 2 = 1 + 4 (b) L.H.S.
1 1 md = (E1/2 + E-1/2) (E1/2 - E-1/2) = (E – E-1) 2 2 R.H.S.
1 1 1 (D + (cid:209) ) = [(E-1) + (1-E-1)] = (E – E-1).
2 2 2 Hence, the result.
(c) We have 1 1 md = (E1/2 + E-1/2) (E1/2 - E-1/2) = (E – E-1) 2 2 (E - E-1)2 (E - E-1)2 + 4 (E + E-1)2 \ 1 + m2d2 = 1 + = = 4 4 4 E + E-1 (E1/2 - E-1/2)2 + 2 \ 1+ m2d2 = = 2 2 d2 + 2 ¶ 2 = = 1 + 2 4 3.2 Difference Formulas We shall now derive different difference formulas using the results obtained in the preceding section (Section 3.2).
207MTH 213 NUMERICAL ANALYSIS 1 3.2.1 Newton’s Forward-Difference Formula In Unit 2, we have derived Newton’s form of interpolating polynomial (using divided differences).
We have also established in Section 3.2 1, the following relationship between divided differences and forward differences 1 f[x , ...., x ] = Vnf (21) k k+n n!hn k Substituting the divided differences in terms of the forward differences in the Newton’s form, and simplifying we get Newton’s forward- difference form.
The Newton’s form of interpolating polynomial interpolating at x , x , ...., x is k k+1 k+n P (x) = ∑n (x- x )(x- x )...........(x- x )f[x ,........x ] n k k+1 k+ i- 1 k k+1 i=0 Substituting (22), we obtain P (x) = ∑n (x- x )(x- x )...........(x- x ) 1 D i f (23) n k k+1 k+ i- 1 1!h1 k i=0 Setting k = 0, we have the form P (x) =∑n 1 (x- x )(x- x )...........(x- x )D i f n 1!h1 0 1 i- 1 0 i=0 (x - x ) D f (x - x )(x - x ) D 2 f = f + 0 0 + 0 1 0 +... 0 1!
h h2 h2 (x - x )....(x - x ) D n f + 0 n-1 0 (24) n!
hn Using the transformation (2), we have x – x = x + sh – [x + (k + j)h] = (s – k – i + 1) Vif k+j 0 0 k n s- k = ∑D 1f   ki  i=0 (s - k)(s - k - 1) =f + (s – k) D f + D 2 f +... k k 2!
k 208 MTH 213 MODULE 3 (s - k)(s - n - 1) + D n f (25) n!
k of degree £ n. Setting k = 0 in (25) we get the formula n s Pn(x0 + sh) =∑D i f0i (26) i=0 The form (23), (24), (25) or (26) is called the Newton’s forward- difference formula.
The error term is now given by s  En(x) = n+1hn+1 fn+1 (x) - Example 4: Find the Find the Newton’s forward-difference interpolating polynomial which agrees with the table of values given below.
Hence obtain the value of f(x) at x = 1.5. x 1 2 3 4 5 6 f(x) 10 19 40 79 142 235 Solution: We form a table of forward differences of f(x).
Table 5: Forward differences x f(x) D f D 2f D 3f 1 10 9 2 19 12 21 6 3 40 18 39 6 4 79 24 63 6 5 142 30 93 6 235 Since the third order differences are constant, the higher order differences vanish and we can infer that f(x) is a polynomial of degree 3 and the Newton’s forward-differences interpolation polynomial exactly 209MTH 213 NUMERICAL ANALYSIS 1 represents f(x) and is not an approximation to f(x).
The step length in the data id h = 1.
Taking x = 1 and the subsequent values of x as x , x , ...., 0 1 2 x the Newton’s forward-differences interpolation polynomial.
5 (x - 1)(x - 2) f(x) = f + (x – 1) Vf + V2f + 0 0 0 2!
(x - 1)(x - 2)(x - 3) V3f 0 3!
becomes (x - 1)(x - 2) (x - 1)(x - 2)(x - 3) f(x) = 10 + (x – 1) (9) + (12)+ (6) 2 6 l= 10 + (x – 1) + 6(x – 1) (x – 2) + (x – 1) (x – 2) (x – 3) which on simplification gives f(x) = x3 + 2x + 7 \ f(1.5) = (1.5)3 + 2(1.5) + 7 = 3.375 + 3 + 7 = 13.375 Note: If we want only the value of (1.5) and the interpolation polynomial is not needed, we can use the formula (26).
In this case, x - x 1.5- 1 s = 0 = = 0.5 h 1 and (0.5)(- 0.5) (0.5)(- 0.5)(- 1.5) f(1.5) = 10 + (0.5) (9) + (12) + (6) 2 6 = 10 + 4.5 – 1.5 + 0.375 = 13.375.
Example 5: From the following table, find the number of students who obtained less than 45 marks.
Marks 30 - 40 40 - 50 50 – 60 60 - 70 70 - 80 No.
of students 31 42 51 35 31 210 MTH 213 MODULE 3 Solution: We form a table of the number of students’ f(x) whose marks are less than x.
In other words, we form a cumulative frequency table.
Table 6: Frequency Table x f(x) Vf V2f V3f V4f 40 31 42 50 73 9 51 -25 60 124 -16 37 35 12 70 159 -4 31 80 190 We have x = 40, x = 45 and h = 10 0 \ s = 0.5 (0.5)(- 0.5) (0.5)(- 0.5)(- 1.5) \ f(45) ; 31 + (0.5) (42) + (9) + (-25) 2 6 (0.5)(- 0.5)(- 1.5)(- 2.5) + (37) 24 = 31 + 21 – 1.125 – 1.5625 – 1.4453 = 47.
8672 ; 48 \ The number of students who obtained less than 45 marks is approximately 48.
3.2.2 Newton’s Backward-Difference Formula Reordering the interpolating nodes as x , x , ...., x and applying the n n-1 0 Newton’s divided difference form, we get P (x) = f[x ] + (x – x ) f[x , x ] + (x – x ) f[x , x , x ] n n n n-1 n n-1 n-2 n-1 n + .... + (x – x) ... (x –x ) f[x , ...., x ] (27) n 0 n We may also write é x - x ù P (x) = P x + n h n nêë n h úû 211MTH 213 NUMERICAL ANALYSIS 1 n = P [x + sh] = å (x - x )(x - x )...(x - x )f[x ,....,x ] n n n n-1 n- i+1 n n-1 i=0 n 1 = å (x - x )(x - x )...(x - x )(cid:4270)if (28) i!hi n n-1 n- i+1 n i=0 Set x = x + sh, then n x – x = x + sh – [x – (n – i)h] = (s + n – i)h i n n x – x = (s + n – n + j)h = (s + j)h n-j and (x – x ) (x – x ) ... (x – x ) = s(s + 1) ... s(s + i – 1)hi n n-1 n-i+1 Equation (28) becomes P (x) = ∑n 1s(s+1)........(s+i- 1)f n i!!
n i=0 s(s + 1) s(s + 1)...(s + n - 1) = f + s(cid:209) f + (cid:209) 2f + (cid:209) nf (29) n n n n 2!
n!
We have seen already that s s(s + 1)...(s + k - 1)  = (-1)k k k!
Hence, equation (29) ca be written as ( )s ( ) ( ) s ( ) Pn(x) = f(xn) + - 1 1(cid:209) f xn (-1) + - 1 22(cid:209) 2 f xn (-1)2 ( ) s ( ) + ... + - 1 k (cid:209) k f x k n or Pn(x) = ∑n (- 1)kks(cid:209) k f(xn) (30) k=0 Equation (27), (28) or (29) is called the Newton’s backward-difference form.
212 MTH 213 MODULE 3 In this case error is given by s(s + 1)...(s + n) E (x) = (-1)n+1 hn+1 fn+1 (x).
(31) n (n + 1)!
The backward-difference form is suitable for approximating the value of the function at x that lies towards the end of the table.
Example 6: Find the Newton’s backward differences interpolating polynomial for the data of Example 4.
Solution: We form the table of backward differences of f(x).
Table 7: Backward Difference Table x f(x) (cid:209) f (cid:209) 2f (cid:209) 3f 1 10 9 2 19 12 21 6 3 40 18 39 6 4 79 24 63 6 5 142 30 93 6 235 Tables 5 and 7 are the same except that we consider the differences of Table 7 as backward differences.
If we name the abscissas as x , x , ...., 0 1 x , then x = x = 6, f = f = 235. with h = 1, the Newton’s backward 5 n 5 n 5 differences polynomial for the given data is given by (x - x )(x - x ) P(x) = f + (x – x ) (cid:209) f + 5 4 (cid:209) 2f + 5 5 5 5 2!
(x - x )(x - x )(x - x ) 5 4 3 (cid:209) 3f 5 3!
(x - 6)(x - 5) (x - 6)(x - 5)(x - 4) = 235 + (x – 6) (93) + (30) + (6) 2 6 = 235 + 93(x – 6) + 15(x – 6) + (x – 4) (x - 5) (x – 6) which on simplification gives 213MTH 213 NUMERICAL ANALYSIS 1 P(x) = x3 + 2x + 7, which is the same as the Newton’s forward differences interpolation polynomial in Example 4.
Example 7: Estimate the value of (1.45) from the data given below: x 1.1 1.2 1.3 1.4 1.5 f(x) 1.3357 1.5095 1.6984 1.9043 2.1293 Solution: We form the backward differences table for the data given.
Table 8: Backward Differences Table x f(x) (cid:209) f (cid:209) 2f (cid:209) 3f (cid:209) 4f 1.1 1.3357 0.1738 1.2 1.5095 0.0151 0.1889 0.0019 1.3 1.6984 0.0170 0.0002 0.2059 0.0021 1.4 1.9043 0.0191 0.2250 1.5 2.1293 Here x = 1.5, x = 1.45, h = 0.1 n x - x 1.45- 1.5 Hence, s = n = = -0.5 h 0.5 The Newton’s backward differences interpolation formula gives s(x + 1) s(s + 1)(s + 2) f(x) = f + s(cid:209) f + (cid:209) 2f + (cid:209) 3f + n n n n 2!
3!
s(s + 1)(s + 2)(s + 3) (cid:209) 4f n 4!
(- 0.5)(0.5) = 2.1293 + (-0.5) (0.2250) + (0.0191) 2 (- 0.5)(0.5)(1.5) (- 0.5)(0.5)(2.5) + (0.0021) + (0.0002) 6 24 214 MTH 213 MODULE 3 = 2.1293 – 0.1125 – 0.00239 – 0.00013 – 0.0000078 = 2.01427 » 2.0143 3.3.3 Stirling’s Central Difference Form A number of central difference formulas are available which can be used according to a situation to maximum advantage.
But we shall consider only one such method known as Stirling’s method.
This formula is used whenever interpolation is required of x near the middle of the table of values.
For the central difference formulas, the origin x , is chosen near the 0 point being approximated and points below x are labelled as x , x , ... 0 1 2 and those directly above as x , x , ... (as in Table 3).
Using this -1 -2 convention, Stirling’s formula for interpolation is given by s s2 P (x) = f(x ) + [df + df ] + d2f n 0 1/2 -1/2 0 2 2!
s(s2 - 12) 1 + [d3f + d3f ] + ... 1/2 -1/2 3!
2 s(s2 - 12)s(s2 - 22)...[s2 - (p - 1)2]1 + [d2p-1f + d2p-1f ] 1/2 -1/2 (2p - 1)!
2 s(s2 - 12)...[s2 - (p - 1)2] + d2pf 0 (2p)!
s(s2 - 12)...s(s2 - p2) 1 + [d2p+1f + d2p+1f ] (32) 1/2 -1/2 (2p + 1)!
2 where s = (x – x )/h and if n = 2p + 1 is odd.
0 If n = 2p is even, then the same formula is used deleting the last term.
The Stirling’s interpolation is used for calculation when x lies between 1 1 x - h and x + h. 0 0 4 4 It may be noted from the Table 3, that the odd order differences at x -1/2 are those which lie along the horizontal line between x and x .
0 -1 Similarly, the odd order differences at x are those which lie along the 1/2 horizontal line between x and x .
even order differences at x are those 0 1 0 which lie along the horizontal line through x .
0 215MTH 213 NUMERICAL ANALYSIS 1 Example 8: Using Stirling’s formula, find the value of (1.32) from the following table of values.
x 1.1 1.2 1.3 1.4 1.5 f(x) 1.3357 1.5095 1.6984 1.9043 2.1293 Solution: Table 9: Central Difference x f(x) df d2f d3f d4f 1.1 1.3357 0.1738 1.2 1.5095 0.0151 0.1889 0.0019 1.3 1.6984 0.0170 0.0002 0.2059 0.0021 1.4 1.9043 0.0191 0.2250 1.5 2.1293 Choose x = 1.3 0 (x - x ) 1.32- 1.3 Therefore s = 0 = = 0.2. h 0.1 From Eqn.
(32), we have s s2 s(s2 - 12) 1 f(x) » f + [df + df ]+ d2f + [d3f + d3f ]+ 0 -1/2 1/2 0 -1/2 1/2 2 2!
3!
2 s2(s2 - 12) d4f .
0 4!
Now, 1 1 [df + df ] = (0.1889 + 0.2059) = 0.1974 -1/2 1/2 2 2 1 1 [d3f + d3f ] = (0.0019 + 0.0021) = 0.0020 -1/2 1/2 2 2 Also d2f = 0.0170, d4f = 0.0002.
0 0 Substituting in the above equation, we get 0.04 (0.2)(- 0.96) f(x) = 1.6984 + (0.2) (0.1974) + (0.0170) + (0.0020) 2 6 216 MTH 213 MODULE 3 (0.04)(- 0.96) + (0.0002) 24 = 1.6984 + 0.03948 + 0.00034 – 0.00006 – 0 = 1.73816 ; 1.7382.
4.0 CONCLUSION As in the summary.
5.0 SUMMARY.
In this unit, we have derived interpolation formulas for data with equally spaced values of the argument.
We have seen how to find the value of f(x) for a given value of x by applying an appropriate interpolation formula derived in this section.
The application of the formulas derived in this section is easier when compared to the application of the formulas derived in Units1 and 2.
However, the formulas derived in this unit can only be applied to data with equally spaced arguments whereas the formulas derived in Units 1 and 2 can be applied for data with equally spaced or unequally spaced arguments.
Thus, the formulas derived in Units 1 and 2 are of a more general nature than those of Unit 3.
The interpolation polynomial which fits a given data can be determined by using any of the formulas derived in this section which will be unique whatever be the interpolation formula that is used.
The interpolation formulas derived in this unit are listed below: 1) Newton’s forward difference formula: n s Pn(x) = Pn(x0 + sh) = ∑k(cid:209) i f0 i=0 s(s - 1) s(s - 1)...s(s - n + 1) f + sVf + V2f + ... + Vnf 0 0 0 0 2!
n!
where s = (x – x )/h.
0 2) Newton’s backward difference formula: Pn(x) = Pn(xn + sh) = ∑n (- 1)kks(cid:209) k fn where s = (x – x0)/h k=0 3) Stirling’s central difference formula: 217MTH 213 NUMERICAL ANALYSIS 1 s s2 P (x) = P (x + sh) = f + [df + df ] + d2f + n n 0 0 1/2 -1/2 0 2 2!
s(s2 - 12) 1 s2(s2 - 12)...(s2 - (p - 1)2)s2f [d3f + d3f ] +...+ 0 1/2 -1/2 3!
2 (2p)!
s2(s2 - 12)...(s2 - p2) + [d2p+1f + d2p+1f ] 1/2 -1/2 (2p + 1)!
if n = 2p + 1 is odd.
If n = 2p is even, the same formula is used deleting the last term.
6.0 TUTOR-MARKED ASSIGNMENT.
1) Express (cid:209) 4f in terms of function values.
5 2) Show that (E + 1) d = 2(E – 1) m. 3) The population of a town in the decimal census was given below.
Estimate population for the year 1915.
Year x 1911 1921 1931 1941 1951 Population: y 46 66 81 93 101 (in thousands) 4) from the following table, find the value of y (0.23): x 0 .20 0.22 0.24 0.26 0.28 0.30 y 1.6596 1.6698 1.6804 1.6912 1.7024 1.7139 5) Find the number of men getting wages between Rs.
10 and Rs.
15 from the following table.
Wages in Rs.
x 0 - 10 10 - 20 20 - 30 30 -40 No.
of men y 9 30 35 42 6) The area A of a circle of diameter d is given in the following table.
Find the area of the circle when the diameter is 82 units.
d 80 85 90 95 100 A 5026 5674 6362 7088 7854 7) From the table of values of 3a, find the value of y when x = 0.29.
218 MTH 213 MODULE 3 8) Using the backward differences interpolation, find the polynomial which agree with the values of y(x) where y(0) = 1, y(1) = 0, y(2) = 1 and y(3) = 10.
9) In 3c, find the number of candidates whose marks are less than or equal to (i) 70, (ii) 89.
219MTH 213 NUMERICAL ANALYSIS 1 10) Find f(1.725) from the following table.
x 1.5 1.6 1.7 1.8 1.9 f(x) 4.4817 4.9530 5.4739 6.0496 6.6859 11) Evaluate f(4.325) from the following.
x 4.1 4.2 4.3 4.4 4.5 f(x) 30.1784 33.3507 36.8567 40.7316 45.0141 12) Find the approximate value of y(2.15) from the table x 0 1 2 3 4 f(x) 6.9897 7.4036 7.7815 8.1281 8.4510 7.0 REFERENCES/FURTHER READINGS.
Engineering Mathematics P.D.S.
Verma.
Generalized Functions in Mathematical Physics by V.S.
Viadimirov.
Fundamentals of the Finite Element Method.
Hartley Grandin, Fr.
220 MTH 213 MODULE 3 MODULE 2 SOLUTION OF LINEAR ALGEBRAIC EQUATIONS Unit 1 Direct Methods Unit 2 Inverse of a Square Matrix Unit 3 Iterative Methods Unit 4 Eigen Values and Eigen Vectors UNIT 1 DIRECT METHOD CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Preliminaries 3.2 Cramer’s Rule 3.3 Direct Methods for Special Matrices 3.4 Gauss Elimination Methods 3.5 LU Decomposition Methods 4.0 Conclusion 5.0 Summary 6.0 Tutor-Marked Assignment 7.0 References/Further Readings Notations and Symbols A = [a ] Matrix with the elements a ik ik det A = |A| Determinant of a square matrix A ¥ infinity r Rho u Nu m Mu l Lambda ||A|| Norm of a matrix A i Imaginary unit, i2 = -1.
Also see the list given in Block 1.
1.0 INTRODUCTION One of the commonly occurring problems in applied mathematics is finding one or more roots of an equation f(x) = 0.
In most cases explicit solutions are not available and we are satisfied with being able to find 221MTH 213 NUMERICAL ANALYSIS 1 one or more roots to a specified degree of accuracy.
In Block 1, we have discussed various numerical methods for finding the roots of an equation f(x) = 0.
There we have also discussed the convergence of these methods.
Another important problem of applied mathematics is to find the solution of systems of linear equations arise in a large number of areas, both directly in modelling physical situations and indirectly in the numerical solution of other mathematical models.
These applications occur in all areas of the physical, biological and engineering sciences.
For instance, in physics, the problem of steady state temperature in a plate is reduced to solving linear equations.
Engineering problems such as determining the potential in certain electrical networks, stresses in a building frame, flow rates in a hydraulic system etc.
are all reduced to solving a set of algebraic equations simultaneously.
Linear algebraic systems are also involved in the optimization theory, least squares fitting of data, numerical solution of boundary value problems for ordinary and partial differential equations, statistical inference etc.
Hence, the numerical solution of systems linear algebraic equations plays a very important role.
Numerical methods for solving linear algebraic systems may be divided into two types, direct and iterative.
Direct methods are those which, in the absence of round-off or other errors, yield the exact solution in a finite number of elementary arithmetic operations.
Iterative methods start with an initial approximation.
To understand the numerical methods for solving linear system of equations it is necessary to have some knowledge of the properties of matrices.
You might have already studied matrices, determinants and their properties in your linear algebra courses.
However, we begin with a quick recall of few definitions here.
In this unit, we have also discussed some direct methods for finding the solution of system of linear algebraic equations.
2.0 OBJECTIVES After studying this unit, you should be able to: •••• state the difference between the direct and iterative methods of solving the system of linear algebraic equations •••• obtain the solution of system of linear algebraic equations by using the direct method •••• use the pivoting technique while transforming the coefficient matrix to upper or lower triangular matrix.
222 MTH 213 MODULE 3 3.0 MAIN CONTENTS 3.1 Preliminaries As we have mentioned earlier, you might be already familiar with vectors, matrices, determinants and their properties (Ref.
Linear algebra MTE-02).
A rectangular array of (real or complex) numbers of the from     a a ...... a  11 12 2n  a a ...... a   21 22 2n      a a ....... a  n1 n2 nn is called a matrix.
The numbers a , a , ..., a are the elements of the 11 12 nn matrix.
The horizontal lines are called rows and the vertical lines called columns of the matrix.
A matrix with m rows and n columns is called an m´ n matrix (read as m by n matrix).
We usually denote matrices by capital letters A, b etc., or by (a ), (b ) etc.
jk ik If the matrix has the same number of rows and columns, we call it a square matrix and the number of rows or columns is called its order.
If a matrix has only one column it is a column matrix or column vector and if it has only one row it is a row matrix or row vector.
a  11   a The matrices A =  21= [a , a , ... a ]T and  :  11 21 n1   a  n1 B = [a , a , ..., a ] are respectively the column and row matrices.
We 11 12 1n give below some special square matrices A = (a ) of order n. ij 1) A matrix A = (a ) in which a = 0 (i, j = 1, 2 ....., n) is called a ij ij null matrix and is denoted by 0.
e.g., 0 0 A =   is a 2 ´ 2 null matrix.
0 0 2) A matrix A in which all the non-diagonal elements vanish i.e., a ij = 0 for i ¹ j is called a diagonal matrix.
223MTH 213 NUMERICAL ANALYSIS 1 a 0 0  11   E.g., A = 0 a 0  22   0 0 a  33 is a 3 ´ 3 diagonal matrix.
3) The identity matrix I is a diagonal matrix in which all the diagonal elements are equal to one.
The identity matrix of order 4 is 1 0 0 0   0 1 0 0   I = 0 0 1 0   0 0 0 1 4) A square matrix is lower triangular if all the elements above the main diagonal vanish i.e., a = 0 for j > i.
A lower triangular ij matrix of order 3 has the form a 0 0  11   A = a a 0  21 22  a a a  31 32 33 Similarly upper triangular matrices are matrices in which, a = 0 for i > j. ij a a a  11 12 13   e.g., A = 0 a a  22 23  0 0 a  33 Two matrices A = (a ) and B = (b ) are equal iff they have the same ij ij number of rows and columns and their corresponding elements are equal, that is a = b for all i, j. ij ij You must also be familiar with the addition and multiplication of matrices.
Addition of matrices is defined only for matrices of same order.
The sum C = A + B of two matrices A and B, is obtained by adding the corresponding elements of A and B, i.e., c = a + b .
ij ij ij  4 6 3 5 - 1 0 For example, if A =  and B =   then  0 1 2 3 1 0 224 MTH 213 MODULE 3 1 5 3 A + B =   3 2 2 Product of an m ´ n matrix A = (a ) and an n ´ p matrix B = (b ) is an ij ij m ´ p matrix C. C = AB, whose (i, k)th entry is 0 ∑ c = a b = a b + a b + ... + a b ij ij ij ij ij i2 i2 in nk j=1 That is, to obtain the (i, k)th element of AB, take the ith row of A and kth column of B, multiply their corresponding elements and add up all these products.
For example, if 1 1 2 2 3 - 1   A =   and B = 2 4 2 then (1, 2)the element 1 0 2  1 2 1 of AB is 1   4   [2 3 -1] = 2 * 1 + 3 * 4 + (-1) *2 = 12 2     Note that two matrices A and B can be multiplied only if the number of columns of A equals the number of rows of B.
In the above example the product BA is not defined.
The matrix obtained by interchanging the rows and columns of A is called the transpose of A and is denoted by AT 2 3 2 - 1 If A =   then AT =   1 1 3 1  Determinant is a number associated with square matrices.
a a  For a 2 ´ 2 matrix A =  11 12 a a  21 22 a a  det (A) = det  11 12 = a a – a a 11 22 12 21 a a  21 22 225MTH 213 NUMERICAL ANALYSIS 1 a a a  11 12 13   For a 3 ´ 3 matrix A = a a a  21 22 23 a a a  31 32 33 a a  a a  a a  det(A) = a det  22 23 - a det  21 23+ a det  21 22 11 12 13 a a  a a  a a  32 33 31 33 31 32 A determinant can be expanded about any row or column.
The determinant of an n ´ n matrix A = (a ) is given by det(A) = (-1)i+1a ij ij det(A ) + (-1)i+2a det(A ) + ... + (-1)i+na det(A ), where the ij i2 i2 in in determinant is expanded about the ith row and A is the (n – 1) ´ (n – 1) ij matrix obtained from A by deleting the ith row and jth column and i £ i £ n. Obviously, computation is simple if det(A) is expanded along a row or column that has maximum number of zeros.
This reduces the number of terms to be computed.
The following example will help you to get used to calculating determinants.
Example 1: 1 2 6   If A = 5 4 1 calculated det (A).
  7 3 2 Solution: Let us expand by the first row.
We have 4 1 5 1 |A | =   = 4 * 2 – 1 * 3 = 5, |A | =   = 5 * 2 = 7 * 1 = 3 11 12 3 2 7 2 , 5 4 |A | =  = 5 * 3 – 4 * 7 = -13.
13 7 3 Thus, |A| = (-1)1+1*1*|A |+(-1)1+2*2*|A |+(-1)1+3*6*|A |=5–6–78 = -79 11 12 13 If the determinant of a square matrix A has the value zero, then the matrix A is called a singular matrix, otherwise, A is called a nonsingular matrix.
We shall now give some more definitions.
226 MTH 213 MODULE 3 Definition: The inverse of an n ´ n nonsingular matrix A is an n ´ n matrix B having the property A B = B A = i where I is an identity matrix of order n ´ n. the inverse matrix B if it exists, is denoted by A-1 and is unique.
Definition: For a matrix A = (a ), the cofactor A of the element a is given by ij ij ij A = (-1)i+j M ij ij where M (minor) is the determinant of the matrix of order (n – 1) ´ (n ij – 1) obtained from A after deleting its ith row and the jth column.
Definition: The matrix of cofactors associated with the n ´ n matrix A is an n ´ n matrix Ac obtained from A by replacing each element of A by its cofactor.
Definition: The transpose of the cofactor matrix Ac of A is called the adjoint of A and is written as adj(A).
Thus adj(A) = (Ac)T Let us now consider a system of n linear algebraic equations in n unknowns a x + a x + .... + a x = b 11 1 12 2 1n n 1 a x + a x + .... + a x = b (1) 21 1 22 2 2n n 2 .
.
.
.
.
.
.
.
.
a x + a x + .... + a x = b n1 1 n2 2 nn n n where the coefficients a and the constant b (i = 1, ...., n) are real and ij i known.
This system of equations in matrix from may be written as A x = b (2) 227MTH 213 NUMERICAL ANALYSIS 1 where a a a  x  b  11 12 1n 1 1       a a a x b  21 22 2n  2  2 A =   x =   b =                     a a a  x  b  n1 n2 nn n n A is called the coefficient matrix and has real elements.
Our problem is to find the values x, i = 1, 2 ...., n if they exist, satisfying i Eqn.
(2).
Before we discuss some methods of solving the system (2), we give the following definitions.
Definition: A system of linear Eqns.
(2) is said to be consistent if it has at least one solution.
If no solution exists, then the system is said to be inconsistent.
Definition: The system of Eqns.
(2) is said to be homogeneous if b = 0, that is, all the elements b, b , ...., b are zero, otherwise the system is called non- i 2 n homogeneous.
In this unit, we shall consider only non-homogeneous systems.
You also know from you linear algebra that the non-homogeneous system of Eqns.
(2) has a unique solution, if the matrix A is nonsingular.
You may recall the following basic theorem on the solvability of linear systems (Ref.
Theorem 4, Sec.
5.0, Unit 1, Block 3, Module 1).
Theorem 1: A non-homogeneous system of n linear equations in n known has a unique solution if and only if the coefficient matrix A is nonsingular.
If A is nonsingular, thenA-1 exists, and the solution of system (2) can be expressed as x = A-1b.
In case the matrix A is singular, then the system (2) has no solution if b ¹ 0 or has an infinite number of solutions if b = 0. here we assume that A is a nonsingular matrix.
228 MTH 213 MODULE 3 As we have already mentioned in the introduction, the methods of solution of the system (2) may be classified into two types: i) Direct Methods: which in the absence of round-off errors give the exact solution in a finite number of steps.
ii) Iterative Methods: Starting with an approximate solution vector x(0), these methods generates a sequence of approximate solution vectors {x(k)} which converge to the exact solution vector x as the number of iterations k ® ¥ .
Thus iterative methods are infinite processes.
Since we perform only a finite number of iterations, these methods can only find some approximation to the solution vector x.
We shall discuss iterative methods later in Units 4 and 5.
In this unit we shall discuss only the direct methods.
You are familiar with one such method due to the mathematician Cramer and known as Cramer’s Rule.
Let us briefly review it.
3.2 Cramer’s Rule In the system (2), let d = det(A) ¹ 0 and b ¹ 0.
Then the solution of the system is obtained as x = d/d, i = 1, 2, ...., n (3) i i where d is the determinant of the matrix obtained from A by replacing i the ith column of A by the column vector b. let us illustrate the method through an example.
Example 2: Solve the system of equations.
3x + x + 2x = 3 1 2 3 2x - 3x - x = -3 1 2 3 x - 2x - x = 4 1 2 3 using Cramer’s rule.
Solution: We have, 3 1 2 d = |A| = 1 - 3 - 1 = 8 1 2 1 229MTH 213 NUMERICAL ANALYSIS 1 3 1 2 d = - 3 - 3 - 1 1 4 2 1 = 8 (first column in A is replaced by the column vector b) 3 3 2 d = 2 - 3 - 1 2 1 4 1 = 16 (second column in A is replaced by the column vector b 3 1 3 d = 2 - 3 - 3 3 1 2 4 = -8 (third column in A is replaced by the column vector b) Using (3), we get the solution x = d /d = 1; x = d /d = 2; x = d /d = -1 1 1 2 2 3 3 While going through the example and attempting the self assessment exercises you must have observed that in Cramer’s methods we need to evaluate n + 1 determinants each of order n, where n is the number of equations.
If the number of operations required to evaluate a determinant is measured in terms of multiplications only, then to evaluate a determinant of second order, i.e., a a   11 12 = a a – a a 11 22 12 21 a a  21 22 we need two multiplications or (2 – 1) 2!
multiplications.
To evaluate a determinant of third order a a a  11 12 13   a a a =(a a a -a a a -a a a +a a a +a a a -a a a  21 22 23 11 22 33 11 23 32 12 21 33 12 23 31 13 21 32 13 22 31) a a a  31 32 33 we need 12 multiplication or (3 – 1)3!
multiplications.
In general, to evaluate a determinant of nth order we need (n – 1)n!
multiplications.
230 MTH 213 MODULE 3 Also for a system of n equations, Cramer’s rule requires n + 1determinants each of order n and performs n divisions to obtain x, i = i 1, 2, ...., n. Thus the total number of multiplications and divisions needed to solve a system of n equations, using Cramer’s rule becomes M = total number of multiplications + total number of divisions = (n + 1) (n - 1)n!
+ n In Table 1, we have given the values of M for different values of n. Table 1 Number of equations Number of operations N n 2 8 3 51 4 364 5 2885 6 25206 7 241927 8 2540168 9 29030409 10 359251210 From the table, you will observe that as n increases, the number of operations required for Cramer’s rule increases very rapidly.
For this reason, Cramer’s rule is not generally used for n > 4. hence for solving large systems, we need more efficient methods.
In the next section we describe some direct methods which depend on the form of the coefficient matrix.
3.3 Direct Methods for Special Matrices We now discuss three special forms of matrix A in Eqn.
(2) for which the solution vector x can be obtained directly.
Case 1: A = D, where D is diagonal matrix.
In this case the systems of Eqns.
(2) are of the form a x ...................... = b 11 1 1 .
a x .
= b 22 2 2 .
.
.
= .
.
.
.
.
.
.
.
.
.
a x = b nn n n 231MTH 213 NUMERICAL ANALYSIS 1 and det (A) – a a .... a 11 22 nn Since the matrix A is nonsingular, a ¹ 0 for 1, 2, ....., n and we obtain 11 the solution as x = b/a , i = 1, 2, ...., n. i i ii Note that in this case we need only n divisions to obtain the solution vector.
Case 2 : A = L, where L is a lower triangular matrix (a = 0, j > i).
The system ij of Eqns.
(2) is now of the form a x = b 11 1 1 a x + a x = b 21 1 22 2 2 a x + a x + a x = b 31 1 32 2 33 3 3 .
(4) .
.
a x + a x + a x + ... + a x = b n1 1 n2 2 n3 3 nn n n and det (A) = a a ...a .
11 22 nn You may notice here that the first equation of the system (4) contains only x , the second equation contains only x and x and so on.
Hence, 1 1 2 we find x from the first equation, x from the second equation and 1 2 proceed in that order till we get x from the last equation.
n Since the coefficient matrix A is nonsingular, a ¹ 0, i = 1, 2, ..., n. we 11 thus obtain x = b /a 1 1 11 x = (b – a x )/a 2 2 21 1 22 x = (b – a x – a x )/a 3 3 31 1 32 2 33 .
.
.
n- 1 ∑ x = (b - a x)/a n n ij j nn j=1 In general, we have for any i n- 1( ) ∑ x = (b - a x /a i = 1, 2, ...., n. (5) i i ij j ii j=1 232 MTH 213 MODULE 3 For example, consider the system of equations 5x = 5 1 -x - 2x = -7 1 2 -x + 3x + 2x = 5 1 2 3 From the first equation we have, x = 1 1 From the second equation we get, - 7 + x x = 1 = 3 2 - 2 and from the third equation we have, 5 + x - 3x 3 x = 1 2 = - .
3 2 2 Since the unknowns in this methods are obtained in the order x , x , ...., 1 2 x , this method is called the forward substitution method.
n The total number of multiplications and divisions needed to obtain the complete solution vector x, using this method is M = 1 + 2 + ..... + n = n(n + 1)/2.
Case 3: A = U, where U is an upper triangular matrix (a = 0, j < 1).
The ij system (2) is now of the form a x + a x + a x + ... + a x = b 11 1 12 2 13 3 1n n 1 a x + a x + ... + a x = b 22 2 23 3 2n n 2 a x + ... + a x = b (6) 33 3 3n n 3 a x + a x = b n-1,n-1 n-1 n-1,n n n-1 a x = b nn n n and det (A) = a a ...a .
11 22 nn You may notice here that the nth (last) equation contains only x , the (n n – 1)th equation contains x and x and so on.
We can obtain x from the n n-1 n nth equation, x from the (n – 1)th equation and proceed in that order n-1 233MTH 213 NUMERICAL ANALYSIS 1 till we get x from the first equation.
Since the coefficient matrix A is 1 nonsingular, a ¹ 0, i = 1, 2, ...., n and we obtain ii x = b /a n n nn x = (b – a x )/a n-1 n-1 n-1,n n n-1,n-1 n ∑ x = (b - a x)/a 1 i ij j 11 j=2 or in general n ∑ x = (b - a x)/a i = 1, 2, ..., n (7) i i ij j ii j=i+1 Since the unknowns in this method are determined in the order x , x , n n-1 ..., x , this method is called the back substitution method.
The total 1 number pf multiplications and divisions needed to obtain the complete solution vector x using this method is again n(n + 1)/2.
Let us consider the following example.
Example 3: Solve the linear system of equations 2x + 3x – x = 5 1 2 3 -2x – x = -7 2 3 -5x = -15 3 Solution: From the last equation, we have x = 3.
3 From the second equation, we have b - a x (- 7 + 3) x = 2 23 3 = = 2.
2 a (- 2) 22 Hence from the first equation, we get b - a x - a x (5- 3.2 + 3) x = 1 12 2 13 3 = = 1 1 a 2 11 234 MTH 213 MODULE 3 In the above discussion you have observed that the system of Eqns.
(2) can be easily solved if the coefficient matrix A in Eqns.
(2) has one of the three forms D, L or U or if it can be transformed to one of these forms.
Now, you would like to know how to reduce the given matrix A into one of these three forms?
One such method which transforms the matrix A to the form U is the Gauss elimination method which we shall describe in the next section.
3.4 Gauss Elimination Method Gauss elimination is one of the oldest and most frequently used methods for solving systems of algebraic equations.
It is attributed to the famous German mathematician, Carl Fredrick Gauss (1777 – 1855).
This method is the generalization of the familiar method of eliminating one unknown between a pair of simultaneous linear equations.
You must have learnt this method in your linear algebra course (MTH 122).
In this method the matrix A is reduced to the form U by using the elementary row operations which include: i) interchanging any two rows ii) multiplying (or dividing) any row by a non-zero constant iii) adding (or subtracting) a constant multiple of one row to another row.
The operation R + mR is an elementary row operation, that means, add i j to the elements of the ith row m times the corresponding elements of the jth row.
The elements in the jth row remain unchanged.
If any matrix A is transformed into another matrix B by a series of elementary row operations, we say that A and B are equivalent matrices.
Consequently, we have the following definition.
To understand the Gauss elimination method let us consider a system of three equations: a x + a x + a x = b 11 1 12 2 13 3 1 a x + a x + a x = b (8) 21 1 22 2 23 3 2 a x + a x + a x = b 31 1 32 2 33 3 3 Let a ¹ 0.
In the first stage of elimination we multiply the first 11 equation in Eqns.
(8) by m = (-a /a ) and add to the second equation.
21 21 11 Then multiply the first equation by m = (-a /a ) and add to the third 31 31 11 equation.
This eliminates x from the second and third equations.
The 1 new system called the first derived system then becomes 235MTH 213 NUMERICAL ANALYSIS 1 a x + a x + a x = b 11 1 12 2 13 3 1 a(1)x + a(1)x = b(1) (9) 22 2 23 3 2 a(1)x + a(1)x = b(1) 32 2 33 3 3 where, a a(1) = a - 21 a 22 22 a 12 11 a a(1) = a - 21 a 23 23 a 13 11 a b(1) = b - 21 b 2 2 a 1 11 a a(1) = a - 31a 32 32 a 12 11 a a(1) = a - 31a 33 33 a 13 11 a b(1) = b - 31b 3 3 a 1 11 In the second stage of elimination we multiply the second equation in (9) by m = (-a(1)/a(1)), a(1) ¹ 0 and add to the third equation.
This 32 32 22 22 eliminates x from the third equation.
The new system called the second 2 derived system becomes a x + a x + a x = b 11 1 12 2 13 3 1 a(1)x + a(1)x = b(1) (11) 22 2 23 3 2 a(2)x = b(2) 33 3 3 where a(1) a(2) = a(1) - 32 a(1) 33 33 a(1) 23 22 a(1) b(2) = b(1) - 32 b(1) (12) 3 3 a(1) 2 22 You may note here that the system of Eqns.
(11) is an upper triangular system of the form (6) and can be solved using the back substitution provided method a(2) ¹ 0.
33 Let us illustrate the method through an example.
236 MTH 213 MODULE 3 Example 4: Solve the following linear system 2x + 3x – x = 5 1 2 3 4x + 4x – 3x = 3 (13) 1 2 3 -2x + 3x – x = 1 1 2 3 using Gauss elimination method.
Solution: To eliminate x from the second and third equations of the system (13) 1 - 4 add = -2 times the first equation to the second equation and 2 add -(-2)/2 = 1 times the first equation to the third equation.
We obtain the new system as 2x + 3x – x = 5 1 2 3 -2x – x = -7 (14) 2 3 6x – 2x = 6 2 3 In the second stage, we eliminate x from the third equation of system 2 (14).
Adding -6/(-2) = 3 times the second equation to the third equation, we get 2x + 3x - x = 5 1 2 3 -2x - x = -7 (15) 2 3 -5x = -15 3 System (15) is in upper triangular form and its solution is x = 3, x = 2, x = 1.
3 2 1 You may observe that we can write the above procedure more conveniently in matrix form.
Since the arithmetic operations we have performed here affect only the elements of the matrix A and the vector b, we consider the augmented matrix i., [A|b] (matrix A augmented by the vector b) and perform the elementary now operations on the augmented matrix.
a a a b   11 12 13 1 a a [A|b] = a a a b R - 21 R , R - 31 R  21 22 23 2 2 a 1 3 a 1 a a a b  11 11 31 32 33 3 237MTH 213 NUMERICAL ANALYSIS 1 a a a b   11 12 13 1  a(1) ( ) ( ) () »  a1 a1 b1  R - 32 R 22 32 2 3 a(1) 2  ( )  a1 a b 22  32 33 3  a a a b   11 12 13 1  ( ) ( ) () »  a1 a1 b1  22 32 2   a b  33 3  which is in the desired from where, a(1), a(1), a(1), a(1), b(1), b(1), a(2), a(2) 22 23 32 33 2 3 33 3 are given by Eqns.
(10) and (12).
Definition: The diagonal elements a , a(1) and a(2) which are used as 11 22 33 divisors are called pivots.
You might have observed here that for a linear system of order 3, the elimination was performed in 3 – 1 = 2 stages.
In general for a system of n equations given by Eqns.
(2) the elimination is performed in (n – 1) stages.
At the ith stage of elimination, we eliminate x, starting from (i + i 1)th row up to the nth row.
Sometimes, it may happen that the elimination process stops in less than (n – 1) stages.
But this is possible only when no equations containing the unknowns are left or when the coefficients of all the unknowns in remaining equations become zero.
Thus if the process stops at the rth stage of elimination then we get a derived system of the form a x + a x + ... + a x = b 11 1 12 2 1n n 1 a(1)x + ... + a(1)x = b(1) 22 2 2n n 2 .
.
.
(16) a(r-1)x + ... + a(r-1)x = b(r-1) rr r rn n r 0 = b(r-1) r+1 .
.
.
.
.
.
0 = b(r-1) n Where r £ n and a ¹ 0, a(1) ¹ 0, ...., a(r-1) ¹ 0.
11 22 rr In the solution of system of linear equations we can thus expect two different situations 238 MTH 213 MODULE 3 1) r = n 2) r < n. Let us now illustrate these situations through examples.
Example 5: Solve the system of equations 4x + x + x = 4 1 2 3 x + 4x – 2x = 4 1 2 3 -x + 2x – 4x = 2 1 2 3 using Gauss elimination method Solution: Here we have 4 1 1 4   1 1 [A|b] = 1 4 - 2 4 R - R , R + R   2 1 3 1 4 4 1 2 - 4 2 4 1 1 4   3 = 0 15/4 9/4 3 R3 - R2 5 0 9/4 15/43 4 1 1 4    = 0 15/4 - 9/4 3  0 0 - 12/56/5 using back substitution method, we get x = -1/2; x = 1/2; x = 1 3 2 1 15 (- 12) Also, det (A) = 4 * * = -36 4 5 Thus in this case we observe that r = n = 3 and the given system of equations has a unique solution.
Also the coefficient matrix A in this case is nonsingular.
Let us look at another example.
Example 6: Solve the system of equations 239MTH 213 NUMERICAL ANALYSIS 1 3x + 2x + x = 3 1 2 3 2x + x + x = 0 1 2 3 6x + 2x + 4x = 6 1 2 3 using Gauss elimination method.
Does the solution exist?
Solution: We have 3 2 13   2 [A|b] = 2 1 1 0 R - R , R – 2R   2 1 3 1 3 6 2 46 3 2 1 3    = 0 - 1/3 1/3- 2 R3 – 6R2 0 - 2 2 0  3 2 1 3    = 0 - 1/3 1/3- 2 0 0 0 12  In this case you can see that r < n and elements b , b(1) and b(2) are all 1 2 3 non-zero.
Since we cannot determine x from the last equation, the system has no 3 solution.
In such a situation we say that the equations are inconsistent.
Also note that det (A) = 0 i.e., the coefficient matrix is singular.
We now consider a situation in which not all b’s are non-zero.
Example 7: Solve the system of equations 16x + 22x + 4x = -2 1 2 3 4x – 3x + 2x = 9 1 2 3 12x + 25x + 2x = -11 1 2 3 using gauss elimination method.
Solution: In this case we have 240 MTH 213 MODULE 3 6 22 4 - 2    1 3 [A|b] = 4 - 3 29 R - R , R - R   2 1 3 1 4 4 12 25 2 - 11 6 22 4 - 2    = 0 - 17/2 1 19/2  R3 + R2 0 17/2 - 1- 19/2 6 22 4 - 2    = 0 - 17/2 119/2 0 0 0 0  Now in this case r < n and elements b , b(1) are non-zero, but b(2) is zero.
1 2 3 Also the last equation is satisfied for any value of x .
Thus, we get 3 x = any value 3 2 19 x = - ( - x ) 2 3 17 2 1 x = (-2 – 22x – 4x ) 1 2 3 16 Hence the system of equations has infinitely many solutions.
Note that in this case also det(A) = 0.
The conclusions derived from Examples 4, 5 and 6 are true for any system of linear equations.
We now summarize these conclusions as follows: i) If r = n, then the system of Eqns.
(2) has a unique solution which can be obtained using the back substitution method.
Moreover, the coefficient matrix A in this case is nonsingular.
ii) If r < n and all the elements b(r-1), b(r-1), ...., b(r-1) are zero then r+1 r+2 n the system has no solution.
In this case we say that the system of equations inconsistent.
iii) If r < n and all the elements b(r-1), b(r-1), ....., b(r-1), if present, are r+1 r+2 n zero, then the system has infinite number of solutions.
In this case the system has only r linearly independent rows.
241MTH 213 NUMERICAL ANALYSIS 1 In both the cases (ii) and (iii), the matrix A is singular.
Now we estimate the number of operations (multiplication and division) in the Gauss elimination method for a system of n linear equations in n unknowns as follows: No.
of divisions 1st step of elimination (n – 1) divisions 2nd step of elimination (n – 2) divisions (n – 1)th step of elimination 1 divisions \ Total number of divisions = ( n – 1) + (n – 2) + ..... + 1 n(n - 1) = å (n – 1) = 2 No.
of multiplications 1st step of elimination n(n – 1) multiplications 2nd step of elimination(n – 1) (n – 2) multiplications (n – 1)th step of elimination 2.1 multiplications \ Total number of multiplications = n(n – 1) + (n – 1) (n – 1) + .... + 2.1 = å n(n – 1) = å n2 - å n n(n + 1)(2n + 1) n(n + 1) = - 6 2 1 = n(n + 1) (n – 1) 3 Also the back substitution adds n divisions (one division at each step) and the numbers of multiplications added are (n – 1)th equation 1 multiplication (n – 2)th equation 2 multiplication 1st equation ( n – 1) multiplication n(n - 1) \ Total multiplications = å (n – 1) = 2 n(n - 1) n(n + 1) Total operation added by back substitution = + n = 2 2 You can verify these results for n = 3 from Eqns.
(9) and (11).
Thus to find the solution vector x using the Gauss elimination method, we need 242 MTH 213 MODULE 3 n(n - 1) 1 n M = + n(n2 – 1) + (n + 1) 2 3 2 n = [2n2 + 6n – 2] 6 n3 n = + n2 - 6 3 operations.
For large n, we may say the total number of operations 1 needed is n3 (approximately).
Thus, we find that Gauss elimination 3 method needs much lesser number of operations compared to the Cramer’s rule.
It is clear from above that you can apply Gauss elimination method to a system of equations of any order.
However, what happens if one of the diagonal elements i.e., the pivots in the triangularization process vanishes?
Then the method will fail.
In such situations we modify the Gauss elimination method and this procedure is called pivoting.
Pivoting In the elimination procedure the pivots a , a(1), ..., a(n-1) are used as 11 22 nn divisors.
If at any stage of the elimination one of these pivots say a(i-1), ii (a(0) = a ), vanishes then the elimination procedure cannot be continued 11 11 further (see Example 8).
Also, it may happen that the pivot a(i-1), though ii not zero, may be very small in magnitude compared to the remaining elements in the ith column.
Using a small number as a divisor may lead to the growth of the round-off error.
In such cases the multipliers (e.g.
- a(i- 2) - a(i- 3) i- 1,i , i- 2,i ) will be larger than one in magnitude.
The use of large a(i- 1) a(i- 1) ii ii multiplier will lead to magnification of error both during the elimination phase and during the back substitution phase of the solution.
To avoid this we rearrange the remaining rows (ith row upto nth row) so as to obtain a non-vanishing pivot or to make it the largest element in magnitude in that column.
The strategy is called pivoting (see Example 9).
The pivoting is of the two types; partial pivoting and complete pivoting.
Partial Pivoting In the first stage of elimination, the first column is searched for the largest element in magnitude and this largest element is then brought at the position of the pivot by interchanging the first row with the row having the largest element in magnitude in the first column.
In the second stage of elimination, the second column is searched for the 243MTH 213 NUMERICAL ANALYSIS 1 largest element in magnitude among the (n – 1) elements leaving the first element and then this largest element in magnitude is brought at the position of the second pivot by interchanging the second row with the row having the largest element in the second column.
This searching and interchanging of rows is repeated in all the n – 1 stages of the elimination.
Thus we have the following algorithm to find the pivot.
For i = 1, 2, ....., n, find j such that a(i-1) = max a(i-1) , i k≤ n, ≤ ji k ki and interchange rows i and j.
Complete Pivoting In the first stage of elimination, we search the entire matrix A for the largest element in magnitude and bring it at the position of the pivot.
In the second stage of elimination we search the square matrix of order n – 1 (leaving the first row and the first column) for the largest element in magnitude and bring it to the position of second pivot and so on.
This requires at every stage of elimination not only the interchanging of rows but also interchanging of columns.
Complete pivoting is much more complicated and is not often used.
In this unit, by pivoting we shall mean only partial pivoting.
Let us now understand the pivoting procedure through examples.
Example 8: Solve the system of equations x + x + x = 6 1 2 3 3x + 3x + 4x = 20 1 2 3 2x + x + 3x = 13 1 2 3 Using Gauss elimination method with partial pivoting.
Solution: Let us first attempt to solve the system without pivoting.
We have 1 1 1 6    [A|b] = 3 3 4 20 R – 3R , R – 2R   2 1 3 1 2 1 313 244 MTH 213 MODULE 3 1 1 16   = 0 0 12 0 - 1 11 Note that in the above matrix the second pivot has the value zero and the elimination procedure cannot be continued further unless, pivoting is used.
Let us now use the partial pivoting.
In the first column 3 is the largest element.
Interchanging the rows 1 and 2, we have 3 3 4 20   1 2 [A|b] = 1 1 1 6 R - R , R - R   2 1 3 1 3 3 2 1 313 3 3 4 20    = 0 0 - 1/3- 2/3 0 - 1 1/3 - 1/3 In the second column, 1 is the largest element in magnitude leaving the first element.
Interchanging the second and third rows we have 3 3 4 20    [A|b] = 0 - 1 1/3 - 1/3 0 0 - 1/3- 2/3 You may observe here that the resultant matrix is in triangular form and no further elimination is required.
Using back substitution method, we obtain the solution x = 2, x = 1, x = 3.
3 2 1 Let us consider another example.
Example 9: Solve the system of equations 0.0003 x + 1.566 x = 1.569 1 2 0.3454 x – 0.436 x = 3.018 1 2 (17) 245MTH 213 NUMERICAL ANALYSIS 1 using Gauss elimination method with and pivoting.
Assume that the numbers in arithmetic calculations are rounded to four significant digits.
The solution of the system (17) is x = 10, x = 1.
1 2 Solution: Without Pivoting a 0.3454 m = - 21 = - = -1151.0 (rounded to four places) 21 a 0.0003 11 a(1) = -0.436 – 1.566 ´ 1151 22 = -0.436 – 1802.0 – 1802.436 = -1802.0 b(1) = 3.018 – 1.569 ´ 1151.0 2 = 3.018 – 1806.0 = -1803.0 Thus, we get the system of equations 0.0003 x + 1.566 x = 1.569 1 2 - 1802.0 x = -1803.0 2 which gives 1803.0 x = = 1.001 2 1802.0 1.569- 1.566´ 1.001 1.569- 1.568 x = = 1 0.0003 0.0003 = 3.333 which is highly inaccurate compared to the exact solution.
We interchange the first and second equations in (17) and get 0.3454 x – 0.436 x = 3.018 1 2 0.0003 x + 1.566 x = 1.569 1 2 we obtain a m = - 21 = -0.0009 21 a 11 a(1) = 1.566 – 0.0009 ´ (0.436) 22 1.566 – 0.0004 = 1.566 b(1) = 1.569 – 3.018 ´ (0.0009) 2 = 1.569 - -.0027 = 1.566 246 MTH 213 MODULE 3 Thus, we get the system of equations 0.3454 x – 0.436 x = 3.018 1 2 1.566 x = 1.566 2 which gives x = i 2 3.018 + 0.436 3.454 x = = = 10 1 0.3454 0.3454 which is the exact solution.
We now make the following two remarks about pivoting.
Remark: If the matrix A is diagonally dominant i.e., n a ³ ∑a , then no pivoting is needed.
See Example 5 in which A is ii ii i=1 j=1 diagonally dominant.
Remark: If exact arithmetic is used throughout the computation, pivoting is not necessary unless the pivot vanishes.
However, if computation is carried up to a fixed number of digits, we get accurate results if pivoting is used.
There is another convenient way of carrying out the pivoting procedure.
Instead of physically interchanging the equations all the time, the n original equations and the various changes made in them can be recorded in a systematic way.
Here we use an n ´ (n + 1) working array or matrix which we call W and is same as our augmented matrix [A|b].
Whenever some unknown is eliminated from an equation, the changed coefficients and right side for this equation are calculated and stored in the working array W in place of the previous coefficients and right side.
Also, we use an n-vector which we call p = (p) to keep track of which i equations have already been used as pivotal equation (and therefore should not be changed any further) and which equations are still to be modified.
Initially, the ith entry p pf p contains the integer i, i = 1, ........, i n and working array W is of the form 247MTH 213 NUMERICAL ANALYSIS 1 a a a b  11 12 1n 1   a a a b   21 22 2n 2 W = (w ) =   ij       a a a b  n1 n2 nn n Further, one has to be careful in the selection of the pivotal equation for each step.
For each step the pivotal equation must be selected on the basis of the current state of the system under consideration i.e.
without foreknowledge of the effect of the i = 1, ......, n, where d is the number i d = max |a | i ij 1 j≤ n ≤ At the beginning of say kth step of elimination, e pick as pivotal equation that one from the available n – k, which has the absolutely largest coefficient of x relative to the size of the equation.
This means k that the integer j is selected between k and n for which w w pjk ³ ik , " i = p , ....., p k n d d pj i We can also store the multipliers in the working array W instead of storing zeros.
That is, if p is the first pivotal equation and we use the i multipliers m , i = 2, ....., n to eliminate x from the remaining (n – 1) pi,1 1 positions of the first column then in the first column we can store the multipliers m , i = 2, ....., n, instead of storing zeros.
pi,1 Let us now solve the following system of linear equations by scaled partial pivoting by storing the multipliers and maintaining pivotal vector.
Example 10: Solve the following system of linear equations with pivoting x – x + 3x = 3 1 2 3 2x + x + 4x = 7 1 2 3 3x + 5x – 2x = 6 1 2 3 Solution: Here the working matrix is 248 MTH 213 MODULE 3 1 - 1 3 3   W = 2 1 4 7 p = [p , p , p ]T = [1, 2, 3]T   1 2 3 3 5 - 2 6 and d = 3, d = 4and d = 5.
1 2 3 Note that d’s will not change in the successive steps.
w 1 w 2 1 w 3 Step 1: Now p1,1 = p2,1 = = , p3,1 = .
d 3 d 4 2 d 5 1 2 3 3 1 1 Since > , , 5 2 3 Hence, p1 = 3, p2 = 2 and p3 = 1.
We use the third equation to eliminate x from first and second 1 equations and store corresponding multipliers instead of storing zeros in the working matrix.
w The multipliers are m = pi,1 , i = 2, 3 pi,1 w p i,1 w w 2 Therefore, m2,1 = wp2,1 =w2,1 = 3 p 3,1 1,1 w w 1 and m = p3,1 = 1,1 = 1,1 w w 3 p1,1 3,1 After the first step the working matrix is transformed to ( )  1/3 - 8/3 11/3 1 ( )  W(1) = 2/3 - 7/3 16/3 3 p = (p , p , p )T = (3, 2, 1)T   1 2 3  3 5 - 2 6 w w 7/ 3 7 Step 2: p2,2 = 2,2 = = dp d 4 12 2 2 w w 8/ 3 8 p3,2 = 1,2 = = dp d 3 9 3 1 8 7 Now > so that we have p = (p , p , p )T = (3, 2, 1)T. 1 2 3 9 12 249MTH 213 NUMERICAL ANALYSIS 1 w Multiplier is m = pi,2 , i = 3 pi.2 w p2,2 w - 7/ 3 7 Þ m = pi,2 = = .
p3.2 w - 8/ 3 8 p2,2 That is, we use the first equation as pivotal equation to eliminate x from 2 second equation and also we store the multiplier.
After the second step, we have the following working matrix.
1 8 11  - 1   3 3 3   2 7 51 17 W(2) =   p = [3, 1, 2]T 3 8 24 8  3 5 - 2 6      In the working matrix the circled numbers denote multipliers and squared ones denote pivotal elements.
Rearranging the equations (i.e., 3rd equation becomes the first equation, 1st becomes the 2nd and 2nd becomes the third) we get the reduced upper triangular system which can be solved by back substitution.
3x + 5x – 2x = 6 1 2 3 8 11 - x + x = 1 2 3 3 3 51 17 x = 3 24 8 By back substitution, we get x = 1, x = 1 and x = 1.
1 2 3 We now make the following two remarks.
Remark: We do not interchange rows in Step 1 and 2, instead we maintain a pivotal vector and use it at the end to get upper triangular system.
250 MTH 213 MODULE 3 Remark: We store multipliers in the working matrix so that we can easily solve Ax = c, once we have solved Ax = b.
This will be explained to you in detail in Unit 2 when we discuss the method of obtaining inverse of a matrix A.
We shall now describe the triangularization method which is also a direct method for the solution of system of equations.
In this method the matrix of coefficients of the linear system being solved is factored into the product of two triangular matrices.
This method is frequently used to solve a large system of equations.
We shall discuss the method in the next section.
3.5 LU Decomposition Method Let us consider the system of Eqns.
(2), where A is a non-singular matrix.
We first write the matrix A as the product of a lower triangular matrix L and an upper triangular matrix U in the form A = LU or in matrix form we write (18) a a a  l 0 0 u u u  11 12 1n 11 11 12 1n      a a a l l 0 0 u u  21 22 2n  21 22  22 2n  =   (19)                a a a  l l l  0 0 u  n1 n2 nn n1 n2 nn nn The left side matrix A has n2 elements, whereas L and U have 1 + 2 + ... + n = n(n + 1)/2 elements each.
Thus, we have n2 + n unknowns in L and U which are to be determined.
On comparing the corresponding elements on two sides in Eqn.
(19), we get n2 equations in n2 + n unknowns and hence n unknowns are determined.
Thus, we get a solution in terms of these n unknowns i.e., we get a n parameter family of solutions.
In order to obtain a unique solution we either take all the diagonal elements of L as 1, or all the diagonal elements of U as 1.
For u = 1, i = 1, 2, ...., n, the method is called the Crout LU ij decomposition method.
For 1 = 1, i = 1, 2, ...., n we have Doolittle LU ii decomposition method.
Usually Crout’s LU decomposition method is 251MTH 213 NUMERICAL ANALYSIS 1 used unless it is specifically mentioned.
We shall now explain the method for n = 3 with u = 1, i = 1, 2, 3.
We have ii a a a  l 0 o  1 u u  11 12 13 11 12 13       a a a = l l 0 0 1 u  21 22 23  21 22   23 a a a  l l l  0 0 1  31 32 33 31 32 33 or a a a  l l u l u  11 12 13 11 11 12 11 13     a a a = l l u +l l u +l u  21 22 23  21 21 22 22 21 23 22 23  a a a  l l u +l l u +l u +l  31 32 33 31 31 12 32 31 13 32 23 33 On comparing the elements of the first column, we obtain 1 = a , 1 = a , 1 = a (20) 11 11 21 21 31 31 i.e., the first column of L is determined.
On comparing the remaining elements of the first row, we get 1 u = a ; 1 u = a 11 12 12 11 13 13 which gives u = a /1 ; u = a /1 (21) 12 12 11 13 13 11 Hence the first row of U is determined On comparing the elements of the second column, we get 1 u + 1 = a 21 12 22 22 1 u + 1 = a 31 12 32 32 which gives l = a - l u   22 22 21 12 (22) l = a - l u  32 32 31 12 Now the second column of L is determined.
On comparing the elements of the second row, we get 1 u +1 u = a 21 13 22 23 23 which gives u = (a – 1 u )/1 (23) 23 23 21 13 22 and the second row of U is determined.
On comparing the elements of the third column, we get 1 u + 1 u + 1 = a 31 13 32 23 33 33 which gives 1 = a – 1 u – 1 u (24) 33 33 31 13 32 23 You must have observed that in this method, we alternate between getting a column of L and a row of U in that order.
If instead of u = 1 1, 2, ...., n, we ii 252 MTH 213 MODULE 3 take 1 = 1, i = 1, 2, ...., n, then we alternative between getting a row of U and ii a column of L in that order.
Thus, it is clear from Eqns.
(20) – (24) that we can determine all the elements of L and U provided the nonsingular matrix A is such that a a  a ¹ 0,  11 12¹ 0.
11 a a  21 22 Similarly, for the general system of Eqns.
(2), we obtain the elements of L and U using the relations j=1 ∑ 1 = a - 1 u , i ³ j ij ij ik kj i=1 j=1 ∑ u = (a - 1 u )/1 , i³ j ij ij ik kj ii i=1 u = 1 ii Also, det (A) = 1 1 ....., 1 .
11 22 nn Thus w can say that every nonsingular matrix A can be written as the product of a lower triangular matrix and an upper triangular matrix if all principal minors of A are nonsingular, i.e., if a a a a a  11 12 13 a ¹ 0,  11 12 ¹ 0, a a a ¹ 0, ..... |A| ¹ 0.
11 a a  21 22 23 21 22 a a a 31 32 33 Once we have obtained the elements of the matrices L and U, we write the system of equations A x = b (25) in the form L U x = b (26) The system (26) may be further written as the following two systems U x = y (27) L y = b (28) Now, we first solve the system (28), i.e., L y = b, using the forward substitution method to obtain the solution vector y.
Then using this y, we solve the system (27), i.e., U x = y, 253MTH 213 NUMERICAL ANALYSIS 1 using the backward substitution method to obtain the solution vector x.
The number of operations for this method remains the same as that in the Gauss-elimination method.
We now illustrate this method through an example.
Example 11: Use the LU decomposition method to solve the system of equations x + x + x = 1 1 2 3 4x + 3x – x = 6 1 2 3 3x + 5x + 3x = 4 1 2 3 Solution: Using 1 = 1, i = 1, 2, 3, we have ii 1 1 1  1 0 0 u u u  11 12 31       4 3 - 1 = l 1 0 0 u u    21   22 23 3 5 3  l l 1  0 0 u  31 32 33  u u u  11 12 13   = l u l u +u l u +u  21 11 21 12 22 21 13 23  l u l u +l u l u +l u +u  31 11 31 12 32 22 31 13 32 23 33 On comparing the elements of row and column alternatively, on both sides, we obtain first row : u = 1, u = 1, u = 1 11 12 13 first column : 1 = 4, 1 = 3 21 31 second row : u - -1, u = -5 22 23 second column : 1 = -2 32 third row : u = -10 33 Thus, we have 1 0 0 1 1 1      L = 4 1 0 U = 0 - 1 - 5     3 - 2 1 0 0 - 10 Now from the system L y = b or 254 MTH 213 MODULE 3 1 0 0 y  1 1       4 1 0 y = 6    2   3 - 2 1 y  4 3 we get y = 1, y = 2, y = 5 1 2 3 and from the system U x = y or 1 1 1  x  1 1       0 - 1 - 5 x = 2    2   0 0 - 10 x  5 3 we get x = -1/2, x = 1/2, x = 1.
3 2 1 4.0 CONCLUSION Same as in the summary.
5.0 SUMMARY In this unit we have covered the following: 1) For a system of n equations Ax = b (see Eqn.
(2)) in n unknowns, where A is n ´ n non-singular matrix, the methods of finding the solution vector x may be broadly classified into two types: (1) direct methods and (ii) iterative methods 2) Direct methods produce the exact solution in a finite number of steps provided there are no round-off errors.
Cramer’s rule is one such method.
This method gives the solution vector as d x = i i = 1, 2, ..., n i d where d = |A| and d is the determinant pf the matrix obtained i from A by replacing the ith column of A by the column vector b.
Total number of operations required for Cramer’s rule in solving a system of n equations are M = (n + 1) (n – 1)n!
+ n 255MTH 213 NUMERICAL ANALYSIS 1 Since the number M increases very rapidly, Cramer’s rule is not used for n > 4.
3) For larger systems, direct methods becomes more efficient if the coefficient matrix A is in one of the forms D (diagonal), L (lower triangular) or U (upper triangular).
4) Gauss elimination method is another direct method for solving large systems (n > 4).
In this method the coefficient matrix A is reduced to the form U by using the elementary row operations.
The solution vector x is then obtained by using the back substitution method.
For large n, the total numbers of operations 1 required in Gauss elimination method are n3 (approximately).
3 5) In Gauss elimination method if at any stage of the elimination any of the pivots vanishes or become small in magnitude, elimination procedure cannot be continued further.
In such cases pivoting is used to obtain the solution vector x.
6) Every non-singular matrix A can be written as the product of a lower triangular matrix and an upper triangular matrix, by the LU decomposition method, if all the principal minors of A are non- singular.
Thus, LU decomposition method, which is a modification of the Gauss elimination method can be used to obtain the solution vector x.
6.0 TUTOR-MARKED ASSIGNMENT (TMA) 3 - 2 0 2    2 1 0 - 1   1) If A = calculate det (A).
1 0 1 2    2 1 - 3 1  2) Solve the system of equations 3x + 5x =8 1 2 -x + 2x – x = 0 1 2 3 3x – 6x + 4x = 1 1 2 3 using Cramer’s rule.
3) Solve the system of equations 256 MTH 213 MODULE 3 x + 2x – 3x + x = -5 1 2 3 4 x + 3x + x = 6 2 3 4 2x + 3x + x + x = 4 1 2 3 4 x + x + x = 1 1 3 4 using Cramer’s rule.
4) Solve the system of equations x = 1 1 2x = x = 1 1 2 3x – x – 2x = 0 1 2 3 4x + x – 3x + x = 3 1 2 3 4 5x – 2x – x – 2x + x = 1 1 2 3 4 5 using forward substitution method.
5) Solve the system of equations x – 2x + 3x – 4x + 5x = 3 1 2 3 4 5 x – 2x + 3x – 4x = -2 2 3 4 5 x – 2x + 3x = 2 3 4 5 x – 2x = -1 4 5 x = 1 5 using backward substitution method.
6) Use Gauss elimination method to solve the system of equations x + 2x + x = 3 1 2 3 3x – 2x – 4x = -2 1 2 3 2x + 3x – x = -6 1 2 3 7) Solve the system of equations 1 2 - 3 1 x  5 1       0 1 3 1 x 6    2=   2 3 1 1 x  4    3   1 0 1 1 x  1 4 8) Use Gauss elimination method to solve the system of equations 257MTH 213 NUMERICAL ANALYSIS 1 2 - 1 0 0 0 x  1 1      1 2 - 1 0 0 x 0   2   0 - 1 2 - 1 0 x = 0   3   0 0 - 1 2 - 1x  0 4 0 0 0 - 1 2 x  1 5 9) Solve the system of equations 0.729x + 0.81y + 0.9z = 0.6867 x + y + z = 0.8338 1.331x + 1.21y + 1.1z = 1.000 using gauss eliminating method with and without pivoting.
Round off the numbers in arithmetic calculations to four significant digits.
The exact solution of the system rounded to four significant digit is x = 0.2245, y = 0.2814 z = 0.3279 10) Use the LU decomposition method with u = 1, i = 1, 2, 3 to ii solve the system of equations given in Example 11.
11) Use the LU decomposition method with 1 = 1, i = 1, 2, 3 to ii solve the system of equations given in TMA Question 4 no.
1.
12) Use L U decomposition method to solve the system of equations given in TMA Question 4 no.
3.
7.0 REFERENCES/FURTHER READINGS.
Engineering Mathematics P.D.S.
Verma.
Generalized Functions in Mathematical Physics by V.S.
Viadimirov.
Fundamentals of the Finite Element Method.
Hartley Grandin, Fr.
258 MTH 213 MODULE 3 UNIT 2 DIRECT METHOD CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 The Method of adjoints 3.2 The Gauss-Jordan Reduction Method 3.3 LU Decomposition Method 4.0 Conclusion 5.0 Summary 6.0 Tutor-Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION In the previous unit, you have studied the Gauss elimination and LU decomposition methods for solving systems of algebraic equations A x = , when A is a n ´ n nonsingular matrix.
Matrix inversion is another problem associated with the problem of finding solutions of a linear system.
If the inverse matrix A-1 of the coefficient matrix A is known then the solution vector x can be obtained from x = A-1b.
In genral, inversion of matrices for solving system of equations should be avoided whenever possible.
This is because, it involves greater amount of work and also it is difficult to obtain the inverse accurately in many problems.
However, there are two cases in which the explicit computation of the inverse is desirable.
Firstly, when several systems equations, having the same coefficient matrix A but different right hand side b, have to b e solved.
Then computations are reduced if we first find the inverse matrix and then find the solution.
Secondly, when the elements of A-1 themselves have some special physical significance.
For instance, in the statistical treatment of the fitting of a function to observational data by the method of least squares, the elements of A-1 give information about the kind and magnitude of errors in the data.
In this unit, we shall study a few important methods for finding the inverse of a nonsingular square matrix.
2.0 OBJECTIVES After studying this unit, you should be able to: •••• obtain the inverse by adjoint method for n < 4 •••• obtain the inverse by the Gauss-Jordan and LU decomposition methods 259MTH 213 NUMERICAL ANALYSIS 1 •••• obtain the solution of a system of linear equations using the inverse method.
3.0 MAIN CONTENTS 3.1 The Method of Adjoints You already know that the transpose of the matrix of the cofactors of elements of A is called the adjoint matrix and is denoted by adj(A).
Formally, we have the following definition.
Definition: The transpose of the cofactor matrix Ac of A is called the adjoint of A and is written a adj(A).
adj(A) = (Ac)T The inverse of a matrix can be calculated using the adjoint of a matrix.
E obtain the inverse matrix A-1 of A from 1 A-1 = adj(A) det(A) (1) This method of finding the inverse of a matrix is called the method of adjoints.
Note that det(A) in Eqn.
(1) must not be zero and therefore the matrix A must be nonsingular.
We shall not be going into the details of the method here.
We shall only illustrate it through examples.
Example 1: Find A-1 for the matrix 5 8 1    A = 0 2 1   4 3 - 1 and solve the system of equations 260 MTH 213 MODULE 3 A x = b (2) for 2 1 1       i) b = 1 ii) b = 0 iii) b = 2       3 0 3 Solution: Since det(A) = -1 ¹ 0, the inverse of A exists.
We obtain the cofactor matrix Ac from A by replacing each element of A by its cofactor as follows: 5 4 - 8   Ac = 11 - 9 17   6 - 5 10 5 11 6    \ adj(A) = (Ac)T = 4 - 9 - 5   8 17 10 1 Now A-1 = adj(A) det(A) 5 11 6  5 - 11 - 6     \ A-1 = - = 4 - 9 - 5 = 4 9 5     8 17 10 8 - 17 - 10 Also the solution of the given system of equations are 5 - 11 - 6 2 3       i) x = A-1b = 4 9 5 1 = 2       8 - 17 - 10 3 3 5 - 11 - 6 1 5       ii) x = A-1b = 4 9 5 0 = 4       8 - 17 - 10 0 8 261MTH 213 NUMERICAL ANALYSIS 1 5 - 11 - 6 1 9        iii) x = A-1b = 4 9 5 2 = 7       8 - 17 - 10 3 12 We now take up an example in which the given matrix A is lower triangular and we shall show that its inverse is also a lower triangular matrix.
Example 2: Find A-1 for the matrix 1 0 0   A = 2 3 0   4 5 6 Solution: We have det(A) = 18 ¹ 0.
Thus A-1 exists.
Now 18 - 12 - 2   Ac = 0 6 - 5   0 0 3  18 0 0  1 0 0  (Ac)T 1     \ A-1 = = 12 6 0 = 2/3 1/3 0     adj(A) 18 - 2 - 5 3 1/9 - 5/18 1/6 Thus, A-1 is again a lower triangular matrix.
Similarly, we can illustrate that the inverse of an upper triangular matrix is again upper triangular.
Example 3: Find A-1 for the matrix 1 2 3   A = 0 4 5   0 0 6 262 MTH 213 MODULE 3 Solution: Since, det(A) = 24 ¹ 0, A-1 exists.
We obtain 24 0 0   Ac = 12 6 0   - 2 - 5 4 24 - 12 - 2 1 - 1/2 - 1/12 1     \ A-1 = 0 6 - 5 = 0 1/4 - 5/24     24  0 0 4  0 0 1/6  which is again an upper triangular matrix.
The method of adjoints provides a systematic procedure to obtain the inverse of a given matrix and for solving systems of linear equations.
To obtain the inverse of an n ´ n matrix, using this method, we need to evaluate one determinant of order n, n determinants each of order n – 1 and perform n2 divisions.
In addition, if this method is used for solving a linear system we also need matrix multiplication.
The number of operations (multiplications and divisions) needed, for using this method, increases very rapidly as n increases.
For this reason, this method is not used when n > 4.
For large n, there are methods which are efficient and are frequently used for finding the inverse of a matrix and solving linear systems.
We shall now discuss these methods.
3.2 The Gauss-Jordan Reduction Method This method is a variation of the Gauss elimination method.
In the Gauss elimination method, using elementary row operations, we transform the matrix A to an upper triangular matrix U and obtain the solution by using back substitution method.
In Gauss-Jordan reduction not only the elements below the diagonal but also the elements above the diagonal of A are made zero at the same time.
In other words, we transform the matrix A to a diagonal matrix D. This diagonal matrix may then be reduced to an identity matrix by dividing each row by its pivot element.
Alternately, the diagonal elements can also be made unity at the same time when the reduction is performed.
This transforms the coefficient 263MTH 213 NUMERICAL ANALYSIS 1 matrix into an identity matrix.
Thus, on completion of the Gauss-Jordan method, we have [A|b] [I|d] (3) The solution is then given by x = d, i = 1, 2, ......, n (4) i i In this method also, we use elementary row operations that are used in the Gauss elimination method.
We apply these operations both below and above the diagonal in order to reduce all the off-diagonal elements of the matrix to zero.
Pivoting can be used to make the pivot non-zero or make it the largest element in magnitude in that column as discussed.
We illustrate the method through an example.
Example 4: Solve the system of equations x + x + x =1 1 2 3 4x + 3x – x = 6 1 2 3 3x + 5x + 3x = 4 1 2 3 using Gauss-Jordan method with pivoting.
Solution: We have 1 1 1 1   [A|b] = 4 3 - 16 (interchanging first and second row)   3 5 3 4 4 3 - 16   1 3 » 1 1 1 1 R - R , R - R   2 1 3 1 4 4 3 5 3 4 4 3 - 1 6    » 0 1/4 5/4 - 1/2 (interchanging second and third row)   0 11/4 15/4 - 1/2 4 3 - 1 6    12 » 0 11/4 `15/4 - 1/2 R – 1/11 R , R - R   3 2 1 2 11 0 1/4 5/4 - 1/2 264 MTH 213 MODULE 3 4 0 - 56/11 72/11   56 33 » 0 11/4 15/4 - 1/2 R + R , R - R   1 3 2 3 10 8 0 0 10/11 - 5/11 4 0 0 4    » 0 11/4 0 11/8   0 0 10/115/11 R1/4 (divide first row by 4), 4 R (divide second row by 1 1/ 4), 11 2 11 R (divide third row by 10/ 11).
10 3 1 0 0 1    » 0 1 0 1/2   0 0 1 - 1/2 which is the desired form.
Thus, we obtain 1 1 x = 1, x = , x = - .
1 2 3 2 2 The method can be easily extended to a general system of n equations.
Just as we calculated the number of operations needed for Gauss elimination method in the same way you can verify that the total number 1 n2 of operations needed for this method is M = n3 + + n. 2 2 Clearly this method requires more number of operations compared to the Gauss elimination method.
We therefore, do not use this method generally for solving system of equations but is very commonly used for finding the inverse matrix.
This is don by augmenting the matrix A by the identity matrix I of the order same as that of A.
Using elementary row operations on the augmented matrix [A|I] we reduce the matrix A to the form I and in the process the matrix I is transformed to A-1 That is [A|I] [I|A_1] (5) We now illustrate the method through examples.
265MTH 213 NUMERICAL ANALYSIS 1 Example 5: Find the inverse of the matrix 3 1 2    A = 2 - 3 - 1   1 - 2 1  using the Gauss-Jordan method.
Solution: We have 3 1 2 1 0 0   [A|I] = 2 - 3 - 10 1 0   1 - 2 1 0 0 1 R/3 1 1/3 2/31/3 0 0   » 2 - 3 - 1 0 1 0   1 - 2 1 0 0 1 R – 2R, R - R 1 1/3 2/3 1/3 0 0   » 0 - 11/3 - 7/3 - 2/3 1 0 0 - 7.3 1/3 - 1/3 0 1 3R/11 1 1/3 2/3 1/3 0 0   1 7 » 0 1 7/11 2/11 - 3/11 0 R1 - R2, R3 + R2 3 3 0 - 7/3 1/3 - 1/3 0 1 1 0 5/11 3/11 1/11 0   11 » 0 1 7/11 2/11 - 3/11 0 R   3 20 0 0 20/111/11 - 7/11 1 1 0 5/11 3/11 1/11 0    5 7 » 0 1 7/112/11 - 3/11 0 R - R , R - R   1 3 2 3 11 11 0 0 0 1/20 - 7/20 11/20 266 MTH 213 MODULE 3 1 0 0 1/4 1/4 - 1/4    » 0 1 03/20 - 1/20 - 7/20   0 0 11/20 - 7/20 11/20 Thus, we obtain 1/4 1/4 - 1/4    A-1 = 3/20 - 1/20 - 7/20   1/20 - 7/20 11/20 Example 6: Find the inverse of the matrix 2 0 0 0    1 1/2 0 0   A = 1 0 - 3 0    1 - 7/2 - 17 55/3 using the Gauss-Jordan method Solution: Here we have 2 0 0 0 1 0 0 0   1 1/2 0 0 0 1 0 0 1 [A|I] = R 2 0 - 3 0 0 0 1 0 2 1   1 - 7/2 - 17 55/30 0 0 1 1 0 0 0 1/2 0 0 0   1 1/2 0 0 0 1 0 0   » 2 0 - 3 0 0 0 1 0   1 - 7/2 - 17 55/3 0 0 0 1 R – R , R – 2R , R – R 2 1 3 1 4 1 1 0 0 0 1/2 0 0 0   0 1/2 0 0 - 1/2 1 0 0   » 2R 0 0 - 3 0 - 1 0 1 0 2   0 - 7/2 - 17 55/3- 1/2 0 0 1 267MTH 213 NUMERICAL ANALYSIS 1 1 0 0 0 1/2 0 0 0   0 1 0 0 - 1 2 0 0 7 » R + R 0 0 - 3 0 - 1 0 1 0 4 2 2   0 - 7/2 - 17 55/3- 1/2 0 0 1 1 0 0 0 1/2 0 0 0   0 1 0 0 - 1 2 0 0 ( 1 ) » - R 0 0 - 3 0 - 1 0 1 0 3 3   0 0 - 17 55/3 - 4 7 0 1 1 0 0 0 1/2 0 0 0   0 1 0 0 - 1 2 0 0 ( 1 ) » - R 0 0 1 0 1/3 0 - 1/3 0 17 4   0 0 - 17 55/3 - 4 7 0 1 1 0 0 0 1/2 0 0 0    0 1 0 0 - 1 2 0 0   » R –R 0 0 1 0 1/3 0 - 1/3 0  4 3   0 0 - 17 55/34/17 - 7/17 0 - 1/17 1 0 0 0 1/2 0 0 0    0 1 0 0 - 1 2 0 0  ( 51 ) » - R 0 0 1 0 1/3 0 - 1/3 0  55 4   0 0 0 - 55/51- 5/51 - 7/17 1/3 - 1/17 1 0 0 0 1/2 0 0 0    0 1 0 0 - 1 2 0 0   » 0 0 1 0 1/3 0 - 1/3 0    0 0 0 11/11 21/55 - 17/55 3/55 Hence 1/2 0 0 0    - 1 2 0 0 A-1 =   1/3 0 - 1/3 0    1/11 21/55 - 17/55 3/55 is the inverse of the given lower triangular matrix.
268 MTH 213 MODULE 3 Let us now consider the problem of finding the inverse of an upper triangular matrix.
Example 7: Find the inverse of the matrix 1 3/2 2 1/2   0 1 - 4 1   A = 0 0 1 2/3   0 0 0 1  Using the Gauss-Jordan method.
1 3/2 2 1/2 1 0 0 0   0 1 - 4 1 0 1 0 0 3 [A|I] = R - R 0 0 1 2/30 0 1 0 1 2 2   0 0 0 1 0 0 0 1 1 0 8 - 1 1 - 3/2 0 0   0 1 - 4 1 0 1 0 0   » R – 8R , R + 4R   1 3 2 3 0 0 1 2/30 0 1 0   0 0 0 1 0 0 0 1 1 0 0 - 19/31 - 3/2 - 8 0   0 1 0 11/3 0 1 4 0   »   0 0 1 2/3 0 0 1 0   0 0 0 1 0 0 0 1 19 11 2 R + R , R - R , R - R 1 4 2 4 3 4 3 3 3 1 0 0 0 1 - 3/2 - 8 19/3    0 1 0 0 0 1 4 - 11/3   » 0 0 1 0 0 0 1 - 2/3   0 0 0 1 0 0 0 1  269MTH 213 NUMERICAL ANALYSIS 1 Hence 1 - 3/2 - 8 19/3    0 1 4 - 11/3 A-1 =   0 0 1 - 2/3   0 0 0 1  which is the inverse of the given upper triangular matrix.
Note that in Example 2, 3, 6 and 7, the inverse of a lower/upper triangular matrix is again a lower/upper triangular matrix.
There is another method of finding the inverse of a matrix A which uses the pivoting strategy.
Recall that in Sec.
3.4 of Unit 1, for the solution of system of linear algebraic equation Ax = b, we showed you how the multipliers m ’s can be stored in working array W during the process p,i,k of elimination.
The main advantage of storing these multipliers is that if we have already solved the linear system of equations Ax = b or order n, by the elimination method and we want to solve the system Ax = c with the same coefficient matrix A, only the right side being different, then we do not have to go through the entire elimination process again.
Since we have saved in the working matrix W all the multipliers used and also have saved the p vector, we have only to repeat the operations on the right hand side to obtain β, such that Ux = β is equivalent to Ax = c. In order to understand the calculations necessary to derive β , from c consider the changes made in the right side b during the elimination process.
Let k be an integer between 1 and n, and assume that the ith equation was used as pivotal equation during step k of the elimination process.
Then i = p .
initially, the right side of equation i is just b. k i If k > 1, then after Step 1, the right side is b(1) = b – m b i i i1 p1 If k > 2, then after Step 2, the right side is b(2) = b(1) = m b(1) i i i2 p2 = b – m b – m b(1) i i1 p1 i2 p2 In the same manner, we have the right side of equation i = p as k b(k-1) = b – m b – m b(1) - ..... - m b(k-2) (6) i i i1 p1 i2 p2 i,k-1 pk-1 Replacing i by p in Eqn.
(6), we get k b(k-1) = b - m b - m b(1) - .... - m b(k-2) (7) pk pk pk'1 p1 pk'2 p2 pk'k-1 pk-1 270 MTH 213 MODULE 3 k = 1, 2, ....., n. Also, sinceb% = b(j-1), j = 1, 2, ...., n, we can rewrite Eqn.
(7) as j pj b% = b% - m b% - m b% - ..... - m b% (8) k pk pk,1 1 pk,2 2 pk.k-1 k- 1 k = 1, ...., n. % Eqn.
(8) can then be used to calculate the entries of b.
But since the multipliers m ’s are stored in entries w ’s of the working matrix W, we ij ij can also write Eqn.
(8) in the form k-1 b% = b% - å W b%, k = 1, ...., n (9) k pk j=1 pkj j Hence, if we just know the final content of the first n columns of W and the pivoting strategy p then we can calculate the solution x of Ax = b by using the back substitution method and writing n % b - å W x k p j j x = j=k+1 k , k = n, n – 1 , ....., 1 (10) k W p kk The vector x = [x x ....... x ]T will then be the solution of Ax = b.
1 2 n For finding the inverse of an n ´ n matrix A, we use the above algorithm.
We first calculate the final contents of the n columns of the working matrix W and the pivoting vector p and then solve each of the n systems Ax = e, j = 1, ......., n j (11) where e = [1 0 ...... 0]T, e = [0 1 0 ..... 0]T, ......., e = [0 0 ...... 1]T, 1 2 n with the help of Eqn.
(9) and (10).
Then for each j = 1, ......, n the solution of system of system (11) will be the corresponding column of the inverse matrix A-1.
The following example will help you to understand the above procedure.
Example 8: Find the inverse of the matrix 1 2 - 1   A = 2 1 0   1 1 2  using partial pivoting.
271MTH 213 NUMERICAL ANALYSIS 1 Solution: Initially p = [p , p , p ]T = [1, 2, 3]T and the working matrix is 1 2 3 1 2 - 1   W(0) = 2 1 0   1 1 2  Now d = 2, d = 2, d = 2.
1 2 3 | W | 1 | W | 2 | W | 1 Step 1: p1,1 = , p2,1 = = 1, p3,1 = d 2 d 2 d 2 1 2 3 1 1 1 > , \ p = 2, p = 1, p = 3 1 2 3 2 2 We use the second equation to eliminate x from first and third 1 equations and store corresponding multipliers instead of storing zeros in the working matrix.
The multipliers are w m = pi,1 , i = 2, 3 pi,1 w pi,1 w 1 \ m = m = p2,1 = p2,1 11 w 2 p1,1 w 1 m = m = p3,1 = - p3,1 31 w 2 p1,1 we get the following working matrix 1/2 3/2 - 1   W(1) = 2 1 0 , p = (2, 1, 3)T   1/2 3/2 2  w w 3/ 2 3 Step 2: p2,2 = p1,2 = = dp d 2 4 2 1 w w 3/ 2 3 p3,2 = p3,2 = = dp d 2 4 3 3 3 3 Since = so we take p = (2, 1, 3)T 4 4 w Now m = pi,2 , i = 3 pi,2 w p2,2 272 MTH 213 MODULE 3 w 3/ 2 \ m = m = p3,2 = = 1 p3,2 32 w 3/ 2 p1,2 We use the first equation as pivotal equation to eliminate x from the 2 third equation and also store the multipliers.
After the second step we have the following working matrix 1/2 3/2 - 1   W(2) = 2 1 0 , p = (2, 1, 3)T   1/2 1 3  Now in this case, w(2) is our final working matrix with pivoting strategy p = (2, 1, 3)T Note that circled ones denote multipliers and squared ones denote pivot elements in the working matrices.
To find the inverse of the given matrix A, we have to solve Ax = e = [b b b ]T 1 1 2 3 Ax = e = [b b b ]T 2 1 2 3 Ax = e = [b b b ]T 3 1 2 3 where e = [1 0 0]T, e = [0 1 0]T, e = [0 0 1]T 1 2 3 First we solve the system Ax = e and consider 1 1/2 3/2 - 1 x 1       2 1 0 x = 0 , p = (2, 1, 3)T (12)       1/2 1 3  x 0 Using Eqn.
(9), we get with p = 2, b% = b = 0 1 1 2 with p = 1, b% = b – w b% 2 2 1 11 1 1 = 1 - 0   2 = 1 with p = 3, b%= b – w b% - w b% 3 3 3 31 1 32 2 1 = 0 - .0 – 1.1 = -1   2 Using Eqn.
(10), we then get the following system of equations 273MTH 213 NUMERICAL ANALYSIS 1 3x = -1 3 3 x – x = 1 2 3 2 2x + x = 0 1 2 1 4 2 which gives x = - , x = and x = - 3 2 1 3 9 9 1 4 1T i.e., vector x = .
- is the solution of system (12).
  2 9 3 Remember that the solution of system (12) constitutes the first column of the inverse matrix A-1.
In the same way we solve the system of equations Ax = e and Ax = e , 2 3 or 1/2 3/2 - 1 x1 0       2 1 0 x2 = 1 , p = (2, 1, 3)T (13)       1/2 1 3  x3 0 and 1/2 3/2 - 1 x1 0       2 1 0 x2 = 0 , p = (2, 1, 3)T (14)       1/2 1 3  x3 1 Using Eqns (9) and (10), we obtain the solution of system (13) as 5 1 1T x = .
- which is the second column of A-1 and the solution of   9 9 3 1 2 1T system (14), i.e., x = .
- as the third column of A-1   9 9 3 2/9 5/9 - 1/9   Hence A-1 = 4/9 - 1/9 2/9   1/3 1/3 1/3  You may recall that in Sec.
3.5 of Unit 1 we discussed the LU decomposition method.
Using this method we can factorise any non- singular square matrix A into the product of a lower triangular matrix L and upper triangular matrix U.
That is, we can write 274 MTH 213 MODULE 3 A = L U.
... (15) In the next section we shall discuss how form (15) can be used to find the inverse of non-singular square matrices.
3.3 L U Decomposition Method Let us consider Eqn.
(15) and take the inverse on both the sides.
If we use the fact that the inverse of the product of matrices is the product of their inverses takes in reverse order, then we obtain A-1 = (L U)-1 = U-1 L-1 (16) We can now find the inverse of U and L separately and obtain the inverse matrix A-1 from Eqn.
(16).
Remark: It may appear to you that finding an inverse of a matrix by this method is a lengthy process.
But, in practice, this method is very useful because of the fact that here we deal with triangular matrices and triangular matrices are easily invertible.
It involves only forward and backward substitutions.
Let us now consider an example to understand how the method works.
Example 9: Find the inverse of the matrix 3 1 2    A = 2 - 3 - 1   1 - 2 1  Using LU decomposition method.
Solution: We write, 3 1 2  1 0 0 1 u u       A = 2 - 3 - 1 = LU = 1 1 0 0 1 u (17)       1 - 2 1  1 1 1 0 0 1 Comparing the coefficients on both sides of Eqn.
(17), we obtain 275MTH 213 NUMERICAL ANALYSIS 1 1 = 3, 1 = 2, 1 = 1 (multiplying the rows of L by the first 11 21 31 column of U) 1 1 u = 1, u = (multiplying the rows of L by the 11 12 12 3 1 u = 2, u = 2/3 second and third column of U) 11 13 13 The second column of L is obtained from 2 11 1 u + 1 = a , 1 = -3 - = - 21 12 22 22 22 3 3 1 7 1 u + 1 = a , 1 = -2 - = - 31 12 32 32 32 3 3 u is obtained from 23 - 1- 2(2/ 3) 7 1 u + 1 u = a , u = = 21 13 22 23 23 23 - 11/ 3 11 1 is obtained from 33 20 1 u + 1 u + 1 = 1, 1 = 31 13 32 23 33 33 11 Thus we have 3 0 0  1 1/3 2/3     L = 2 - 11/3 0 and U = 0 1 7/11     1 - 7/3 20/11 0 0 1  Now since L is a lower triangular matrix L-1 is also a lower triangular matrix.
Let us assume that 1 0 0   L-1 = 1 1 0   1 1 1 Using the identity LL-1, we have 3 0 0  3 0 0 1 0 0 1 0 0         LL-1 = 2 - 11/3 0 2 - 11/3 0 1 1 0 = 0 1 0         1 - 7/3 20/11 1 1 1 1 1 1 0 0 1 Comparing the coefficients, we get 1 3 11 1' = , 1' = - , 1' = 11 3 22 11 33 20 276 MTH 213 MODULE 3 Also, 11 6 2 2 1' - 1' = 0, 1' = = 11 3 21 21 33 11 7 20 1 1' - 1' + 1' = 11 3 21 11 31 20 7 20 7 - 1' + 1' = 0, 1' = - 3 22 11 32 32 20 1/3 0 0    \ L-1 = 2/11 - 3/11 0   1/20 - 7/20 11/20 Similarly, since U is an upper triangular matrix, U-1 is also upper triangular matrix.
Using UU-1 = I, we obtain by backward substitution.
1 1/3 2/3 1 - 1/3 - 5/11     U = 0 1 7/11 and U-1 = 0 1 - 7/11     0 0 1  0 0 1  Therefore, we have from Eqn.
(16) 1 - 1/3 - 5/11  1/3 0 0      A-1 = U-1 L-1 = 0 1 - 7/11 2/11 - 3/11 0     0 0 1  1/20 - 7/20 11/20 1/4 1/4 - 1/4    = 3/20 - 1/20 - 7/20   1/20 - 7/20 11/20 4.0 CONCLUSION We now end this unit by giving a summary of what we have covered in it.
5.0 SUMMARY In this unit we have covered the following: 1) Using the method of adjoints, the inverse of a given non-singular matrix A can be obtained from 277MTH 213 NUMERICAL ANALYSIS 1 1 A-1 = adj(A) (see Eqn.
(1)) det(A) Since the number of operations in the adjoint method to find the inverse of n ´ n non-singular matrix A increases rapidly as n increases, the method is not generally used for n > 4.
2) For large n, the Gauss-Jordan reduction method, which is an extension of the Gauss elimination method can be used for finding the inverse matrix and solve the linear systems.
Ax = b (see Eqn.
(2)) using the Gauss-Jordan method.
a) the solution of system of Eqns (2) can be obtained by using elementary row operations reduced to [A|b] ¾ ¾ ¾ ¾ ¾® [I|d] b) the inverse matrix A-1 can be obtained by using elementary row operations [A|I] ¾r¾edu¾ce¾d ¾to® [I|A-1] 3) For large n, another useful method of finding the inverse matrix A-1 is LU decomposition method.
Using this method any non- singular matrix A is first decomposed into the product of a lower triangular matrix L and an upper triangular matrix U.
That is A = LU U-1 and L-1 can be obtained by backward and forward substitutions.
Then the inverse can be found from A-1 = U-1 L-1 6.0 TUTOR-MARKED ASSIGNMENT 1) Solve the system of equations 3x + x + 2x = 3 1 2 3 2x – x – x = 1 1 2 3 x – 2x + x = -4 1 2 3 using the method of adjoints.
2) Solve the system of equations 278 MTH 213 MODULE 3 2 3 4 1  X1 3       1 2 0 1 X2 2       = 2 3 1 - 1 X3 1       1 - 2 - 1 4  X4 5 using the method of adjoints.
3) Verify that the total number of operations needed for Gauss- 1 n2 Jordan reduction methods is n3 + + n. 2 2 4) In example 6 and 7 verify that A A-1 = A-1 A = I.
5) Solve the system of equation x + 2x + x = 0 1 2 3 2x + 2x + 3x = 3 1 2 3 -x – 3x = 2 1 2 using the Gauss-Jordan method with pivoting.
6) Find the inverse of the matrix  2 - 1 0 0    - 1 2 - 1 0   A =  0 - 1 2 - 1    0 0 - 1 2  using the Gauss-Jordan method.
7) Find the inverse of the matrix 5 8 1    A = 0 2 1   4 3 - 1 using the LU decomposition method.
8) Find the inverse of the matrix 3 1 2    A = 2 - 1 - 1   1 - 2 1  Using the LU decomposition method.
279MTH 213 NUMERICAL ANALYSIS 1 7.0 REFERENCES/FURTHER READINGS Engineering Mathematics P.D.S.
Verma.
Generalized Functions in Mathematical Physics by V.S.
Viadimirov.
Fundamentals of the Finite Element Method.
Hartley Grandin, Fr.
280 MTH 213 MODULE 3 UNIT 3 ITERATIVE METHODS CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 The General Iteration Methods 3.2 The Jaccobi’s Iteration Method 3.3 The Gauss-Seidel Iteration Method 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION In the previous two units, you have studied direct methods for solving linear system of equations Ax = b, A being n ´ n non-singular matrix.
Direct methods provide the exact solution in a finite number of steps provided exact arithmetic is used and there is no round-off error.
Also, direct methods are generally used when the matrix A is dense or filled, that is, there are few zero elements, and the order of the matrix is not very large say n < 50.
Iterative methods, on the other hand, start with an initial approximation and by applying a suitably chosen algorithm, lead to successively better approximations.
Even if the process converges, it would give only an approximate solution.
These methods are generally used when the matrix A is sparse and the order of the matrix A is very large say n > 50.
Sparse matrices have very few non-zero elements.
In most cases these non-zero elements lie on or near the main diagonal giving rise to tri- diagonal, five diagonal or band matrix systems.
It may be noted that there are no fixed rules to decide when to use direct methods and when to use iterative methods.
However, when the coefficient matrix is sparse or large, the use of iterative methods is ideally suited to find the solution which take advantage of the sparse nature of the matrix involved.
In this we shall discuss two iterative methods, namely, Jacobi iteration and Gauss-Seidel iteration methods which are frequently used for solving linear system of equations.
281MTH 213 NUMERICAL ANALYSIS 1 2.0 OBJECTIVES After studying this unit, you should be able to: •••• obtain the solution of system of linear equations, Ax = b, when the matrix A is large or sparse, by using the iterative method viz; Jacobi method or the Gauss-Seidel method •••• tell whether these iterative methods converges or not •••• obtain the rate of convergence and the approximate number of iterations needed for the required accuracy of these iterative methods.
3.0 MAIN CONTENT 3.1 The General Iteration Method In iteration methods as we have already mentioned, we start with some initial approximate solution vector x(0) an generate a sequence of approximation {x(k)} which converge to the exact solution vector x as k ® ¥ .
If the method is convergent, each iteration produces a better approximation to the exact solution.
We repeat the iterations till the required accuracy is obtained.
Therefore, in an iterative method the amount of computation depends on the desired accuracy whereas in direct methods the amount of computation is fixed.
The number of iterations needed to obtain the desired accuracy also depends on the initial approximation, closer the initial approximation to the exact solution, faster will be the convergence.
Consider the system of equations Ax = b ... (1) where A is an n´ n non-singular matrix.
Writing the system in expanded form, we get a x + a x + ...... a x = b 11 1 12 2 1n n 1 a x + a x + ...... a x = b (2) 21 1 22 2 2n n 2 .............................................. a x + a x + ...... + a x = b n1 1 n2 2 nn n n We assume that the diagonal coefficients a ¹ 0, (i = 1, ....., n).
If some ii of a = 0, then we arrange the equations so that this condition holds.
We ii then rewrite system (2) as 282 MTH 213 MODULE 3 1 b x = - (a x + a x + .... + a x ) + 1 1 12 2 13 3 1n n a a 11 11 1 b x = - (a x + a x + .... + a x ) + 2 (3) 2 21 1 23 3 2n n a a 22 22 1 b x = - (a x + a x + .... + a x ) + n n n1 1 n2 2 nn-1 n-1 a a nn nn In matrix form, system (3) can be written as x = Hx + c where  0 - a12 - a13 - a1n a11 a11 a11   H = a21 0 - a23 - a2n   a22 a22 a22 an1 - an2 - an,n- 1 0  ann ann ann (4) b and the elements of c are c = i (i = 1, 2, ..., n) i a ii To solve system (3) we make an initial guess x(0) of the solution vector and substitute into the r.h.s.
of Eqn.
(3).
The solution of Eqn.
(3) will then yield a vector x(1), which hopefully is a better approximation to the solution than x(0).
We then substitute x(1) into the r.h.s.
of Eqn.
(3) and get another approximation, x(2).
We continue in this manner until the successive iterations x(k) have converged to the required number of significant figures.
In general we can write the iteration method for solving the linear system of Eqns.
(1) in the form x(k+1) = Hx(k) + c, k = 0, 1...... (5) where x(k) and x(k+1) are the approximations to the solution vector x at the kth and the (k + 1)th iterations respectively.
H is called the iteration matrix and depends on A. c is a column vector and depends on both A and b.
The matrix H is generally a constant matrix.
When the method (5) is convergent, then limx(k) = lim x(k+1) = x k®¥ k®¥ and we obtain from Eqn.
(5) x = Hx + c (6) 283MTH 213 NUMERICAL ANALYSIS 1 If we define the error vector at the kth iteration as Î (k) = x(k) – x (7) then subtracting Eqn.
(6) from Eqn.
(5), we obtain Î (k+1) = H Î (k) (8) Thus, we get from Eqn.
(8) Î (k) = H Î (k-1) = H2 Î (k-2)= ... = Hk Î (0) (9) Where Î (0) is the error in the initial approximate vector.
Thus, for the convergence of the iterative method, we must have limÎ (k) = 0 k®¥ independent of Î (0).
Before we discuss the above convergence criteria, let us recall the following definitions from linear algebra.
Definition: For a square matrix A of order n, and a number l the value of l for which the vector equation Ax = l x has non-trivial solution x ¹ 0, is called an eigenvalue or characteristic value of the matrix A.
Definition: The largest eigenvalue in magnitude of A is called the spectral radius of A ad is denoted by p(A).
The eigenvalues of the matrix A are obtained from the characteristic equation det(A - l I) = 0 which is an nth degree polynomial in l .
The roots of this polynomial l , l , ......., l are the eigenvalues of A.
Therefore, we have 1 2 n r (A) = max|l | (10) i i We now state a theorem on the convergence of the iterative methods.
284 MTH 213 MODULE 3 Theorem 1: An iteration method of the form (5) is convergent for arbitrary initial approximate vector x(0) if and only if r (H) < 1.
We shall not be proving this theorem here as its proof makes use of advanced concepts from linear algebra and is beyond the scope of this course.
We define the rate of convergence as follows: Definition: The number n = -log r (H) is called the rate of convergence of an 10 iteration method.
Obviously, smaller the value of r (H), larger is the value of n. Definition: The method is said to have converged to m significant digits if max|Î (k)| ‚ 10-m, that is, largest element in magnitude, of the error i i vector Î (k) ‚ 10-m. Also the number of iterations k that will be needed to make max|Î (k)| ‚ 10-m is given by i i m k = (11) n Therefore, the number of iterations that are required to achieved the desired accuracy depends onn.
For a method having higher rate of convergence, lesser number of iterations will be needed for a fixed accuracy and fixed initial approximation.
There is another convergence criterion for iterative methods which is based on the norm of a matrix.
The norm of a square matrix A of order n can be defined in the same way as we define the norm of an n-vector by comparing the size of Ax with the size of x (an n-vector) as follows: Ax i) ||A|| = max 2 2 x 2 based on the Euclidean vector norm, ||x|| = |x |2+|x |2+...+|x |2 2 1 2 n and 285MTH 213 NUMERICAL ANALYSIS 1 Ax ii) ||A|| = max ¥ , based on the maximum vector norm, ||x|| ¥ x ¥ ¥ = max|x|.
i 1£i£n In (i) and (ii) above the maximum is taken over all (non zero) n- vector.
The most commonly used norms is the maximum norm ||A|| , as it is easier to calculate.
It can be calculated in any of the ¥ following two ways: ||A|| = max å |a | (maximum absolute column-sum) ¥ x i ik Or ||A|| = max å |a | (maximum absolute row sum) ¥ i k ik The norm of a matrix is a non-negative number which in addition to the property ||AB||‚ ||A|| ||B|| satisfies all the properties of a vector norm, viz., a) ||A|| ƒ 0 and ||A|| = 0 if A = 0 b) ||a A|| = |a | ||A||, for all numbers a .
c) ||A + B|| ‚ ||A|| + ||B|| where A and B are square matrices of order n. We no state a theorem which gives the convergence criterion for iterative methods in terms of the norm of a matrix.
Theorem 2: The iteration method of the form (5) for the solution of system (1) converges to the exact solution for any initial vector, if ||H||<1.
Also note that ||H|| ƒ r (H).
This ca be easily proved by considering the eignevalue problem Ax = l x.
Then ||A|| = ||l x|| = |l | ||x|| or |l | ||x|| = ||Ax|| ‚ ||A|| ||x|| i.e., |l | ‚ ||A|| since ||x|| ¹ 0 Since this results is true for all eignevalue, we have 286 MTH 213 MODULE 3 r (A) ‚ ||A||.
The criterion given in Theorem 2 is only a sufficient condition, it is not necessary.
Therefore, for a system of equations for which the matrix H n is such that either max å |h | < 1, the iteration always converges, but if ik i k=1 the condition is violated it is not necessary that the iteration diverges.
There is another sufficient condition for convergence as follows: Theorem 3: If the matrix A is strictly diagonally dominant that is, n |a | > å |a |, i = 1, 2, ......, n. ii ij j=1 j¹i Then the iteration method (5) converges for nay initial approximation x .
If no better initial approximation is known, we generally take x(0) = 10 0.
We shall mostly use the criterion given in Theorem 1, which is both necessary and sufficient.
For using the iteration method (5), we need the matrix H and the vector c which depend on the matrix A and the vector b. the well-known iteration methods are based on the splitting of the matrix A in the form A = D + L + U (12) where D is the diagonal matrix, L and U are respectively the lower and upper triangular matrices with zero diagonal elements.
Based on the splitting (12), we now discuss two iteration methods of the form (5).
3.2 The Jacobi’s Iteration Method We write the system of Eqn.
(1) in the form (2), viz., a x + a x + ... + a x = b 11 1 12 2 1n n 1 a x + a x + ... + a x = b 21 1 22 2 2n n 2 .
.
.
.
.
.
.
.
.
.
.
.
a x + a x + ... + a x = b n1 1 n2 2 nn n n We assume that a , a , ..... a are pivot elements and a ¹ 0, i = 1, 2, 11 22 nn ii ...., n. if any of the pivots is zero, we can interchange the equations to obtain non-zero pivots (partial pivoting).
287MTH 213 NUMERICAL ANALYSIS 1 Note that, A being a non-singular matrix, it is possible for us to make all the pivots non-zero.
It is only when the matrix A is singular that even complete pivoting may not lead to all the non-zero pivots.
We rewrite system (2) in the form (3) and define the Jacobi iteration method as 1 x(k+1) = - (a x(k) + a x(k) + ... + a x(k)-b ) 1 a 12 2 13 3 1n n 1 11 1 x(k+1) = - (a x(k) + a x(k) + ... + a x(k)-b ) 2 a 21 2 23 3 2n n 2 22 .
.
.
1 x(k+1) = - (a x(k) + a x(k) + ... + a x(k) -b ) n a n1 i n2 2 n,n-1 n-1 n ii 1 n or x(k+1) = - ∑a x (k) - b , i = 1, 2, .... n, k = 0, 1, .... (13) i a ij j i ii j=1 The method (13) can be put in the matrix form as x(k+1) x- (k) b   1   1   0 a .... a   1   1 a11 12 1n           x(k+1)     x- (k) b   1   1  a 0 .... a   2   2    a22   21 2n     = - - r              ...   ...                             1  a a .... 0      x(k+1) ann n1 n2 x- (k) b  1 n n x(k+1) = -D-1 (L + U) x(k) + D-1b, k = 0, 1, .... (14) where 288 MTH 213 MODULE 3  0 0 .......... 0   a 0 .......... 0  a 0 .......... 0 11  21    D = 0 a .......... 0 , L = a a 0 0  22   31 32   0 .......... a    nn   an1 an2 an,n- 1 0 0 a a .......... a  12 13 1n   0 0 a a  23 2n  and U =  ..........    a  n- 1,n   0 0 0 .......... 0  The method (14) is for the form (5), where H = -D-1 (L + U) and c = D-1b For computation purpose, we obtain the solution vector x(k+1) at the (k + 1)th iteration, element by element using Eqn.
(13).
For large n, we rarely use the method in its matrix form as given by Eqn.
(14).
In this method in the (k + 1)th iteration we use the values, obtained at the kth iteration viz., x(k), x(k), ...., x(k) on the right hand side of Eqn.
1 2 n (13) and obtain the solution vector x(k+1).
We then replace the entire vector x(k) on the right side of Eqn.
(13) by x(k+1) to obtain the solution at the next iteration.
In other words each of the equations is simultaneously changed by using the most recent set of x-values.
It is for this reason this method is also known as the method of simultaneous displacements.
Let us now solve a few examples for better understanding of the method and its convergence.
Example 1: Perform four iterations of the Jacobi method for solving the system of equations 8 1 1  x  1  1       1 - 5 1 x = 16 (15)    2   1 1 - 4 x  7  3 with x(0) = 0, the exact solution is x = [-1 -4 -3]T. 289MTH 213 NUMERICAL ANALYSIS 1 Solution: The Jacobi method when applied to the system of Eqns.
(15) becomes 1 x(k+1) = [x(k) + x(k) - 1] 1 8 2 3 1 x(k+1) = [x(k) + x(k) - 16] (16) 2 5 1 3 1 x(k+1) = [x(k) + x(k) - 7], k = 0, 1, .... 3 4 1 2 Starting with x(0) = [0 0 0]T, we obtain form Eqns.
(16), the following results: k = 0 1 x(1) = [0 + 0 – 1] = -0.125 1 8 1 x(1) = [0 + 0 – 16] = -3.2 2 5 1 x(1) = [0 + 0 – 7] = -1.75 3 4 k = 1 1 x(2) = [-3.2 – 1.75 – 1] = -0.7438 1 8 1 x(2) = [-0.125 – 1.75 – 16] = 3.5750 2 5 1 x(2) = [-0.125 – 3.2 – 7] = -2.5813 3 4 k = 2 1 x(3) = [-3.5750 – 2.5813 – 1] = -0.8945 1 8 1 x(3) = [-0.7438 – 2.5813 – 16] = -3.8650 2 5 1 x(3) = [-0.7438 – 3.5750 – 7] = 2.8297 3 4 k = 3 1 x(4) = [-3.8650 – 2.8297 – 1] = 0.9618 1 8 1 x(4) = [-0.8945 – 2.8297 – 16] = -3.9448 (17) 2 5 290 MTH 213 MODULE 3 1 x(4) = [-0.8945 – 3.8650 – 7] = -2.9399 3 4 Thus, after four iterations we get the solution as given in Eqns (17).
We find that after iteration, we get better approximation to the exact solution.
Example 2: Jacobi method is used to solve the system of equations  4 - 1 1 x  7  1       4 - 8 1 x = 21 (18)    2   - 2 1 5 x  15 3 Determine the rate of convergence of the method and the number of iterations needed to make max|Î (k)| ‚ 10-2 i i Perform these number of iteration starting with initial approximation x(0) = [1 2 2]T and compare the result with the exact solution [2, 4 3]T Solution: The Jacobi method when applied to the system of Eqns.
(18), gives the iteration matrix  1   0 0  a  1 a a  11 12 13  1  H = - 0 0 a 0 a  a 21 23  22 a a 0  1 31 32   0 0  a  33 1  0 0   4 0 - 1 1   1 = -0 0 4 0 1  8   1 2 1 0 0 0    5   0 1/4 - 1/4   = 1/2 0 1/8   2/5 - 1/5 0  291MTH 213 NUMERICAL ANALYSIS 1 The eignevalues of the matrix H are the roots of the characteristic equation.
det (H - l I) = 0 Now  1 1/4 - 1/4   3 det (H - l I) = 1/2 - 1 1/8 = l 3 - = 0   80 2/5 - 1/5 - 1  All the three eigenvalues of the matrix H are equal and they are equal to l = 0.3347 The spectral radius is r (H) = 0.3347 (19) We obtain the rate of convergence as n = -log (0.3347) = 0.4753 10 The number of iterations needed for the required accuracy is given by 2 k = » 5 (20) n The Jacobi method when applied to the system of Eqns.
(18) becomes  0 1/4 - 1/4 7/4     x(k+1) = 1/2 0 1/8 x(k) + 21/8 , k = 0, 1, ... (21)     2/5 - 1/5 0   3  starting with the initial approximation x(0) = [1 2 2]T, we get from Eqn.
(21) x(1) = [1.75 3.375 3.0]T x(2) = [1.8437 3.875 3.025]T x(3) = [1.9625 3.925 2.9625]T x(4) = [1.9906 3.9766 3.0000]T x(5) = [1.9941 3.9953 3.0009]T which is the result after five iterations.
Thus, you can see that result obtained after five iterations is quite close to the exact solution [2 4 3]T 292 MTH 213 MODULE 3 Example 3: Perform four iterations of the Jacobi method for solving the system of equations  2 - 1 0 0  x  1 1       - 1 2 - 1 0 x 0    2 =   (22)  0 - 1 2 - 1 x  0    3    0 0 - 1 2  x  1 4 With x(0) = [0.5 0.5 0.5 0.5]T. What can you say about the solution obtained if the exact solution is x = [1 1 1 1]T?
Solution: The Jacobi method when applied to the system of Eqns.
(22) becomes 1 x(k+1) = [1 + x(k)] 1 2 2 1 x(k+1) = [x(k) + x(k)] 2 2 1 3 1 x(k+1) = [x(k) + x(k)] (23) 3 2 2 4 1 x(k+1) = [1 + x(k)], k = 0, 1, .... 4 2 3 Using x(0) = [0.5 0.5 0.5 0.5]T, we obtain x(1) = [0.75 0.5 0.5 0.75] T x(2) = [0.75 0.625 0.625 0.75] T x(3) = [0.8125 0.6875 0.6875 0.8125] T x(4) = [0.8438 0.75 0.75 0.8438] T You may notice here that the solution is improving after each iteration.
Also the solution obtained after four iterations is not a good approximation to the exact solution x = [1 1 1 1]T. this shows that we require a few more iterations to get a good approximation.
Example 4: Find the spectral radius of the iteration matrix when the Jacobi method, is applied to the system of equations 293MTH 213 NUMERICAL ANALYSIS 1 1 0 2  x  1 1       0 1 - 2 x = 5    2   1 - 1 1  x  3 3 Verify that the iterations do not converge to the exact solution x = [1 3 -1]T. Solution: The iteration matrix H in this case becomes 1 0 0 0 0 2      H = - 0 1 0 0 0 - 2     0 0 1 1 - 1 0  0 0 - 2   = 0 0 2   1 1 0  and c = [-1 5 -3]T The eigenvalue of H are roots of the characteristic equation det (H - l I) = 0.
This gives us - l ( l 2 – 4) = 0 i.e., l = 0, ± 2 \ r (H) = 2 > 1.
Thus, the condition in Theorem 1 is violated.
The iteration method does not converge.
We now perform few iteration and see what happens actually.
Taking x(0) = 0 and using the Jacobi method 0 0 - 2 1     x(k+1) = 0 0 2 x(k) + 5     1 1 0  3 we obtain x(1) = (-1 5 -3)T x(2) = (5 -1 3)T x(3) = (-7 11 -9)T 294 MTH 213 MODULE 3 x(4) = (17 -13 15)T x(5) = (-31 35 -33)T and so on, which shows that the iterations are diverging fast.
You may also try to obtain the solution with other initial approximations.
Let us now consider an example to show that the convergence criterion given in Theorem 3 is only a sufficient condition.
That is, there are systems of equation which are not diagonally dominant but, the Jacobi iteration method converges.
Example 5: Perform iterations of the Jacobi method for solving the system of equations 1 1 1  x  3 1       0 2 0 x = 2    2   0 3 - 1 x  1 3 With x(0) = [0 1 1]T. What can you say about the solution obtained if the exact solution is x = [0 1 2]T?
Solution: The Jacobi method when applied to the given system of equations becomes x(k+1) = [3 - x(k) - x(k)] 1 2 3 x(k+1) = 1 2 x(k+1) = [-1 + 3x(k)], k = 0, 1, .... 3 2 Using x(0) = [0 1 1]T, we obtain x(1) = [1 1 2]T x(2) = [0 1 2]T x(3) = [0 1 2]T You may notice here that the coefficient matrix is not diagonally dominant but the iterations converge to the exact solution after only two iterations.
We have already mentioned that iterative methods are usually applied to large linear system with a sparse coefficient matrix.
For sparse matrices, the number of non-zero entries is small, and hence the number of arithmetic operations to be performed per step is small.
However, 295MTH 213 NUMERICAL ANALYSIS 1 iterative methods may not always converge, and even when they converge, they may require a large number of iterations.
We shall now discuss the Gauss-Seidel method which is a simple modification of the method of simultaneous displacements and has improved rate of convergence.
3.3 The Gauss-Seidel Iteration Method Consider the system of Eqns.
(2) written in form (3).
For this system of equations, we define the Gauss-Seidel method as: 1 x(k+1) = - (a x(k) + a x(k) + ... + a x(k)-b ) 1 a 12 2 13 3 1n n 1 11 1 x(k+1) = - (a x(k+1) + a x(k) + ... + a x(k)-b ) 2 a 21 1 23 3 2n n 2 22 .
.
(24) .
1 x(k+1) = - (a x(k+1) + a x(k+1) + ... + a x(k+1)-b ) n a n1 1 n2 2 n,n-1 n-1 n nn 1 n n or x(k+1) = - ∑a x (k+1)+ ∑a x (k) - b , i = 1, 2, .... n i a ij j ij j i ii j=1 j=i+1 You may notice here that in the first equation of system (24), we substitute the initial approximation (x(0), x(0), ...., x(0)) on the right hand 2 3 n side.
In the second equation w substitute (x(1), x(0), ...., x(0)) on the right 1 3 n hand side.
In the third equation, we substitute (x(1), x(1), x(0), ...., x(0)) on 1 2 4 n the right hand side.
We continue in this manner until all the components have been improved.
At the end of this first iteration, we will have an improved vector (x(1), x(1), ...., x(1)).
The entire process is then repeated.
1 2 n In other words, the method uses an improved component as soon as it becomes available.
It is for this reason the method is also called the method of successive displacements.
We can also write the system of Eqns.
(24) as follows: a x(k+1) = -a x(k) - a x(k) - ... a x(k)+ b 11 1 12 2 13 3 1n n 1 a x(k+1) + a x(k+1) = - a x(k) - ... - a x(k)+ b 21 2 21 2 23 3 2n n 2 .
296 MTH 213 MODULE 3 .
.
a x(k+1) + a x(k+1) + ...+ a x(k+1) b n1 1 n2 2 nn n n In matrix form, this system can be written as (D + L) x(k+1) = -U x(k) + b (25) where D is the diagonal matrix a 0  11   0 a ..  22   a ..  D =  33  ..        0 a  nn and L and U are respectively the lower and upper triangular matrices with the zeros along the diagonal and are of the form  0 0 0 ...... 0 0  0 a a ..... a  12 13 1n     a 0 0 ...... 0 0 0 a ..... a  21   23 2n  a a 0 0 ....... 0  0 0 0 ..... a -  L =  31 32  U =  3n  ...... ..   .....      ....... .. a    n- 1,n a a ...... a  0 0  n1 n2 nn From Eqn.
(25), we obtain x(k+1) = - (D + L)-1 Ux(k) + (D + L)-1b (26) which is of the form (5) with H = -(D + L)-1 U and c = (D + L)-1b.
It may again be noted here, that if A is diagonally dominant then the iteration always converges.
Gauss-Seidel method will generally converge if the Jacobi method converges, and will converge at a faster rate.
For symmetric A, it can be shown that r (Gauss-Seidel iteration method) = [r (Jacobi iteration method)]2 Hence the rate of convergence of the Gauss-Seidel method is twice the rate of convergence of the Jacobi method.
This result is usually true even when A is not symmetric.
297MTH 213 NUMERICAL ANALYSIS 1 We shall illustrate this fact through examples.
Example 6: Perform four iterations (rounded to four decimal places) using the Gauss-Seidel method for solving the system of equations 8 1 1  x  1  1       1 - 5 1 x = 16 (27)    2   1 1 - 4 x  7  3 with x(0) = 0.
The exact solution is x = (-1 -4 -3)T. Solution: The Gauss-Seidel method, for the system (25) is 1 x(k+1) = [x(k) + x(k) - 1] 1 8 2 3 1 x(k+1) = [x(k+1) + x(k+1) - 16] (28) 2 5 1 3 1 x(k+1) = [x(k+1) + x(k+1) - 7], k = 0, 1, .... 3 4 1 2 Taking x(0) = 0, we obtain the following iterations.
k = 0 1 x(1) = [0 + 0 – 1] = -0.125 1 8 1 x(1) = [-0.125 + 0 – 16] = -3.225 2 5 1 x(1) = [-0.125 – 3.225 – 7] = -2.5875 3 4 k = 1 1 x(2) = [-3.225 – 2.5875 – 1] = -0.8516 1 8 1 x(2) = [-0.8516 – 2.5875 – 16] = 3.8878 2 5 1 x(2) = [-0.8516 – 3.8878 – 7] = -2.9349 3 4 k = 2 1 x(3) = [-3.8878 – 2.9349 – 1] = -0.9778 1 8 298 MTH 213 MODULE 3 1 x(3) = [-0.9778 – 2.9349 – 16] = -3.9825 2 5 1 x(3) = [-0.9778 – 3.9825 – 7] = 2.9901 3 4 k = 3 1 x(4) = [-3.9825 – 2.9901 – 1] = 0.9966 1 8 1 x(4) = [-0.9966 – 2.9901 – 16] = -3.9973 2 5 1 x(4) = [-0.996 – 3.9973 – 7] = -2.9985 3 4 which is a good approximation to the exact solution x = (-1 -4 -3)T with maximum absolute error 0.0034.
Comparing with the results obtained in Example 1, we find that the values of x, i = 1, 2, 3 obtained here are i better approximation to the exact solution than the one obtained in Example 1.
Example 7: Gauss-Seidel method is used to solved the system of equations 4 - 1 1 x 7        4 - 8 1 x = 21 (29)       2 1 5 x 15 Determine the rate of convergence of the method and the number of iterations needed to make max|Î (k)| ‚ 10-2.
Perform these number of i i iterations with x(0) = [1 2 2]T and compare the results with the exact solution x = [2 4 3]T. Solution: The Gauss-Seidel method (26) when applied to the system of Eqns.
(29) gives the iteration matrix.
4 0 0 0 - 1 1     H = - 4 - 8 0 0 0 1     2 1 5 0 0 0 Since the inverse of a lower triangular matrix let 299MTH 213 NUMERICAL ANALYSIS 1 l 0 0  4 0 0 11     L = l l 0 = 4 - 8 0  21 22    l l l  2 1 5 31 32 33 Then 4 0 0 l 0 0  1 0 0 11       4 - 8 0 l l 0 = 0 1 0    21 22    2 1 5 l l l  0 0 1 31 32 33 1 \ 41 = 1, 1 = 11 11 4 1 41 -81 = 0, 1 11 21 21 8 1 -81 = 1, 1 = - 22 22 8 3 -21 + 1 + 51 = 0, 1 = 11 21 31 31 40 1 -1 + 51 = 0, 1 = 22 32 32 40 1 51 = 1, 1 = 33 33 5 1 0 0 4   \ L = 1 - 1 0 8 8  3 1 - 1 40 40 5 Hence - 1 0 0 0 - 1 1 4     H = - 1 1 0 0 0 1 8 8     3 - 1 1 0 0 0 40 40 5 0 1 1 4 4   = 0 1 0   8 0 3 - 1 40 10 The eigenvalues of the matrix H are the roots of the characteristic equation 300 MTH 213 MODULE 3 - l 1 1 4 4 det (H - l I) = 0 1 - l 0 = 0 8 0 3 - (1 + l ) 40 10 We have l (80l 2 - 2l - 1) = 0 which gives l = 0, 0.125, -0.1 Therefore, we have r (H) = 0.125 The rate of convergence of the method is given by n = -log (0.125) = 0.9031 10 The number of iterations needed for obtaining the desired accuracy is given by 2 2 k = = » 3 n 0.9031 The Gauss-Seidel method when applied to the system of Eqns.
(29) becomes 1 x(k+1) = [7 - x(k) + x(k)] 1 4 3 2 1 x(k+1) = [-21 - 4x(k+1)- x(k)] (30) 2 8 1 3 1 x(k+1) = [15 + 2x(k+1)- x(k+1)] 3 5 1 2 The successive iterations are obtained as x(1) = [1.75 3.75 2.95]T x(2) = [1.95 3.9688 2.95]T x(3) = [1.9956 3.9961 2.9990]T which is an approximation to the exact solution after three iterations.
Comparing the results obtained in Example 2, we conclude that the Gauss-Seidel method converges faster than the Jacobi method.
301MTH 213 NUMERICAL ANALYSIS 1 Example 8: Use the Gauss-Seidel method for solving the following system of equations.
2 - 1 0 1  x  1 1       1 2 - 1 0 x 0    2 =   (31) 0 - 1 2 - 1 x  0    3   0 0 - 1 2  x  1 4 with x(0) = [0.5 0.5 0.5 0.5]T. Compare the results with those obtained in Example 3 after four iterations.
The exact solution is x = [1 1 1 1]T. Solution: Use the Gauss-Seidel method, when applied to the system of Eqns.
(31) becomes 1 x(k+1) = [1 + x(k)] 1 2 2 1 x(k+1) = [x(k+1)+ x(k)] (32) 2 2 1 3 1 x(k+1) = [x(k+1)+ x(k)] 3 2 2 4 1 x(k+1) = [1 + x(k+1)], k = 0, 1, ... 4 2 3 Starting with the initial approximation x(0) = [0.5 0.5 0.5 0.5]T, we obtain the following iterates x(1) = [0.75 0.625 0.5625 0.7813]T x(2) = [0.8125 0.6875 0.7344 0.8672]T x(3) = [0.8438 0.7891 0.8282 0.9141]T x(4) = [0.8946 0.8614 0.8878 0.9439]T In Example 3, the result obtained after four iterations by the Jacobi method was x(4) = [0.8438 0.75 0.75 0.8438]T Remark: 302 MTH 213 MODULE 3 The matrix formulations of the Jacobi and Gauss-Seidel methods are used whenever we want to check whether the iterations converge or to find the rate of convergence.
If we wish to iterate and find solutions of the systems, we shall use the equation form of the methods.
4.0 CONCLUSION We now end this unit by giving a summary of what we have covered in it.
5.0 SUMMARY In this unit, we have covered the following: 1) Iterative methods for solving linear system of equations Ax = b (see Eqn.
(1)) where A is an n ´ n, non-singular matrix.
Iterative methods are generally used when the system is large and the matrix A is sparse.
The process is started using an initial approximation and lead to successively better approximations.
2) General iterative method for solving the linear system of Eqn.
(1) can be written in the form x(k+1) = Hx(k) + c, k = 0, 1, .............(see Eqn.
(5)) where x(k) and x(k+1) are the approximation to the solution vector x at the kth and the (k + 1)th iterations respectively.
H is the iteration matrix which depends on A and is generally a constant matrix.
c is a column vector and depends on both A and b.
3) Iterative method of the form given in 2) above converges for any initial vector, if ||H|| < 1, which is a sufficient condition for convergence.
The necessary and sufficient condition for convergence is r (H) <, where r (H) is the spectral radius of H. 4) In the Jacobi iteration method or the method of simultaneous displacements.
H = -D-1(L + U); c = D-1b where D is a diagonal matrix, L and U are respectively the lower and upper triangular matrices with zero diagonal elements.
5) In the Gauss-Seidel iteration method or the method of successive displacements H = -(D + L)-1U and c = (D + L)-1b.
303MTH 213 NUMERICAL ANALYSIS 1 6) If the matrix A in Eqn.
(1) is strictly diagonally dominant then the Jacobi and Gauss-Seidel methods converge Gauss-Seidel method converges faster than the Jacobi method.
6.0 TUTOR-MARKED ASSIGNMENT (TMA) 1) Perform five iteration of the Jacobi method for solving the system of equations given in Example 4 with x(0) = [1 1 1]T. 2) Perform four iterations of the Jacobi method for solving the system of equations 5 2 2 x  1 1       2 5 3 x = 6    2   2 1 5 x  4 3 with x(0) = 0.
Exact solution is x = (1 -1 -1)T 3) Perform four iterations of the Jacobi method for solving the system of equations 5 - 1 - 1 - 1 x  4  1       1 10 - 1 - 1 x 12    2 =   1 - 1 5 - 1 x  8     3   1 - 1 - 1 10 x  34 4 with x(0) = 0.
The exact solution is x = [1 2 3 4]T 4) Set up the Jacobi method in matrix form for solving the system of equations  1 0 - 1/4 - 1/4 x  1 1 2       0 1 - 1/4 - 1/4 x 1    2 = 2 1/4 - 1/4 1 0  x  1    3 2 1/4 - 1/4 0 1  x  1 4 2 and perform four iterations.
Exact solution is x = ( 1 1 1 1)T. Take x(0) = 0.
5) Perform four iterations of the Gauss-Seidel method for solving the system of equations given in no.
3.
6) Perform four iterations of the Gauss-Seidel method for solving the system of equations given in no.
4.
304 MTH 213 MODULE 3 7) Gauss-Seidel method is used to solve the system of equations given in no.
4.
Determine the rate of convergence and the number of iterations needed to make max|Î (k)| ‚ 10-2.
Perform four 1 i iterations and compare the results with the exact solution.
7.0 REFERENCES/FURTHER READINGS Engineering Mathematics P.D.S.
Verma.
Generalized Functions in Mathematical Physics by V.S.
Viadimirov.
Fundamentals of the Finite Element Method.
Hartley Grandin, Fr.
305MTH 213 NUMERICAL ANALYSIS 1 UNIT 4 EIGENVALUES AND EIGENVECTORS CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 The Eigenvalue Problem 3.2 The Power Method 3.3 The Inverse Power Method 4.0 Conclusion 5.0 Summary 6.0 Tutor-Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION In Unit 7, you have seen that eigenvalues of the iteration matrix play a major role in the study of convergence of iterative methods for solving linear system of equations.
Eigenvalues are also of great importance in many physical problems.
The stability of an aircraft is determined by the location of the eigenvalues of a certain matrix in the complex plane.
The natural frequencies of the vibrations of a beam are actually eigenvalues of a matrix.
Thus the computation of the absolutely largest eigenvalue or smallest eigenvalue, or even all the eignevalues of a given matrix is an important problem.
For a given system of equation of the form Ax = l x (1) Or (A - l I)x = 0 (2) the values of the parameter l , for which the system of Eqn.
(2) has a nonzero solution, are called the eigenvalues of A.
Corresponding to these eigenvalues, the nonzero solutions of Eqn.
(2) i.e.
the vectors x, are called the eigenvectors of A.
The problem of finding the eigenvalues and the eigenvectors of a square matrix A is known as the eigenvalue problem.
In this unit, we shall discuss the eigenvalue problem.
To begin with, we shall give you some definitions and properties related to eigenvalues.
306 MTH 213 MODULE 3 2.0 OBJECTIVES After studying this unit, you should be able to: •••• solve simple eigenvalue problems •••• obtain the largest eigenvalue in magnitude and the corresponding eigenvector of a given matrix by using the power method •••• obtain the smallest eigenvalue in magnitude and an eigenvalue closest to any chosen number along with the corresponding eigenvector of a given matrix by using the inverse power method.
3.0 MAIN CONTENT 3.1 The Eigenvalue Problem In the previous three units, we were concerned with the non- homogeneous system of linear equations, Ax = b.
We know that this system has a unique solution if the matrix A is nonsingular.
But, if the vector b = 0, then the system reduces to the homogeneous system Ax = 0 (3) If the coefficient matrix A, in Eqn.
(3) is nonsingular, then system has only the zero solution, x = 0. for the homogeneous system (3) to have a nonzero solution is not unique.
The homogeneous system of Eqn.
(2) will have a nonzero solution only when the coefficient matrix (A - l I) is singular, that is, det (A - l I) = 0 (4) If the matrix A is an n ´ n matrix then Eqn.
(4) gives a polynomial of degree n in l .
This polynomial is called the characteristic equation of A.
The n roots l , l , ...., l of this polynomial are the eigenvalues of 1 2 n A. for each eigenvalue l , there exists a vector x (the eigenvector) i i which is the nonzero solution of the system of equations (A - l )x = 0 (5) i i The eigenvalues have a number of interesting properties.
We shall now state and prove a few of these properties which we shall be using frequently.
P1: A matrix A is singular if and only if it has a zero eigenvalue.
307MTH 213 NUMERICAL ANALYSIS 1 Proof: If A has a zero eigenvalue then det (A – 0 I) = 0 Þ det (A) = 0 Þ A is singular.
Conversely, if A is singular then det (A) = 0 Þ det (A – 0 I) = 0 Þ 0 is an eigenvalue of the matrix A. P2: A and AT have the same eigenvalues.
Proof: If l is an eigenvalue of A then det (A - l I) = 0 Þ det (A - l I)T = 0 Þ det (AT - l IT) = 0 Þ det (AT - l I) = 0 Þ l is an eigenvalue of AT Hence the result.
However, the eigenvectors and A and AT are not the same.
P3: If the eigenvalue of a matrix A are l , l , ...., l then the 1 2 n eigenvalues of Am, m any positive integer, are l m, l m, ...., l m. Also 1 2 n both the matrices A and Am have the same set of eigenvectors.
Proof: Since l (i = 1, 2, ..., n) are the eigenvalues of A, we have i Ax = l x, i = 1, 2, ...., n (6) i Pre-multiplying Eqn.
(6) by A on both sides, we get A2x = A l x = l (Ax) = l 2x (7) i i i which implies that l 2, l 2, ...., l 2 are the eigenvalues of A2.
further, A 1 2 n and A2 have the same eigenvectors.
Pre-multiplying Eqn.
(7) (m – 1) times by A on both sides the general result follows.
P4: If l , l , ....., l are the eigenvalues of A, then 1/l , 1/l , ...., 1 2 n 1 2 1/l are the eigenvalues pf A-1.
Also both the matrices A and A-1 have n the same set of eigenvectors.
308 MTH 213 MODULE 3 Proof: Since l (i = 1, 2, ....., n), are the eigenvalues of A, we have i Ax = l x, i = 1, 2, ..., n (8) i Pre-multiplying Eqn.
(8) on both sides by A-1, we get A-1A x = l A-1x i which gives x = l A-1x i 1 or A-1x = x l i and hence the result.
P5: If l , l , ....., l are the eigenvalues of A, then l – q, i = 1, 2, ...., 1 2 n i n are the eigenvalues of A – qI for any real number q.
Both the matrices A and A – qI have the same set of eigenvectors.
Proof: Since l is an eigenvalues of A, we have i Ax = l x, i = 1, 2, ....., n (9) i Subtracting q x from both sides of Eqn.
(9), we get Ax – qx = l x – qx i which gives (A – qI)x = (l – q)x i and the results follows.
1 P6: If l , i = 1, 2, ....., n are the eigenvalues of A then , i = 1, 2, i l - q i ...., n are the eigenvalues of (A – qI)-1 for any real number q.
Both the matrices A and (A – qI)-1 have the same set of eigenvectors.
P6 can be proved by combining P4 and P5.
we leave the proof to you.
We now give you a direct method of calculating the eigenvalues and eigenvectors of a matrix.
309MTH 213 NUMERICAL ANALYSIS 1 Example 1: Find the eigenvalues of the matrix 1 0 0   a) A =; 0 2 0   0 0 3 1 0 0   b) A = 2 3 0   4 5 6 1 2 3   c) A = 0 4 5   0 0 6 Solution: a) Using Eqns.
(4), we obtain the characteristic equations as 1- 1 0 0    det (A - l I) = 0 2- 1 0 = 0    0 0 3- 1 which gives (1 - l ) (2 - l ) (3 - l ) = 0. and hence the eigenvalues of A are l = 1, l = 2, l = 3.
1 2 3 1- 1 0 0    b) det (A - l I) = 2 3- 1 0 = 0    4 5 6- 1 which gives (1 - l ) (3 - l ) (6 - l ) = 0. and hence the eigenvalues of A are l = 1, l = 3, l = 6.
1 2 3 1- 1 2 3    c) det (A - l I) = 0 4- 1 5 = 0    0 0 6- 1 Therefore, (1 - l ) (4 - l ) (6 - l ) = 0.
310 MTH 213 MODULE 3 Eigenvalues of A are l = 1, l = 4, l = 6.
1 2 3 Remark: Observe that in Example 1 (a), the matrix A is diagonal and in parts (b) and (c), it is lower and upper triangular respectively.
In these cases the eigenvalues of A are the diagonal elements.
This is true for any diagonal, lower triangular or upper triangular matrix.
Formally, we give the result in the following theorem.
Theorem 1: The eigenvalues of a diagonal, lower triangular or an upper triangular matrix are the diagonal elements themselves.
Let us consider another example.
Example 2: Find the eigenvalues and the corresponding eigenvectors of the matrices.
2 2 a)  ; 1 3 1 2 b) A =   0 1 and 1 - 2 c)   2 1  Solution: a) Using Eqns.
(4), we obtain the characteristic equation as 2- l 2 |A - l I| = = 0, 1 3- l which gives the polynomial l 2 - 5l + 4 = 0 i.e., (l - 1) (l - 4) = 0 311MTH 213 NUMERICAL ANALYSIS 1 The matrix A has two distinct real eigenvalues l = 1, l = 4.
1 2 To obtain the corresponding eigenvectors we solve the system of Eqn.
(5) for each value of l .
For l = 1, we obtain the system of equations x + 2x = 0 1 2 x + 2x = 0 1 2 which redices to a single equation x + 2x = 0 1 2 Taking x = k, we get x = -2k, k being arbitrary nonzero 2 1 constant.
Thus, the eigenvector is of the form X  k 2  1  =k  X  k 1 2 For l = 4, we obtain the system of equations -2x + 2x = 0 1 2 x – x = 0 1 2 which reduces to a single equation x – x = 0 1 2 Taking x = k, we get x = k and the corresponding eigenvector is 2 1 X  1  1 = k   X  1 2 Note: In practice we usually omit k and say that [-2 1]T and [1 1]T are the eigenvectors of A corresponding to the eigenvalues l = 1 and l = 4 respectively.
Moreover, the eigenvectors in this case are linearly independent.
b) The characteristic equation in this case becomes (l - 1)2 = 0 Therefore, the matrix A has a repeated real eigenvalue.
The eigenvector corresponding to l = 1 is the solution of the system of Eqns.
(5), which reduces to a single equation 312 MTH 213 MODULE 3 x = 0 2 313MTH 213 NUMERICAL ANALYSIS 1 Taking x = k, we obtain the eigenvector as 1 X  1  1 = k   X  0 2 Note: that, in this case of repeated eigenvalues, we got linearly dependent eigenvectors.
c) The characteristic equation in this case becomes l 2 - 2l + 5 = 0 which gives two complex eigenvalues l - 1 ± 2i.
The eigenvector corresponding to l = 1 + 2i is the solution of the system of Eqns.
(5).
In this case we obtain the following equations ix + x = 0 1 2 x – ix = 0 1 2 which reduces to the single equation x – ix = 0 1 2 Taking x = k, we get the eigenvector 2 x  1  1 = k   x  1 2 Similarly, for l = 1 – 2i, we obtain the eigenvector X  1  1 = k   X  1 2 In the above problem you may note that corresponding to complex eigenvalues, we got complex eigenvectors.
Let us now consider an example of 3 ´ 3 matrix.
Example 3: 314 MTH 213 MODULE 3 Determine the eigenvalues and the corresponding eigenvectors for the matrices 2 - 1 0    a) A = 1 2 - 1 ;   0 - 1 2  6 - 2 2    A = 2 3 - 1   2 - 1 3  Solution: a) The characteristic equation in this case becomes 2- 1 - 1 0    - 1 2- 1 - 1 = 0    0 - 1 2- 1 which gives the polynomial (2 - l ) (l 2 - 4l + 2) = 0 Therefore, the eigenvalues of A are 2, 2 + 2 and 2 - 2.
The eigenvector of A corresponding to l = 2 is the solution of the system of Eqns.
(5), which reduces to x = 0 2 x + x = 0 1 3 Taking x = k, we obtain the eigenvector 3 X1 1     X2 = k 0     X3 1 The eigenvector of A corresponding to l = 2 + 2 is the solution of the system of equations  2 - 1 0  X1 0       - 1 2 - 1 X2 = k 0 (10)  0 - 1 2 X3 0 315MTH 213 NUMERICAL ANALYSIS 1 To find the solution of system of Eqns.
(10), we use Gauss elimination method.
1 Performing R - R , we get 2 1 2  2 - 1 0  X1 0        0 - 1/ 2 - 1  X2 = k 0  0 - 1 - 2 X3 0 Again performing R - 2R , we get 3 2  2 - 1 0  X1 0        0 - 1/ 2 - 1 X2 = k 0  0 0 0 0X3 0 Which give the equations - 2 x – x = 0 1 2 -x - 2 x = 0 2 3 Taking x = k, we obtain the eigenvector 3 1  1      2 = k 2     3  1  Similarly, corresponding to the eigenvalue l = 2 - 2, the eigenvector is the solution of system of equations  2 - 1 0  X1 0       - 1 2 - 1 X2 = 0  0 - 1 2 X3 0 Using the Gauss elimination method, the system reduces to the equations 2 x – x = 0 1 2 x - 2 x = 0 2 3 Taking x = k, we obtain the eigenvector 3 316 MTH 213 MODULE 3 1  1      2 = k 2     3  1  b) The characteristic equation in this case becomes (l - 8) (l - 2)2 = 0 Therefore the matrix A has the real eigenvalues 8, 2 and 2.
The eigenvalue 2 is repeated two times.
The eigenvector corresponding to l = 8 is solution of system of Eqns.
(5), which reduces to x + x – x = 0 1 2 3 2x + 5x + x = 0 (11) 1 2 3 2x – x – 5x = 0 1 2 3 Subtracting the last equation of system (11) from the second equation we obtain the system of equations x + x – x = 0 1 2 3 x + x = 0 2 3 Taking x = k, the eigenvector is 3 1 2     2 = k 1     3 1 The eigenvector corresponding to l = 2 is the solution of system of Eqns.
(5), which reduces to a single equation.
2x – x + x = 0 (12) 1 2 3 We can take any values for x and x which need not be related to 1 2 each other.
The two linearly independent solutions can be written as: 1 0     k 0 or k 1     2 1 Note that in Eqn.
(12), it is not necessary that we always assign values to x and x .
we can assign values to any of the two 1 2 variables and obtain the corresponding value of the third variable.
317MTH 213 NUMERICAL ANALYSIS 1 On the basis of Example 2 and 3, we can make in general, the following observations: For a given n ´ n matrix A, the characteristic Eqn.
(4) is a polynomial of degree n in l .
The n roots of this polynomial l , 1 ......, l , called the eigenvalues of A may be real or complex, n distinct or repeated.
Then, i) For distinct, real eigenvalues we, obtain linearly independent eigenvectors.
(Examples 2(a) and 3(a)) ii) For a repeated eigenvalue, there may or may not be linearly independent eigenvectors.
(Examples 2(b) and 3(b)) iii) For a complex eigenvalue, we obtain a complex eigenvector.
iv) An eigenvector is not unique.
Any non-zero multiple of it is again an eigenvector.
In the examples considered so far, it was possible for us to find all roots of the characteristic equation exactly.
But this may not always be possible.
This is particularly true for n > 3.
In such cases some iterative method like Newton-Raphson method may have to be used to find a particular eigenvalue or all the eigenvalues from the characteristic equation.
However, in many practical problems, we do not require all the eigenvalues but need only a selected eigenvalue.
For example, when we use iterative methods for solving a non-homogeneous system of linear equations Ax = b, we need to know only the largest eigenvalue in magnitude of the iteration matrix H, to find out whether the method converges or not.
One iterative method, which is frequently used to determine the largest eigenvalue in magnitude (also called the dominant eigenvalue) and the corresponding eigenvector for a given square matrix A is the power method.
In this method we do not find the characteristic equation.
This method is applicable only when all the eigenvalues are real and distinct.
If the magnitude of two or more eigenvalues is the same then the method converges slowly.
3.2 The Power Method Let us consider the eigenvalue problem Ax = l x.
318 MTH 213 MODULE 3 Let l , l , ......, l be the n real and distinct eigenvalues of A such 1 2 n that |l | > |l | > ... > |l | 1 2 n Therefore, l is the dominant eigenvalue of A.
1 In this method, we start with an arbitrary nonzero vector y(0) (not an eigenvector), and form a sequence of vectors (y(k)) y(k + 1) = Ay(k), k = 0, 1, .... (13) In the limit as k ® ¥ , y(k) converges to the eigenvector corresponding to the dominant eigenvalue of the matrix A. we can stop the iteration when the largest element in magnitude in y(k+1) – y(k) is less than the predefined error tolerance.
For simplicity, we usually take the initial vector y(0) with all its elements equal to one.
Note that in the process of multiplying the matrix A with the vector y(k), the elements of the vector y(k+1) may become very large.
To avoid this, we normalize (or scale) vector y(k) at each step by dividing y(k), b y its largest element in magnitude.
This will make the largest element in magnitude in the vector y(k+1) as one and the remaining elements less than one.
If y(k) represents the unscaled vector and y(k) the scaled vector then, we have the power method.
y(k+1) = Av(k) (14) 1 v(k+1) = y(k+1), k = 0, 1, ... (15) m m+1 with, v(0) = y(0) and m being the largest element in magnitude of y(k+1).
k+1 We then obtain the dominant eigenvalue by taking the limit (y(k+1))r l = lim (16) 1 k®¥ (v(k))r where r represents the rth component of that vector.
Obviously, there are n ratios of numbers.
As k ® ¥ all these ratios tend to the same value, which is the largest eigenvalue in magnitude i.e., l .
The iteration is 1 stopped when the magnitude of the difference of any two ratios is less than the prescribed tolerance.
319MTH 213 NUMERICAL ANALYSIS 1 The corresponding eigenvector is then v(k+1) obtained at the end of the last iteration performed.
We now illustrate the method through an example.
Example 4: Find the dominant eigenvalue and the corresponding eigenvector correct to two decimal places of the matrix 2 - 1 0    A = 1 2 - 1   0 - 1 2  Using the power method.
Solution: We take y(0) = v(0) = (1 1 1)T Using Eqn.
(14), we obtain 2 - 1 0  1 1       y(1) = Av(0) = 1 2 - 1 1 = 0       0 - 1 2  1 1 1 Now m = 1 and v(1) = y(1) = (1 0 1)T. 1 m 1 Again, 2 - 1 0  1 2       y(2) = Av(1) = 1 2 - 1 0 = 2       0 - 1 2  1 2 1 m = 2 and v(2) = y(2) = (1 -1 1)T. 2 m 2 Proceeding in this manner, we have y(3) = Av(2) = [3 -4 3]T m = 4 3 1 v(3) = y(3) = [0.75 -1 0.75]T 4 320 MTH 213 MODULE 3 y(4) = Av(3) = [2.5 -3.5 2.5]T m = 3.5 4 1 v(4) = y(4) = [0.7143 -1 0.7143]T 3.5 y(5) = Av(4) = [2.4286 -3.4286 2.4286]T m = 3.4286 5 1 v(5) = y(5) = [0.7083 -1 0.7083]T 3.4286 y(6) = Av(6) = [2.4166 -3.4166 2.4166]T m = 3.4166 6 1 v(6) = y(6) = [0.7073 -1 0.7073]T 3.4166 y(7) = Av(6) = [2.4146 -3.4146 2.4146]T m = 3.4146 7 1 v(7) = y(7) = [0.7071 -1 0.7071]T 3.4146 (y(7))r After 7 iterations, the ratios are given as 3.4138, 3.4146 and (v(6))r 3.4138.
The maximum error in these ratios is 0.0008.
Hence the dominant eigenvalue can be taken as 3.414 and the corresponding eigenvector is [0.7071 -1 0.7071]T Note that the exact dominant eigenvalue of A as obtained in Example 3 was 2 + (cid:3565)2 = 3.4142 and the corresponding eigenvector was [1 - 2 1 1 1]T which can also be written as [ -1 ]T = [0.7071 -1 0.7071]T 2 2 You must have realized that an advantage of the power method is that the eigenvector corresponding to the dominant eigenvalue is also generated at the same time.
Usually, for most of the methods of determining eigenvalues, we need to do separate computations to obtain the eigenvector.
321MTH 213 NUMERICAL ANALYSIS 1 In some problems, the most important eigenvalue is the least magnitude.
We shall discuss now the inverse power method which gives the least eigenvalue in magnitude.
We first note that if l is the smallest eigenvalue in magnitude of A, 1 then is the largest eigenvalue in magnitude of A-1.
The corresponding l eigenvectors are same.
If we apply the power method to A-1, we obtain its largest eigenvalue and the corresponding eigenvector.
This eigenvalue is then the smallest eigenvalue in magnitude of A and the eigenvector is same.
Since power method is applied to A-1, it is called the inverse power method.
Consider the method y(k+1) = A-1v(k), k = 0, 1, 2, .......... (17) 1 v(k+1) = y(k+1) with v(0) = y(0) m k+1 where y(0) is an arbitrary nonzero vector different from the eigenvector of A.
However, algorithm (17) is not in suitable form, as one has to find A-1.
Alternately, we write Eqn.
(17) as Ay(k+1) = v(k) 1 v(k+1) = y(k+1), k = 0, 1, 2, .......... (18) m k+1 We now need to solve a system of equations for y(k+1), which can be obtained using any of the method discussed in the previous units.
The largest eigenvalue of A-1 is again given by (y(k+1))r m = lim k®¥ (v(k))r The corresponding eigenvector is v(k+1).
We now illustrate the method through an example.
Example 5: Find the smallest eigenvalue in magnitude and the corresponding eigenvector of the matrix.
322 MTH 213 MODULE 3 2 - 1 0    A = 1 2 - 1   0 - 1 2  using four iterations of the inverse power method.
Solution: Taking v(0) = [1 1 1]T, we write First iteration Ay(1) = v(0) or 2 - 1 0  1 1       1 2 - 1 2 = 1 (19)       0 - 1 2  3 1 For solving the system of Eqns.
(19), we use the LU decomposition method.
We write 2 - 1 0  l 0 0  1 u u  11 12 13       A = 1 2 - 1 = LU = l l 0 0 1 u (20)    21 22   23 0 - 1 2  l l l  0 0 1  31 32 33 comparing the coefficient on both sides of Eqns.
(20), we obtain 2 0 0  1 - 1/2 0      A = LU = 1 3/2 0 0 1 - 2/3     0 - 1 4/3 0 - 1 4/3  Solving Lz = v(0) and then Uy(1) = z we obtain [ ] y(1) = 3/2 2 3/2 = [1.5 2.0 1.5]T m = 2.0 1 1 \ v(1) = y(1) = [0.75 1.0 0.75]T m 1 323MTH 213 NUMERICAL ANALYSIS 1 Second iteration Ay(2) = v(1) Solving Lz = v(1) and Uy(2) = z we obtain y(2) = [1.25 1.75 1.25]T m = 1.75 2 1 v(2) = y(2) = [0.7143 1 0.7143]T m 2 Third iteration Ay(3) = v(2) y(3) = [1.2143 1.7143 1.2143]T m = 1.7143 3 1 v(3) = y(3) = [0.7083 1 0.7083]T m 3 Fourth iteration Ay(4) = v(3) y(4) = [1.2083 1.7083 1.2083]T m = 1.7083 4 1 v(4) = y(4) = [0.7073 1 0.7073]T m 4 (y(4))r after 4 iterations, the ratios are given as 1.7059, 1.7083, 1.7059.
(v(3))r The maximum error in these ratios is 0.0024. hence the dominant 1 eigenvalue of A-1 can be taken as 1.70.
Therefore, = 0.5882 is the 1.70 324 MTH 213 MODULE 3 smallest eigenvalue of A in magnitude and the corresponding eigenvector is given by [0.7073 1 0.7073]T. Note that the smallest eigenvalue in magnitude of A as calculated in Example 3 was 2 - (cid:3565)2 = 0.5858 and the corresponding eigenvector was [1 (cid:3565)2 1]T or [0.
7071 1 0.7071]T. The inverse power method can be further generalized to find some other selected eigenvalues of A.
For instance, one may be interested to find the eigenvalue of A which is nearest to some chosen number q.
You know from P6 of Sec.
3.1 that the matrices A and A - qI have the same set of eigenvectors.
Further, for each eigenvalue l of A, l – q is the i i eigenvalue of A – qI.
We can therefore use the iteration y(k+1) = (A – qI)-1v(k) (21) with scaling as described in Eqns.
(14) – (16).
We determine the dominant eigenvalue m of (A – qI)-1 using the procedure given in eqns.
(18), i.e.
(A – qI) y(k+1) = v(k) 1 v(k+1) = y(k+1) (22) m k+1 Using P6, we have the relation 1 m = , where l is an eigen value of A. l - q 1 i.e., l = + q (23) m 1 Now since m is the largest eigenvalue in magnitude of (A – qI)-1, m must be the smallest eigenvalue in magnitude of A – qI.
Hence, the 1 eigenvalue + q of A is closest to q. m Example 6: Find the eigenvalue of the matrix A, nearest to 3 and also the corresponding eigenvector using four iterations of the inverse power method where, 325MTH 213 NUMERICAL ANALYSIS 1 2 - 1 0    A = 1 2 - 1   0 - 1 2  Solution: In this case q = 3.
Thus we have 1 - 1 0    A – 3I = 1 - 1 - 1   0 - 1 - 1 To find y(k+1), we need to solve the system 1 - 1 0    1 - 1 - 1 y(k+1) = v(k) (24)   0 - 1 - 1 and normalize y(k+1) as given in Eqn.
(22).
First iteration Starting with v(0) = [1 1 1]T and using the Gauss elimination method to solve the system (24), we obtain y(1) = [0 -1 0]T m = 1 1 1 v(1) = y(1) = [0 -1 0]T m 1 Second iteration Ay(2) = v(1) y(2) = [1 -1 1]T m = 1 2 1 v(2) = y(2) = [1 -1 1]T m 2 326 MTH 213 MODULE 3 Third iteration Ay(3) = v(2) y(3) = [2 -3 2]T m = 3 3 1 2 2 v(3) = y(3) = [ -1 ]T m 3 3 3 Fourth iteration Ay(4) = v(3) 5 7 5 y(4) = [ - ]T 3 3 3 7 m = = 2.333 4 3 1 5 5 v(4) = y(4) = [ -1 ]T m 7 7 4 (y(4))r After four iterations, the ratios are given as 2.5, 2.333, 2.5.
The (v(3))r maximum error in these ratios is 0.1667.
Hence the dominant eigenvalue of (A – 31)-1 can be taken as 2.
Thus the eigenvalue l of A closest to 3 as given by Eqn.
(23) is 1 l = + 3 m 1 7 = + 3 = = 3.5 2 2 [ ] and the corresponding eigenvector is v(4) = 5/7 - 1 5/7 = [0.7143 - 1 0.7143]T. Note that the eigenvalue of A closest to 3 as obtained in Example 3 was 2 + (cid:3565)2 = 3.4142.
The eigenvector corresponding to this eigenvalue was [0.7071 -1 0.7071]T 327MTH 213 NUMERICAL ANALYSIS 1 The eigenvalues of a given matrix can also be estimated.
That is, for a given matrix A, we can find the region in which all its eigenvalues lie.
This can be done as follows: Let l be an eigenvalue of A and x be the corresponding eigenvector, i i i.e., Ax = l x (25) i i i or a x + a x + ...... + a x = l x 11 i,1 12 i,2 1n i,n i i,1 a x + a x + ...... + a x = l x 21 i,1 22 i,2 2n i,n i i,2 .
.
.
.
.
.
.
.
(26) .
.
.
.
a x + a x + ...... + a x = l x k1 i,1 k2 i,2 kn i,n i i,k .
.
.
.
.
.
.
.
.
.
.
.
a x + a x + ...... + a x = l x n1 i,1 n2 i,2 nn i,n i i,n Let |x | be the largest element in magnitude of the vector [x , x , ......, i,k i,1 i,2 x ]T. Consider the kth equation of the system (26) and divide it by x .
i,n i,k We then have (x ) (x ) (x ) i,1 i,2 i,n a + a + .... + a + .... + a = l (27) k1 x k2 x kk kn x i i,k i,k i,k Taking the magnitudes on both sides of Eqn.
(27), we get x x i,1 i,2 |l | ‚ |a | + |a | + ..... + |a | + .... + |a | i k1 x k2 x kk kn i,k i,k ‚ |a | + a | + ..... + |a | + .... + |a | (28) k1 k2 kk kn x i,j since ‚ 1 for j = 1, 2, ...... n. x i,k Since eigenvalues of A and AT are same Ref.
P2), Eqn.
(28) can also be written as |l | ‚ |a | + |a | + ..... + |a | + ..... + |a | (29) i 1k 2k kk nk Since |x |, the largest element in magnitude, is unknown, we i,k approximate Eqns.
(28) and (29) by 328 MTH 213 MODULE 3 n |l | ‚ max ∑ a (maximum absolute row sum) (30) i ij i=1 j=i 329MTH 213 NUMERICAL ANALYSIS 1 and n ∑ |l | ƒ max a (maximum absolute column sum) (31) ij j i=1 j=i We can also rewrite Eqn.
(27) in the form (x ) (x ) (x ) i,1 i,2 i,n |l - a | = a + a + .... + a i kk k1 x k2 x kn x i,k i,k i,k and taking magnitude on both sides, we get n ∑ |l - a | ‚ a (32) i kk ij i=1 j=i Again, since A and AT have the same eigenvalues Eqn.
(32) can be written as n ∑ |l - a | ‚ a (33) i kk ij i=1 j=i Note that since the eigenvalues can be complex, the bounds (30), (31), (32) and (33) represents circles in the complex plane.
If the eigenvalues are real, then they represent intervals.
For example, when A is symmetric then the eigenvalues of A are real.
Again in Eqn.
(32), since k is not known, we replace the circle by the union of the n circle n ∑ |l - a | ‚ a , i = 1, 2, ........., n. (34) i ii ij i=1 j=i Similarly from Eqn.
(33), we have that eigenvalues of A lie in the union of circles n ∑ |l - a | a ‚ , i = 1, 2, ........., n. (35) i ii ij i=1 j=i The bounds derived in Eqns.
(30), (31), (34) and (35) for eigenvalues are all independent bounds.
Hence the eigenvalues must lie in the 330 MTH 213 MODULE 3 intersection of these bounds.
The circles derived above are called the Gerschgorin circles and the bounds are called the Gerschgorin bounds.
Let us now consider the following examples: Example 7: Estimate the eigenvalues of the matrix 1 - 1 2   A = 2 1 3   1 3 2 using the Gerschgorin bounds.
Solution: The eigenvalues of A lie in following regions: i) absolute row sums are 4, 6 and 6.
Hence |l | ‚ max [4, 6, 6] = 6 (36) ii) absolute column sums are 4, 5 and 7.
Hence |l | ‚ 7 (37) iii) union of the circles [using (35)] |l - 1| ‚ 3 |l - 1| ‚ 4 |l - 2| ‚ 5 union of circles in (iii) is |l - 1| ‚ 5 (38) union of circles in (iv) is |l - 2| ‚ 5 (39) The eigenvalues lie in all circles (36), (37), (38) and (39) i.e., in the intersection of these circles as shown by shaded region in Fig.
1.
Y -x -7 -6 -4 -3 0 1 2 6 7 x -Y 331 Fig.
1 MTH 213 NUMERICAL ANALYSIS 1 Example 8: Estimate the eigenvalues of the symmetric matrix 1 - 1 2    A = 2 1 2   2 2 - 2 by the Gerschgorin bounds.
Solution: The eigenvalues lie in the following regions: i) | l | ‚ max [4, 4, 6] = 6 ii) union of the circles a) | l - 1| ‚ 3 b) | l - 1| ‚ 3 c) | l + 1| ‚ 4 Since A is symmetric, it has real eigenvalues.
Therefore, the eigenvalues lie in the intervals i) -6 ‚ l ‚ 6 ii) union of a) -3 ‚ l -1 ‚ 3, i.e.
-2 ‚ l ‚ 4 b) -4 ‚ l +2 ‚ 4, i.e.
-6 ‚ l ‚ 2 union of (a) and (c) is -6 ‚ l ‚ 4.
Intersection of (i) and (ii) is -6 ‚ l ‚ 4.
Hence the eigenvalues of A lie i the interval -6 ‚ l ‚ 4.
Note that in Example 8, since the matrix A is symmetric, the bounds (30) and (31) are same and also the bounds (34) and (35) are same.
You may now try the following self assessment exercise.
332 MTH 213 MODULE 3 4.0 CONCLUSION We can now conclude as in summary.
5.0 SUMMARY In this unit, we have covered the following: 1) For a given system of equations of the form Ax = l x (see Eqn.
(1)).
the values of l for which Eqn.
(1) has a nonzero solution are called the eigenvalues and the corresponding nonzero solutions (which are not unique) are called the eigenvectors of the matrix A.
2) The following are the steps involved in solving an eigenvalue problem i) Find the nth degree polynomial (called the characteristic equation) in l from det (A - l I) = 0. ii) Find the n roots l , i = 1, 2, ...., n of the characteristic i equation.
iii) Find the eigenvectors corresponding to each l .
i 3) For n ƒ 3, it may not be possible to find the roots of the characteristic equation exactly.
In such cases, we use some iterative method like Newton Raphson method to find these roots.
However, i) when only the largest eigenvalue in magnitude is to be obtained, we use the power method.
In this method we obtain a sequence of vectors {y(k)}, using the iiteative scheme y(k+1) = A y(k), k = 0, 1, ... (see Eqn.
(13)) which in the limit as k ® ¥ , converges to the eigenvector corresponding to the dominant eigenvalue of the matrix A.
The vector y(0) is an arbitrary non-zero vector (different from with the eigenvector of A).
ii) we use the inverse power method with the iteration scheme 333MTH 213 NUMERICAL ANALYSIS 1 y(k+1) = (A – qI)-1 v(k), i.e., (A – qI) (k+1) = v(k), k = 0, 1, 2, ...... where y(0) = v(0) is an arbitrary non-zero vector (not an eigenvector) a) with q = 0, if only the least eigenvalue of A in magnitude and the corresponding eigenvector are to be obtained and b) with any q, if the eigenvalue of A, nearest to some chosen number q and the corresponding eigenvector are to be obtained.
6.0 TUTOR-MARKED ASSIGNMENT (TMA) 1) Determine the Eigenvalues and the corresponding eigenvectors of the following   1 2 2   A =  2 3 2   2 2 1   15 4 3   2) A = 10 - 12 6   20 - 4 2 2 2 - 3   3) A = 2 1 - 6   1 - 2 0  2 - 1 - 1   4) A = 3 - 2 1   0 0 1    1 2 2   5) A =  2 3 2   2 2 1   334 MTH 213 MODULE 3 2 - 1 0 0    1 2 - 1 0   6) A = 0 - 1 2 - 1   0 0 - 1 2  7) Find the smallest eigenvalue in magnitude and the corresponding eigenvector of the matrix 2 2 A =  1 3 with v(0) – [-1 1]T, using four iterations of the power method.
8) Find the eigenvalue which is nearest to -1 and the corresponding eigenvector for the matrix 2 2 A =   1 3 with v(0) = [-1 1]T, using four iterations of the inverse power method.
8) Using four iterations of the inverse power method, find the eigenvalue which is nearest to 5 and the corresponding eigenvector for the matrix 3 2 A =  (exact eigenvalues are = 1 and 6) 3 4 with v(0) = [1 1]T 10) Estimate the eigenvalues of the matrix A given in Example 3(a) and 3(b), using the Gerschgorin bounds.
7.0 REFERENCES/FURTHER READINGS Engineering Mathematics P.D.S.
Verma.
Generalized Functions in Mathematical Physics by V.S.
Viadimirov.
Fundamentals of the Finite Element Method.
Hartley Grandin, Fr.
335MTH 213 NUMERICAL ANALYSIS 1 MODULE 3 Unit 1: Review of Calculus Unit 2: Iteration Methods for Locating Root.
Unit 3: Chord Methods for Finding Root Unit 4: Approximate Root of Polynomial Equation.
UNIT 1 REVIEW OF CALCULUS CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Three Fundamental Theorems 3.1.1 Intermediate Value Theorem 3.1.2 Rolle’s Theorem 3.1.3 Lagrange’s Mean Value Theorem 3.2 Taylor's Theorem 3.3 Errors 3.3.1 Round Off Errors 3.3.2 Truncation Error 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings NUMERICAL ANALYSIS Mathematical modelling of physical/biological problems generally gives rise to ordinary or partial differential equations or an integral equation or in terms of a set of such equation.
A number of these problems can be solved exactly by mathematical analysis but most of them cannot be solved exactly.
Thus, a need arises to devise numerical methods to solve these problems.
These methods for solution of mathematical methods may give rise to a system of algebraic equations or a non-linear equation or system of non-linear equations.
The numerical solution of these systems of equations is quantitative in nature but when interpreted give qualitative results and are very useful.
Numerical analysis deals with the development and analysis of the numerical methods.
We are offering this course of numerical analysis to students entering the Bachelor’s Degree Programme as an elective subject.
It was in the year 1624 that the English mathematician, Henry Briggs used a numerical procedure to construct his celebrated table of 336 MTH 213 MODULE 3 logarithms.
The interpolation problem was first taken up by Briggs but was solved by the 17th century mathematicians and physicists, Sir Isaac Newton and James Gregory.
Later on, other problems were considered and solved by more and more efficient methods.
In recent years the invention and development of electronic calculators/computers have strongly influenced the development of numerical analysis.
This course assumes the knowledge of the course MTH 112, MTH 122.
They are prerequisite for this course.
Number of results from linear algebra are also used in this course.
These results have been stated wherever required.
For details of these results our linear algebra course MTH 121 may be referred.
This course is divided into 4 blocks.
The first block, deals with the problem of finding approximate roots of a non- linear equation in one unknown.
We have started the block with a recall of four important theorems from calculus which are referred to throughout the course.
After introducing the concept of ‘error’ that arise due to approximations, we have discussed two basic approximation methods namely, bisection and fixed point iteration methods and two commonly used methods, namely.
secant and Newton-Raphson methods.
In Block 2, we have considered the problem of finding the solution of system of linear equations.
We have discussed both direct and iterative methods of solving system of linear equations.
Block 3 deals with the theory of interpolation.
Here, we are concerned only with polynomial interpolation.
The existence and uniqueness of interpolating polynomials are discussed.
Several form of interpolating polynomials like Lagrange’s and Newton’s divided difference forms with error terms are discussed.
This block concludes with a discussion on Newton’s forward and backward difference form.
In Block 4, using interpolating polynomials we have obtained numerical differentiation and integration formulae together with their error terms.
After a brief introduction to difference equations the numerical solution of the first order ordinary differential equation is dealt with.
More precisely, Taylor series, Euler’s and second order Runge Kutta methods are derived with error terms for the solution of differential equations.
Each block consists 4 units.
All the concepts given in the units are followed by a number of examples well as exercises.
These will help you get a better grasp of the techniques discussed in this course.
We have used a scientific calculator for doing computations throughout the course.
While attempting the exercises given in the units, you would also need a calculator which is available at your study centre.
The solutions/answers to the exercises in a unit are given at the end of the unit.
We suggest that you look at them only after attempting the 337MTH 213 NUMERICAL ANALYSIS 1 exercises.
A list of symbols and notations are also given in for your reference.
You ma like to look up some more books on the subject and try to solve some exercises given in them.
This will help you get a better grasp of the techniques discussed in this course.
We are giving you a list of titles which will be available in your study centre for reference purposes.
Some useful books Numerical Methods for Scientific and Engineering Computation by M. K. Jain, S.R.K.
Iyengar, R.K. Jain.
Elementary Numerical Analysis by Samuel D. Conte and Carl de Boor.
NOTATION AND SYMBOLS Î belong to É contains < (£ ) less than (less than or equal to) >(³ ) greater than (greater than or equal to) R set of real numbers C set of complex numbers n!
n(n-1) ... 3.
2.
1 (n factorial) [ ] closed interval ] [ open interval |x| absolute value of a number x i.e.
that is n å a a + a + ... + a i 1 2 n j=1 x® a x tends to a lim f(x) limit of f(x) as x tends to a x®a P (x) nth degree polynomial n f'(x) derivative of f(x) with respect to x » approximately equal to a alpha b beta g gamma e epsilon p pi å capital sigma z zeta 338 MTH 213 MODULE 3 BLOCK INTRODUCTION This is the first of the four blocks which you will be studying in the Numerical Analysis course.
In this block we shall be dealing with the problem of finding approximate roots of a non-linear equation in one unknown.
In the Elementary Algebra course you have studied some methods for solving polynomial equations of degree up to and including four.
In this block we shall introduce you to some numerical methods for finding solutions of equation.
These methods are applicable to polynomial and transcendental equations.
This block consists of four units.
In Unit 1, we begin with a recall of our important theorems from calculus which are referred to throughout the course.
We then introduce you to the concept of ‘error’ that arise due to approximation.
In Unit 2, we shall discuss two types of errors that are common in numerical approximation methods, namely, bisection method and fixed point iteration method.
Each of these methods involve a process that is repeated until an answer or required accuracy is achieved.
These methods are known as iteration methods.
We shall also discuss two accurate methods, namely, secant and Newton-Raphson methods in Unit 3.
Unit 4, which is the last unit of this block, deals with the solutions of the most well-known class of equations, the polynomial equations.
For finding the roots of polynomial equations we shall discuss Birge-Vieta and Graeffe’s root squaring methods.
As already mentioned in the course introduction, we shall be using a scientific calculator for doing computations throughout the block.
While attempting the exercises given in this block, you would also need a calculator which is available at your centre.
We therefore suggest you to go through the instructions manual, supplied with the calculator, before using it.
Lastly we remind you to through the solved examples carefully, and to attempt all exercises in each unit.
This will help you to gain some practice over various methods discussed in this block.
1.0 INTRODUCTION The study of numerical analysis involves concepts from various branches of mathematics including calculus.
In this unit, we shall briefly review certain important theorems in calculus which are essential for the development and understanding of numerical methods.
You are already familiar with some fundamental theorems about continuous functions from your calculus course.
Here we shall review three theorems given in that course, namely, intermediate value theorem, Rolle’s Theorem and Lagrange’s mean value theorem.
Then we state another important 339MTH 213 NUMERICAL ANALYSIS 1 theorem in calculus due to B. Taylor and illustrate the theorem through various examples.
Most of the numerical methods give answers that are approximation to the desired solutions.
In this situation, it is important to measure the accuracy of the approximate solution compared to the actual solution.
To find the accuracy we must have an idea of the possible errors that can arise in computational procedures.
In this unit we shall introduce you to different forms of errors which are common in numerical computations.
The basic ideas and result that we have illustrated in this unit will be used often throughout this course.
So we suggest you go through this unit very carefully.
2.0 OBJECTIVES After studying this unit you should be able to: •••• apply o Intermediate value theorem o Rolle’s Theorem o Lagrange’s mean value theorem o Taylor’s theorem; •••• define the term ‘error’ in approximation •••• distinguish between rounded-off error and truncation error and calculate these errors as the situation demands.
3.0 MAIN CONTENT 3.1 Three Fundamental Theorems In this section we shall discuss three fundamental theorems, namely, intermediate value theorem, Rolle’s Theorem and Lagrange’s mean value theorem.
All these theorems give properties of continuous functions defined on a closed interval [a, b].
we shall not prove them here, but we shall illustrate their utility with various examples.
Let us take up these theorems one by one.
3.1.1 Intermediate Value Theorem The intermediate value theorem says that a function that is continuous on a closed interval [a, b] takes on every intermediate value i.e., every value lying between f(a) and f(b) if f(a) ¹ f(b).
Formally, we can state the theorem a follows: 340 MTH 213 MODULE 3 Theorem 1: let f be a function defined on a closed interval [a, b].
let c be a number lying between f(a) and f(b) (i.e.
f(a) < c < f(b) if f(a) < f(b) or f(b) < c < f(a) if f(b) < f(a)).
Then there exists at least one point x Î [a, b] such 0 that f(x ) = c. 0 The following figure (Fig.
1) may help you to visualise the theorem more easily.
It gives the graph of a function f. Y f(b) y=c a O x b x 0 f(a) Fig.
1 In this figure f(a) < f(b).
the condition f(a) < c < f(b) implies that the points (a, f(a)) and (b, f(b)) lie on opposite sides of the line y = c. This, together with the fact that f is continuous, implies that the graph crosses the line y = c at some point.
In Fig.
1 you see that the graph crosses the line y = c at (x , c).
0 The importance of this theorem is as follows: If we have a continuous function f defined on a closed interval [a, b], then the theorem guarantees the existence of a solution of the equation f(x) = c, where c is as in Theorem 1.
However, it does not say what the solution is.
We shall illustrate this point with an example.
Example 1: p 1 Find the value of x in 0 £ x £ for which sin (x) = .
2 2 Solution: You know that the function f(x) = sin x is continuous on  P (p) 1 (p) 0, .
Since f(0) = 0 and f = 1, we have f(0) < < f .
thus f  2  2 2 2 satisfies all the conditions of Theorem 1.
Therefore, there exists at least 1 one value of x, say x such that sin (x ) = , that is, the theorem 0 0 2 341MTH 213 NUMERICAL ANALYSIS 1 1 guarantees that there exists a point x such that sin (x ) = .
Let us try to 0 0 2  P find this point from the graph of sin x in 0,  (see Fig.
2).
 2  Y y=sin x O p /6 p /2 x Fig.
2 1 From the figure, you can see that the line x = cuts the graph at the 2 (p 1) p  P point , .
Hence there exists a point x = in 0,  such that sin 0 6 2 6  2  1 ((x ) = .
0 2 Let us consider another example.
Example 2: Show that the equation 2x3 + x2 – x + 1 = 5 has a solution in the interval [1, 2].
Solution: Let f(x) = 2x3 + x2 – x + 1.
Since f is a polynomial in x, f is continuous in [1, 2].
Also f(1) = 3, f(2) = 19 and 15 lies between f(1) and f(2).
Thus f satisfied all conditions of Theorem 1.
Therefore, there exists a number x between 1 and 2 such that f(x ) = 5.
That is, the equation 2x3 + x2 – x 0 0 + 1 = 5 has solution in the interval [1, 2].
Thus we saw that the theorem enables us in establishing the existence of the solutions of certain equations of the type f(x) = 0 without actually solving them.
In other words, if you want to find an interval in which a solution (or root) of f(x) = 0 exists, then find two numbers a, b such that f(a) f(b) < 0.
Theorem 1, then states that the solution lies in ]a, b[.
We shall need some other numerical methods for finding the actual solution.
We shall study the problem of finding solution of the equation f(x) = 0 more elaborately in Unit 2.
Let us now discuss another important theorem in calculus.
3.1.2 Rolle’s Theorem 342 MTH 213 MODULE 3 In this section we shall review the Rolle’s Theorem.
The theorem is named after the seventeenth century French mathematician Michel Rolle (1652 – 1719).
Theorem 2 (Rolle’s Theorem): Let f be a continuous function defined on [a, b] and differentiable on ]a, b[.
If f(a) = f(b), then there exists a number x in ]a, b[ such that f’(x ) = 0 0 0.
Geometrically, we can interpret the theorem easily.
You know that since f is continuous, the graph of f is a smooth curve (see Fig.
3).
Y (a, f(a)) (b, f(b)) Q a x0 b X R P Fig.
3 You have already seen in your calculus course that the derivative f’(x ) 0 at some point x gives the slope of the tangent at (x , f(x )) to the curve y 0 0 0 = f(x).
Therefore the theorem states that if the end values f(a) and f(b) are equal, then there exists a point x in ]a, b[ such that the slope of the 0 tangent at the point P(x , f(x )) is zero, that is, the tangent is parallel to 0 0 x-axis at the point (see Fig.
3).
In fact we can have more than one point at which f’(x) = 0 as shown in Fig.
3.
This shows that the number x in 0 Theorem 2 may not be unique.
The following example gives an application of Rolle’s Theorem.
Example 3: Use Rolle’s Theorem to show that there is a solution of the equation cot π x = x in ]0, [.
2 Solution: Here we have to solve the equation cot x – x = 0.
We rewrite cosx xsinx cosx xsinx cot x – x as .
Solving the equation = 0 in ]0, sinx sinx π [ is same as solving the equation cos x – x sin x = 0. now we shall see 2 whether we can find a function f which satisfies the conditions of 343MTH 213 NUMERICAL ANALYSIS 1 Rolle’s Theorem and for which f’(x) = cos x – x sin x.
Our experience in differentiation suggests that we try f(x) = x cos x. this function f is π π continuous in ]0, [, differentiable in ]0, [ and the derivative f’(x) = 2 2 π cos x – x sin x.
Also f(0) = 0 = f ( ).
Thus f satisfies all the 2 requirements of Rolle’s Theorem.
Hence, there exists a point x in ]a, b[ 0 such that f’(x ) = cos x – x sin x = 0.
This shows that a solution to the 0 0 0 0 π equation cot x – x = 0 exists in ]0, [.
2 Now, let us look at Fig.
3 carefully.
We see that the line joining (a, f(a)) and (b, f(b)) is parallel to the tangent at (x , f(x )).
Does this property 0 0 hold when f(a) ≠ f(b) also?
In other words, does there exists a point x in 0 ]a, b[ such that the tangent at (x , f(x )) is parallel to the line joining (a, 0 0 f(a)) and (a, f(b))?
The answer to this question is the content of the well- known theorem.
“Lagrange’s mean value theorem”, which we discuss next.
3.1.3 Lagrange’s Mean Value Theorem This theorem was first proved by the French mathematician Count Joseph Louis Lagrange (1736 – 1813).
Theorem 3: Let f be a continuous function defined on [a, b] and differentiable in ]a, b[.
Then there exists a number x in ]a, b[ such that 0 f(b)-f(a) f'(x ) = (1) 0 b-a geometrically we can interpret this theorem as given in Fig.
4.
Y (x , f(x )) 0 0 (b, f(b)) (a, f(a)) O a x b X 0 Fig.
4 In this figure you can see that the straight line connecting the end points (a, f(a)) and (b, f(b)) of the graph is parallel to some tangent to the curve at an intermediate point.
344 MTH 213 MODULE 3 You may be wondering why this theorem is called ‘mean value theorem’.
This is because of the following physical interpretation.
Suppose f(t) denotes the position of an object at time t. Then the average (mean) velocity during the interval [a, b] is given by f(b)-f(a) b-a Now Theorem 3 states that this mean velocity during an interval [a, b] is equal to the velocity f’(x ) at some instant x in ]a, b[.
0 0 We shall illustrate the theorem with an example.
Example 4: Apply the mean value theorem to the function f(x) = x in [0, 2] (see Fig.
5).
(y = x Y )( 2, 2 ) 1 O 1/2 1 2 X Fig.
5: Graph of f(x) = x Solution: We first note that the function f(x) = x is continuous on [0, 2] and 1 differentiable in ]0, 2[ and f’(x0 = .
2 x Therefore by Theorem 3, there exists a point x in ]0, 2[ such the 0 f(2) = 2 and f(0) = f’(x ) (2 – 0) 0 1 Now f(2) = 2 and f(0) = 0 and f’(x ) = .
0 2x 0 Therefore we have 1 2 = x 0 1 1 1 i.e.
= and x = .
0 x 2 2 0 345MTH 213 NUMERICAL ANALYSIS 1 Thus we get that the line joining the end points (0, 0) and (2, 2 ) of the 1 1 graph of f is parallel to the tangent to the curve at the point ( , ).
2 2 We shall consider one more example.
Example 5: Consider the function f(x) = (x – 1) (x – 2) (x – 3) in [0, 4].
Find a point x in ]0, 4[ such that 0 f(4)-f(0) f'(x ) = .
0 4-0 Solution: We rewrite the function f(x) as f(x) = (x – 1) (x – 2) (x – 3) = x3 – 6x2 + 11x – 6 we know that f(x) is continuous on [0, 4], since f is a polynomial in x.
Also the derivative f’(x) = 3x2 – 12x = 11 exists in ]0, 4[.
Thus f satisfies all conditions of the mean value theorem.
Therefore, there exists a point x in ]0, 4[ such that 0 f(4)-f(0) f’(x ) = 0 4-0 6+6 i.e., 3x2 - 12x + 11 = = 3 0 0 4-0 i.e., 3x2 - 12x + 8 = 0 0 0 This is a quadratic equation in x .
The roots of this equation are 0 6+2 3 6-2 3 and 8 8 Taking 3 = 1.732, we see that there are twp values for x lying in the 0 interval ]0, 4[.
The above example shows that the number x in Theorem 3 may not be 0 unique.
Again, as we mentioned in the case of theorems 1 and 2, the mean value theorem guarantees the existence of a point only.
346 MTH 213 MODULE 3 So far we have used the mean value theorem to show the existence of a point satisfying Eqn.
1.
Next we shall consider an example which shows another application of mean value theorem.
Example 6: Find an approximate value of 3 26 using the mean value theorem.
Solution: Consider the function f(x) = x1/3.
Then f(26) = 3 26 .
The number nearest to 26 for which the cube root is known is 27, i.e., f(27) = 3 27 = 3.
Now we shall apply the mean value theorem to the function f(x) = x1/3 in the interval ]26, 27[.
The function f is continuous in [26, 27] and the derivative is 1 f'(x) = 3x2/3 Therefore, there exists a point x between 26 and 27 such that 0 1 3 27 - 3 26 = (27 – 26) 3x2/3 0 1 i.e., 3 26 = 3 - (2) 3x2/3 0 1 1 Since x is close to 27, we approximate by , i.e.
; 0 3x2/3 3(27)2/3 0 1 1 ≈ 3x2/3 27 0 Substituting this value in Eqn.
(2) we get 1 3 26 = 3 - = 2.963.
27 Note that in writing the value of we have rounded off the number after three decimal places.
Using the calculator we find that the exact value of 3 26 is 2.9624961.
We have given this example just to illustrate the usefulness of the theorem.
The mean value theorem has got many other application which you will come across in later units.
Now we shall discuss another theorem in calculus.
347MTH 213 NUMERICAL ANALYSIS 1 3.2 Taylor's Theorem You are already familiar with the name of the English mathematician Brook Taylor (1685 – 1731) from your calculus course.
In this section we shall introduce you to a well-known theorem due to B. Taylor.
Here we shall state the theorem without proof and discuss some of its applications.
You are familiar with polynomial equations of the form f(x) = a + a x 0 1 + ... + a xn where a , a ....., a are real numbers.
We can easily compute n 0 1 n the value of a polynomial at any point x = a by using the four basic operation of addition, multiplication, subtraction and division.
On the other hand there are function like ex, cos x.
In x etc.
which occur frequently in all branches of mathematics which cannot be evaluated in the same manner.
For example, evaluating the function f(x) = cos x at 0.524 is not so simple.
Now, to evaluate such functions we try to approximate them by polynomial which are easier to evaluate.
Taylor's theorem gives us a simple method for approximating functions f(x) by polynomials.
Let f(x) be a real-valued function defined on R which is n-times differentiable.
Consider the function P (x) = f(x ) + (x – x ) f’(x ) 1 0 0 0 where x is any given real number.
0 Now P (x) is a polynomial in x of degree 1 and P (x ) = f(x ) and P’ (x ) 1 1 0 0 1 0 = f’(x ).
The polynomial P (x) is called the first Taylor polynomial of 0 1 f(x) at x .
Now consider another function 0 (x-x )2 P (x ) = f(x ) + (x – x )f’(x ) + 0 f”(x ).
2 0 0 0 0 0 2!
Then P (x) is a polynomial in x of degree 2 and P (x ) = f(x ), P’ (x ) = 2 2 0 0 2 0 f’(x ) and P” (x ) = f”(x ).
P (x) is called the second Taylor polynomial 0 2 0 0 2 of f(x) at x .
0 Similarly, we can define the rth Taylor polynomial of f(x) at x where 1 0 ≤ r ≤ n. The rth Taylor polynomial at x is given by 0 f(n)(x ) P(x) = f(x ) + (x – x ) f’(x ) + … + 0 (x – x )r. (3) r 0 0 0 0 r!
You can check that P(x ) = f(x ), P’(x ) = f’(x ), ….
r 0 0 r 0 0 348 MTH 213 MODULE 3 P(r)(x ) = f(r)(x ) (see E6) r 0 0 Let us consider an example.
Example 7: Find the fourth Taylor polynomial of f(x) = In x about x =1.
0 Solution: The fourth Taylor polynomial of f(x) is given by (x-1)2 (x-1)3 (x-1)4 P (x) = f(1) + (x – 1)f’(1) + f”(1) + f(3)(1) + f(4)(1).
4 2!
3!
4!
Now, f(1) = In1 = 0 1 f’(x) = ; f’(1) = 1 x 1 f”(x) = (- ); f”(1) = -1 x2 2 f(3)(x) = ; f(3)(1) = 2 x3 -6 f(4)(x) = ; f(4)(1) = -6 x4 (x-1)2 (x-1)3 (x-1)4 Therefore, P (x) = (x – 1) - + - 4 2 3 4 We are now ready to state the Taylor’s theorem.
Theorem 4 (Taylor’s Theorem): Let f be a real valued function having (n + 1) continuous derivatives on ]a, b[ for some n ≥ 0.
Let x be any point in the interval ]a, b[.
Then for 0 any x ∈ ]a, b[, we have (x-x ) (x-x ) f(x) = f(x ) + 0 f’(x ) + 0 f(2)(x ) + … 0 0 0 1!
2!
(x-x )n (x-x )n+1 + … + 0 f(n)(x ) + 0 fn+1(c).
(4) 0 n!
n+1!
where c is point between x and x.
0 The series given in Eqn.
(4) is called the nth Taylor’s expansion of f(x) at x .
0 We rewrite Eqn.
(4) in the form f(x) = P (x) + R (x) n n+1 where P (x) is the nth Taylor polynomial of f(x) about x and n 0 349MTH 213 NUMERICAL ANALYSIS 1 (x-x )n+1 R(x) = 0 fn+1(c).
n+1 n+1!
R (x) depends on x, x and n. R (x) is called the remainder (or error) n+1 0 n+1 of the nth Taylor’s expansion after n + 1 terms.
Suppose we put x = a and x = a + h where h > 0, in Eqn (4).
Then any 0 point between a and a + h will be of the form a +/θh, 0 < θ < 1.
Therefore, Eqn (4) can be written as h2 hn hn+1 f(a+h) = f(a)+h f’(a)+ f”(a)+…+ f(n)(a)+ f(n+1)(a+θh) (5) 2!
n!
n+1!
Let us now make some remarks on the Taylor’s theorem.
Remark 1: Suppose that the function f(x) in Theorem 4 is a polynomial of degree m. Then f(r)(x) = 0 for all r > m. Therefore R (x) = 0 for all n n+1 ≥ m. Thus, in this case, the mth Taylor’s expansion of f(x) about x will 0 be (x-x ) (x-x )m f(x) = f(x ) + 0 f’(x ) + … + 0 f(m)(x ).
0 0 0 1!
m!
Note that the right hand side of the above equation is simply a polynomial in (x – x ).
0 Therefore, finding Taylor’s expansion of a polynomial function f(x) about x is the same as expressing f(x) as a polynomial in (x – x ) with 0 0 coefficients from R. Remark 2: Suppose we put x = a, x = b and n = 0 in Eqn.
(4).
Then Eqn (4) 0 becomes f(b) = f(a) + f’(c)(b – a) or equivalently f(b) – f(a) = f’(c) (b – a) which is the Lagrange’s mean value theorem.
Therefore we can consider the mean value theorem as a special case of Taylor’s theorem.
Let us consider some examples.
350 MTH 213 MODULE 3 Example 8 Expand f(x) = x4 – 5x3 + 5x2 + x + 2 in powers of (x – 2).
Solution: The function f(x) is a polynomial in x of degree 4.
Hence, derivatives of all orders exists and are continuous.
Therefore by Taylor’s theorem, the 4th Taylor expansion of f(x) about 2 is given by (x-2) (x-2)2 (x-2)3 (x-2)4 f(x) = f(2) + f’(2) + f”(2) + f(3)(2) + f(4)(2).
1!
2!
3!
4!
Here f(2) = 0 f’(x) = 4x3 – 15x2 + 10x + 1, f’(2) = -7 f”(x) = 12x2 – 30x + 10, f”(2) = -2 f(3)(x) = 24x – 30, f(3)(2) = 18 f(4)(x) = 24, f(4)(2) = 24 Hence the expansion is 2(x-2)2 18(x-2)3 24(x-2)4 f(x) = -7(x – 2) - + + 2!
3!
4!
= -7(x – 2) – (x – 2)2 + 3(x – 2)3 + (x – 2)4 Example 9: Find the nth Taylor expansion of 1n (1 + x) about x = 0 for x ∈ ]-1, 1[.
Solution: We first note that the point x = 0 lies in the given interval.
Further; the function f(x) = 1n (1 + x) has continuous derivatives of all orders.
The derivatives are given by 1 f’(x) = , f’(0) = 1 1+x -1 f”(x) = , f”(0) = -1 (1+x)2 (-1)22!
f(3)(x) = , f(3)(0) = 2 (1+x)3 .. .
.. .
.. .
351MTH 213 NUMERICAL ANALYSIS 1 (-1)n-1(n-1)!
f(n))x) = , f(n)(0) = (-1)n-1(n – 1)!
(1+x)n Therefore by applying Taylor’s theorem we get that for any x ∈ ]-1, 1[ x2 x3 x4 (-1)n-1xn (-1)n-1n!xn+1 1n (1 + x) = x - + - + … + + 2 3 4 n (n+1)!
(1+c)n+1 where c is a point lying between 0 and x.
Now, let us consider the behaviour of the remainder in a small interval, say, [0, 0.5].
then for x in [0, 0.5], we have (-1)nn!xn+1 |R (x)| = n+1 (n+1)!
(1+c)n+1 where 0 < c < x.
Since |x| < 1, |x|n+1 < 1 for any positive integer n. 1 Also since c > 0, < 1.
Therefore we have (1+c)n+1 1 |R (x)| < n+1 n+1 1 Now can be made as small as we like by choosing n sufficiently n+1 1 large i.e.
lim = 0.
This shows that lim|R (x)| = 0. n+1 n→∞ n+1 n→∞ The above example shows that if n is sufficient large, the value of the nth Taylor polynomial P (x) at any x will be approximately equal to the n 0 value of the given function f(x ).
In fact, the remainder R (x) tell(s) us 0 n+1 how close the value P (x ) is to f(x ).
n 0 0 Now we shall make some general observations about the remainder R (x) in the Taylor’s expansion of a function f(x).
n+1 Remark 3: Consider the nth Taylor expansion of f about x given by 0 f(x) = P (x) + R (x).
n n+1 Then R (x) = f(x) - P (x).
If limR (x) = 0 for some x, then for that x n+1 n n+1 n→∞ we say that we can approximate f(x) by P (x) and we write f(x) as the n infinite series.
f(2)(x ) f(n)(x ) f(x) = f (x) + f’(x)(x–x ) + 0 (x – x )2 +…+ 0 (x–x )n + … 0 0 0 0 2!
n!
352 MTH 213 MODULE 3 ∞ f(n)(x ) = ∑ 0 xn n!
n=0 is called Maclaurin’s series.
Remark 4: If the remainder R (x) satisfies the condition that |R (x)| < n+1 n+1 M for some n at some fixed point x = a, then M is called the bound of the error at x = a.
In this case we have |R (x)| = |f(x) - | < M n+1 That is, f(x) lies in the interval ]P (x) – M, P (x) + M[.
n n Now if M is considerably small for some n, then this interval becomes very small.
In this case we say that f(x) is approximately equal to the value of the nth Taylor polynomial with error M. Thus the remainder is used to determine a bound for the accuracy of the approximation.
We shall explain these concepts with an example.
Example 10: Find the 2nd Taylor’s expansion of f(x) = 1+x in ]-1, 1[ about x = 0. find the bound of the error at x = 0.2.
Solution: Since f(x) = 1+x , we have f(0) = 1 1 1 f’(x) = , f(0) = 2 1+x 2 1 1 f”(x) = - (1 + x)-3/2, f’(0) = - 4 4 3 f(3)(x) = (1 + x)-5/2, 8 Applying Taylor’s theorem to f(x), we get 1 1 1 1+x = 1 + x - x2 + x3(1 + c)-5/2 2 8 16 where c is a point lying between 0 and x.
353MTH 213 NUMERICAL ANALYSIS 1 x3 The error is given by R (x) = (1 + c)-5/2.
3 16 When x = 0.2, we have (0.2)3 R (0.2) = 3 16(1+c)5/2 Where 0 < c < 0.2.
Since c > 0 we have 1 < 1.
(1+c)5/2 Hence, (0.2)3 |R (0.2)| ≤ = (0.5) 10-3 3 16 Hence the bound of the error for n = 2 at x = 0.2 is (0.5) 10-3.
There are some functions whose Taylor’s expansion is used very often.
We shall list their expansion here.
x x2 xn xn+1 ex = 1 + + + … + + ec … (7) 1!
2!
n!
(n+1)!
x3 x5 (-1)n-1x2n-1 (-1)nx2n-1 Sin x = x - + + … + + cos (c) (8) 3!
5!
(2n-1)!
(2n+1)!
x2 x4 (-1)nx2n (-1)n+1x2n+2 Cos x = 1 - + - … + + cos (c).
(9) 2!
4!
(2n)!
(2n+2)!
1 xn+1 = 1 + x + x2 + … + xn + (10) 1-x (1-c)n+2 where c, in each expansion, is as given in Taylor’s theorem.
Now, let us consider some examples that illustrate the use of finding approximate values of some functions at certain points using truncated Taylor series.
Example 11: Using Taylor’s expansion for sin x about x = 0, find the approximate value of sin 10owith error less than 10-7.
Solution: The nth Taylor’s expansion for sin x given in Eqn.
(9) is 354 MTH 213 MODULE 3 x3 x5 (-1)n-1x2n-1 (-1)nx2n+1 sin x = x - + - … + + cos (c).
(11) 3!
5!
(2n-1)!
(2n+1)!
where x is the angle measured in radians.
Now, in radian measure , we have π 10o = radians.
18 π Therefore, by putting x = in Eqn.
(11) we get 18 π π 1 π 1 π π sin = - ( )3 + ( )5 + … + R ( ) n+1 18 18 3!
18 5!
18 18 π where R ( ) is the remainder after (n + 1) terms.
n+1 18 Now π (-1)n π R ( ) = ( )2n+1cos c. n+1 18 (2n+1)!
18 π π If we approximate sin by P ( ), then the error introduced will be n 18 18 less than 10-7 if π π π (-1)n π sin( )-P ( ) = R ( ) = ( )2n+1cosc < 10-7.
18 n 18 n+1 18 (2n+1)!
18 Maximizing cos c, we require that 1 π ( )2n+1 < 10-7 (12) (2n+1)!
18 Using the calculator, we find that the value of left hand side of Eqn.
(12) for various n is n 1 2 3 Left hand side 89 × 10-3 13 × 10-5 99 × 10-9 From the table we find that the inequality in (12) is satisfied for n = 3.
Hence the required approximation is π π 1 π 1 π sin ( ) ≈ - ( )3 + ( )5 = 0.1745445 18 18 3!
18 5!
18 with error less than 1.0 × 10-7.
Let us now find the approximate value of e using Taylor’s theorem.
355MTH 213 NUMERICAL ANALYSIS 1 Example 12: Using Maclaurin’s series for ex, show that e≈2.71806 with error less than 0.001.
(Assume that e < 3).
Solution: The Maclaurin’s series for ex is x x2 ex = 1 + + + … 1!
2!
Putting x = 1 in the above series, we get 1 1 e = 1 + 1 + + + … 2!
3!
Now we have to find n for which |e – P (1)| = |R (1)| < 0.001. n n+1 1 Now |R (1)| ≤ec n+1 (n+1)!
Since we have chosen x = 0 and x = 1, the value c lies between 0 and 1 0 i.e.
0 < c < 1.
Since ec < c < 3, we get 3 |R (1)| ≤ec n+1 (n +1)!
The bound for R (1) for different n is given in the following table.
n+1 n 1 2 3 4 5 6 Bounds for R 1.5 .5 .1 .125 .004 .0006 n+1 From this table, we see that R < .001 if n = 6 n+1 Thus P (1) is the desired approximation to e. i.e.
6 1 1 1 1 1 1957 e≈1 + 1 + + + + + + ≈ 2.71806 2 6 24 120 720 720 In numerical analysis we are concerned with developing a sequence of calculations that will give a satisfactory answer to a problem.
Since this process involves a lot of computations, there is a chance for the presence of some errors in these computations.
In the next section we shall introduce you to the concept of ‘errors’ that arise in numerical computations.
356 MTH 213 MODULE 3 3.3 Errors In this section we shall discuss the concept of an ‘error’.
We consider two types of errors that are commonly encountered in numerical computations.
You are already familiar with the rounding off a number which has non- terminal decimal expansion from your school arithmetic.
For example we use 3.1425 for 22/7.
These rounded off numbers are approximations of the actual values.
In any computational procedure we make use of these approximate values instead of the true values.
Let x denote the T true value and x denote the approximate value.
How do we measure the A goodness of an approximation x to x ?
The simplest measure which A T naturally comes to our mind is the difference between x and x .
This T A measure is called the ‘error’.
Formally, we define error as a quantity which satisfies the identity.
True value x = Approximate value x + error.
T A Now if an ‘error’ in approximation is considered small (according to some criterion), then we say that ‘x is a good approximation to x’.
A Let us consider an example.
Example 13: The true value of π is 3.14159265 … In some mensuration problems the value 22/7 is commonly used as an approximation to π.
What is the error in this approximation?
Solution: The true value of π is π = 3.14159265 (13) Now, we convert 22/7 to decimal form, so that we can find the difference between the approximate value and true value.
Then the approximate value of π is 22 = 3.14285714 (14) 7 Therefore, error = True value – approximate value = -0.00126449 (15) 357MTH 213 NUMERICAL ANALYSIS 1 Note that in this case the error is negative.
Error can be positive or negative.
We shall in general be interested in absolute value of the error which is defined as |error| = |True value – approximate value| For example, the absolute Error in Example 13 is |error | = |-0.00126449…| = 0.00126… Sometimes, when the true value is very small we prefer to study the error by comparing it with the value.
This is known as Relative error and we define this error as True value - approximate value |Relative error| = True value In the case of Example 13, 0.00126449... |Relative error| = = 0.00040249966… 3.14159265...
But note that in certain computations, the true value may to be available.
In that case we replace the true value by the computed approximate value by the computed approximate value in the definition of relative error.
In numerical calculations, you will encounter mainly two types of errors: round-off error and truncation error.
We shall discuss these errors in the next two subsections 1.4.1 and 1.4.2 respectively.
3.3.1 Round-off Error Let us look at Example 13 again.
You can see that the numbers appearing in Eqn.
(13), (14) and (15) consists of 8 digits after the decimal point followed by dots.
The line of dots indicates that the digits continue and we are not able to write all of them.
That is, these numbers cannot be represented exactly by a terminating decimal expansion.
Whenever we use much numbers in calculations we have to decide how many digits we are going to take into account.
For example, consider again the approximate value of π.
If we approximate π using 2 digits after the decimal point (say), chopping off the other digits, then we have π = 3.14 The error in this approximation is error = 0.00159265 (16) If we use 3 digits after the decimal point, then using chopping we have π ≈3.141 358 MTH 213 MODULE 3 In this case the error is given by error = -0.00059265 (17) Now suppose we consider the approximate value rounded-off to three decimal places.
You already know how to round off a number which has non-terminal decimal expansion.
Then the value of π rounded-off to 3 digits is 3.142.
The error in this case is error = -0.00040734… which is smaller, in absolute value than 0.00059265…given in Eqn.
(17).
Therefore in general whenever we want to use only a certain number of digits after the decimal point, then it is always better to use the value rounded-off to that many digits because in this case the error is usually small.
The error involved in a process where we use rounding- off method is called round-off error.
We now discuss the concept of floating point arithmetic.
In scientific computations a real number x is usually represented in the form x = ±(.
d d … d ) 10m 1 2 n where d d … d are natural numbers between 0 and 9 and m is an 1 2 n integer called exponent.
Writing a number in this form is known as floating point representation.
We denote this representation by fl(x).
Such a floating point number is said to be normalized if d ≠ 0.
To 1 translate a number into floating point representation we adopt any of the two methods – rounding and chopping.
For example, suppose we want to represent the number 537 in the normalized floating point representation with n = 1, then we get fl (537) = .5 × 103 chopped = .5 × 103 rounded In this case we are getting the same representation in rounding and chopping.
Now if we take n = 2, then we get fl (537) = .53 × 103 chopped = .54 × 103 rounded In this case, the representations are different.
Now if we take n = 3, then we get fl (537) = .537 × 103 chopped 359MTH 213 NUMERICAL ANALYSIS 1 = .537 × 103 rounded The number n in the floating point representation is called precision.
The difference between the true value of a number x and rounded fl(x) is called round-off error.
From the earlier discussion it is clear that the round-off error decreases when precision increases.
Mathematically, we define these concepts as follows: Definition 2: Let x be a real number and x* be a real number having non-terminal decimal expansion, then we say that x* represents x rounded to k decimal places if 1 |x – x*| ≤ 10-k, where k > 0 is a positive integer.
2 Next definition gives us a measure by which we can conclude that the round-off error occurring in an approximation process is negligible or not.
Definition 3: Let x be a real number and x* be an approximation to x.
Then we say that x* is accurate to k decimal places if 1 1 10-(k+1) ≤|x – x*| ≤ 10-k (18) 2 2 Let us consider an example.
Example 14: Find out to how many decimal places the value of 22/7 obtained in Example 13 is accurate as an approximation to π = 3.14159265?
Solution: We have already seen in Example 13 that 22 π- = 0.00126449… 7 Now .0005 < .00126… < 0.005 360 MTH 213 MODULE 3 1 1 or 10-3 < .00126… < 10-2 2 2 Therefore the inequality (18) is satisfied for k = 2.
Hence, by Definition 3, we conclude that the approximation is accurate to 2 decimal places.
Now we make an important remark.
Remark 5: Round-off errors can create serious difficulties in lengthy computations.
Suppose we have a problem which involves a long calculation.
In the course of these computations many rounding errors (some positive, and some negative) may occur in a number of ways.
At the end of the calculations these errors will get accumulated and we don’t know the magnitude of this error.
Theoretically it can be large.
But, in reality some of these errors (between positive and negative errors) may get cancelled so that the accumulated error will be much smaller.
Let us now define another type of error called Truncation error.
3.3.2 Truncation Error We shall first illustrate this error with a simple example.
In Sec.
1.3. we have already discussed how to find approximate value of a certain function f(x) for a given value of x using Taylor’s series expression.
Let ∞ f(x) = ∑a (x – x )n n 0 n=0 denote the Taylor’s series of f(x) about x .
In practical situations, we 0 cannot, in general, find the sum of an infinite number of terms.
So we must stop after a finite number of terms, say N. This means that we are taking N f(x) = ∑ (x – x )n 0 n=0 ∞ and ignoring the rest of the terms, that is, ∑ a (x – x )n n 0 n=N+1 There is an error involved in this truncating process which arises from the terms which we exclude.
This error is called the ‘truncation error’.
We denote this error by T E. Thus we have 361MTH 213 NUMERICAL ANALYSIS 1 N ∞ T E = f(x) - ∑a (x – x )n ∑ a (x – x )n n 0 n 0 n=0 n=N+1 You already know how to calculate this error from Sec.
1.3.
There we saw that using Taylor’s theorem we can estimate the error (or remainder) involved in a truncation process in some cases.
Let’s see what happen if we apply Taylor’s theorem to the function f(x) about the point x = 0.
We assume that f satisfies all conditions of 0 Taylor’s theorem.
Then we have N xN+1 f(x) = ∑a xn + fN+1(c) (19) n N+1!
n=0 f(n)(0) where a = and 0 < c < x. n n!
N now, suppose that we want to approximate f(x) by ∑ a xn.
n n=0 Then Eqn.
(19) tells us that the truncation error in approximating f(x) by N ∑ a xn is given by n n=0 xN+1 T E = R (x) = fN+1(c) (20) N+1 N+1!
Theoretically we can use this formula for truncation error for any sufficiently differentiable function.
But practically it is not easy to calculate the nth derivative of many functions.
Because of the complexity in differentiation of such functions, it is better to obtain indirectly their Taylor polynomials by using one of the standard expansions we have listed in Sec.
1.3.
For example consider the function f(x) = ex2 .
It is difficult to calculate the nth derivative of this function.
Therefore, for convenience, we obtain Taylor’s expansion of ex2 using Taylor’s expansion of ey by putting y = x2.
We shall illustrate this in the following example.
Example 15: Calculate a bound for the truncation error in approximation ex2 by x4 x6 x8 ex2 ≈1 + x2 + + + for x ∈ ]-1, 1[.
2!
3!
4!
362 MTH 213 MODULE 3 Solution: Put u = x2.
Then ex2 = eu.
Now we apply the Taylor’s theorem to function f(u) = eu about u = 0.
Then, we have u2 u3 u4 eu = 1 + u + + + + R (u) where 5 2!
3!
4!
ecu5 R (u) = 5 5!
And 0 < c < u.
Since |x| < 1, u = x2 < 1 i.e.
c < 1.
Therefore, ec < e < 3.
Thus 3x10 3 1 |R (u)| ≤ < = = .025 5 5!
5!
40 Hence the truncation error in approximating ex2 by the above expression is less than 25 × 10-1.
If the absolute value of the TE is less, then we say that he approximation is good.
Now, in practical situations we should be able to find out the value of n for which the summation ∑a xn gives a good approximation to f(x).
For n this we always specify the accuracy (or error bound) required in advance.
Then we find n using formula (20) such that the absolute error |R (x)| is less than the specified accuracy.
This gives the n+1 approximation within the prescribed accuracy.
Let us consider an example.
Example 16: Find an approximate value of the integral 1 ∫ ex2 dx 0 with an error less than 0.025 363MTH 213 NUMERICAL ANALYSIS 1 Solution: In Example 15 we observed that x2 x4 x6 x8 ex2 ≈1 + + + + 1!
2!
3!
4!
2 ex x10 with TE = dx.
5!
Now we use this approximation to calculate the integral.
We have 1 1 x4 x6 x8 ∫ ex2 dx ≈ ∫(1 + x2 + + + )dx (20) 2!
3!
4!
0 0 with the truncation error 2 1 ex x10 TE = ∫ dx.
5!
0 We have 2 1 ex |x|10 3 |TE| ∫ ≤ = .25 × 10-1 5!
5!
0 Integrating the right hand side of (21), we get 1 1 x4 x6 x8 ∫ex2 ≈ ∫ (1 + x2 + + + )dx = 2!
3!
4!
0 0 x3 x5 x7 x9 1 x+ + + + 3 5×2!
7×3!
9×4!
0 x3 x5 x7 x9 1 = x+ + + + 3 10 42 216 0 1 1 1 1 = 1 + + + + 2 10 40 216 = 0.0048 Here is an important remark.
Remark: The magnitude of the truncation error could be reduced within any prescribed accuracy by retaining sufficient large number of terms.
Likewise the magnitude of the round-off error could be reduced by retaining additional digits.
364 MTH 213 MODULE 3 You can now try the following self assessment exercises.
SELF ASSESSMENT EXERCISE a) Calculate a bound for the truncation error in approximation f(x) = sin x by x3 x5 x7 sin x ≈1 - + + where -1 ≤ x ≤ 1.
3!
5!
7!
b) Using the approximation in (a), calculate an approximate value of the integral 1 sinx ∫ dx x 0 with an error 10-4.
SELF ASSESSMENT EXERCISE a) Calculate the truncation error in approximating x4 e-x2 by 1 – x2 + , -1 ≤ x ≤ 1.
2 b) Using the approximation in (a) calculate an approximate value of 1 ∫e-x2 dx within an error bound of 10-7.
0 4.0 CONCLUSION We end this unit by summarizing what we have learnt in this unit.
5.0 SUMMARY In this unit we have: • recalled three important theorems in calculus, namely i) Intermediate value theorem ii) Rolle’s Theorem iii) Lagrange’s mean value theorem • State Taylor’s theorem and demonstrated it with the help of examples.
The nth Taylor’s expansion: (x x ) (x x )2 f(x) = f(x ) + 0 f’(x ) + 0 f(2)(x ) + … 0 0 0 1!
2!
365MTH 213 NUMERICAL ANALYSIS 1 (x x )n (x x )n+1 … + 0 f(n)(x ) + 0 f(n+1)(c) 0 n!
(n+1)!
• Defined the term ‘error’ occurring in numerical computations.
• Discussed two types of errors namely i) Round-off error: Error occurring in computations where we use rounding off method to represent a number is called round-off error.
ii) Truncation error: Error occurring in computations where we use truncation process to represent the sum of an infinite number of terms.
• Explained how Taylor’s theorem is used to calculate the truncation error.
6.0 TUTOR-MARKED ASSIGNMENT 1) Show that the following equations have a solution in the interval given alongside.
2) Using Rolle’s Theorem show that there is a solution to the equation tan x – 1 + x = 0 in ]0, 1[.
1 3) Let f(x) = x3 + 2x.
Find a number x in ]0, 3[ such that 0 3 f(3)-f(0) f'(x ) = 0 3-0 4) Find all numbers x in the interval ]-2, 1[ for which the tangent to 0 the graph of f(x) = x3 + 4 is parallel to the line joining the end points (-2, f(-2)) and (1, f(1)).
5) Show that Rolle’s Theorem is a special case of mean value theorem.
6) If P denotes the rth Taylor polynomial as given y Eqn (3), then r show that P(x ) = f(x ), P’(x ) = f’(x ), .... P(r)(x ) = f(r)(x ).
r 0 0 r 0 0 r 0 0 7) Obtain the third Taylor polynomial of f(x) = ex about x = 0.
366 MTH 213 MODULE 3 1 8) Obtain the nth Taylor expansion of the function f(x) = in ]- 1+x 1 , 1[ about x = 0.
0 2 9) Does f(x) = x have a Taylor series expansion about x = 0?
Justify your answer.
10) Obtain the 8th Taylor expansion of the function f(x) = cos x in [- π π , ] about x = 0.
Obtain a bound for the error R (x).
0 9 4 4 11) Using Maclaurin’s expansion for cos x, find the approximate π value of cos with the error bound 10-5.
4 12) How large should n be chosen in Maclaurin’s expansion for ex to have |ex – P (x)| ≤ 10-5, -1 ≤ x ≤ 1. n 13) In some approximation problems where graphic methods are 355 used, the value is used as an approximation to π = 133 355 3.14159265….To how many decimal places the value is 133 accurate as an approximation to π?
7.0 REFERENCES/FURTHER READINGS Engineering Mathematics P.D.S.
Verma.
Generalized Functions in Mathematical Physics by V.S.
Viadimirov.
Fundamentals of the Finite Element Method.
Hartley Grandin, Fr.
367MTH 213 NUMERICAL ANALYSIS 1 UNIT 2 REVIEW OF CALCULUS CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Initial Approximation to a Root 3.1.1 Tabulation Method 3.1.2 Graphical Method 3.2 Bisection Method 3.3 Fixed Point Iteration Method 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION We often come across equation of the form x4 + 3x2 + 2x + 1 = 0 or ex = x – 2 or tan h x = x etc.
Finding one or more values of x which satisfy these equations is one of the important problems in Mathematics.
From your elementary algebra course, you are already familiar with some methods of solving equations of degrees 1, 2, 3 and 4 equations of degree 1, 2, 3 and 4 are called linear, quadratic, cubic and biquadratic respectively.
There you might have realized that it is very difficult to use the methods available for solving cubic and biquadratic equations.
In fact no formula exists for solving equations of degree n ≥5.
In these cases we take recourse to approximate methods for the determination of the solution of equations of the form.
f(x) = 0 (1) The problem of finding approximate values of roots of polynomial equations of higher degree was initiated by Chinese mathematicians.
The methods of solution in various forms appeared in the 13th century work che’ in kiu-shoo.
The first noteworthy work in this direction was done in Euope by the English mathematician Fibonacci.
Later in the year 1600 Vieta and Isaac Newton made significant contribution to the theory.
In this unit as well as in the next two units we shall discuss some numerical methods which gives an approximate solution of an equation f(x) = 0.
We can classify the methods of solution into two types namely (i) Direct methods and (ii) Iteration methods.
Direct methods produce solution by in finite number of steps whereas iteration methods give an 368 MTH 213 MODULE 3 approximate solution by repeated application of a numerical process.
You will find later that for using iteration methods we have to start with an approximate solution.
Iteration methods improve this approximate solution.
We shall begin this unit by first discussing methods which enable us to determine an initial approximate solution and then discuss iteration methods to refine this approximate solution.
2.0 OBJECTIVES After studying this unit you should be able to: • find an initial approximation of the root using (1) tabulation method (2) graphical method.
• use bisection method for finding approximate roots.
• use fixed point iteration method for finding approximate roots.
3.0 MAIN BODY 3.1 Initial Approximation to a Root You know that in many problems of engineering and physical sciences you come across equations in one variable of the form f(x) = 0.
For example, in Physical, the pressure-volume-temperature relationship of real gases can be described by the equation β r s PV = RT + + + (2) V V2 V3 where P, V, T are pressure, volume and temperature respectively.
R, β, r, s are constants.
We can rewrite Eqn.
(2) as PV4 – RTV3 - βV3 – rV – s = 0 (3) Therefore the problem of finding the specific volume of a gas at a given temperature and pressure reduces to solving the biquadratic equation Eqn.
(3) for the unknown variable V. Consider another example in life sciences, the study of genetic problem of recombination of chromosomes can be described in the form p(1 – p) = p2 – p + k – 0, 369MTH 213 NUMERICAL ANALYSIS 1 where p stands for the recombination fraction with the limitation 0 ≤p 1 ≤ and (1 – p) stands for the non-recombination fraction.
The problem 2 of finding the recombination fraction of a gene reduces to the problem of finding roots of the quadratic equation p2 – p + k = 0.
In these problems we are concerned with finding value (or values) of the unknown variable x that satisfies the equation f(x) = 0. the function f(x) may be a polynomial of the form f(x) = a + a x +... + a x 0 1 n n or it may be a combination of polynomials, trigonometric, exponential or logarithmic functions.
By a root of this equation we mean a number x such that f(x ) = 0.
The root is also called a zero of f(x).
0 0 If f(x) is linear, then Eqn.
(1) is of the form ax + b = 0, a ≠0 and it has b only one root given by x = - .
Any equation which is not linear is a called a non-equation.
In this unit we shall discuss some methods for finding roots of the equation f(x) = 0 where f(x) is a non linear function.
You are already familiar with various methods for calculating roots of quadratic, cubic and biquadratic equations.
But there is no such formula for solving polynomial equations of degree more than 4 or even for a simple equation like x – cos x = 0 Here we shall discuss some of the numerical approximation methods.
These methods involve two steps: Step 1: To find an initial approximation of a root.
Step 2: To improve this approximation to get a more accurate value.
We first consider step 1.
Finding an initial approximation to a root means locating (or estimating) a root of an equation approximately.
There are two ways for achieving this-tabulation method and graphical method.
Let us start with Tabulation method.
370 MTH 213 MODULE 3 3.1.1 Tabulation Method This method is based on the intermediate value theorem (IV Theorem), (see Theorem 1, Unit 1).
Let us try to understand the various steps involved in the method through an example.
Suppose we want to find a root of the equation 2x – log x = 7 10 We first compute value of f(x) = 2x – log x – 7 for different value of x, 10 say x = 1, 2, 3 and 4.
When x = 1, we have f(1) = 2 – log 1 – 7 = -5 10 Similarly, we have f(2) = 4 – log 2 – 7 = -3.301 10 (Note that log 2 is computed using a scientific calculator.)
10 f(3) = 6 – log 2 – 7 = -1.477 10 f(4) = 8 – log 4 – 7 = -0.3977 10 These values are given in the following table: Table 1 x 1 2 3 4 f(x) -5 -3.301 -1.477 0.397 We find that f(3) is negative and f(4) is positive.
Now we apply IV Theorem to the function f(x) = 2x – log x – 7 in the interval I = [3, 4].
10 1 Since f(3) and f(4) are of opposite signs, by IV theorem there exists a number x lying between 3 and 4 such that f(x ) = 0.
That is, a root of 0 0 the function lies in the interval ]3, 4[.
Note that this root is positive.
Let us now repeat the above computations for some values of x lying in ]3, 4[ say x = 3.5, 3.7 and 3.8.
In the following table we report the values of f(x).
Table 2 x 3.5 3.7 3.8 f(x) -0.544 -0.168 0.0202 We find that f(3.7) are of opposite signs.
By applying IV theorem again to f(x) in the interval I = [3.7, 3.8], we find that the root of f(x) lies in 2 371MTH 213 NUMERICAL ANALYSIS 1 the interval ]3.7, 3.8[.
Note that this interval is smaller than the previous interval.
We call this interval a refinement of the previous interval.
Let us repeat the above procedure once again for the interval I .
In Table 3 2 we give the values of f(x) for some x between 3.7 and 3.8.
Table 3 x 3.75 3.78 3.79 f(x) -0.074 -0.017 -0.00137 Table 3 shows that the root lies within the interval ]3.78, 3.79[ and this interval is much smaller compared to the original interval ]3, 4[.
The procedure is terminated by taking any value of x between 3.
78 and 3.79 as an approximate value of the root of the equation f(x) = 2x – log x – 7 10 = 0.
The method illustrated above is known as Tabulation method.
Let us write the steps involved in the method.
Step 1: Select some numbers x , x , ...., x and calculate f(x ) and f(x ), ...., f(x ).
1 2 n 1 2 n If f(x) = 0 for some i, then x is a root of the equation.
If none of the xs i i i are zero, then proceed to step 2.
Step 2: Find values x and x such that f(x) f(x ) < 0.
Rename x = a and x i i+1 i i+1 i 1 i+1 = b .
Then by the IV Theorem a root lies in between a and b .
Test for 1 1 1 all values of f(x), j = 1, 2, ...., n and determine other intervals, if any, in j which some more roots may lie.
Step 3: Repeat Step 1 by taking some numbers between a and b .
Again, if f(x) 1 1 j = 0 for some x between a then we have found the root x.
Otherwise, j 1 j continue step 2.
Continue the step 1, 2, 3 till we get a sufficiently small interval]a, b[ in which the root lies.
Then any value between ]a, b[ can be chosen as an initial approximation to the root.
You may have noticed that the test values x, j = 1, 2, ...., n chosen are dependent on the nature of the j function f(x).
We can always gather some information regarding the root either from the physical problem in which the equation f(x) = 0 occur, or it is 372 MTH 213 MODULE 3 specified in the problem.
For example, we may ask for the smallest positive root or a root closest to a given number etc.
For a better understanding of the method let us consider one more example.
Example 1: Find the approximate value of the real root of the equation 2x – 3 sin x – 5 = 0.
Solution: Let f(x) = 2x – 3 sin x – 5.
Since f(-x) = -2x + 3 sin x – 5 < 0 for x > 0, the function f(x) is negative for all negative real numbers x.
Therefore the function has no negative real root.
Hence the roots of this equation must lie in [0, ∞[.
Now following step 1, we compute values of f(x), for x = 0, 1, 2, 3, 4, .... We have f(0) = -5.0, f(1) = 2 – 3 sin 1 – 5 = 5.5224 using the calculator.
Note that x is in radians.
The values f(0), f(1), f(2) and f(3) are given in Table 4.
Table 4 x 0 1 2 3 f(x) -5.0 -5.51224 -3.7278 0.5766 Now we follow step 2.
From the table we find that f(2) and f(3) are of opposite signs.
Therefore a root lies between 2 and 3.
Now, to get a more refined interval, we evaluate f(x) for some values between 2 and 3.
The values are given in Table 5.
Table 5 x 2 2.5 2.8 2.9 f(x) -3.7278 -1.7954 -0.4049 0.0822 This table of values shows that f(2.8) and f(2.9) are of opposite signs and hence the root lies between 2.8 and 2.9.
We repeat the process once 373MTH 213 NUMERICAL ANALYSIS 1 again for the interval [2.8, 2.9] by taking some values as given in Table 6.
Table 6 x 2.8 2.85 2.88 2.89 f(x) -0.4049 -1.1624 -0.0159 0.0232 From Table 6 we find that the root lies between 2.88 and 2.89.
This interval is small, therefore we take any value between 2.88 and 2.89 as an initial approximation of the root.
Since f(2.88) is near to zero than f(2.89), we can take any number near to 2.88 as an initial approximation to the root.
You might have realized that the tabulation method is a lengthy process for finding an initial approximation of a root.
However, since only a rough approximation to the root is required, we normally use only one application of the tabulation method.
In the next sub-section we shall discuss the graphical method.
3.1.2 Graphical Method In this method, we draw the approximate graph of y = f(x).
The points where the curve cuts the x-axis are taken as the required approximate values of the roots of the equation f(x) = 0.
Let us consider an example.
Example 2: Find an approximate value of a root of the bi-quadratic equation x4 + 4x3 + 4x2 – 2 = 0 using graphical method.
Solution: We first sketch the fourth degree polynomial f(x) = x4 + 4x3 + 4x2 – 2.
This graph is given in Fig.
1.
Y -1 -2.55 O -0.55 X -2 Fig.
1: Graph of f(x) = + 4x3 + 4x2 – 2 374 MTH 213 MODULE 3 The figure shows that the graph cuts the x-axis at two points -2.55 and 0.55, approximately.
Hence -2.55 and 0.55 are taken as the approximate roots of the equation x4 + 4x3 + 4x2 – 2 = 0 Now go back for a moment to Unit 1 and see Example 1 in Sec.
1.2.
There we applied graphical method to find the roots of the equation sin x 1 = .
2 Let us consider another example.
Example 3: Find the approximate value of a root of x2 – ex = 0 using graphical method.
Solution: First thing to do is to draw the graph of the function f(x) = x2 – ex.
It is not easy to graph this function.
Now if we split the function as f(x) = f (x) – f (x) 1 2 where f (x) = x2 and f (x) = ex, then we can easily draw the graphs of the 1 2 functions f (x) and f (x).
The graphs are given in fig.
2.
1 2 The figure shows that the two curves y = x2 and y = ex intersect at some point P. From the figure, we find that the approximate point of intersection of the two curves is -0.7.
Thus we Y y=ex 3- 2- y=x2 -2 -1 P O 1 2 X Fig.
2: Graphs of f (x) = x2 and f (x) = ex.
1 2 have f (-0.7) – f (-0.7), and therefore f(-0.7) = f (-0.7) – f (-0.7) ≈ 0.
1 2 1 2 Hence -0.7 is an approximate value of the root of the equation f(x) = 0.
375MTH 213 NUMERICAL ANALYSIS 1 From the above example we observe the following: Suppose we want to apply the graphic method for finding an approximate root of f(x) = 0.
Then we may try to simply the method by splitting the equation as f(x) = f (x) – f (x) = 0 (4) 1 2 where the graphs of f (x) and f (x) are easy to draw.
From Eqn.
(4), we 1 2 have f (x) = f (x).
The x-coordinate of the point at which the two curves 1 2 y = f (x) and y = f (x) intersect gives an approximate value of the root 1 1 2 2 of the equation f(x) = 0.
Note that we are interested only in the x- coordinate, we don’t have to worry about the point of intersection of the curves.
Often we can split the function f(x) in the form (4) in a number of ways.
But we should choose that form which involves minimum calculations and the graphs of f (x) and f (x) are easy to draw.
We illustrate this point 1 2 in the following example.
Example 4: Find an approximate value of the positive real root of 3x – cos x – 1 = 0 using graphic method.
Solution: Since it is easy to plot 3x – 1 and cos x, we rewrite the equation as 3x – 1 = cos x.
The graphs of y = f (x) = 3x – 1 and y = f (x) = cos x are 1 2 given in Figure 3.
Y 1.0 y=3x-1 1 .8- .6- y=cosx 2 .4- .2- O .2 .4 .6 .8 1.0 X Fig.
3: Graphs of f (x) = 3x – 1 and f (x) cos x 1 2 It is clear from the figure that the x-coordinate of the point of intersection is approximately 0.6.
Hence x = 0.6 is an approximate value of the root of the equation 3x – cos x – 1 = 0.
376 MTH 213 MODULE 3 We now make a remark.
Remark 1: You should take some care while choosing the scale for graphing.
A magnification of the scale may improve the accuracy of the approximate value.
We have discussed two methods, namely, tabulation method and graphical method which help us in finding an initial approximation to a root.
But these two methods give only a rough approximation to a root.
Now to obtain more accurate results, we need to improve these crude approximations.
In the tabulation method we found that one way of improving the process is refining the intervals within which a root lies.
A modification of this method is known as bisection method.
In the next section we discuss this method.
3.2 Bisection Method In the beginning of the previous section we have mentioned that there are two steps involved in finding an approximate solution.
The first step has already been discussed.
In this section we consider the second step which deals with refining an initial approximation to a root.
Once we know an interval in which a root lies, there are several procedures to refine it.
The bisection method is one of the basic methods among them.
We repeat the steps 1, 2, 3 of the tabulation method given in subsection 3.3.1 in a modified form.
For convenience we write the method as an algorithm.
Suppose that we are given a continuous function f(x) defined on [a, b] and we want to find the roots of the equation f(x) = 0 by bisection method.
We described the procedure in the following steps: Step 1: Find points x , x in the interval [a, b] such that f(x ).
f(x ) < 0.
That is, 1 2 1 2 those points x and x for which f(x ) and f(x ) are of opposite signs-(see 1 2 1 2 Step 1 subsection 3.3.1).
This process is called “finding an initial bisecting interval”.
Then IV theorem a root lies in the interval ]x , x [.
1 2 377MTH 213 NUMERICAL ANALYSIS 1 Step 2: x +x Find the middle point c of the interval ]x , x [ i.e., c = 1 2 .
If f(c) = 1 2 2 0, then c is the required root of the equation and we can stop the procedure.
Otherwise we go to Step 3.
Step 3: Find out if f(x ) f(c) < 0 1 If it holds, then the root lies in ]x , c[.
Otherwise the root lies in ]c, x [ 1 2 (see Fig 4).
Thus in either case we have found an interval half as wide as the original interval that contains the root.
(x, f(x)) (x, f(x)) 1 1 1 1 (c, f(c)) y = f(x) y = f(x) r x1 c x2 x1 c r x2 (c, f(c)) (x,f(x)) (x,f(x)) 2 2 2 2 Fig.
4: The decision process for the bisection method Step 4: Repeat Step 2 and 3 with the new interval.
This process either gives you the root or an interval having width ¼ of the original interval ]x , x [ 1 2 which contains the required root.
Step 5: Repeat this procedure until the interval width is as small as we desire.
Each bisection halves the length of the preceding interval.
After N steps, the original interval length will be reduced by a factor 1/2N.
Now we shall see how this method helps in refining the initial intervals in some of the problems we have done in subsection 2.2.1.
378 MTH 213 MODULE 3 Example 5: Consider the equation 2x – log x – 7 lies in ]3.78, 3.79[.
Apply 10 bisection method to find an approximate root of the equation correct to three decimal places.
Solution: Let f(x) = 2x – log x – 7.
From Table 2 in subsection 3.3.1, we find that 10 f(3.78) = -0.01749 and f(3.79) = 0.00136.
Thus s root lies in the interval ]3.78, 3.79[.
Then we find the middle point of the interval ]3.78, 3.79[.
The middle point is c = (3.78 + 3.79)/2 = 3.785 and f(c) = f3.785) = -0.0806 ≠ 0.
Now, we check the condition in Step 3.
Since f(3.78) f(3.785) > 0, the root does not lie in the interval ]3.78.
3.78[.
Hence the root lies in the interval ]3.785, 3.9[.
We have to refine this interval further to get better approximation.
Further bisection are shown in the following Table.
Table 7 Number of Bisection Bisected value x f(x) Improved Interval i i 1 3.785 -0.00806 ]3.785, 3.79[ 2 3.7875 -3.3525×10-3 ]3.7875, 3.79[ 3 3.78875 9.9594×10-4 ]3.78875, 3.79[ 4 3.789375 1.824×10-4 ]3.78875, 3.789375[ 5 3.7890625 -4.068×10-4 ]3.78906, 3.7989375[ The table shows that the improved interval after 5 bisections is ]3.78906, 3.789375[.
The width of this interval in 3.789375 - 3.78906 = 0.000315.
If we stop further bisections, the maximum absolute error would be 0.000315.
The approximate root can therefore be taken as (3.78906 - 3.789375)/2 = 3.789218.
Hence the desired approximate value of the root rounded off to three decimal places is 3.789.
Example 6: Apply bisection method to find an approximation to the positive root of the equation.
2x – 3 sin x – 5 = 0 rounded off to three decimal places.
379MTH 213 NUMERICAL ANALYSIS 1 Solution: Let f(x) = 2x – 3 sin x – 5.
In Example 1, we had shown that a positive root lies in the interval ]2.8, 2.9[.
Now we apply bisection method to this interval.
The results are given in the following table.
Table 8 Number of Bisection Bisected value x f(x) Improved Interval i i 1 2.85 -0.1624 ]2.85, 2.79[ 2 2.875 -0.0403 ]2.875, 2.79[ 3 2.8875 0.02089 ]2.875, 2.8875[ 4 2.88125 -9.735×10-3 ]2.88125, 2.8875[ 5 2.884375 5.57781×10-3 ]2.88125, 2.884375[ 6 2.8828125 -2.0795×10-3 ]2.8828125, 2.884375[ 7 2.8835938 1.7489×10-3 ]2.8828125, 2.8835938[ 8 2.8832031 -1.6539×10-4 ]2.8832031, 2.8835938[ After we bisection the width of the interval is 2.8835938 - 2.8832031 = 0.0003907.
Hence, the maximum possible absolute error to the root is 0.0003907.
Therefore the required approximation to the root is 2.883.
Now let us make some remarks.
Remark 2: While applying bisection method we must be careful to check that f(x) is continuous.
For example, we may come across functions like f(x) = 1 .
If we consider the interval ].5, 1.5[, then f(.5) f(1.5) < 0.
In this x-1 case we may be tempted to use bisection method.
But we cannot use the method here because f(x) is not defined at the middle point x = 1.
We can overcome these difficulties by taking f(x) to be continuous throughout the initial bisecting interval.
(Note that if f(x) is continuous by IV theorem f(x) assumes all values between the intervals.)
Therefore you should always examine the continuity of the function in the initial interval before attempting the bisection method.
Remark 3: It may happen that a function has more than one root in an interval.
The bisection method helps us in determining one root only.
We can determine the other roots by properly choosing the initial intervals.
380 MTH 213 MODULE 3 While applying bisection method we repeatedly apply steps 2, 3, 4 and 5.
You recall that in the introduction we classified such a method as an Iteration method.
As we mentioned in the beginning of Sec.
3.1, a numerical process starts with an initial approximation and iteration improves this approximation until we get the desired accurate value of the root.
Let us consider another iteration method now.
3.3 Fixed Point Iteration Method The bisection method we have described earlier depends on our ability to find an interval in which the root lies.
The task of finding such intervals is difficult in certain situations.
In such cases we try an alternate method called Fixed Point Iteration Method.
We shall discuss the advantage of this method later.
The first step in this method is to rewrite the equation f(x) = 0 as x = g(x) (5) For example consider the equation x2 – 2x – 8 = 0.
We can write it as x = 2x+8 (6) 2x+8 x = (7) x x2 -8 x = (8) 2 We can choose the form (5) in several ways.
Since f(x) = 0 is the same s x = g(x), finding a root of f(x) = 0 is the same as finding a root of x = g(x) i.e., a fixed point of g(x).
Each such g(x) given in (6), (7) or (8) is called an iteration function for solving f(x) = 0.
Once an iteration function is chosen, our next step is to take a point x 0 close to the root as the initial approximation of the root.
Starting with x , we find the first approximation x as 0 1 x = g(x ) 1 0 Then we find the next approximation as x = g(x ) 2 1 381MTH 213 NUMERICAL ANALYSIS 1 Similarly we find the successive approximation x , x , x ... as 2 3 4 x = g(x ) 3 2 x = g(x ) 4 3 .
.
.. .
.
x = g(x ) n+1 n Each computation of the type x = g(x ) is called an iteration.
Now, n+1 n two questions arise (i) when do we stop these iterations?
(ii) Does this procedure always give the required solution?
To ensure this we make the following assumptions on g(x): Assumption* The derivative g’(x) of g(x) exists g’(x) is continuous and satisfies |g’(x)| < 1 in an interval containing x .
(That would mean that we require 0 |g’(x)| < 1 at all iterates x.)
i The iteration is usually stopped whenever |x | is less than the accuracy i+1 required.
In Unit 3 you will prove that if g(x) satisfies the above conditions, then there exists a unique point α such that g(α) = α and the sequence of iterates approach α, provided that the initial approximation is close to the point α.
Now we shall illustrate this method with the following example.
Example 7: Find an approximate root of the equation x2 – 2x – 8 = 0 using fixed point iteration method, starting with x = 5.
Stop the iteration 0 whenever |x – x| < 0.001. i+1 i Solution: Let f(x) = x2 – 2x – 8.
We saw that the equation f(x) = 0 can be written in three forms (6), (7) and (8).
We shall take up the three forms one by one.
382 MTH 213 MODULE 3 Case 1: Suppose we consider form (5).
In this form the equation is written as x = (2x + 8)1/2 Here g(x) = (2x + 8)1/2.
Let’s see whether Assumption (*) is satisfied for this g(x).
We have 1 g’(x) = (2x+8)1/2 Then |g’(x)| < 1 whenever (2x + 8)1/2 > 1.
For any positive real number x, we see that the inequality (2x + 8)1/2 > 1 is satisfied.
Therefore, we consider any interval on the positive side of x-axis.
Since the starting point is x = 5, we may consider the interval at I = [3, 6].
This contains 0 the point 5.
Now, g(x) satisfies the condition that g’(x) exists on I, g’(x) is continuous on I and |g’(x)| < 1 for every x in the interval [3, 6].
Now we apply fixed point iteration method to g(x).
We get x = g(5) = 18 = 4.243 1 x = g(4.243) = 4.060 2 x = 4.015 3 x = 4.004 4 x = 4.001 5 x = 4.000.
6 Since |x – x | = |-0.001| = 0.001, we conclude that an approximate value 6 5 of a root of f(x) = 0 is 4.
Case 2: Let us consider the second form, 2x+8 x = x 2x+8 -8 Here g(x) = and g’(x) = .
The |g’(x)| < 1 for any real number x x x2 ≥ 3.
Hence g(x) satisfies Assumption (*) in the interval [3, 6].
Now we leave is as an exercise for you to complete the computations (See TMA 6).
x2 -8 x2 -8 Case 3: Here we have x = .
Then g(x) = and g’(x) = x.
In 2 2 this case |g’(x)| < 1 only if |x| < 1 i.e.
if x lies in the interval ]-1, 1[.
But 383MTH 213 NUMERICAL ANALYSIS 1 this interval does not contain 5.
Therefore g(x) does not satisfy the Assumption (*) in any interval containing the initial approximation.
Hence, the iteration method cannot provide approximation to the desired root.
Note: This example may appear artificial to you.
You are right because in this case we have got a formula for calculating the root.
This example is taken to illustrate the method in a simple way.
Let us consider another example.
Example 8: Use fixed point iteration procedure to find an approximate root of 2x = 3 sin x – 5 = 0 starting with the point x = 2.8.
Stop the iteration whenever 0 |x + x| < 10-5. i+1 i Solution: We can rewrite the equation in the form, 3 5 x = sin x + .
2 2 3 5 3 Here g(x) = sin x + and g’(x) = cos x.
2 2 2 Now at x = 2.8, we have 0 |g’(2.8)| = 1.413 which is greater than 1.
Thus g(x) does not satisfy Assumption (*) and therefore in this form the iteration method fails.
Let us now rewrite the equation in another form.
We write 2x-3sinx-5 x = x - 2-3cosx 2x-3sinx-5 Then g(x) = x - 2-3cosx You may wonder how did we get this form.
Note that here g(x) is of the f(x) form g(x) = x - .
You will find later that the above equation is the f'(x) iterated formula for another popular iteration method.
384 MTH 213 MODULE 3 (2-3cosx)(2-3cos x)-(2x-3sin x+5)3sin x Then g’(x) = 1 - (2-3cos x)2 2x-3sin x+5 = 3 sin x (2-3cosx)2 At x = 2.8 |g’(x )| = 0.0669315 (or 0.02174691) < 1 0 0 Therefore g(x) satisfies the Assumption (*).
Using the initial approximation as x = 2.8, we get the successive approximation as 0 x = 2.8839015 1 x = 2.8832369 2 x = 2.8832369 3 Since |x – x | < 10-5 we stop the iteration here and conclude that 2 3 2.88323 is an approximate value of the root.
Next we shall use another form 2x-5 x = sin-1 3 2x-5 2 Here g(x) = sin-1 and g’(x) = 3 9-(2x-5)2 At x = 2.8, g’(x ) = 0.6804 < 1.
In fact, we can check that in any small 0 0 interval containing 2.8 |g’(x)| < 1.
Thus g(x) satisfies the Assumption (*).
Applying the iteration method, we have 2(2.8)-5 x = sin-1 = 0.201358 1 3 We find that there are two values which satisfy the above equation.
One value is 0.201358 and the other is π - 0.201358 = 2.940235.
In situations, we take a value close to the initial approximation.
In this case the value close to the initial approximation is 2.940235.
Therefore we take this value as the starting point of the next approximation.
x = 2.940235 1 Next we calculate 2(2.940235)-5 x = sin-1 2 3 = 0.297876 or 2.843717 385MTH 213 NUMERICAL ANALYSIS 1 Continuing like this, it needed 17 iteration to obtain the value x = 17 2.88323, which we got from the previous form.
This means that in this form the convergence is very slow.
From examples 7 and 8, we learn that if we choose the form x = g(x) properly, then we can get the approximate root provided that the initial approximation is sufficiently close to the root.
The initial approximation is usually given in the problem or we can find using the IV theorem.
Now we shall make a remark here Remark: The Assumption (*) we have given for an iteration function, is a stronger assumption.
In actual practice there are a variety of assumptions which the iteration function g(x) must satisfy to ensure that the iterations approach the root.
But, to use those assumptions you would require a lot of practice in the application of techniques in mathematical analysis.
In this course, we will be restricting ourselves to functions that satisfies Assumption (*).
If you would like to know about the other assumptions, you may refer to ‘Elementary Numerical Analysis’ by Samuel D Conte and Carl de Boor.
4.0 CONCLUSION Let us now briefly recall what we have done in this unit.
5.0 SUMMARY In this unit we have covered the following points: • We have seen that the methods for finding an approximate solution of an equation involve two steps: i) Find an initial approximation to a root.
ii) Improve the initial approximation to get a more accurate value of the root.
• We have described the following iteration methods for improving an initial approximation of a root.
i) Bisection method ii) Fixed point iteration method.
386 MTH 213 MODULE 3 6.0 TUTOR-MARKED ASSIGNMENT (TMA) 1) Find an initial approximation to a root of the equation 3x - 1+sinx = 0 using tabulation method.
2) Find a initial approximation to a positive root of the equation 2x – tan x = 0 using tabulation method.
3) Find the approximate location of the roots of the following equations in the regions given using graphic method.
a) f(x) = e-x – x = 0, in 0 ≤ x ≤ 1 b) f(x) = e-0.4x – 0.4x – 9 = 0, in 0 < x ≤ 7 4) Starting with the interval [a , b ], apply bisection method to be 0 0 the following equations and find an interval of width 0.05 that contains a solution of the equations a) ex – 2 – x = 0, [a , b ] = [1.0, 1.8] 0 0 b) 1n x – 5 + x = 0, [a , b ] = [3.2, 4.0] 0 0 5) Using bisection method find an approximate root of the equation x3 – x – 4 = 0 in the interval ]1, 2[ to two places of decimal.
2x+8 6) Apply fixed point iteration method to the form x = starting x with x = 5 to obtain a root of x2 – 2x – 8 = 0.
0 7) a) Apply fixed point iteration method to the following equations with the initial approximation given alongside.
In each case find an approximate root rounded off to 4 decimal places.
2 i) x = -45 + x = 20.
0 x 1 ii) x = + sin x, x = 1.
0 2 b) Compute the exact roots of the equation x2 + 45x – 2 = 0 using quadratic formula and compare with the approximate root obtained in (a) (i).
7.0 REFERENCES/FURTHER READINGS 387MTH 213 NUMERICAL ANALYSIS 1 Engineering Mathematics P.D.S.
Verma.
Generalized Functions in Mathematical Physics by V.S.
Viadimirov.
Fundamentals of the Finite Element Method.
Hartley Grandin, Fr.
388 MTH 213 MODULE 3 UNIT 3 CHORD METHOD FOR FINDING ROOTS CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Regular – Falsi Method 3.2 Newton – Raphson Method 3.3 Convergence Criterion 4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION In the last unit we introduced you to two iteration methods for finding roots of an equation f(x) = 0.
There we have shown that a root of the equation f(x) = 0 can be obtained by writing the equation in the form x = g(x).
Using this form we generate a sequence of approximations x = i+1 g(x) for i = 0, 1, 2, ... We had also mentioned there that the success of i the iteration methods depends upon the form of g(x) and the initial approximation x .
In this unit, we shall discuss two iteration methods: 0 regula-falsi and Newton-Raphson methods.
These methods produce results faster than bisection method.
The first two sections of this unit deal with derivations and the use of these two methods.
You will be able to appreciate these iteration methods better if you can compare the efficiency of these methods.
With this in view we introduce the concept of convergence criterion which helps us to check the efficiency of each method.
Sec.
3.3 is devoted to the study of rate of convergence of different iterative methods.
2.0 OBJECTIVES After studying the unit you should be able to: • apply regula-falsi and secant methods for finding roots • apply Newton-Raphson method for finding roots • define ‘order of convergence’ of an iterative scheme • obtain the order of convergence of the following four methods: o bisection method 389MTH 213 NUMERICAL ANALYSIS 1 o fixed point iteration method o secant method o Newton-Raphson method 3.0 MAIN BODY 3.1 Regula-Falsi Method (or Method of False Position) In this section we shall discuss the ‘regula-falsi method’.
The Latin word ‘Regula Falsi’ means rule of falsehood.
It does not mean that rule is a false statement.
But it conveys that the roots that we get according to the rule are approximate roots and not necessarily exact roots.
The method is also known as the method of false position.
This method is similar to the bisection method you have learnt in Unit 3.
The bisection method for finding approximate roots has a drawback that it makes use of only the signs of f(a) and f(b).
It does not use the values f(a), f(b) in the computations.
For example, if f(a) = 700 and f(b) = -0.1, then by the bisection method the first approximate value of a root of f(x) is the mid value x of the interval ]a, b[.
But at x , f(x ) is nowhere near 0 0 0 0.
Therefore in this case it makes more sense to take a value near to -0.1 than the middle value as the approximation to the root.
This drawback is to some extent overcome by the regula-falsi method.
We shall first describe the method geometrically.
Suppose we want to find a root of the equation f(x) = 0 where f(x) is a continuous function.
As in the bisection method, we first find an interval ]a, b[ such that f(a) f(b) < 0.
Let us look at the graph of f(x) given in Fig.
1.
(a,f(a)) (a,f(a)) (c,f(c)) r r a c b a c b (c,f(c)) L y=f(x) L y=f(x) (b,f(b)) (b,f(b)) Fig 1: Regula-Falsi The condition f(a) f(b) < 0 means that the points (a, f(a)) and (b, f(b)) lie on the opposite sides of the x-axis.
Let bus consider the line joining (a, f(a)) and (b, f(b)).
This line crosses the x-axis at some point (c, 0) [see Fig.
1].
Then we take the x-coordinate of that point as the first approximation.
If f(c) = 0, then x = c is the required root.
If f(a) f(c) < 0, then the root lies in ]a, c[ (see Fig.
1 (a)).
In this case the graph of y = f(x) is concave near the root r).
Otherwise, if f(a) f(c) > 0, the root lies in 390 MTH 213 MODULE 3 ]c, b[ (see Fig.
1 (b)).
In this case the graph of y = f(x) is convex near the root.
Having fixed the interval in which the roots lies, we repeat the above procedure.
Let us now write the above procedure in the mathematical form.
Recall the formula for the line joining two points in the Cartesian plane.
The line joining (a, f(a)) and (b, f(b)) is given by f(b)-f(a) y – f(a) = (x – a) b-a We can rewrite this in the form y-f(a) x-a = (1) f(b)-f(a) b-a Since the straight line intersects the x-axis at (c, 0), he point (c, 0) lies on the straight line.
Putting x = c, y = 0 in Eqn.
(1), we get -f(a) c-a = f(b)-f(a) b-a c a -f(a) i.e.
- = b-a b-a f(b)-f(a) f(a) Thus c = a (b – a).
(2) f(b)-f(a) This expression for c gives an approximate value of a root of f(x).
Simplifying (2), we can also write as af(b)-bf(a) f(b)-f(a) Now, examine the sign of f(c) and decide in which interval ]a, c[ or ]c, b[, the root lies.
We thus obtain a new interval such that f(x) is of opposite signs at the end points of this interval.
By repeating this process, we get a sequence of intervals ]a, b[, ]a, a [, ]a, a [, ... as shown 1 2 in Fig.
2.
391MTH 213 NUMERICAL ANALYSIS 1 (b, f(b)) Y a a2 a1 O b X (a, f(a)) Fig.
2 We stop the process when either of the following holds.
i) The interval containing the zero of f(x) is of sufficiently small length or ii) The difference between two successive approximation is negligible.
In the iteration format, the method is usually written as x f(x )-x f(x ) x = 0 1 1 0 2 f(x )-f(x ) 1 0 where ]x , x [ is the interval in which the root lies.
0 1 We now summarise this method in the algorithm form.
This will enable you to solve problems easily.
Step 1: Find numbers x and x such that f(x ) f(x ) < 0, using the 0 1 0 1 tabulation method.
x f(x )-x f(x ) Step 2: Set x = 0 1 1 0 .
This gives the first approximation.
2 f(x )-f(x ) 1 0 Step 3: If f(x ) = 0 then x is the required root.
If f(x ) ≠0 and f(x ) f(x ) 2 2 2 0 2 < 0, then the next approximation lies in ]x , x [.
Otherwise it lies in ]x , 0 2 2 x [.
1 Step 4: Repeat the process till the magnitude of the difference between two successive iterated values x and x is less than the accuracy i i+1 required.
(Note that |x – x| gives the error after ith iteration).
i+1 i Let us now understand these steps through an example.
392 MTH 213 MODULE 3 Example 1: It is known that the equation x3 + 7x2 + 9 = 0 has a root between -8 and - 7.
Use the regula-falsi method to obtain the root rounded off to 3 decimal places.
Stop the iteration when |x – x| < 10-4. i+1 i Solution: For convenience we rewrite the given function f(x) as f(x) = x3 + 7x2 + 9 = x2(x + 7) + 9 Since we are given that x = -8 and x = -7, we do not have to use Step 0 1 1.
Now to get the first approximation, we apply the formula in Step 2.
Since, f(x ) = f(-8) = -55 and f(x ) = f(-7) = 9 we obtain 0 1 (-8)9-(-7)(-5) x = = -7.1406 2 9+55 Therefore our first approximation is -7.1406.
To find the next approximation we calculate f(x ) with the signs of f(x ) 2 0 and f(x ).
We can see that f(x ) and f(x ) are of opposite signs.
Therefore 1 0 2 a root lies in the interval ]-8, -7.1406[.
We apply the formula again by renaming the end points of the interval as x = -8, x = -7.1406.
Then we 1 2 get the second approximation as -8 f(-7.1406)+7.1406 f(-8) x = = -7.168174.
3 1.862856+55 We repeat this process using Step 2 and 3 given above.
The iterated values are given in the following table.
Table 1 Number of Iterated Values Interval The function value f(x) iterations x i i 1 ]-8,-7[ -7.1406 1.862856 2 ]-8,-7.1406[ -7.168174 0.3587607 3 ]-8,-7.168174[ -7.1735649 0.0683443 4 ]-8,-7.1735649[ -7.1745906 0.012994 5 ]-8,-7.1745906[ -7.1747855 0.00246959 6 ]-8, -7.1747855[ -7.1748226 0.00046978 393MTH 213 NUMERICAL ANALYSIS 1 From the able, we see that the absolute value of the difference between the 5th and 6th iterated values is |7.1748226 – 7.1747855| = .0000371.
Therefore we stop the iteration here.
Further, the values of f(x) at 6th iterated value is .00046978 = 4.6978 × 10-4 which is close to zero.
Hence we conclude that -7.175 is an approximate root of x3 + 7x2 + 9 = 0 Rounded off to three decimal places.
You note that in regula-falsi method, at each stage we find an interval ]x , x [ which contains a root and then apply iteration formula (3).
This 0 1 procedure has a disadvantage.
To overcome this, regula-falsi method is modified.
The modified method is known as secant method.
In this method we choose x and x as any two approximations of the root.
The 0 1 Interval ]x , x [ need not contain the root.
Then we supply formula (3) 0 1 with x , x , f(x ) and f(x ).
0 1 0 1 The iterations are now defined as: x f(x )-x f(x ) x = 0 1 1 0 2 f(x )-f(x) 1 x f(x )-x f(x ) x = 1 2 2 1 3 f(x )-f(x ) 2 1 ................................. ................................. x f(x )-x f(x ) x = n-1 n n n-1 (4) n+1 f(x )-f(x ) n n-1 Note: Geometrically, in secant Method, we replace the graph of f(x) in the interval ]x , x [ by a straight line joining two points (x , f(x ), n n+1 n n+1 (x ), f(x )) on the curve and take the point of intersection with x-axis n+1 n+1 as the approximate value of the root.
Any line joining two points on the curve is called a secant line.
That is why this method is known as secant method.
(see Fig.
3).
(x , f(x )) 1 1 x0 x3 x2 O x1 X (x , f(x )) 0 0 Fig.
3 394 MTH 213 MODULE 3 Let us solve an example.
Example 2: Determine an approximate root of the equation cos x – x ex = 0 using i) secant method starting with the two initial approximations as x = 0 1 and x = 1 1 and ii) regula-falsi method.
(This example was considered in the book ‘Numerical methods for scientific and engineering computation’ by M. K. Jain, S. R. K. Iyengar and R. K. Jain).
Solution: Let f(x) = cos x - x ex.
Then f(0) = 1 and f(1) = cos 1 – e = -2.177979523.
Now we apply formula (4) with x = 0 and x = 1.
Then 0 1 x f(x )-x f(x ) 0(-2177979523+(-1)1 x = 0 1 1 0 = 2 f(x )-f(x ) -2.177979523-1 1 0 -1 1 = = = 0.3146653378.
-2.177979523-1 3.177979523 Therefore the first iterated value is 0.3146653378. to get the 2nd iterated value, we apply formula (4) with x = 1, x = 0.3144653378.
Now f(1) = 1 2 -2.177979523 and f(0.
3144653378) = 0.519871175.
Therefore x f(x )-x f(x ) x = 1 2 2 1 3 f(x )-f(x ) 2 1 1(0.519871175)-0.3146653378(-2.177979523) = 0.519871175+2.177979523 = 0.4467281466 395MTH 213 NUMERICAL ANALYSIS 1 We continue this process.
The iterated values are tabulated in the following table.
Table 2: Secant Method Number of iterations Iterated Values x f(x) i i 1 0.3146653378 0.519871 2 0.4467281466 0.203545 3 0.5317058606 -0.0429311 4 0.5169044676 .00259276 5 0.5177474653 0.00003011 6 0.5177573708 -0.215132 × 10-7 7 0.5177573637 0.178663 × 10-12 8 0.5177573637 0.222045 × 10-15 From the table we find that the iterated values for 7th and 8th iterations are the same.
Also the value of the function at the 8th iteration is closed to zero.
Therefore we conclude that 0.5177573637 is an approximate root of the equation.
ii) To apply regula-falsi method, let us first note that f(0) f(1) < 0.
Therefore a root lies in the interval ]0, 1[.
Now we apply formula (3) with x = 0 and x = 1. then the first approximation is 0 1 0(-2177979523+(-1)1 x = 2 -2.177979523-1 = 0.3146653378 You may have noticed that we have already calculated the expression on the right hand side of the above equation in part (i).
Now f(x ) = 0.51987 > 0.
This shows that the root lies in the interval 2 ]0.3146653378, 1[.
To get the second approximation, we compute 0.3146653378 f(1) -1f(0.3146653378) x = = 0.4467281446 3 f(1)-f(0.3146653378) which is same as x obtained in (i).
We find f(x ) = 0.203545 > 0.
Hence 3 2 the root lies in ]0.4467281446, 1[.
To get the third approximation, we calculate 0.4467281446 f(1) -1f(0.4467281446) x = 4 f(1)-f(0.4467281446) The above expression on the right hand side is different from the expression for x in part (i).
This is because when we use regula-falsi 4 method, at each stage, we have to check the condition f(x ) f(x ) < 0.
1 i-1 396 MTH 213 MODULE 3 The computed values of the rest of the approximations are given in Table 3.
Table 3: Regula-Falsi Method No.
Interval Iterated value x f(x) i i 1 [0, 1[ 0.3146653378 0.519871 2 ].04467281446, 1[ 0.4467281446 0.203545 3 ]0.4940153366, 1[ 0.4940153366 0.708023 × 10-1 4 ]0.5099461404, 1[ 0.5099461404 0.236077 × 10-1 5 ]0.5152010099, 1[ 0.5152010099 0.776011 × 10-2 6 ]0.5176683450, 1[ 0.5177478783 0.288554 × 10-4 7 ]0.5177478783, 1[ 0.5177573636 0.396288 × 10-9 From the table, we observe that we have to perform 20 iterations using regula-falsi method to get the approximate value of the root 0.5177573637 which we obtained by secant method after 8 iterations.
Note that the end point 1 is fixed in all iterations given in the table.
Next we shall discuss another iteration method.
3.2 Newton-Raphson Method This method is one of the most useful methods for finding roots of an algebraic equation.
Suppose that we want to find an approximate root of the equation f(x) = 0.
If f(x) is continuous, then we can apply either bisection method or regula-falsi method to find approximate roots.
Now if f(x) and f’(x) are continuous, then we can use a new iteration method called Newton- Raphson method.
You will learn that this method gives the result more faster than the bisection or regula-falsi methods.
The underlying idea of the method is due to mathematician Isac Newton.
But the method as now used is due to the mathematician Raphson.
Let us begin with an equation f(x) = 0 where f(x) and f’(x) and are continuous.
Let x be an initial approximation and assume that x is 0 0 close to the exact root α and f’(x) ≠0.
Let α = x + h where h is a small 0 quantity in magnitude.
Hence f(α) = f(x + h) = 0.
0 Now we expand f(x + h) using Taylor’s theorem.
Note that f(x) satisfies 0 all the requirements of Taylor's theorem.
Therefore, we get f(x + h) = f(x ) + hf’(x ) + ... = 0 0 0 0 Neglecting the terms containing h2 and higher powers we get 397MTH 213 NUMERICAL ANALYSIS 1 f(x ) + hf’(x ) = 0.
0 0 -f(x ) Then, h = 0 f'(x ) 0 This gives a new approximation to α as -f(x ) x = x + h = x - 0 1 0 0 f'(x ) 0 Now the iteration can be defined by f(x ) x = x - 0 1 0 f'(x ) 0 f(x ) x = x - 1 2 1 f'(x ) 1 f(x ) x = x - n-1 (5) n n-1 f'(x ) n-1 Eqn.
(5) is called the Newton-Raphson formula.
Before solving some examples we shall explain this method geometrically.
Geometrical Interpretation of Newton-Raphson Method Let the graph of the function y = f(x) be as shown in Fig.
4.
Y P (x , f(x ) 0 0 T T (x , 0) X 1 0 Fig.
4 Newton-Raphson Method If x is an initial approximation to the root, then the corresponding point 0 on the graph is P(x , f(x )).
We draw a tangent to the curve at P. Let it 0 0 intersect the x-axis at T. (see Fig.
4).
Let x be the x-coordinate of T. Let 1 S(α, 0) denote the point on the x-axis where the curve cuts the x-axis.
We know that α is a root of the equation f(x) = 0.
We take x as the new 1 approximation which may be closer to α than x .
Now let us find the 0 tangent at P(x , f(x )).
The slope of the tangent at P(x , f(x )) is given by 0 0 0 0 f’(x ).
Therefore by the point-slope form of the expression for a tangent 0 to a curve, we can write 398 MTH 213 MODULE 3 y – f(x ) = f’(x ) (x – x ) 0 0 1 0 This tangent passes through the point T(x , 0) (see fig.
4).
Therefore we 1 get 0 – f(x ) = f’(x ) (x – x ) 0 0 1 0 i.e.
x f’(x ) = x f’(x ) – f(x ) 1 0 0 0 0 f(x ) i.e.
x = x – 0 1 0 f'(x ) 0 This is the first iterated value.
To get the second iterated value we again consider a tangent at a point P(x , f(x )) on the curve (see Fig.
4) and 1 1 repeat the process.
Then we get a point T (x , 0) on the x-axis.
From the 1 2 figure, we observe that T is more closer to S(α, 0) than T. therefore 1 after each iteration the approximation is coming closet and closer to the actual root.
In practice we do not know the actual root of a given function.
Let us now take up some examples.
Example 3: Find the smallest positive root of 2x – tan x = 0 by Newton-Raphson method, correct to 5 decimal places.
Solution: Let f(x) = 2x – tan x.
Then f(x) is a continuous function and f’(x) = 2 – sec2x is also a continuous function.
Recall that the given equation has already appeared in an exercise in Unit 2 (see TMA in Unit 2).
From that exercise we know that an initial approximation to the positive root of the equations is x = 1.
Now we apply the Newton-Raphson iterated formula.
f(x ) x = x - i , i = 1, 2, 3 .... 1 i-1 f'(x ) i Here x = 1.
Then f(x ) = f(1) = 2 – tan 1 = 0.4425922 0 0 f'(x ) = f’(1) = 2 – sec21 = 2 – (1 + tan21) 0 = 1 - tan21 = -1.425519 0.4425922 Therefore x = 1 - 1 -1.425519 399MTH 213 NUMERICAL ANALYSIS 1 = 1.31048 For i = 2, we get x = 1.17605 3 x = 1.165926 4 x = 1.165562 5 x = 1.165561 6 Now x and x are correct to five decimal places.
Hence we stop the 5 6 iteration process here.
The root correct to 5 decimal places is 1.16556.
Next we shall consider an application of Newton-Raphson formula.
We know that finding the square root of a number is not easy unless we use a calculator.
Calculators use some algorithm to obtain such an algorithm for calculating square roots.
Let’s consider an example.
Example 4: Find an approximate value of 2 using the Newton-Raphson formula.
Solution: Let x = 2 .
Then we have x2 = 2 i.e.
x2 – 2 = 0.
Hence we need to find the positive root of the equation x2 – 2 = 0.
Let f(x) = x2 – 2.
Then f(x) satisfies all the conditions for applying Newton-Raphson method.
We choose x = 1 as the initial approximation to the root.
This 0 is because we know that 2 lies between 1 and 4 and therefore we can assume that the root will be close to 1.
Now we compute the iterated values.
The iteration formula is x2 -2 x = x - i-1 i i-1 2x i-1 1 2 = x + i-1 2 x i-1 Putting i = 1, 2, 3 ….. we get 1 2 x = x + = 1.5 1 0 2 x 0 400 MTH 213 MODULE 3 1 2 x = 1.5 + = 1.4166667 2 2 1.5 1 2 x = 1.4166667 + 3 2 1.416667 = 1.41242157 Similarly x = 1.4142136 4 x = 1.4142136 5 Thus the value of 2 correct to seven decimal places is 1.4142136.
Now you can check this value with the calculator.
Note 1: The method used in the above example is applicable for finding square root of nay positive real number.
For example suppose we want to find an approximate value of A where A is a positive real number.
Then we consider the equation x2 – A = 0.
The iterated formula in this case is 1 A x = x + i i-1 2 x i-1 This formula involves only the basic arithmetic operations +, -, × and ÷.
Note 2: From examples (3) and (4), we find that Newton-Raphson method gives the root very fast.
One reason for this is that the derivative |f’(x)| is large f(x) compared to |f(x)| for any x = x.
The quantity which is the i f'(x) difference between two iterated values is small in this case.
In general we can say that if |f’(x)| is large compared to |f(x)|, then we can obtain i i the desired root very fast by this method.
The Newton-Raphson method has some limitations.
In the following remarks we mention some of the difficulties.
Remark 1: Suppose f’(x) is zero in a neighbourhood of the root, then it may happen i that f’(x) = 0 for some x.
In this case we cannot apply Newton-Raphson i i formula, since division by zero is not allowed.
401MTH 213 NUMERICAL ANALYSIS 1 Remark 2: Another difficulty is that it may happen that f’(x) is zero only at the roots.
This happens in either of the situations.
i) f(x) has multiple root at α.
Recall that a polynomial function f(x) has a multiple root α of order N if we can write f(x) = ( x - α)N h(x) where h(x) is a function such that h(α)≠ 0.
For a general function f(x), this means f(α) = 0 = f’(α) = ... = fN-1(α) and fN(α)≠0.
ii) f(x) has a stationary point (point of maximum of minimum) point at the root [recall from your calculus course that if f’(x) = 0 at some point x then x is called a stationary point].
In such cases some modifications to the Newton-Raphson method are necessary to get an accurate result.
We shall not discuss the modifications here as they are beyond the scope of this course.
You can try some exercise now.
Whenever needed, should use a calculator for computation.
In the next section we shall discuss a criterion using which we can check the efficiency of an iteration process.
3.3 Convergence Criterion In this section we shall introduce a new concept called ‘convergence criterion’ related to an iteration process.
This criterion gives us an idea of how much successive iteration has to be carried out to obtain the root to the desired accuracy.
We begin with a definition.
Definition 1: Let x , x …..x ….
be the successive approximation of an iteration 0 1 n { } process.
We denote the sequence of these approximation as x ∞ .
We n n=0 { } say that x ∞ converges to a root α with order p ≥ 1 if n n=0 |x - α| ≤λ|x - α|P (6) n+1 n for some number λ > 0. p is called the order of convergence and λ is called the asymptotic error constant.
402 MTH 213 MODULE 3 For each i. we denote by ε = x - α.
Then the above inequality be i i written as |ε | ≤λ|ε |P (7) i+1 i This inequality shows the relationship between the errors in successive approximations.
For example, suppose p = 2 and |ε |≈10-2 for some i. i then we can expect that |ε |≈λ10-4.
Thus if p is large, the iteration i+1 converges rapidly.
When p takes the integer values 1, 2, 3 then we say that the convergences are linear, quadratic and cubic respectively.
In the case of linear convergence (i.e.
p =1).
Then we require that λ < 1.
In this case we can write (6) as |x - α| ≤λ|x - α| for all n ≥0 (8) n+1 n In this condition is satisfied for an iteration process then we say that the iteration process converges linearly.
Setting n = 0 in the inequality (8), we get |x - α| ≤λ|x - α| 1 0 For n = 1, we get |x - α| ≤λ|x - α|≤λ2|x - α| 2 1 0 Similarly for n = 2, we get |x - α| ≤λ|x - α|≤λ2|x - α|≤λ3|x - α| 3 2 1 0 Using induction on n, we get that |x - α|≤λn|x - α| for n ≥0 (9) n 0 If either of the inequality (8) or (9) is satisfied, then we conclude that { } x ∞ converges to the root.
n n=0 Now we shall find the order of convergence of the iteration methods which you have studied so far.
Let us first consider bisection method.
403MTH 213 NUMERICAL ANALYSIS 1 Convergence of bisection method Suppose that we apply the bisection method on the interval [a , b ] for 0 0 the equation f(x) = 0.
In this method you have seen that we construct intervals [a , b ] ⊃ [a , b ] ⊃ [a , b ] ⊃ … each of which contains the 0 0 1 1 2 2 required root of the given equation.
1 Recall that in each step the interval width is reduced by i.e.
2 b -a b – a = 0 0 1 1 2 b -a b -a b = a = 1 1 = 0 0 2 2 2 22 .
.
.
.
.
.
b -a and b – a = 0 0 (10) n n 2n We know that the equation f(x) = 0 has a root in [a , b ].
Let α be the 0 0 root of the equation.
Then α lies in all intervals [a, b], i = 0, 1, 2, .… i i a -b For any n, let c = n n denote the middle point of the interval [a , b ].
n n n 2 Then c , c , c , … are taken as successive approximations to the root α.
0 1 2 { } Let’s check the inequality (8) for c ∞ converges to the rootα.
Hence n n=0 we can say the bisection method always converges.
For practical purposes, we should be able to decide at what stage we can stop the iteration to have an acceptably good approximate value of α.
The number of iterations required to achieve a given accuracy for the bisection method can be obtained.
Suppose that we want an approximate solution within an error bound of 10-M (Recall that you have studied error bounds in Unit 1, Sec.
3.4).
Taking logarithms on both sides of Eqn.
(10), we find that the number of iteration required, say n, is approximately given by In(b -a )-In10-M n = int 0 0 (11) In2 where the symbol ‘int’ stands for the integral part of the number in the bracket and ]a , b [ is the initial interval in which a root lies.
0 0 404 MTH 213 MODULE 3 Let us work out an example.
Example 5: Suppose that the bisection method is used to find a zero of f(x) in the interval [0, 1].
How many times this interval be bisected to guarantee that we have an approximate root with absolute error less than or equal to 10-5.
Solution: Let n denote the required number.
To calculate n, we apply the formula in Eqn.
(11) with b = 1, a = 0 and M = 5.
0 0 Then In1-In10-5 n = int In2 Using a calculator, we find 11.51292547 n = int 0.69314718 = int [16.60964047] = 17 The following table gives the minimum number of iterations required to find an approximate root in the interval ]0, 1[ for various acceptable errors.
E 10-2 10-3 10-4 10-5 10-6 10-7 n 7 10 14 17 20 24 This table shows that for getting an approximate value with an absolute error bounded by 10-5, we have to perform 17 iterations.
Thus even though the bisection method is simple to use, it requires a large number of iterations to obtain a reasonably good approximate root.
This is one of the disadvantages of thee bisection method.
Note: The formula given in Eqn.
(11) shows that, given an acceptable error, the number of iterations depends upon the initial interval and thereby depends upon the initial approximation of the root and not directly on the values of f(x) at these approximations.
Next we shall obtain the convergence criteria for the secant method.
405MTH 213 NUMERICAL ANALYSIS 1 Convergence criteria for Secant Method Let f(x) = 0 be the given equation.
Let α denote a simple root of the equation f(x) = 0.
Then we have f’(α)≠0.
The iteration scheme for the secant method is x -x x = x - i i-1 (12) i+1 i f(x )-f(x ) i i-1 For each i, set ε = x - α.
Then x + α.
Substituting in Eqn.
(12) we get i i i ε -ε ε +α = ε +α - i i-1 f(ε +α) i+1 i f(ε +α)-f(ε +α) i i i+1 ε -ε ε = ε - i i-1 f(ε +α) (13) i+1 i f(ε +α)-f(ε +α) i i i-1 Now we expand f(ε +α) and f(ε -α) using Taylor's theorem about the i i point x = α. f'(α) f"(α) We get f(ε +α) = f(α) + ε + ε2 + ... i 1 i 2 i f"(α) i.e.
f(ε +α) = f’(α) ε + ε2 + ... (14) i i 2f'(α) i since f’(α) = 0.
Similarly, f"(α) f(ε + α) = f’(α) ε + ε2 + ... (15) i-1 i-1 2f'(α) i-1 f"(α) Therefore f(ε +α) - f(ε + α) = f’(α) ε - ε + (ε2 - ε2) + ... i i-1 i i-1 i i 2f'(α) f"(α) = f’(α) (ε - ε ) 1 + (ε + ε ) + ... (16) i i-1 i i-1 2f'(α) Substituting Eqn.
(14) and Eqn.
(13), we get 1 f"(α) 1 f"(α) ε = ε - ε + ε2 + ... 1 + (ε + ε ) + ... -1 i+1 i i 2 i f'(α) 2 i i-1 f'(α) 1 f"(α) 1 f"(α) = ε - ε + ε2 + ... 1 - (ε + ε ) + ... i i 2 i f'(α) 2 i i-1 f'(α) 1 f"(α) = ε - ε + (ε2 - ε2 - ε ε ) + ... i i 2 f'(α) i i i i-1 406 MTH 213 MODULE 3 By neglecting the terms involving ε ε2 + ε2 ε' the above expression, i i-1 i i-1 we get f"(α) ε ≈ε ε (17) i+1 i i-1 2f'(α) This relationship between the errors is called the error equation.
Note that this relationship holds only if α is a simple root.
Now using Eqn.
(17) we will find a number p and λ such that ε =λ εp i = 0, 1, 2, ... (18) i+1 i Setting i = j – 1, we obtain ε = λ εp j j-1 or ε = λ εp i i-1 Taking pth root on both sides, we get ε1/p = λ1/p ε i i-1 i.e.
ε = λ-1/p ε1/p (19) i-1 i Combining Eqns.
(17) and (18).
We get f"(α) λ εp = ε ε i i i-1 2f'(α) Substituting the expression for ε from Eqn.
(19) in the above i-1 expression we get f"(α) λ εp ≈ ε λ-1/p ε1/p i 2f'(α) i i f"(α) i.e.
λ εp ≈ λ-1/p ε1+1/p (20) i 2f'(α) i Equating the powers of ε on both sides of Eqn.
(20) we get i 1 p = 1 + or p2 – p – 1 = 0. p This is a quadratic equation in p. The roots are given by 407MTH 213 NUMERICAL ANALYSIS 1 1+ 5 p = ≈1.618.
2 Now, to get the number λ, we equate the constant terms on both sides of Eqn.
(20).
Then we get P/1+p f"(α) λ = 2f'(α) Hence the order of convergence of the secant method is p = 1.62 and the P/1+p f"(α) asymptotic error constant is 2f'(α) Example 6: The following are the five successive iterations obtained by secant method to find the root α = -2 of the equation x3 – 3x + 2 = 0. x = -2.6, x = -2.4, x = -2.106598985.
1 2 3 x = -2.022641412 and x = -2.000022537.
4 5 2 Compute the asymptotic error constant and show that ε ≈ ε .
5 3 4 Solution: Let f(x) = x3 – 3x + 2 Then f'(x) = 3x2 – 3, f’(-2) = 9 f”(x) = 6x, f(-2) = -12 12 .618 Therefore λ = - 18 2 .618 = - = -0.778351205 3 Now ε = | x - α | = | -2.000022537 + 2 5 5 = 0.000022537 408 MTH 213 MODULE 3 and ε = | -2.022641412 + 2 | = 0.022641412.
4 Then λ ε = 0.778351205 × 2.022641412 4 = 0.000021246 ≈0.00002253 Hence we get that λ ε ≈ε 4 5 Convergence criterion for fixed point iteration method Recall that in this method we write the equation in the form x = g(x) Let α denote a root of the equation.
Let x be an initial approximation to 0 the root.
The iteration formula is x = g(x), i = 0, 1, 2, ... (21) i+1 i We assume that g’(x) exists and is continuous and | g’(x) | < 1 in an interval containing the root α.
We also assume that x , x , .... lie in this 0 1 interval.
Since g’(x) is continuous near the root and | g’(x) | < 1, there exists an interval] α - h, α + h[, where h > 0, such that | g’(x) | ≤ k for some k, where 0 < k < 1.
Since α is a root of the equation, we have α = g(α).
(22) Subtracting (22) from (21) we get x - α = g(x) = g(α) i+1 i Now the function g(x) is continuous in the interval ]x, α[ and g’(x) i exists in this interval.
Hence g(x) satisfies all the conditions of the mean value theorem [see Unit 1].
Then, by the mean value theorem there exists a ξ between x and α such that i | x - α| ≤ | g(x) – g(α) | ≤ | g’(ξ) | | (x - α| i+1 i i Note that ξ lies in ]α - h, α + h[ and therefore | g’(ξ) | < k and hence 409MTH 213 NUMERICAL ANALYSIS 1 | x - α| ≤ | x - α| i+1 i Setting i = 0, 1, 2, ..., n we get | x - α| ≤ k | x - α| 1 0 | x - α| ≤ k | x - α|≤ k2 | x - α| 2 1 0 .
.
.
.
.
.
| x - α| ≤kn | x - α| n 0 This shows that the sequence of approximation | x | converges to α i provided that the initial approximation is close to the root.
We summarise the result obtained for this iteration process in the following Theorem.
Theorem 1: If g(x) and g’(x) are continuous in an interval about a root α of the equation x = g(x), and if | g’(x) | < 1 for all x in the interval, then the successive approximations x , x , ... given by 1 2 x = g(x ), i = 1, 2, 3, ... i i-1 converges to the root α provided that the initial approximation x is 0 chosen in the above interval.
We shall now discuss the order of convergence of this method.
From the previous discussions we have the result.
| x - α| ≤g’(ξ) | (x - α) | i+1 i Note that ξ is dependent on each x.
Now we wish to determine the i constant λ and p independent of x such that i | x - α| ≤ c | (x - α) |P i+1 i Note that as the approximations x get closer to the root α, g’(ξ) i approaches a constant value g’(α).
Therefore, in the limiting case, as i → ∞,the approximation satisfy the relation | x - α| ≤g’(α) | (x - α) | i+1 i Therefore, we conclude that if g’(α)≠0, then the convergence of the method is linear.
If g’(α) = 0, then we have 410 MTH 213 MODULE 3 -α = g(x) -α i+1 i = g(x - α) + α - α i (x α)2 = g(α) + (x - α) g’(α) + i g”(ξ) - α i 2 (x α)2 = i g”(ξ) 2 since g(α) = α and g’(α) = 0 and ξ lies between x and α. i Therefore, in the limiting case we have 1 | x - α| ≤ | g”(α) | | (x - α) |2 i+1 i 2 Hence, if f’(α) = 0 and g’(α)≠0, then this iteration method is of order 2.
Example 7: Suppose α and β are the roots of the equation x2 + ax + b = 0.
Consider a rearrangement of this equation as (ax+b) x = - x (ax +b) Show that the iteration x = - i will converge near x = α when i+1 x i |α| > |β| Solution: The iteration are given by (ax +b) x = g(x) = - i , i = 0, 1, 2,... i+1 i x i By Theorem 1, these iterations converge to α if |g’(x) | < 1 near α i.e.
if b |g’(x) | = - < 1.
Note that g’(x) is continuous near α.
If the iterations x2 b converge to x = α, then we require |g’(x) | = - < 1. α2 Thus | b | < | α |2 i.e.
| α |2 > | b |.
(23) 411MTH 213 NUMERICAL ANALYSIS 1 Now you recall from your elementary algebra course that if α and β are the roots, then α + β = -a and α β = b Therefore | b | = |α| |β|.
Substituting in Eqn.
(23), we get |α|2 > | b | = |α| | β|.
Hence |α| > |β| Finally, we shall discuss the convergence of the Newton-Raphson method.
Convergence of Newton-Raphson Method Newton-Raphson iteration formula is given by f(x ) x = x - i (24) i+1 i f'(x ) i To obtain the order of the method we proceed as in the secant method.
We assume that α is a simple root of f(x) = 0.
Let x - α = ε , i = 0, 1, 2,... i i Then we have f(ε +α) ε + α = ε + α - i i+1 i f'(ε +α) i ε f'(ε +α)-f(ε +α) i.e.
ε = i i i i+1 f'(ε +α) i Now we expand f(ε + α) and f’(ε + α), using Taylor's theorem about i i the point α.
We have [ { } ε2 ε f'(α+ε f"(α)+ 1 f"(α)+... i i 2 { ε2 }] - f(α)ε f'(α)+ 1 f"(α)+... ε = i 2 i+1 f'(α)+ε f"(α)+ε2f"(α)+... i 1 But f(α) = 0 and f’(α)≠0.
Therefore [ε2 ] 1 [ εf"(α) ]-1 ε = 1 f"α+... 1+ i +... i+1 2 f"(α) f'(α) 412 MTH 213 MODULE 3 1 [ε2 ][ εf"(α) ] = 1 f"α+... 1- i +... f'(α) 2 f'(α) Hence, by neglecting higher powers of ε , we get i f"(α) ε ≈ ε2 i+1 2f'(α) i f"(α) This shows that the errors satisfy Eqn.
(6) with p = and λ = .
2f'(α) Hence, Newton-Raphson method is of order 2.
That is at each step, the error is proportional to the square of the previous error.
Now, we shall discuss an alternate method for showing that the order is 2.
Note that we can write (24) in the form x = g(x) where f(x) g(x) = x f'(x) [ ] f'(x) 2 -f(x)f"(x) d [ ] f(x) g’(x) = x- = 1 - dx f(x) [f'(x)]2 f(x)f"(x) = [f'(x)]2 f(α)f"(α) Now, g’(α) = = 0, since f(α) = 0 and f’(α)≠0.
[f'(α)]2 Hence by the conclusion drawn just above Example 7, the method is of order 2.
Note that this is true only if α is a simple root.
If α is a multiple root i.e.
if g’(α) = 0, then the convergence is not quadratic, but only linear.
We shall not prove this result, but we shall illustrate this with an example.
Let us consider an example.
Example 8: Let f(x) = (x – 2)4 = 0.
Starting with the initial approximation x = 2.1, 0 compute the iterations x , x , x and x using Newton-Raphson method.
1 2 3 4 Is the sequence conveying quadratically or linearly?
Solution: The given function has multiple roots at x = 2 and is of order 4.
413MTH 213 NUMERICAL ANALYSIS 1 Newton-Raphson iteration formula for the given equation is (x -2)4 1 x = x - i = x - (x – 2) i+1 i 4(x -2)3 i 4 i i 1 = (3x – 2) (25) 4 i Starting with x = 2.1, the iteration are given by 0 1 8.3 x = (6.3 + 2) = = 2.075 1 4 2 Similarly, x = 2.05625 2 x = 2.0421875 3 x = 2.031640625 4 Now ε = x – 2 = 0.1, ε = x -2 = 0.075, ε = 0.05625, ε = 0.0421875, 0 0 i 1 2 3 ε = 0.031640625.
4 Then 3 3 ε = .075 = × 0.1 = ε i 4 4 0 and 3 ε = ε 2 4 i 3 ε = ε 3 4 2 3 ε = ε 4 4 3 Thus the convergence is linear in this case.
The error is reduced by a 3 factor of with each iteration.
This result can also be obtained directly 4 from Eqn.
(25).
4.0 CONCLUSION Same as in Summary 414 MTH 213 MODULE 3 5.0 SUMMARY In this unit we have • described the following methods for finding a root of an equation f(x) = 0 i) Regula-Falsi method: The formula is a f(b)-b f(a) c = f(b)-f(a) where ]a, b[ is an interval such that f(a) f(b) < 0. ii) Secant method: The iteration formula is x f(x )-x f(x ) x = i-1 i i i-1 i = 0, 1, 2,.... i+1 f(x )-f(x ) i i-1 where x and x are any two given approximation of the 0 1 root.
iii) Newton-Raphson method: The iteration formula is f(x ) x = x - i , i = 0, 1, 2, ... i+1 i f'(x ) i where x is an initial approximation to the root.
0 • introduced the concept called convergence criterion of an iteration process.
• discussed the convergence of the following iterative methods i) Bisection method.
ii) Fixed point iteration method.
iii) Secant method.
iv) Newton-Raphson method.
6.0 TUTOR-MARKED ASSIGNMENT (TMA) 1.)
Obtain an approximate root for the following equations rounded off to three decimal places, using regula-falsi method a) x log x – 1.2 = 0 10 b) x sin x – 1 = 0 415MTH 213 NUMERICAL ANALYSIS 1 2.)
Use secant method to find an approximate root to the equation x2 – 2x + 1 = 0, rounded off to 5 decimal places, starting with x = 0 2.6 and x = 2.5.
Compare the result with the exact root 1 + 2 .
1 3.)
Find an approximate root of the cubic equation x3 + x2 + 3x – 3 = 0 using a) i) regula-falsi method, correct to three decimal places.
ii) secant method starting with a = 1, b = 2, rounded- off to three decimal places.
b) compare the results obtained by (i) and (ii) in part (a).
4.)
Starting with x = 0 find an approximate root of the equation x3 – 0 4x + 1 = 0, rounded off to five decimal places using Newton- Raphson method.
5.)
The motion of a planet in the orbit is governed by an equation of the form y = x – e sin x where e stands for the eccentricity.
Let y 1 = 1 and e = .
Then find a approximate root of 2x – 2 – sin x = 0 2 in the interval [0, π] with error less than 10-5.
Start with x = 1.5.
0 6.)
Using Newton-Raphson square root algorithm, find the following roots within an accuracy of 10-4. i) 81/2 starting with x = 3 0 ii) 911/2 starting with x = 10 0 7.)
Can Newton-Raphson iteration method be used to solve the equation x1/3 = 0?
Give reasons for your answer.
8.)
For the problem given in Example 5, Unit 2, find the number n of bisection required to have an approximate root with absolute error less than or equal to 10-7.
9.)
For the equation given in Example 7, show that the iteration x i+1 b = will converge to the root x = α, when |α| < |β|.
x +a i 7.0 REFERENCES/FURTHER READINGS Engineering Mathematics P.D.S.
Verma.
416 MTH 213 MODULE 3 Generalized Functions in Mathematical Physics by V.S.
Viadimirov.
Fundamentals of the Finite Element Method.
Hartley Grandin, Fr.
417MTH 213 NUMERICAL ANALYSIS 1 UNIT 4 APPROXIMATE ROOTS OF POLYNOMIAL EQUATION CONTENTS 1.0 Introduction 2.0 Objectives 3.0 Main Content 3.1 Some Results on Roots of Polynomial Equations.
3.2 Birge-Vieta Method.
3.3 Graeffe’s Root Squaring Method.
4.0 Conclusion 5.0 Summary 6.0 Tutor Marked Assignment 7.0 References/Further Readings 1.0 INTRODUCTION In the last two units we discussed methods for finding approximate roots of the equation f(x) = 0.
In this unit we restrict our attention to polynomial equations.
Recall that a polynomial equation is an equation of the form f(x) = 0 where f(x) is a polynomial in x. Polynomial equation arise very frequently in all branches of science especially in physical applications.
For example, the stability of electrical of mechanical systems is related to the real part of one of the complex roots of a certain polynomial equation.
Thus there is a need to find all roots, real and complex, of a polynomial equation.
The four iteration methods, we have discussed so far, applies to polynomial equations also.
But you have seen that all those methods are time consuming.
Thus it is necessary to find some efficient methods for obtaining roots of polynomial equations.
The sixteenth century French mathematician Francois Vieta was the pioneer to develop methods for finding approximate roots of polynomial equations.
Later, several other methods were developed for solving polynomial equations.
In this unit we shall discuss two simple methods: Birge-Vieta’s and Graeffe’s root squaring methods.
To apply these methods we should have some prior knowledge of location and nature of roots of a polynomial equation.
You are already familiar with some results regarding location and nature of roots from the elementary algebra course.
We shall begin this unit by listing some of the important result about the roots of polynomial equations.
418 MTH 213 MODULE 3 2.0 OBJECTIVES After reading this unit you should be able to: • apply the following methods for finding approximate roots of polynomial equations o Birge-Vieta method o Graeffe’s root squaring method • list the advantages of the above methods over the methods discussed in the earlier units.
3.0 MAIN BODY 3.1 Some Results on Roots of Polynomial Equations The main contribution in the study of polynomial equations due to the French mathematician Rene Descartes’ The results appeared in the third part of his famous paper ‘La geometric’ which means ‘The geometry’.
Consider a polynomial equation of degree n p(x) = a xn + a xn-1 + ... +a x + a (1) n n-1 1 0 where a , a , .... a are real numbers and a ≠ 0.
You know that the roots 0 1 n n of a polynomial equation need not be real numbers, it can be complex numbers, that is numbers of the form z = a + ib where a and b are real numbers.
The following results are basic to the study of roots of polynomial equations.
Theorem 1: (Fundamental Theorem of Algebra): Let p(x) be a polynomial of degree n ≥ 1 given by Eqn.
(1).
Then p(x) = 0 has at least one root: that is there exists a number α ∈ C such that p(α) = 0.
In fact p(x) has n complex roots which may not be distinct.
Theorem 2: Let p(x) be a polynomial of degree n and α is a real number.
Then p(x) = (x - α) q (x) + r (2) 0 0 for some polynomial q (x) of degree n – 1 and some constant number r .
0 0 q (x) and r are called the quotient polynomial and the remainder 0 0 respectively.
419MTH 213 NUMERICAL ANALYSIS 1 In particular, if α is a root of the equation p(x) = 0, then r = 0: that is (x 0 - α) divides p(x).
Then we get p(x) = (x - α) q (x) 0 How do we determine q (x) and r ?
We can find them by the method of 0 0 synthetic division of a polynomial p(x).
Let us now discuss the synthetic division procedure.
Consider the polynomial p(x) as given in Eqn.
(1) p(x) = a xn + a xn-1 + ... +a x + a n n-1 1 0 Dividing p(x) by x - α we get p(x) = q (x) (x - α) + r (3) 0 0 where q (x) is a polynomial of degree n – 1 and r is a constant.
0 0 Let q (x) be represented as 0 q (x) = b xn-1 + b xn-2 + ... + b x + b 0 n n-1 2 1 (Note that for convenience we are denoting the coefficient by b , ..., b 1 n instead of b , b , .... b ).
Set b = r .
Substituting the expressions for 0 1 n-1 0 0 q (x) and r in Eqn.
(3) we get 0 0 p(x) = (x - α) (b xn-1 + b xn-2 + ... + b x + b ) + b (4) n n-1 2 1 0 Now, to find b , b ..... b we simplify the right hand side of Eqn.
(4) and 0 1 n compare the coefficients of xi, i = 0, 1, .... n on both sides.
Note that p(α) = b .
Comparing the coefficient we get 0 Coefficient of xn : a = b b = a n n n n Coefficient of xn-1 : a = b - αb , b = a + αb n-1 n-1 n n-1 n-1 n .
.
.
Coefficient of xk : a – b - αb , b = a + αb k k k+1 k k k+1 .
.
.
Coefficient of x0 : a = b - α, b = a + αb 0 0 0 0 1 It is easy to perform the calculations if we write the coefficient of p(x) on a line and perform the calculation b = a + αb below a as given k k k+1 k in the table below.
420 MTH 213 MODULE 3 Table 1: Horner’s table for synthetic division procedure α a a a ... a ... a a a n n-1 n-2 k 2 1 0 αb αb ... αb ... αb αb αb n n-1 k+1 3 2 1 b b b b b b b =p (α) n n-1 n-2 k 2 1 0 0 We shall illustrate this procedure with an example.
Example 1: Divide the polynomial p(x) = x5 – 6x4 + 8x3 + 8x2 + 4x – 40 by x – 3 by the synthetic division method and find the remainder.
Solution: Here p(x) is a polynomial of degree 5.
If a , a , a , a , a , a are the 5 4 3 2 1 0 coefficients of p(x), then the Horner’s table in this case is Table 2 a a a a a a 5 4 3 2 1 0 1 -6 8 8 4 -40 3 -9 -3 15 57 1 -3 -1 5 19 17 b b b b b b 5 4 3 2 1 1 Hence the quotient polynomial q (x) is 0 q (x) = x4 – 3x3 – x2 + 5x + 19 0 and the remainder is r = b = 17. thus we have p(3) = b =17.
0 0 Theorem 3: Suppose that z = a + ib is a root of the polynomial equation p(x) = 0.
Then the conjugate of z, namely z, = a – ib is also a root of the equation p(x) = 0, i.e.
complex roots occur in pairs.
We denote by p(-x) the polynomial obtained by replacing x by –x in p(x).
We next give an important Theorem due to Rene Descartes.
Theorem 4: (Descartes’ Rule of signs): A polynomial equation p(x) = 0 cannot have more positive roots than the number of changes in sign of its 421MTH 213 NUMERICAL ANALYSIS 1 coefficients.
Similarly p(x) = 0 cannot have more negative roots than the number of changes in sign of the coefficients of p(-x).
For example, let us consider the polynomial equation p(x) = x4 – 15x2 + 7x – 11 = 0 = 1x4 – 15x2 + 7x – 11 = 0 We count the changes in the sign of the coefficients.
Going from left to right there are changes between 1 and -15, between -15 and 7 and between 7 and -11.
The total number of changes is 3 and hence it can have at most 3 positive roots.
Now we consider p(-x) = (-x)4 – 15(-x)2 + 7(-x) – 11 = 0 = x4 – 15x2 – 7x – 11 Here there is only one change between 1 and -15 and hence the equation cannot have more than one negative root.
We now give another theorem which helps us in locating the real roots.
Theorem 5: Let p(x) = 0 be a polynomial equation of degree n ≥ 1.
Let a and b be two real numbers with a < b.
Suppose further that p(a) ≠ 0 and p(b) ≠ 0.
Then, i) if p(a) and p(b) have opposite signs, the equation p(x) = 0 has an odd number of roots between a and b. ii) if p(a) and p(b) have like signs, then p(x) = 0 either has no root or an even number of roots between a and b.
Note: In this theorem multiplicity of the root is taken into consideration i.e.
if a is a root of multiplicity k it has to be counted k times.
As a corollary of Theorem 5, we have the following results.
Corollary 1: An equation of odd degree with real coefficients has at least one real root whose sign is opposite to that of the last term.
Corollary 2: An equation of even degree whose constant term has the sign opposite to that of the leading coefficient, has at least two real roots one positive and the other negative.
Corollary 3: the result given in Theorem 5(i) is the generalization of the Intermediate value theorem.
422 MTH 213 MODULE 3 The relationship between roots and coefficients of a polynomial equation is given below.
Theorem 6: Let α , α , ....., α be a roots (n ≥ 1) of the polynomial 1 2 n equation p(x) = a xn + a xn-1 + ... + a x + a = 0 n n-1 1 0 -a Then α + α + ... + α = n-1 1 2 n a n a α α + α α + ... + α α = n-2 1 2 2 3 n-1 n a n ............................................ ............................................ a α α ...α = (-1)n 0 1 2 n a n In the next section we shall discuss one of the simple methods for solving polynomial equations.
3.2 Birge-Vieta Method We shall now discuss the Birge-Vieta method for finding the real roots of a polynomial equation.
This method is based on an original method due to two English mathematicians Birge-Vieta.
This method is a modified form of Newton-Raphson method.
Consider now, a polynomial equation of degree n, say p (x) = a xn + ... + a x + a = 0.
(5) n n 1 0 Let x be an initial approximation to the root α.
The Newton-Raphson 0 iterated formula for improving this approximation is p (x ) x = x - n i-1 , i = 1, 2, ... (6) i i-1 p' (x ) n i-1 To apply this formula we should be able to evaluate both p (x) and n p’ (x) at any x.
The most natural way is to evaluate n i i p (x) = a xn + a xn-1 + ... + a x2 + a x + a n i n i n-1 2 i 1 i 0 p’ (x) = n a xn-1 + (n - 1)a xn-2 + ... + 2a x + a n i n i n-1 i 2 i 1 However, this is the most inefficient way of polynomial because of the amount of computations involved and also due to the possible growth of 423MTH 213 NUMERICAL ANALYSIS 1 round off errors.
Thus there is a need to look for some efficient method for evaluating p (x) and p’ (x).
n i n i Let us consider the evaluation of p (x) and p’ (x) at x using Horner’s n i n i 0 method as discussed in the previous section.
We have p (x) = (x – x ) q (x) + r (7) n i 0 n-1 0 where q (x) = b xn-1 + b xn-2 + … + b x + b n-1 n n-2 2 1 and b = p (x ) = r (8) 0 n 0 0 We have already discussed in the previous section how to find b , I = 1, 1 2, …, n. Next we shall find the derivative p’ (x ) using Horner’s method.
We n 0 divide q (x) by (x – x ) using Horner’s method.
That is, we write n-1 0 q (x) = (x – x ) q (x) + r n-1 0 n-2 1 q (x) = c xn-2 + c xn-3 + … + c x + c .
n-1 n n-1 3 2 Comparing the coefficients, we get c as given in the following table i Table 3 b b ... b ... b b n n-1 k 2 1 x x c ... x c ... x c x c 0 0 n 0 k+1 0 3 0 2 cn=bn cn-1 ck c2 c1 As observed in Sec.
1, we have c = q (x ) (9) 1 n-1 0 Now, from Eqn.
(7) and (8), we have p (x) = (x – x ) q (x) + p (x ) (10) n 0 n-1 n 0 Differentiating both sides of Eqn.
(10) w.r.t.x, we get p’ (x) = q (x) + (x – x ) q’ (x) (11) n n-1 0 n-1 Putting x = x in Eqn.
(11), we get 0 p’ (x ) = q (x ) (12) n 0 n-1 0 Comparing (9) and (12), we get p’ (x ) = q (x ) = c n 0 n-1 0 1 Hence the Newton-Raphson method (Eqn.
(6)) simplies to b 0 x = x - (13) i i-1 c 1 424 MTH 213 MODULE 3 We summarise the evaluation of b and c in the following table.
i i Table 4 a a ... a ... a a a n n-1 k 2 1 0 x x b ... x b ... x b x b x b 0 0 n 0 k+1 0 3 0 2 0 1 a =b b b b b b =p (x ) n n n-1 k 2 1 0 n 0 x0 x0cn ... x0ck+1 ... x0c3 x0c2 cn=bn cn-1 ck c2 c1=p’n(x0) Let us consider an example.
Example 2: Evaluate p’(3) for the polynomial p(x) = x5 – 6x4 + 8x3 + 8x2 + 4x – 40.
Solution: Here the coefficients are a = -40, a = 4, a = 8, a = 8, a = -6 and a = 0 1 2 3 4 5 1.
To compute b , we form the following table.
0 Table 5 3 1 -6 8 8 4 -40 3 -9 -3 15 57 3 1 -3 -1 5 19 1 7=p(3)=b0 3 0 -3 6 1 0 -1 2 25 = p’(3)=c 1 Therefore p’(3) = 25 Now we shall illustrate why this method is more efficient than the direct method.
Let us consider an example.
Suppose we want to evaluate the polynomial p(x) = -8x5 + 7x4 – 6x3 + 5x2 – 4x + 3 for any given x.
When we evaluate by direct method, we compute each power of x by multiplying with x the preceding power of x as x3 = x(x2), x4 = x(x3) etc.
425MTH 213 NUMERICAL ANALYSIS 1 Thus each term ck takes two multiplications for k > 1.
Then the total number of multiplications involved in the evaluation pf p(x) is 1 + 2 + 2 + 2 + 2 = 9.
When we use Horner’s method the total number of multiplications in 5.
The number of additions in both cases are the same.
This shows that less computation is involved while using Horner’s method and therapy reduces the error in computation.
Let us now solve some problems using Birge-Vieta method.
Example 3: Use Birge-Vieta method to find all the positive real roots, rounded off to three decimal places of the equation x4 + 7x3 + 24x2 + x – 15 = 0 Stop the iteration whenever | x – x | < 0.0001 i+1 i Solution: We first note that the given equation p4(x) = x4 + 7x3 + 24x2 + x – 15 = 0 is of degree 4.
Therefore, by Theorem 1, this equation has 4 roots.
Since there is only one change of sign in the coefficients of this equation, Descartes’ rule of signs (see Theorem 4), states that the equation can have at most one positive real root.
Now let us examine whether the equation has a positive real root.
Since p4(0) = -15 and p4(1) = 19, by Intermediate value theorem, the equation has a root lying in ]0, 1[.
We take x = 0.5 as the initial approximation to the root.
The first 0 iteration is given by p (x ) x = x - 4 0 1 0 p' (x ) 4 0 p (0.5) = 0.5 - 4 p' (0.5) 4 Now we evaluate p (0.5) and p’ (0.5) using Horner’s method.
The 4 4 results are given in the following table.
426 MTH 213 MODULE 3 Table 6 1 7 24 1 -15 0.5 0.5 3.75 13.875 7.4375 1 7.5 27.75 14.875 -75625=p (0.5) 4 0.5 0.5 4.00 15.875 1 8.0 31.75 30.750 = p’ (0.5) 4 -7.5625 Therefore x = 0.5 - = 0.7459 1 30.75 The second iteration is given by p (x ) p (0.7459) x = x - 4 1 = 0.7459 - 4 2 1 p' (x ) p' (0.7459) 4 1 4 Uisng synthetic division, we form the following table of values Table 7 1 7 24 1 -15 0.7459 0.7459 5.7777 22.2119 17.3138 1 7.7459 29.7777 23.2119 2.3138 0.7459 0.7459 6.3340336 26.935717 1 8.4918 36.111701 50.146879 2.3132 Therefore x = 0.7459 - = 0.6998 2 50.1469 Third iteration is given by p (0.6998) x = x - 4 3 2 p' (0.6998) 4 Table 8 1 7 24 1 -15 0.6998 0.6998 5.3881 20.5649 15.0905 1 7.6998 29.3881 21.5649 0.0905 0.6998 .6998 5.8778 24.6780 1 8.3996 35.2659 46.2429 0.0905 x = 0.6998 - = 0.6978 3 46.2429 For the fourth iteration we have p (0.6978) x = x - 4 4 3 p' (0.6978) 4 427MTH 213 NUMERICAL ANALYSIS 1 Table 9 1 7 24 1 -15 0.6978 0.6978 5.3715248 20.495459 14.999525 1 7.6978 29.3715248 21.495459 0.0905 0.6978 .6978 5.8584497 24.583476 1 8.3956 35.229975 46.078926 0.0005 x = 0.6978 - = 0.6978 4 46.0789 Since x and x are the same, we get | x – x | < 0.0001 and therefore we 3 4 4 3 stop the iteration here.
Hence the approximate value of the root rounded off to three decimal places is 0.698.
Next we shall illustrate how Birge-Vieta’s method helps us to find all real roots of a polynomial equation.
Consider Eqn.
(4) p(x) = (x - α) (b xn-1 + b xn-2 + ... + b x + b ) + b n n-1 2 1 0 If α is a root of the equation p(x) = 0, then p(x) is exactly divisible by x - α, that is, b = 0.
In finding the approximations to the root by the 0 Birge-Vieta method, we find that b approaches zero (b →0) as x 0 0 i approaches α (x → α).
Hence, if x is taken as the final approximation, i n to the root satisfying the criterion | x – x | < ε, then to this n n-1 approximation, the required quotient is q (x) = b xn-1 + b xn-2 + ... + b n-1 n n-1 1 where b’ are obtained by using x and the Horner’s method.
This 1 n polynomial is called the deflated polynomial or reduced polynomial.
The next root is now obtained using q (x) and not p (x).
Continuing n-1 n this process, we can successively reduce the degree of the polynomial and find one real root at a time.
Let us consider an example.
Example 4: Find all the roots of the polynomial equation p (x) = x3 + x – 3 = 0 3 rounded off to three decimal places.
Stop the iteration whenever |x – i+1 x| < 0.0001. i 428 MTH 213 MODULE 3 Solution: The equation p (x) = 0 has three root.
Since there is only one change in 3 the sign of the coefficients, by Descartes’ rule of signs the equation can have at most one positive real root.
The equation has no negative real root since p (-x) = 0 has no change of sign of coefficients.
Since p (x) = 3 3 0 is of odd degree it has at least one real root.
Hence the given equation x3 + x – 3 = 0 has one positive real root and a complex pair.
Since p(1) = -1 and p(2) = 7, by intermediate value theorem the equation has a real root lying in the interval ]1, 2[.
Let us find the real root using Birge- Vieta Method.
Let the initial approximation be 1.1.
First iteration Table 10 1 0 14 -3 1.1 1.1 1.21 2.431 1 1.1 2.21 0.0905 1.1 1.1 2.42 1 2.2 4.63 -0.569 Therefore x = 1.1 - = 1.22289 1 4.63 Similarly, we obtain x = 1.21347 2 x = 1.21341 3 Since | x – x | < 0.0001, we stop the iteration here.
Hence the required 2 3 value of the root is 1.213, rounded off to three decimal places.
Next let us obtain the deflated polynomial of p (x).
To get the deflated 3 polynomial of, we have to find the polynomial q (x) by using the final 2 approximation x = 1.213 (see Table 11).
3 Table 11 1 0 1 -3 1.213 1.213 1.4714 2.9978 1 1.213 2.4714 -0.0022 Note that p (1.213) = -0.0022.
That is, the magnitude of the error in 3 satisfying p (x ) = 0 is 0.0022.
3 3 We find q (x) = x2 + 1.213x + 2.4714 = 0 2 This is a quadratic equation and its roots are given by -1.213± (1.213)2 -4×2.4714 x = 2 429MTH 213 NUMERICAL ANALYSIS 1 -1.213±2.9009i = 2 = 0.
6065±1.4505 i Hence the three roots of the equation rounded off to three decimal places are 1.213, 0.6065 + 1.4505 i and -0.6065 – 1.4505 i.
Remark: We now know that we can determine all the real roots of a polynomial equation using deflated polynomials.
This procedure reduces the amount of computations also.
But this method has certain limitations.
The computations using deflated polynomial can cause unexpected errors.
If the roots are determined only approximately, the coefficients of the deflated polynomials will contain some errors due to rounding off.
Therefore we can expect loss of accuracy in the remaining roots.
There are some ways of minimizing this error.
We shall not be going into the details of these refinements.
3.3 Graeffe’s Root Squaring Method In the last section we have discussed a method for finding real roots of polynomial equations.
Here we shall discuss a direct method for solving polynomial equations.
This method was developed independently by three mathematicians Dandelin, Lobachesky and Graeffe.
But Graeffe’s name is usually associated with this method.
The advantage of this method is that it finds all roots of a polynomial equation simultaneously: the roots may be real and distinct, real and equal (multiple) or complex roots.
The underlying idea of the method is based on the following fact: Suppose β , β , ...., β are the n real and distinct roots of a polynomial 1 2 n equation of degree n such that they are widely separated, that is, |β | >> |β | >> |β | >> ... >> |β | 1 2 3 n where >> stands for ‘much greater than’.
Then we can obtain the roots approximately from the coefficients of the polynomial equation as follows: Let the polynomial equation whose roots are β , β , ...., β be 1 2 n a + a x + a x2 + ... + a xn = 0, a ≠ 0.
0 1 2 n n Using the relations between the roots and the coefficients of the polynomial as given in Sec.
4.2, we get 430 MTH 213 MODULE 3 a β +β +...+β = - n-1 1 2 n a n a β ,β +β β +...+β β = n-2 1 2 1 3 n-1 n a n a β β β +...+β β β = - n-3 (14) 1 2 3 n-2 n-1 n a n ........................................ a β β ...β = (-1)n 0 1 2 n a n Since |β | >> |β | >> |β | >> ... >> |β |, we have from (14) the 1 2 3 n approximations a β ≈- n-1 1 a n a β β ≈ n-2 1 2 a n a β β β ≈- n-3 (15) 1 2 3 a n ... ... a β β ...β ≈(-1)n 0 1 2 n a n These approximations can be simplified as a |β |≈- n-1 1 a n a a a |β |≈ n-2 n ≈ n-2 2 a a a n n-1 n-1 a a a a |β |≈- n-3 n-1 n = n-3 3 a a a a n n-2 n-1 n-2 .
(16) .
.
a |β |≈ 0 n a 1 431MTH 213 NUMERICAL ANALYSIS 1 So the problem now is to find from the given polynomial equation, a polynomial equation whose roots are widely separated.
This can be done by the method which we shall describe now.
In the present course we shall discuss the application of the method to a polynomial equation whose roots are real and distinct.
Let α , α , ...., α be the n real and distinct roots of the polynomial 1 2 n equation of degree n given by a + a x + a x2 + ... + a xn = 0.
(17) 0 1 2 n where a , a , a , ..., a , a are real numbers and a ≠ 0.
We rewrite Eqn.
0 1 2 n-1 n n (17) by collecting all even terms on one side and all odd terms on the other side, i.e.
a + a x2 + a x4 + ... = -( a x + a x3 + a x5 + ...) (18) 0 2 4 1 3 5 Squaring both sides of Eqn.
(18), we get (a + a x2 + a x4 + ...)2 = (a x + a x3 + a x5 + ...)2 0 2 4 1 3 5 Now we expand both the right and left sides and simplify by collecting the coefficients.
We get a2 - (a2 - 2a a )x2 + (a2 - 2a a + 2a a )x4 – 0 1 0 2 2 1 3 0 4 (a2 - 2a a + 2a a - 2a a )x6 + ... + (-1)n a2x2n = 0 (19) 3 2 4 1 5 0 6 n Putting x2 = -y in Eqn.
(19), we obtain a new equation given by b + b y + b y2 + ... + b = 0 (20) 0 1 2 n where b = a2 0 0 b = a2 - 2a a 1 1 0 2 b = a2 - 2a a + 2a a 2 2 1 3 0 4 b = a2 n n The following table helps us to compute the coefficients b , b , ..., b of 0 1 n Eqn.
(20) directly from Eqn.
(17).
432 MTH 213 MODULE 3 Table 12 a a a a a 0 1 2 3... n 2 2 2 2 2 a a a a a 0 1 2 3 n 0 -2a a -2a a -2a a 0 0 2 1 3 2 4 0 0 -2a a -2a a 0 0 4 1 5 0 0 0 -2a a 0 0 6 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
b b b b ... b 0 1 2 3 n To form Table 12 we first write the coefficients a , a , a , ...., a as the 0 1 2 n first row.
Then we form (n + 1) columns as follows.
The terms in each column alternate in sign starting with a positive sign.
The first term in each column is the square of the coefficients a , k = 0, k 1, 2, ..., n. The second term in each column is twice the product of the nearest neighbouring coefficients, if there are nay with negative sign: otherwise put it as zero.
For example, the second term in the first column is zero and second term in the second column is -2a a .
0 2 Likewise the second term of the (k + 1)th column is 2a a .
The third k-1 k+1 term in the (k + 1)th column is twice the product of the next neighbouring coefficients a and a , if there are nay, otherwise put it k-2 k+2 as zero.
This procedure is continued until there are no coefficients available to form the cross products.
Then we add all the term in each column.
The sum gives the coefficients b for k = 0, 1, 2, ..., n which are k listed as the last term in each column.
Since the substitution x2 = -y is used, it is easy to see that if α , α , ..., α are the n roots of Eqn.
(17), 1 2 n then -α2, α2, ..., α2 are the roots of Eqn.
(20).
1 2 n Thus, starting with a given polynomial equation, we obtained another polynomial equation whose roots are the squares of the roots of the original equation with negative sign.
We repeat the procedure for Eqn.
(20) and obtain another equation c + c x + ... + c xn = 0.
0 1 n Whose roots are the squares of the roots of Eqn.
(20) with a negative sign i.e.
they are fourth powers of the roots of the original equation with a negative sign.
Let this procedure be repeated n times.
Then, we obtain an equation q + q x + ... + q xn = 0 (21) 0 1 n whose roots γ , γ , ...., γ are given by 1 2 n 433MTH 213 NUMERICAL ANALYSIS 1 γ =, i = 0, 1, 2, ..., n. (22) i Now, since all the roots of Eqn.
(17) are real and distinct, we have |α | > |α | > ..........> |α | 1 2 n q Hence |γ | = |α2m | = n-1 1 1 q n q |γ | = |α2m | = n-2 2 2 q n-1 .
.
.
.
.
.
.
.
.
q |γ |= |α2m | = 0 n n q 1 The magnitude of the roots of the original equations are therefore given by q |α | = 2m n-1 1 q n q |α | = 2m n-2 2 q n-1 .
.
.
q |α | = 2m 0 n q 1 This gives the magnitude of the roots.
To determine the sign of the roots, we substitute these approximations in the original equation and verify whether positive or negative value satisfies it.
We shall now illustrate this method with an example.
Example 5: Find the roots of the cubic equation x3 – 15x2 + 62x – 72 = 0 by Graeffe’s method using three squaring.
434 MTH 213 MODULE 3 Solution: Let P (x) = x3 – 15x2 + 62x – 72 = 0.
3 The equation has no negative real roots.
Let us now apply the root squaring method successively.
The get the following results: First Squaring Table 13 a a a a 0 1 2 3 -72 62 -15 1 2 2 2 2 a =5184 a =3844 a =225 a =1 0 1 2 3 0 -2a a =-2160 -2a a =-124 0 0 2 1 3 5184 1684 101 1 b b b b 0 1 2 3 Therefore the new equation is x3 + 101x2 + 168x + 5184 = 0.
Applying the squaring method to the new equation we get the following results.
Second Squaring Table 14 5184 1684 101 1 26873856 2835856 10201 1 0 -1047168 -3368 0 26873856 1788688 6833 1 Thus the new equation is x3 + 6833x2 + 1788688x + 26873856 = 0.
For the third squaring, we have the following results.
Third Squaring Table 15 26873856 1788688 6833 1 7.2220414 ×1014 3.1994048×1012 46689889 1 0 -3672581×1012 -3577376 0 7.2220414 ×1014 2.83214×1012 43112513 1 q q q q 0 1 2 3 435MTH 213 NUMERICAL ANALYSIS 1 Hence the new equation is x3 + 43112513x2 + (2.83214 × 1012)x + (7.2220414 ×1014) = 0 After three squaring, the roots γ , γ , and γ of this equation are given 1 2 3 by q 2 |γ | = = 43112513 1 q 3 q 2.83214×1012 1 |γ | = = 2 q 43112513 2 q 7.22204×1014 0 |γ | = = 3 q 2.83214×1012 1 Hence, the roots |α | =8 443112513 = 9.0017 1 2.83214×1012 |α | = 8 = 4.0011 2 43112513 7.22204×1014 |α | = 8 = 1.9990 3 2.83214×1012 Since the equation has no negative real roots, all the roots are positive.
Hence the roots can be taken as 9.0017, 4.0011 and 1.9990.
If the approximations are rounded to 2 decimal places, we have the roots as 9, 4 and 2.
Alternately, we can substitute the approximate roots in the given equation and find their sign.
4.0 CONCLUSION We have seen that Graeffe’s root squaring method obtain all real roots simultaneously.
There is considerable saving in time also.
The method can be extended to find multiple and complex roots also.
However the method is not efficient to find these roots.
We shall not discuss these extensions.
We shall end this block by summarizing what we have covered in this unit.
436 MTH 213 MODULE 3 5.0 SUMMARY In this unit we have • discussed the following methods for finding approximate roots of polynomial equations.
i) Birge-Vieta method.
ii) Graeffe’s root squaring method.
• Mentioned the advantage and disadvantages of the above methods.
6.0 TUTOR-MARKED ASSIGMENT (TMA) 1) Find the quotient and the remainder when 2x3 – 5x2 + 3x – 1 is divided by x – 2.
2) Using synthetic division check whether α = 3 is a root of the 0 polynomial equation x4 + x3 – 13x2 – x + 12 = 0 and find the quotient polynomial.
3) How many negative roots does the equation 3x7 + 5x5 + 4x3 + 10x – 6 = 0 have?
Also determine the number of positive roots, if any.
4) Show that the biquadratic equation p(x) = x4 + x3 – 2x2 + 4x – 24 = 0 has at least two real roots one positive and the other negative.
5) Using synthetic division, show that 2 is a simple root of the equation p(x) = x4 – 2x3 – 7x2 + 8x + 12 = 0.
6) Evaluate p(0.5) and p’(0.5) for p(x) = -8x5 + 7x4 – 6x3 + 5x2 – 4x + 3 7) Find an approximation to one of the roots of the equation p(x) = 2x4 – 3x2 + 3x – 4 = 0 using Birge-Vieta method starting with the initial approximation x = -2.
Stop the iteration whenever | x – x | < 0.4 × 10-2.
0 i+1 i 8) Find all the roots of the equation x3 – 2x – 5 = 0 using Birge- Vieta method.
437MTH 213 NUMERICAL ANALYSIS 1 9) Find the real root rounded off to two decimal places of the equation x4 – 4x3 – 3x + 23 = 0 lying in the interval ]2, 3[ by Birge-Vieta method.
10) Determine all roots of the following equations by Graeffe’s root squaring method using three squaring.
i) x3 + 6x2 – 36x + 40 = 0 ii) x3 – 2x2 – 5x + 6 = 0 iii) x3 – 5x2 – 17x + 20 = 0 7.0 REFERENCES/FURTHER READINGS Engineering Mathematics P.D.S.
Verma.
Generalized Functions in Mathematical Physics by V.S.
Viadimirov.
Fundamentals of the Finite Element Method.
Hartley Grandin, Fr.
438
